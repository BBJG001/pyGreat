{"paging": {"is_end": true, "totals": 137, "previous": "http://zhuanlan.zhihu.com/api/columns/reinforcementlearning/articles?include=data&limit=100&offset=0", "is_start": false, "next": "http://zhuanlan.zhihu.com/api/columns/reinforcementlearning/articles?include=data&limit=100&offset=200"}, "data": [{"updated": 1543801304, "is_labeled": false, "excerpt": "CER\u662fCompetitive Experience Replay\u7684\u7b80\u79f0\uff0c\u662f\u4e00\u79cd\u589e\u5927\u63a2\u7d22\u7684\u65b9\u6cd5\u3002<b>\u539f\u6587\u4f20\u9001\u95e8<\\/b><a href="https://link.zhihu.com/?target=https%3A//openreview.net/forum%3Fid%3DSklsm20ctX" class=" wrap external" target="_blank" rel="nofollow noreferrer">Anonymous, Competitive experience replay, Submitted to International Conference on Learning Representations, 2019 (under review)<\\/a><b>\u7279\u8272<\\/b>\u4f7f\u7528\u4e86\u4e24\u4e2a\u667a\u80fd\u4f53\u7684\u76f8\u4e92\u7ade\u4e89\u5173\u7cfb\u53bb\u2026", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-3b0ee84d6976df00b513a1c128168a24_b.jpg", "id": 51391002, "voteup_count": 3, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 35\u3011CER", "url": "https://zhuanlan.zhihu.com/p/51391002", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1543801304, "comment_count": 0, "image_url": "https://pic2.zhimg.com/v2-3b0ee84d6976df00b513a1c128168a24_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1543741749, "is_labeled": false, "excerpt": "HER\u662fHindsight Experience Replay\u7684\u7b80\u79f0\uff0chindsight\u5927\u6982\u5c31\u662f\u201c\u4e8b\u540e\u8bf8\u845b\u4eae\u201d\u7684\u610f\u601d\u3002<b>\u539f\u6587\u4f20\u9001\u95e8<\\/b><a href="https://link.zhihu.com/?target=https%3A//papers.nips.cc/paper/7090-hindsight-experience-replay.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Andrychowicz, Marcin, et al. &#34;Hindsight experience replay.&#34; Advances in Neural Information Processing Systems. 2017.<\\/a><b>\u7279\u8272<\\/b>\u5956\u52b1\u7a00\u758f\u662f\u5bfc\u81f4\u5f3a\u5316\u5b66\u4e60\u56f0\u96be\u7684\u2026", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-20ff679dfabcf3190ef1ca4d179b79d2_b.jpg", "id": 51357496, "voteup_count": 17, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 34\u3011HER", "url": "https://zhuanlan.zhihu.com/p/51357496", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1543741749, "comment_count": 1, "image_url": "https://pic3.zhimg.com/v2-20ff679dfabcf3190ef1ca4d179b79d2_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1543500969, "is_labeled": false, "excerpt": "RDRL\u4e0d\u662f\u5b98\u65b9\u7684\u540d\u5b57\uff0c\u4ee3\u8868\u7684\u662fRelational Deep Reinforcement Learning\u3002<b>\u539f\u6587\u4f20\u9001\u95e8<\\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1806.01830" class=" wrap external" target="_blank" rel="nofollow noreferrer">Zambaldi, Vinicius, et al. &#34;Relational Deep Reinforcement Learning.&#34; arXiv preprint arXiv:1806.01830 (2018).<\\/a><b>\u7279\u8272<\\/b>\u8003\u8651\u72b6\u6001\u7a7a\u95f4\u4e3a\u56fe\u50cf\u7684\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff08\u6bd4\u5982\u89c6\u9891\u6e38\u620f\uff09\u2026", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-04d9316b41aacefcf2ade50d6c187709_b.jpg", "id": 51186558, "voteup_count": 19, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 33\u3011RDRL", "url": "https://zhuanlan.zhihu.com/p/51186558", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1543500969, "comment_count": 0, "image_url": "https://pic1.zhimg.com/v2-04d9316b41aacefcf2ade50d6c187709_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1543412645, "is_labeled": false, "excerpt": "\u4e2dDistral\u662f<b>Dis<\\/b>till &amp; <b>tra<\\/b>nsfer <b>l<\\/b>earning\u7684\u7f29\u5199\u3002<b>\u539f\u6587\u4f20\u9001\u95e8<\\/b><a href="https://link.zhihu.com/?target=https%3A//papers.nips.cc/paper/7036-distral-robust-multitask-reinforcement-learning.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Teh, Yee, et al. &#34;Distral: Robust multitask reinforcement learning.&#34; Advances in Neural Information Processing Systems. 2017.<\\/a><b>\u7279\u8272<\\/b>\u63d0\u51fa\u4e86\u4e00\u79cd\u540c\u65f6\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u8bad\u7ec3\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u4e3b\u8981\u7684\u2026", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-242c029a7845b51f998c9cc3f21865b7_b.jpg", "id": 51091244, "voteup_count": 13, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 32\u3011Distral", "url": "https://zhuanlan.zhihu.com/p/51091244", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1543412645, "comment_count": 3, "image_url": "https://pic3.zhimg.com/v2-242c029a7845b51f998c9cc3f21865b7_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1543322986, "is_labeled": false, "excerpt": "HRA\u5168\u79f0\u662fHybrid Reward Architecture<b>\u539f\u6587\u4f20\u9001\u95e8<\\/b><a href="https://link.zhihu.com/?target=https%3A//papers.nips.cc/paper/7123-hybrid-reward-architecture-for-reinforcement-learning.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Van Seijen, Harm, et al. &#34;Hybrid reward architecture for reinforcement learning.&#34; Advances in Neural Information Processing Systems. 2017.<\\/a><b>\u7279\u8272<\\/b>\u63d0\u51fa\u4e86\u628a\u771f\u5b9e\u7684reward\u8fdb\u884c\u5206\u89e3\uff0c\u4f7f\u7528\u4e0d\u540c\u7684action valu\u2026", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-8c9284e36e5454d554beb5cc0a4c8f44_b.jpg", "id": 50986023, "voteup_count": 9, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 31\u3011HRA", "url": "https://zhuanlan.zhihu.com/p/50986023", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1543322315, "comment_count": 0, "image_url": "https://pic1.zhimg.com/v2-8c9284e36e5454d554beb5cc0a4c8f44_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1544235615, "is_labeled": false, "excerpt": "<b>\u5e8f\u8a00<\\/b>\u8bb2\u4e86\u597d\u591a\u5f3a\u5316\u5b66\u4e60\u7684paper\u4e86\uff0c\u4e0b\u9762\u662f\u65f6\u5019\u4ed4\u7ec6\u8003\u8651\u4e00\u4e0bImplementation matters\u8fd9\u53e5\u8bdd\u4e86\u3002\u8fd9\u4e9b\u5e38\u89c1\u7684\u7b97\u6cd5\u90fd\u6709\u5df2\u7ecf\u8c03\u597d\u53c2\u6570\u7684\u7a0b\u5e8f\uff0c\u5927\u5bb6\u53ef\u4ee5\u76f4\u63a5\u8dd1\uff0c\u5c31\u5728<a href="https://link.zhihu.com/?target=https%3A//github.com/openai/baselines" class=" wrap external" target="_blank" rel="nofollow noreferrer">[github]openai.baselines<\\/a>\u3002\u5982\u679c\u53ea\u662f\u4e3a\u4e86\u8dd1\u4e00\u4e2a\u5bf9\u7167\u8bd5\u9a8c\u7684\u8bdd\uff0c\u76f4\u63a5\u4f7f\u7528\u522b\u4eba\u5b9e\u73b0\u7684\u4ee3\u7801\u5c31\u53ef\u4ee5\u4e86\u3002\u4f46\u662f\u2026", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-9a8b3231d89fc41c9fdbdb28590dba32_b.jpg", "id": 50322028, "voteup_count": 44, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u5b9e\u8df5 30\u3011\u590d\u73b0PPO", "url": "https://zhuanlan.zhihu.com/p/50322028", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1542888692, "comment_count": 30, "image_url": "https://pic1.zhimg.com/v2-9a8b3231d89fc41c9fdbdb28590dba32_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1542887988, "is_labeled": false, "excerpt": "\u8fc7\u53bb\u6574\u4e00\u5e74\u4e86\uff0c\u6765\u8bb2\u8bb2AlphaGo Zero\u7684\u5177\u4f53\u7b97\u6cd5\u7ec6\u8282\u5427\u3002<b>\u539f\u6587\u4f20\u9001\u95e8<\\/b><a href="https://link.zhihu.com/?target=https%3A//www.nature.com/articles/nature24270.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Silver, David, et al. &#34;Mastering the game of Go without human knowledge.&#34;Nature550.7676 (2017): 354.<\\/a><b>\u7279\u8272<\\/b>AlphaGo Zero\u4e0d\u5229\u7528\u4efb\u4f55\u7684\u4eba\u7c7b\u7ecf\u9a8c\uff0c\u5b8c\u5168\u9760\u7b97\u6cd5\u81ea\u5df1\u63a2\u7d22\uff0c\u5e76\u4e14\u4f7f\u7528\u4e86\u66f4\u4e3a\u4f18\u96c5\u800c\u2026", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-df2d9c393a065e60e4d5645617192150_b.jpg", "id": 50568278, "voteup_count": 11, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 29\u3011AlphaGo Zero", "url": "https://zhuanlan.zhihu.com/p/50568278", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1542887988, "comment_count": 0, "image_url": "https://pic4.zhimg.com/v2-df2d9c393a065e60e4d5645617192150_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1552549633, "is_labeled": false, "excerpt": "\u5168\u79f0\u662fgeneralized advantage estimator\uff0c\u51e0\u4e4e\u6240\u6709\u6700\u5148\u8fdb\u7684policy gradient\u7b97\u6cd5\u5b9e\u73b0\u91cc\u9762\u90fd\u4f7f\u7528\u4e86\u8be5\u6280\u672f\u3002<b>\u539f\u6587\u4f20\u9001\u95e8<\\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1506.02438" class=" wrap external" target="_blank" rel="nofollow noreferrer">Schulman, John, et al. &#34;High-dimensional continuous control using generalized advantage estimation.&#34; arXiv preprint arXiv:1506.024\u2026<\\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-48c6c72ecdb19ca60ea38d8159112474_b.jpg", "id": 45107835, "voteup_count": 26, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u6280\u672f 28\u3011GAE", "url": "https://zhuanlan.zhihu.com/p/45107835", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1542540011, "comment_count": 6, "image_url": "https://pic2.zhimg.com/v2-48c6c72ecdb19ca60ea38d8159112474_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1542286148, "is_labeled": false, "excerpt": "RethinkPolicyGradient\u662f\u6211\u778e\u7f16\u7684\uff0c\u76ee\u7684\u5c31\u662f\u7ed9\u4e2a\u4ee3\u53f7\u4fbf\u4e8e\u533a\u5206\uff0c\u8fd9\u7bc7\u6587\u7ae0\u4e0d\u662f\u8bb2\u7684\u4e00\u4e2a\u7b97\u6cd5\uff0c\u800c\u662f\u5bf9\u4e8e\u73b0\u5728\u6700\u5148\u8fdb\u7684Policy Gradient\u65b9\u6cd5\u63d0\u51fa\u4e86\u4e00\u4e9b\u8d28\u7591\u3002<b>\u539f\u6587\u4f20\u9001\u95e8<\\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1811.02553" class=" wrap external" target="_blank" rel="nofollow noreferrer">Ilyas, Andrew, et al. &#34;Are Deep Policy Gradient Algorithms Truly Policy Gradient Algorit\u2026<\\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-7ea5acdf0e3772bf98944e44b8ec96c8_b.jpg", "id": 49976384, "voteup_count": 25, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60 27\u3011RethinkPolicyGradient", "url": "https://zhuanlan.zhihu.com/p/49976384", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1542285799, "comment_count": 1, "image_url": "https://pic2.zhimg.com/v2-7ea5acdf0e3772bf98944e44b8ec96c8_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1541417842, "is_labeled": false, "excerpt": "RND\u7684\u5168\u79f0\u662frandom network distillation\uff0c\u662fOpenAI\u5728\u521a\u521a\u8fc7\u53bb\u7684\u4e07\u5723\u8282\u6302\u5728arXiv\u4e0a\u9762\u7684\u3002<b>\u539f\u6587\u4f20\u9001\u95e8<\\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1810.12894" class=" wrap external" target="_blank" rel="nofollow noreferrer">Burda, Yuri, et al. &#34;Exploration by Random Network Distillation.&#34; arXiv preprint arXiv:1810.12894 (2018).<\\/a><b>\u7279\u8272<\\/b>\u8fd9\u8fd8\u662f\u4e00\u7bc7\u8bb2intrinsic reward\u7684\u6587\u7ae0\uff0c\u2026", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-1bfa94257482a7b32e31b43aadc0ed07_b.jpg", "id": 48619627, "voteup_count": 19, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 26\u3011RND", "url": "https://zhuanlan.zhihu.com/p/48619627", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1541417842, "comment_count": 6, "image_url": "https://pic4.zhimg.com/v2-1bfa94257482a7b32e31b43aadc0ed07_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1541150667, "is_labeled": false, "excerpt": "\u8fd9\u7bc7\u6587\u7ae0\u4e5f\u6ca1\u6709\u7ed9\u7b97\u6cd5\u7684\u540d\u5b57\u4e86\uff0c\u4f46\u662f\u5176\u6838\u5fc3\u5c31\u662f\u5b9a\u4e49\u4e86empowerment\u5e76\u7ed9\u51fa\u4e86\u5176\u8fed\u4ee3\u6c42\u89e3\u65b9\u6cd5\uff0c\u6240\u4ee5\u8fd9\u91cc\u5c31\u6682\u4e14\u628a\u5b83\u8bb0\u4e3aempowerment\u5427\u3002<b>\u539f\u6587\u4f20\u9001\u95e8<\\/b><a href="https://link.zhihu.com/?target=https%3A//papers.nips.cc/paper/5668-variational-information-maximisation-for-intrinsically-motivated-reinforcement-learning.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Mohamed, Shakir, and Danilo Jimenez Rezende. &#34;Variational information maximisation for intrinsically motiv\u2026<\\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-12827c055e4a13d8f6847ee98ea1b80c_b.jpg", "id": 48293726, "voteup_count": 5, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 25\u3011Empowerment", "url": "https://zhuanlan.zhihu.com/p/48293726", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1541150667, "comment_count": 0, "image_url": "https://pic2.zhimg.com/v2-12827c055e4a13d8f6847ee98ea1b80c_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1540892513, "is_labeled": false, "excerpt": "VIME\u662fVariational Information Maximizing Exploration\u7684\u7f29\u5199\uff0c\u76ee\u7684\u662f\u4e3a\u4e86\u9f13\u52b1\u63a2\u7d22\uff0c\u5f62\u5f0f\u4e0a\u662f\u4e00\u79cdintrinsic reward\u3002<b>\u539f\u6587\u4f20\u9001\u95e8\uff1a<\\/b><a href="https://link.zhihu.com/?target=https%3A//papers.nips.cc/paper/6591-vime-variational-information-maximizing-exploration.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Houthooft, Rein, et al. &#34;Vime: Variational information maximizing exploration.&#34; Advances in Neural Information Proce\u2026<\\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-cc09bab744de7341c05273acd218051f_b.jpg", "id": 48042454, "voteup_count": 28, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 24\u3011VIME", "url": "https://zhuanlan.zhihu.com/p/48042454", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1540892513, "comment_count": 3, "image_url": "https://pic2.zhimg.com/v2-cc09bab744de7341c05273acd218051f_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1540801164, "is_labeled": false, "excerpt": "\u8fd9\u7bc7\u5de5\u4f5c\u53ef\u4ee5\u8ba4\u4e3a\u662f\u672c\u4e13\u680f\u8bb2\u5230\u7684\u53e6\u4e00\u7bc7\u5de5\u4f5c<a href="https://zhuanlan.zhihu.com/p/46334463" class="internal">\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 17\u3011Curiosity<\\/a> \u7684\u540e\u7eed\uff0c\u540d\u5b57\u662fIntrinsic Curiosity Module\u7684\u7f29\u5199\u3002<b>\u539f\u6587\u4f20\u9001\u95e8\uff1a<\\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1808.04355" class=" wrap external" target="_blank" rel="nofollow noreferrer">Burda, Yuri, et al. &#34;Large-scale study of curiosity-driven learning.&#34; arXiv preprint arXiv:1808.04355 (2018).<\\/a>\u2026", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-26d6235db5ab265204b3dfd46998b89c_b.jpg", "id": 47912734, "voteup_count": 4, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 23\u3011ICM", "url": "https://zhuanlan.zhihu.com/p/47912734", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1540800251, "comment_count": 0, "image_url": "https://pic1.zhimg.com/v2-26d6235db5ab265204b3dfd46998b89c_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1558663904, "is_labeled": false, "excerpt": "<b>\u539f\u6587\u4f20\u9001\u95e8<\\/b><a href="https://link.zhihu.com/?target=http%3A//luthuli.cs.uiuc.edu/~daf/courses/games/AIpapers/ng99policy.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Ng, Andrew Y., Daishi Harada, and Stuart Russell. &#34;Policy invariance under reward transformations: Theory and application to reward shaping.&#34; ICML. Vol. 99. 1999.<\\/a><b>\u7279\u8272<\\/b>\u4e2a\u4eba\u611f\u89c9\u9047\u5230\u5b9e\u9645\u7684\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u7684\u65f6\u5019\uff0c\u5982\u679c\u60f3\u89e3\u51b3\u5730\u66f4\u597d\uff0c\u4e0e\u5176\u4e0a\u2026", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-efc98c037f3b57714d73aa8a3b52a3c3_b.jpg", "id": 47741049, "voteup_count": 17, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u601d\u60f3 22\u3011Reward Shaping Invariance", "url": "https://zhuanlan.zhihu.com/p/47741049", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1540546855, "comment_count": 7, "image_url": "https://pic3.zhimg.com/v2-efc98c037f3b57714d73aa8a3b52a3c3_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1540693133, "is_labeled": false, "excerpt": "\u603b\u7ed3\u4e00\u4e0b\u5f3a\u5316\u5b66\u4e60\u9886\u57df\u76ee\u524d\u7684\u4e00\u4e9b\u4e3b\u8981\u95ee\u9898\u548c\u5df2\u6709\u7684\u4e00\u4e9b\u89e3\u51b3\u601d\u8def\uff0c\u5982\u679c\u6709\u505a\u76f8\u5173\u7814\u7a76\u627e\u4e0d\u5230\u8bfe\u9898\u7684\u540c\u5b66\u53ef\u4ee5\u53c2\u8003\u4e00\u4e0b\u3002\u73b0\u5728\u5199\u7684\u4e0d\u662f\u5f88\u5168\uff0c\u8fd9\u90e8\u5206\u5185\u5bb9\u4f1a\u7ecf\u5e38\u66f4\u65b0\u3002\u4e00\u3001\u5b66\u4e60\u6240\u9700\u6837\u672c\u592a\u591a\u73b0\u5728\u5b66\u4e60\u4e00\u4e2a\u7b80\u5355\u7684\u4efb\u52a1\u6240\u9700\u7684\u7ecf\u9a8c\u6570\u76ee\u76f8\u6bd4\u4e0e\u4eba\u7c7b\u591a\u4e86\u597d\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u5373\u4f7f\u6211\u4eec\u2026", "admin_closed_comment": false, "reason": "", "title_image": "", "id": 47602043, "voteup_count": 54, "voting": 0, "title": "\u524d\u6cbf\u5f3a\u5316\u5b66\u4e60\u95ee\u9898", "url": "https://zhuanlan.zhihu.com/p/47602043", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1540435486, "comment_count": 10, "image_url": "", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1539941533, "is_labeled": false, "excerpt": "TD3\u7684\u662fTwin Delayed Deep Deterministic policy gradient algorithm\u7684\u7b80<b>\u539f\u6587\u4f20\u9001\u95e8\uff1a<\\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1802.09477" class=" wrap external" target="_blank" rel="nofollow noreferrer">Fujimoto, Scott, Herke van Hoof, and Dave Meger. &#34;Addressing Function Approximation Error in Actor-Critic Methods.&#34; arXiv preprint arXiv:1802.09477 (2018).<\\/a> <b>\u7279\u2026<\\/b>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-97fae663dbd4e57cc51f97c7fdd0a39d_b.jpg", "id": 47182584, "voteup_count": 8, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 21\u3011TD3", "url": "https://zhuanlan.zhihu.com/p/47182584", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1539941533, "comment_count": 18, "image_url": "https://pic4.zhimg.com/v2-97fae663dbd4e57cc51f97c7fdd0a39d_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1539911841, "is_labeled": false, "excerpt": "<b>\u539f\u6587\u4f20\u9001\u95e8\uff1a<\\/b><a href="https://link.zhihu.com/?target=http%3A//www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14858/14328" class=" wrap external" target="_blank" rel="nofollow noreferrer">Bacon, Pierre-Luc, Jean Harb, and Doina Precup. &#34;The Option-Critic Architecture.&#34; AAAI. 2017.<\\/a> <b>\u7279\u8272\uff1a<\\/b>\u53e6\u4e00\u5927\u7c7b\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u4ee3\u8868\u3002\u4e2a\u4eba\u8ba4\u4e3a\u8fd9\u7c7b\u65b9\u6cd5\u6700\u5927\u7684\u4f18\u52bf\u662f\u628a\u4e0a\u5c42\u7b56\u7565\u548c\u4e0b\u5c42\u7b56\u7565\u7684\u63a7\u5236\u6743\u79fb\u4ea4\u95ee\u9898\u505a\u6210\u4e00\u4e2a\u53ef\u4ee5\u5b66\u4e60\u7684\u51fd\u6570\uff08termin\u2026", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-c7306bb7a67847d195b756e81adf6b27_b.jpg", "id": 47051292, "voteup_count": 11, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 20\u3011Option-Critic", "url": "https://zhuanlan.zhihu.com/p/47051292", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1539911841, "comment_count": 0, "image_url": "https://pic4.zhimg.com/v2-c7306bb7a67847d195b756e81adf6b27_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1539740528, "is_labeled": false, "excerpt": "HIRO\u662fHIerarchical Reinforcement learning with Off-policy correction\u7684\u7f29\u5199\u3002<b>\u539f\u6587\u4f20\u9001\u95e8\uff1a<\\/b> <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1805.08296" class=" wrap external" target="_blank" rel="nofollow noreferrer">Nachum, Ofir, et al. &#34;Data-Efficient Hierarchical Reinforcement Learning.&#34; arXiv preprint arXiv:1805.08296 (2018).<\\/a> <b>\u7279\u8272\uff1a<\\/b>\u63d0\u51fa\u4e86\u4e00\u79cd<b>general<\\/b>\u5e76\u4e14<b>off-pol\u2026<\\/b>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-21473c597269ec09c3b208dd36cfe56c_b.jpg", "id": 46946800, "voteup_count": 12, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 19\u3011HIRO", "url": "https://zhuanlan.zhihu.com/p/46946800", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1539740528, "comment_count": 0, "image_url": "https://pic3.zhimg.com/v2-21473c597269ec09c3b208dd36cfe56c_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1539735828, "is_labeled": false, "excerpt": "\u5f88\u8001\u7684\u4e00\u7bc7\u6587\u7ae0\u63d0\u51fa\u4e86feudal RL\uff0cFuN\u6307\u7684\u662f\u628a\u5b83\u7528\u4e8e\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u3002<b>\u539f\u6587\u4f20\u9001\u95e8\uff1a<\\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1703.01161" class=" wrap external" target="_blank" rel="nofollow noreferrer">Vezhnevets, Alexander Sasha, et al. &#34;Feudal networks for hierarchical reinforcement learning.&#34; arXiv preprint arXiv:1703.01161 (2017).<\\/a> <b>\u80cc\u666f\uff1a<\\/b>\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u88ab\u8ba4\u4e3a\u662f\u89e3\u2026", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-2173d86a3c20337ce68a5d2ef2baa822_b.jpg", "id": 46928498, "voteup_count": 14, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 18\u3011FuN", "url": "https://zhuanlan.zhihu.com/p/46928498", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1539735828, "comment_count": 2, "image_url": "https://pic3.zhimg.com/v2-2173d86a3c20337ce68a5d2ef2baa822_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1568805448, "is_labeled": false, "excerpt": "\u5f52\u7eb3\u4e00\u4e0b\u76ee\u524d\u8bfb\u5230\u5f3a\u5316\u5b66\u4e60\u8bba\u6587\u6240\u6d89\u53ca\u7684\u8bdd\u9898\u4e00\u3001Model-free RL\u4e3b\u8981\u76ee\u6807\u662fStable\u548cData Efficient\uff0c\u53e6\u5916\u5e0c\u671b\u80fd\u591f\u652f\u6301High Dimensional Input\u3001\u652f\u6301continuous action space\u3001\u652f\u6301\u5e76\u884c\u8ba1\u7b97\u3002<a href="https://zhuanlan.zhihu.com/p/44573428" data-draft-node="block" data-draft-type="link-card" data-image="https://pic1.zhimg.com/v2-6b4c4792e8c37c3b6cedb63879744fd8_180x120.jpg" data-image-width="1772" data-image-height="574" class="internal">\u5f20\u695a\u73e9\uff1a\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 1\u3011DQN<\\/a><a href="https://zhuanlan.zhihu.com/p/44594208" data-draft-node="block" data-draft-type="link-card" data-image="https://pic1.zhimg.com/v2-53e7fc355987622bedeeb8f2cc2f8390_180x120.jpg" data-image-width="2346" data-image-height="738" class="internal">\u5f20\u695a\u73e9\uff1a\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 2\u3011DDPG<\\/a><a href="https://zhuanlan.zhihu.com/p/44595815" data-draft-node="block" data-draft-type="link-card" data-image="https://pic3.zhimg.com/v2-aea56d2e701e3bc7a67724a47b16f986_180x120.jpg" data-image-width="1342" data-image-height="396" class="internal">\u5f20\u695a\u2026<\\/a>", "admin_closed_comment": false, "reason": "", "title_image": "", "id": 46600521, "voteup_count": 162, "voting": 0, "title": "\u5f3a\u5316\u5b66\u4e60\u8bba\u6587\u6c47\u603b", "url": "https://zhuanlan.zhihu.com/p/46600521", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1539333014, "comment_count": 7, "image_url": "", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1539157729, "is_labeled": false, "excerpt": "\u539f\u6587\u7684\u53eb\u505a curiosity-driven learning\uff0c\u77e5\u4e4e\u6587\u7ae0\u6807\u9898\u6253\u4e0d\u4e86\u8fd9\u4e48\u957f\uff0c\u5c31\u53ebCuriosity\u5427\u3002<b>\u539f\u6587\u4f20\u9001\u95e8\uff1a<\\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1808.04355" class=" wrap external" target="_blank" rel="nofollow noreferrer">Burda, Yuri, et al. &#34;Large-Scale Study of Curiosity-Driven Learning.&#34; arXiv preprint arXiv:1808.04355 (2018).<\\/a><b>\u7279\u8272\uff1a<\\/b>\u8fd9\u7bc7\u6587\u7ae0\u4e0d\u4f7f\u7528\u5916\u5728\u7684\u5956\u52b1\uff0c\u4ec5\u4f7f\u2026", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-68ee54b50aa8cdfd9b8589e21f1e0dda_b.jpg", "id": 46334463, "voteup_count": 15, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 17\u3011Curiosity", "url": "https://zhuanlan.zhihu.com/p/46334463", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1539087847, "comment_count": 2, "image_url": "https://pic3.zhimg.com/v2-68ee54b50aa8cdfd9b8589e21f1e0dda_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1539070396, "is_labeled": false, "excerpt": "\u4ee5\u524d\u5728\u4fde\u626c\u8001\u5e08\u90a3\u91cc\u505a\u6bd5\u8bbe\u7684\u65f6\u5019\uff0c\u4fde\u626c\u8001\u5e08\u8fd8\u8bb2\u8fc7\u7b97\u6cd5\u8d77\u540d\u5b57\u7684\u91cd\u8981\u6027\uff0c\u4f46\u8fd9\u7bc7\u5de5\u4f5c\u597d\u50cf\u5e76\u6ca1\u6709\u5b98\u65b9\u7ed9\u7684\u540d\u5b57\u3002\u4e3a\u4e86\u4fbf\u4e8e\u672c\u4e13\u680f\u533a\u5206\uff0c\u5c31\u628a\u5b83\u53eb\u505aNJUStarCraft\u5427\u3002<b>\u539f\u6587\u4f20\u9001\u95e8\uff1a<\\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1809.09095" class=" wrap external" target="_blank" rel="nofollow noreferrer">Pang, Zhen-Jia, et al. &#34;On Reinforcement Learning for Full-length Game of StarCr\u2026<\\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-d8d1a20f0896703255ffe13988984849_b.jpg", "id": 46281485, "voteup_count": 5, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 16\u3011NJUStarCraft", "url": "https://zhuanlan.zhihu.com/p/46281485", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1539070395, "comment_count": 0, "image_url": "https://pic3.zhimg.com/v2-d8d1a20f0896703255ffe13988984849_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1538989025, "is_labeled": false, "excerpt": "\u8fd9\u91cc\u7684h-DQN\u662f\u4e00\u79cdhierarchical deep reinforcement learning\u65b9\u6cd5\u3002<b>\u539f\u6587\u4f20\u9001\u95e8\uff1a<\\/b><a href="https://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/6233-hierarchical-deep-reinforcement-learning-integrating-temporal-abstraction-and-intrinsic-motivation.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Kulkarni, Tejas D., et al. &#34;Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation.&#34; Advances in neural information pr\u2026<\\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-f866f401fe6045df9f99c2c6c41c62e9_b.jpg", "id": 46218455, "voteup_count": 12, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 15\u3011h-DQN", "url": "https://zhuanlan.zhihu.com/p/46218455", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1538989025, "comment_count": 5, "image_url": "https://pic2.zhimg.com/v2-f866f401fe6045df9f99c2c6c41c62e9_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1538363313, "is_labeled": false, "excerpt": "\u8fd9\u91cc\u7684GPS\u4e0d\u662f\u7528\u6765\u5bfc\u822a\u7684GPS\uff0c\u5176\u5168\u79f0\u662fGuided Policy Search\uff0c\u662f\u4e00\u79cd\u5c40\u57df\u7684model-based RL\u7b97\u6cd5\uff0c\u5404\u79cd\u7248\u672c\u57fa\u672c\u4e0a\u90fd\u662fLevine\u5927\u795e\u641e\u51fa\u6765\u7684\u3002<b>\u539f\u6587\u4f20\u9001\u95e8\uff1a<\\/b><a href="https://link.zhihu.com/?target=http%3A//www.jmlr.org/proceedings/papers/v28/levine13.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">\u3010Importance-sampled GPS\u3011Levine, Sergey, and Vladlen Koltun. &#34;Guided policy search.&#34; Internationa\u2026<\\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-74b3cd5399c3b719841853fae02f91a7_b.jpg", "id": 45754995, "voteup_count": 10, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 14\u3011GPS", "url": "https://zhuanlan.zhihu.com/p/45754995", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1538363313, "comment_count": 2, "image_url": "https://pic4.zhimg.com/v2-74b3cd5399c3b719841853fae02f91a7_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1538377195, "is_labeled": false, "excerpt": "i\u6253\u5934\u4f46\u5e76\u4e0d\u662f\u82f9\u679c\u5bb6\u7684\u4ea7\u54c1\u54c8\uff0c\u5176\u5168\u79f0\u662f Iterative Linear Quadratic Gaussian\u3002<b>\u539f\u6587\u4f20\u9001\u95e8\uff1a<\\/b><a href="https://link.zhihu.com/?target=http%3A//maeresearch.ucsd.edu/groups/skelton/publications/weiwei_ilqg_CDC43.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Todorov, Emanuel, and Weiwei Li. &#34;A generalized iterative LQG method for locally-optimal feedback control of constrained nonlinear stochastic systems.&#34;\u2026<\\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-b528ccd79db60c8738ad54ca1f09ad77_b.jpg", "id": 45618611, "voteup_count": 19, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 13\u3011iLQG", "url": "https://zhuanlan.zhihu.com/p/45618611", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1538199247, "comment_count": 0, "image_url": "https://pic2.zhimg.com/v2-b528ccd79db60c8738ad54ca1f09ad77_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1538377281, "is_labeled": false, "excerpt": "\u5e76\u4e0d\u662f\u5ba0\u7269\u7684\u610f\u601d\uff0c\u5176\u5b9e\u5b83\u662f PE+TS\uff0c\u5373ensembles of probabilistic model + trajectory optimization\u3002<b>\u539f\u6587\u4f20\u9001\u95e8\uff1a<\\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1807.02303" class=" wrap external" target="_blank" rel="nofollow noreferrer">Chatzilygeroudis K, Vassiliades V, Stulp F, et al. A survey on policy search algorithms for learning robot controllers in a handfu\u2026<\\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-45635e8f53f056f0a9d1e86e092dc9f4_b.jpg", "id": 45418829, "voteup_count": 9, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 12\u3011PETS", "url": "https://zhuanlan.zhihu.com/p/45418829", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1537966444, "comment_count": 1, "image_url": "https://pic3.zhimg.com/v2-45635e8f53f056f0a9d1e86e092dc9f4_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1584412738, "is_labeled": false, "excerpt": "\u4ece\u6587\u7ae0\u7684\u6807\u9898\u5c31\u80fd\u770b\u5f97\u51fa\u6765\uff0cSAC \u4ee3\u8868\u7684\u662f soft actor-critic\u3002<b>\u539f\u6587\u4f20\u9001\u95e8:<\\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1801.01290" class=" wrap external" target="_blank" rel="nofollow noreferrer">Haarnoja, Tuomas, et al. &#34;Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor.&#34; arXiv preprint arXiv:1801.01290 (2018).<\\/a> <b>\u7279\u2026<\\/b>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-14c469eacaf739f6fd9d902b54880939_b.jpg", "id": 44792834, "voteup_count": 13, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 11\u3011SAC", "url": "https://zhuanlan.zhihu.com/p/44792834", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1537242325, "comment_count": 6, "image_url": "https://pic4.zhimg.com/v2-14c469eacaf739f6fd9d902b54880939_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1538377510, "is_labeled": false, "excerpt": "\u5e76\u4e0d\u662f\u6570\u636e\u5e93\u7684\u90a3\u4e2a SQL\uff0c\u8fd9\u91cc\u6307\u7684\u662f soft Q-learning\uff0c\u800c soft \u6307\u7684\u662f\u7b56\u7565\u7684\u5f62\u5f0f\u662f\u4ef7\u503c\u51fd\u6570 softmax \u7684\u5f62\u5f0f\uff0c\u4e0b\u9762\u5c31\u4f1a\u770b\u5230\u3002<b>\u539f\u6587\u4f20\u9001\u95e8\uff1a<\\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1702.08165" class=" wrap external" target="_blank" rel="nofollow noreferrer">Haarnoja, Tuomas, et al. &#34;Reinforcement learning with deep energy-based policies.&#34; arXiv preprint arXiv:1702.\u2026<\\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-fa607ce722fc5f12e65fb4a88699a4ad_b.jpg", "id": 44783057, "voteup_count": 23, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 10\u3011SQL", "url": "https://zhuanlan.zhihu.com/p/44783057", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1537237093, "comment_count": 4, "image_url": "https://pic1.zhimg.com/v2-fa607ce722fc5f12e65fb4a88699a4ad_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1538377598, "is_labeled": false, "excerpt": "ES \u6307\u7684\u662f evolutionary strategy\uff0c\u672c\u6765\u662f\u4e00\u4e2a\u5f88\u5bbd\u6cdb\u7684\u6982\u5ff5\uff0c\u4f46\u662f\u4ee3\u8868\u4e00\u79cd\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u65f6\u5019\u4e3b\u8981\u6307\u7684\u662f\u8fd9\u7bc7\u6587\u7ae0\u7684\u5de5\u4f5c\u3002<b>\u539f\u6587\u4f20\u9001\u95e8\uff1a<\\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1703.03864" class=" wrap external" target="_blank" rel="nofollow noreferrer">Salimans, Tim, et al. &#34;Evolution strategies as a scalable alternative to reinforcement learning.&#34; arXiv preprint \u2026<\\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-b08226a70d8e6fc7644ecd086877c676_b.jpg", "id": 44629892, "voteup_count": 4, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 9\u3011ES", "url": "https://zhuanlan.zhihu.com/p/44629892", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1537156818, "comment_count": 0, "image_url": "https://pic3.zhimg.com/v2-b08226a70d8e6fc7644ecd086877c676_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1538377642, "is_labeled": false, "excerpt": "ARS \u6307\u7684\u662f augmented random search\u3002<b>\u539f\u6587\u4f20\u9001\u95e8\uff1a<\\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1803.07055" class=" wrap external" target="_blank" rel="nofollow noreferrer">Mania, Horia, Aurelia Guy, and Benjamin Recht. &#34;Simple random search provides a competitive approach to reinforcement learning.&#34; arXiv preprint arXiv:1803.07055 (2018).<\\/a><b>\u7279\u8272\uff1a<\\/b>\u8fd9\u7bc7\u6587\u7ae0\u7c7b\u4f3c\u524d\u9762\u2026", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-b0b56586a1f30ecab049c4fc6fe4fdde_b.jpg", "id": 44628186, "voteup_count": 3, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 8\u3011ARS", "url": "https://zhuanlan.zhihu.com/p/44628186", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1537014405, "comment_count": 1, "image_url": "https://pic2.zhimg.com/v2-b0b56586a1f30ecab049c4fc6fe4fdde_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1538377703, "is_labeled": false, "excerpt": "CEM \u6307\u7684\u662f cross entropy method\uff0c\u672c\u6765\u662f\u4e00\u7c7b\u4f18\u5316\u65b9\u6cd5\uff0c\u4f46\u662f\u5927\u5bb6\u5f15\u7528\u7684\u65f6\u5019\u901a\u5e38\u6307\u7684\u662f\u8fd9\u7bc7\u6587\u7ae0\u63d0\u5230\u7684\u7b97\u6cd5\u3002<b>\u539f\u6587\u4f20\u9001\u95e8\uff1a<\\/b><a href="https://link.zhihu.com/?target=http%3A//citeseerx.ist.psu.edu/viewdoc/download%3Fdoi%3D10.1.1.80.6681%26rep%3Drep1%26type%3Dpdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Szita, Istv\xe1n, and Andr\xe1s L\xf6rincz. &#34;Learning Tetris using the noisy cross-entropy method.&#34; Neural computation 18.12 (2006)\u2026<\\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-6a48f1ed5e1384c63f6d0224696c6dc7_b.jpg", "id": 44623211, "voteup_count": 7, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 7\u3011CEM", "url": "https://zhuanlan.zhihu.com/p/44623211", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1537012713, "comment_count": 0, "image_url": "https://pic3.zhimg.com/v2-6a48f1ed5e1384c63f6d0224696c6dc7_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1538377771, "is_labeled": false, "excerpt": "\u4ece\u6587\u7ae0\u7684\u6807\u9898\u53ef\u4ee5\u770b\u51faACER\u6307\u7684actor-critic with experience replay\u3002<b>\u539f\u6587\u4f20\u9001\u95e8\uff1a<\\/b><a href="https://link.zhihu.com/?target=http%3A//www.jmlr.org/proceedings/papers/v48/mniha16.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Mnih, Volodymyr, et al. &#34;Asynchronous methods for deep reinforcement learning.&#34; International conference on machine learning. 2016.\uff08\u524d\u5e8f\u5de5\u4f5c\uff09<\\/a> <a href="https://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/6538-safe-and-efficient-off-policy-reinforcement-learning.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Munos, R\xe9mi, et \u2026<\\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-a5b2c8cb72620f30f8ca79a6832d09be_b.jpg", "id": 44603367, "voteup_count": 13, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 6\u3011ACER", "url": "https://zhuanlan.zhihu.com/p/44603367", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1537003768, "comment_count": 9, "image_url": "https://pic1.zhimg.com/v2-a5b2c8cb72620f30f8ca79a6832d09be_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1537319977, "is_labeled": false, "excerpt": "<b>\u539f\u6587\u4f20\u9001\u95e8\uff1a<\\/b><a href="https://link.zhihu.com/?target=http%3A//www.jmlr.org/proceedings/papers/v48/mniha16.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Mnih, Volodymyr, et al. &#34;Asynchronous methods for deep reinforcement learning.&#34; International conference on machine learning. 2016.<\\/a> <b>\u7279\u8272\uff1a<\\/b>\u53d1\u73b0\u5f02\u6b65\u5e76\u884c\u5730\u6267\u884c\u591a\u4e2aagent\uff0c\u8ba9\u5b83\u4eecon-policy\u5730\u53bb\u9762\u5bf9\u4e0d\u540c\u7684\u72b6\u6001\uff0c\u4e0d\u4ec5\u52a0\u901f\u4e86\u7b97\u6cd5\uff0c\u800c\u4e14\u6709\u4e00\u2026", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-a31b305dfbbb717f2f68d63cca7c0dad_b.jpg", "id": 44621826, "voteup_count": 1, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 5\u3011A3C", "url": "https://zhuanlan.zhihu.com/p/44621826", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1537005287, "comment_count": 0, "image_url": "https://pic1.zhimg.com/v2-a31b305dfbbb717f2f68d63cca7c0dad_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1537320176, "is_labeled": false, "excerpt": "<b>\u539f\u6587\u94fe\u63a5\uff1a<\\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1707.06347" class=" wrap external" target="_blank" rel="nofollow noreferrer">Schulman, John, et al. &#34;Proximal policy optimization algorithms.&#34; arXiv preprint arXiv:1707.06347 (2017).<\\/a> <b>\u7279\u8272\uff1a<\\/b>TRPO\u5f88\u6210\u529f\uff0c\u4f46\u662f\u8ba1\u7b97\u7684\u8fc7\u7a0b\u592a\u590d\u6742\u4e86\uff0c\u6bcf\u6b65\u66f4\u65b0\u8fd0\u7b97\u91cf\u5927\u3001\u8017\u65f6\u957f\u3002\u5728\u6b64\u57fa\u7840\u4e0a\u8fdb\u884c\u6539\u8fdb\u907f\u514d\u590d\u6742\u7684\u5bf9\u4e8eKL divergence\u77e9\u9635\u7684\u6c42H\u2026", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-87a930c56a5160b7c1b852ac0a11cb56_b.jpg", "id": 44600797, "voteup_count": 4, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 4\u3011PPO", "url": "https://zhuanlan.zhihu.com/p/44600797", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1536983920, "comment_count": 3, "image_url": "https://pic4.zhimg.com/v2-87a930c56a5160b7c1b852ac0a11cb56_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1537320237, "is_labeled": false, "excerpt": "<b>\u539f\u6587\u4f20\u9001\u95e8\uff1a<\\/b><a href="https://link.zhihu.com/?target=http%3A//homes.cs.washington.edu/~sham/papers/rl/aoarl.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Kakade, Sham, and John Langford. &#34;Approximately optimal approximate reinforcement learning.&#34; ICML. Vol. 2. 2002.\uff08\u524d\u5e8f\u5de5\u4f5c\uff09<\\/a> <a href="https://link.zhihu.com/?target=http%3A//www.jmlr.org/proceedings/papers/v37/schulman15.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Schulman, John, et al. &#34;Trust region policy optimization.&#34; International Conference on Machine Learni\u2026<\\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-aea56d2e701e3bc7a67724a47b16f986_b.jpg", "id": 44595815, "voteup_count": 6, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 3\u3011TRPO", "url": "https://zhuanlan.zhihu.com/p/44595815", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1536981065, "comment_count": 0, "image_url": "https://pic3.zhimg.com/v2-aea56d2e701e3bc7a67724a47b16f986_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1537320307, "is_labeled": false, "excerpt": "<b>\u539f\u6587\u4f20\u9001\u95e8\uff1a<\\/b><a href="https://link.zhihu.com/?target=http%3A//www.jmlr.org/proceedings/papers/v32/silver14.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Silver, David, et al. &#34;Deterministic policy gradient algorithms.&#34; ICML. 2014.\uff08\u524d\u5e8f\u5de5\u4f5c\uff09<\\/a><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1509.02971" class=" wrap external" target="_blank" rel="nofollow noreferrer">Lillicrap, Timothy P., et al. &#34;Continuous control with deep reinforcement learning.&#34; arXiv preprint arXiv:1509.02971 (2015).<\\/a> <b>\u7279\u8272\uff1a<\\/b>\u80fd\u591f\u5904\u2026", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-53e7fc355987622bedeeb8f2cc2f8390_b.jpg", "id": 44594208, "voteup_count": 5, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 2\u3011DDPG", "url": "https://zhuanlan.zhihu.com/p/44594208", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1536976331, "comment_count": 0, "image_url": "https://pic1.zhimg.com/v2-53e7fc355987622bedeeb8f2cc2f8390_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1537320410, "is_labeled": false, "excerpt": "<b>\u539f\u6587\u4f20\u9001\u95e8\uff1a<\\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1312.5602.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Mnih, Volodymyr, et al. &#34;Human-level control through deep reinforcement learning.&#34; (2015). (ICML\u7248\u672c)<\\/a><a href="https://link.zhihu.com/?target=http%3A//web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Mnih, Volodymyr, et al. &#34;Human-level control through deep reinforcement learning.&#34; Nature 518.7540 (2015): 529. (Nature\u7248\u672c)<\\/a><b>\u2026<\\/b>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-6b4c4792e8c37c3b6cedb63879744fd8_b.jpg", "id": 44573428, "voteup_count": 19, "voting": 0, "title": "\u3010\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 1\u3011DQN", "url": "https://zhuanlan.zhihu.com/p/44573428", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "\u5f20\u695a\u73e9", "is_advertiser": false, "headline": "\u5f3a\u5316\u5b66\u4e60 \u91cf\u5316\u6295\u8d44", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "\u6e05\u534e\u5927\u5b66 \u4ea4\u53c9\u4fe1\u606f\u9662\u535a\u58eb\u5728\u8bfb"}]}, "state": "published", "created": 1536974705, "comment_count": 11, "image_url": "https://pic2.zhimg.com/v2-6b4c4792e8c37c3b6cedb63879744fd8_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}]}