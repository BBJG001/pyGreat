{"paging": {"is_end": false, "totals": 137, "previous": "http://zhuanlan.zhihu.com/api/columns/reinforcementlearning/articles?include=data&limit=100&offset=0", "is_start": true, "next": "http://zhuanlan.zhihu.com/api/columns/reinforcementlearning/articles?include=data&limit=100&offset=100"}, "data": [{"updated": 1585354622, "is_labeled": false, "excerpt": "原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1912.05104.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Islam, Riashat, et al. &#34;Entropy Regularization with Discounted Future State Distribution in Policy Gradient Methods.&#34; arXiv preprint arXiv:1912.05104 (2019).<\/a>特色强化学习的主要问题是状态空间的探索，策略梯度方法要求在有一个较好的 …", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-1b9ad8feb5b9eec919e3b608e9304175_b.jpg", "id": 118422846, "voteup_count": 28, "voting": 0, "title": "【强化学习 114】State Entropy Regularization", "url": "https://zhuanlan.zhihu.com/p/118422846", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1585354622, "comment_count": 1, "image_url": "https://pic1.zhimg.com/v2-1b9ad8feb5b9eec919e3b608e9304175_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1584931754, "is_labeled": false, "excerpt": "原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1812.05905.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Haarnoja, Tuomas, et al. &#34;Soft actor-critic algorithms and applications.&#34; arXiv preprint arXiv:1812.05905 (2018).<\/a><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1910.07207.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Christodoulou, Petros. &#34;Soft Actor-Critic for Discrete Action Settings.&#34; arXiv preprint arXiv:1910.07207 (2019).<\/a>原…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-ed1f5bea643863b6443e4495d37468cc_b.jpg", "id": 115394759, "voteup_count": 14, "voting": 0, "title": "【强化学习 113】Development on SAC", "url": "https://zhuanlan.zhihu.com/p/115394759", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1584931754, "comment_count": 4, "image_url": "https://pic2.zhimg.com/v2-ed1f5bea643863b6443e4495d37468cc_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1584925274, "is_labeled": false, "excerpt": "原文传送门ICLR 2017：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1611.01144.pdf%2520http%3A//arxiv.org/abs/1611.01144.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Jang, Eric, Shixiang Gu, and Ben Poole. &#34;Categorical reparameterization with gumbel-softmax.&#34; arXiv preprint arXiv:1611.01144 (2016).<\/a>特色对于离散变量，最常用的分布就是 categorical 分布，这种分布下需要用 reparameteriza…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-d1a47beb299757957ea9edae518ea9ce_b.jpg", "id": 115386452, "voteup_count": 64, "voting": 0, "title": "【数学】 Gumbel Softmax", "url": "https://zhuanlan.zhihu.com/p/115386452", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1584925274, "comment_count": 8, "image_url": "https://pic1.zhimg.com/v2-d1a47beb299757957ea9edae518ea9ce_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1584340323, "is_labeled": false, "excerpt": "本周张天平学弟在组会上讲了两篇时间序列预测上的最新文章，其中一篇文章用到了 CV 领域非常有意思的一个工作。原文传送门N-BEATS（ICLR 2020）：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1905.10437.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Oreshkin, Boris N., et al. &#34;N-BEATS: Neural basis expansion analysis for interpretable time series for…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-95aafb13937d5d8049c8e1e7c9e7e6cb_b.jpg", "id": 112727228, "voteup_count": 44, "voting": 0, "title": "【深度学习 112】时间序列预测", "url": "https://zhuanlan.zhihu.com/p/112727228", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1584340259, "comment_count": 1, "image_url": "https://pic2.zhimg.com/v2-95aafb13937d5d8049c8e1e7c9e7e6cb_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1584336932, "is_labeled": false, "excerpt": "全称为 mutual information neural estimation。原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1801.04062.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Belghazi, Mohamed Ishmael, et al. &#34;Mutual information neural estimation.&#34; International Conference on Machine Learning. 2018.<\/a>特色这篇文章讲如何用神经网络来估计互信息（mutual informati…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-ec1b64e5e349335afc6697e150abb809_b.jpg", "id": 113455332, "voteup_count": 31, "voting": 0, "title": "【深度学习 111】MINE", "url": "https://zhuanlan.zhihu.com/p/113455332", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1584336932, "comment_count": 2, "image_url": "https://pic2.zhimg.com/v2-ec1b64e5e349335afc6697e150abb809_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1584158330, "is_labeled": false, "excerpt": "<b>论文题目<\/b>：<b>SQIL<\/b>: Imitation Learning via Reinforcement Learning with Sparse Rewards<b>所解决的问题？<\/b> 从高维的状态动作空间中进行模仿学习是比较困难的，以往的行为克隆算法(behavioral cloning BC)算法容易产生分布漂移(distribution shift)，而最近做得…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-589f12d2003902a555e8c5dac043beee_b.jpg", "id": 113124696, "voteup_count": 20, "voting": 0, "title": "【ICLR2020】通过强化学习和稀疏奖励进行模仿学习", "url": "https://zhuanlan.zhihu.com/p/113124696", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic3.zhimg.com/v2-e7f3a66aff8bc0fda395148d2ca35b55_{size}.jpg", "uid": "707172804071538688", "user_type": "people", "is_following": false, "type": "people", "url_token": "he-zhi-qiang-52-74", "id": "a2034395b75bf8d0ddc35345035cf54d", "description": "个人公众号：深度学习与先进智能决策
公众号ID：MultiAgent1024
公众号介绍：主要研究深度学习，强化学习、机器博弈等相关内容！", "name": "小小何先生", "is_advertiser": false, "headline": "以爱与青春为名，陪你一路成长。", "gender": 1, "url": "/people/a2034395b75bf8d0ddc35345035cf54d", "avatar_url": "https://pic3.zhimg.com/v2-e7f3a66aff8bc0fda395148d2ca35b55_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "东北大学 信息科学与工程学院硕士在读"}]}, "state": "published", "created": 1584158330, "comment_count": 1, "image_url": "https://pic4.zhimg.com/v2-589f12d2003902a555e8c5dac043beee_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1583640807, "is_labeled": false, "excerpt": "这篇文章提出了一个比较新的设定，先在状态空间探索，然后求解 MDP 问题。文章给出了在这种设定下的 provably efficient 算法和相应的 lower bound。原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2002.02794.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Jin, Chi, et al. &#34;Reward-Free Exploration for Reinforcement Learning.&#34; arXiv preprint arX…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-1383ee23dba94f9a378c6115294d0d57_b.jpg", "id": 111672225, "voteup_count": 39, "voting": 0, "title": "【强化学习 110】Reward-Free Exploration", "url": "https://zhuanlan.zhihu.com/p/111672225", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1583639759, "comment_count": 4, "image_url": "https://pic2.zhimg.com/v2-1383ee23dba94f9a378c6115294d0d57_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1583465987, "is_labeled": false, "excerpt": "针对 self-play 的强化学习问题，基于 UCB 的思想给出 provably efficient 算法。原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2002.04017" class=" wrap external" target="_blank" rel="nofollow noreferrer">Bai, Yu, and Chi Jin. &#34;Provable Self-Play Algorithms for Competitive Reinforcement Learning.&#34; arXiv preprint arXiv:2002.04017 (2020).<\/a>特色在实践中，很多…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-0517af4d255678cada7334315727ab36_b.jpg", "id": 111191211, "voteup_count": 39, "voting": 0, "title": "【强化学习 109】Provable Self-play", "url": "https://zhuanlan.zhihu.com/p/111191211", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1583465987, "comment_count": 9, "image_url": "https://pic4.zhimg.com/v2-0517af4d255678cada7334315727ab36_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1583418727, "is_labeled": false, "excerpt": "这里介绍 AutoML 领域另外一个研究方向，数据增广。根据我们组周璟师妹的组会报告整理而成。原文传送门AutoAugment（CVPR 2019） <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1805.09501" class=" wrap external" target="_blank" rel="nofollow noreferrer">Cubuk, Ekin D., et al. &#34;Autoaugment: Learning augmentation strategies from data.&#34; Proceedings of the IEEE conference …<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-6ba61101172b4dda2a7de1ad5168ee2f_b.jpg", "id": 111094885, "voteup_count": 24, "voting": 0, "title": "【强化学习 108】AutoAugment", "url": "https://zhuanlan.zhihu.com/p/111094885", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1583404467, "comment_count": 12, "image_url": "https://pic4.zhimg.com/v2-6ba61101172b4dda2a7de1ad5168ee2f_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1583334207, "is_labeled": false, "excerpt": "Neural architecture search (NAS) 是强化学习的一个重要应用方向，也是 AutoML 的一个非常火的研究方向。这里主要结合我们组学弟 <a class="member_mention" href="https://www.zhihu.com/people/7b8d74f4f88d160b4d920470533222bc" data-hash="7b8d74f4f88d160b4d920470533222bc" data-hovercard="p$b$7b8d74f4f88d160b4d920470533222bc">@五更琉璃<\/a> 在组会上的两次报告来梳理一下该方向的主要研究进展。原文传送门NAS (ICLR 2017): <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1611.01578.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Zoph, Barret, and Quoc V. Le.…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-0135f62ff34a21fad46c4401ba0d95b9_b.jpg", "id": 110527110, "voteup_count": 27, "voting": 0, "title": "【强化学习 107】Neural Architecture Search", "url": "https://zhuanlan.zhihu.com/p/110527110", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1583310211, "comment_count": 1, "image_url": "https://pic3.zhimg.com/v2-0135f62ff34a21fad46c4401ba0d95b9_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1583201229, "is_labeled": false, "excerpt": "本来想详细讲解一下这一块的内容，但是我看到知乎上已经有了不错的讲解，这里就不写了，只列举一下重要的方面。资料汇总如果想快速了解小波（wavelet）是什么，可以直接看知乎的这两篇讲解，个人感觉还是比较清楚的（注意到，这个内容也是转载的，并且是经…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-25d922ffe9b16f0c36965c1d98e27423_b.jpg", "id": 110483334, "voteup_count": 9, "voting": 0, "title": "【数学】小波变换", "url": "https://zhuanlan.zhihu.com/p/110483334", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1583201229, "comment_count": 0, "image_url": "https://pic1.zhimg.com/v2-25d922ffe9b16f0c36965c1d98e27423_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1583163018, "is_labeled": false, "excerpt": "最新的 ICLR 2020 的一篇文章，一个理论工作，告诉我们啥样的神经网络结构能做啥样的推理任务。原文传送门<a href="https://link.zhihu.com/?target=https%3A//openreview.net/pdf%3Fid%3DrJxbJeHFPS" class=" wrap external" target="_blank" rel="nofollow noreferrer">Xu, Keyulu, et al. &#34;What Can Neural Networks Reason About?.&#34; arXiv preprint arXiv:1905.13211 (2019).<\/a>特色在理论上从简单的 MLP 到结构比较复杂…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-fea801530ff6e6d1487a0b9497ba8059_b.jpg", "id": 110425877, "voteup_count": 98, "voting": 0, "title": "【深度学习 106】NN Reasoning", "url": "https://zhuanlan.zhihu.com/p/110425877", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1583163018, "comment_count": 5, "image_url": "https://pic2.zhimg.com/v2-fea801530ff6e6d1487a0b9497ba8059_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1583114150, "is_labeled": false, "excerpt": "这里想讲一篇长论文，这篇论文提出一种 representation policy iteration （RPI） 的框架；同时还在强化学习表示学习方面做了比较详细的讲述。原文传送门<a href="https://link.zhihu.com/?target=https%3A//www.nowpublishers.com/article/DownloadSummary/MAL-003" class=" wrap external" target="_blank" rel="nofollow noreferrer">Mahadevan, Sridhar. &#34;Learning representation and control in Markov decision processes: New fron…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-a58915dc326379660c7a6532c5f1817d_b.jpg", "id": 109952463, "voteup_count": 33, "voting": 0, "title": "【强化学习 105】RPI", "url": "https://zhuanlan.zhihu.com/p/109952463", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1583064366, "comment_count": 3, "image_url": "https://pic4.zhimg.com/v2-a58915dc326379660c7a6532c5f1817d_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1581997895, "is_labeled": false, "excerpt": "本文提出使用 Ising 模型的平均场论解法来解决半监督学习问题。原文传送门<a href="https://link.zhihu.com/?target=http%3A//www.jmlr.org/proceedings/papers/v2/wang07c/wang07c.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Wang, Fei, et al. &#34;Semi-supervised mean fields.&#34; Artificial Intelligence and Statistics. 2007.<\/a>特色这篇文章先介绍了 Ising 模型（这是一个很有趣的模型，记得本科电磁学课的小…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-5b99901916cac006d5ed0f1a586ba2fb_b.jpg", "id": 107388314, "voteup_count": 34, "voting": 0, "title": "【强化学习 104】Mean-field for Semi-supervised，也聊 Ising", "url": "https://zhuanlan.zhihu.com/p/107388314", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1581997722, "comment_count": 1, "image_url": "https://pic4.zhimg.com/v2-5b99901916cac006d5ed0f1a586ba2fb_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1581831041, "is_labeled": false, "excerpt": "去年 12 月份在 Arxiv 上更新的关于 GNN 的综述文章，应该还是比较新的。原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1901.00596.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Wu, Zonghan, et al. &#34;A comprehensive survey on graph neural networks.&#34; arXiv preprint arXiv:1901.00596 (2019).<\/a>特色离散状态的强化学习问题中，不同的状态可以自然地…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-8fbcd8fdaf9ad33bf13c8ac212340e19_b.jpg", "id": 107062996, "voteup_count": 33, "voting": 0, "title": "【强化学习 103】GNN综述", "url": "https://zhuanlan.zhihu.com/p/107062996", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1581830370, "comment_count": 2, "image_url": "https://pic3.zhimg.com/v2-8fbcd8fdaf9ad33bf13c8ac212340e19_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1581414824, "is_labeled": false, "excerpt": "DiffPool: Differentiable Pooling介绍了一种聚合图中的节点，从而学习到包含层级信息的图表示。原文传送门<a href="https://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/7729-hierarchical-graph-representation-learning-with-differentiable-pooling.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Ying, Zhitao, et al. &#34;Hierarchical graph representation learning with differentiable pooling.&#34; Advances in neural information processing s…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-100827bc90d091ea1b1340863870d311_b.jpg", "id": 106214278, "voteup_count": 41, "voting": 0, "title": "【强化学习 102】DiffPool，也聊图神经网络", "url": "https://zhuanlan.zhihu.com/p/106214278", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1581414824, "comment_count": 1, "image_url": "https://pic1.zhimg.com/v2-100827bc90d091ea1b1340863870d311_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1578127204, "is_labeled": false, "excerpt": "今天本文的作者之一，姚班毕业的同学，Ruosong Wang 来讲他们的一篇理论工作，还挺有意思的。<a href="https://zhuanlan.zhihu.com/p/99340215" data-draft-node="block" data-draft-type="link-card" data-image="https://pic2.zhimg.com/v2-9c0c59db9947d114a2aa43d445074431_180x120.jpg" data-image-width="1920" data-image-height="1080" class="internal">中关村海华信息技术前沿研究院：讲座预告| 姚班校友王若松将主讲第十七场交叉信息院--海华研究院前沿讲座<\/a>原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1910.03016.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Du, Simon S., et al. &#34;Is a Good Representat…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-b1039e03b20b77e927662099d1ebdb50_b.jpg", "id": 100213425, "voteup_count": 80, "voting": 0, "title": "【强化学习 101】Representation Lower Bound", "url": "https://zhuanlan.zhihu.com/p/100213425", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1577927904, "comment_count": 8, "image_url": "https://pic3.zhimg.com/v2-b1039e03b20b77e927662099d1ebdb50_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1581081637, "is_labeled": false, "excerpt": "终于迎来第 100 篇，在第 100 篇的时候讲一下自己的工作 TDL（AAAI-20 oral）。 TDL 是 target distribution learning 的简称。原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1905.11041.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Zhang Chuheng, Yuanqi Li, and Jian Li. &#34;Policy Search by Target Distribution Learning for Continuous Control.…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-f2c436c48509dcd95a841304431af852_b.jpg", "id": 92916888, "voteup_count": 118, "voting": 0, "title": "【强化学习 100】TDL", "url": "https://zhuanlan.zhihu.com/p/92916888", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1577693347, "comment_count": 41, "image_url": "https://pic3.zhimg.com/v2-f2c436c48509dcd95a841304431af852_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1577200320, "is_labeled": false, "excerpt": "【论文阅读】Mastering Complex Control in MOBA Games with Deep Reinforcement Learning 这个算法运用强化学习框架，在多人在线战术竞技游戏（MOBA）中1v1击败职业选手。<b>绝悟难在哪里？<\/b> 谷歌DeepMind早在2015年用深度Q网络就攻破了Ataria游戏，在2016年更…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-44c6b50c05ff6c06e5ecdf982dbc2ba5_b.jpg", "id": 99210924, "voteup_count": 9, "voting": 0, "title": "腾讯“绝悟”论文披露技术细节。", "url": "https://zhuanlan.zhihu.com/p/99210924", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic3.zhimg.com/v2-e7f3a66aff8bc0fda395148d2ca35b55_{size}.jpg", "uid": "707172804071538688", "user_type": "people", "is_following": false, "type": "people", "url_token": "he-zhi-qiang-52-74", "id": "a2034395b75bf8d0ddc35345035cf54d", "description": "个人公众号：深度学习与先进智能决策
公众号ID：MultiAgent1024
公众号介绍：主要研究深度学习，强化学习、机器博弈等相关内容！", "name": "小小何先生", "is_advertiser": false, "headline": "以爱与青春为名，陪你一路成长。", "gender": 1, "url": "/people/a2034395b75bf8d0ddc35345035cf54d", "avatar_url": "https://pic3.zhimg.com/v2-e7f3a66aff8bc0fda395148d2ca35b55_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "东北大学 信息科学与工程学院硕士在读"}]}, "state": "published", "created": 1577200320, "comment_count": 3, "image_url": "https://pic2.zhimg.com/v2-44c6b50c05ff6c06e5ecdf982dbc2ba5_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1574180884, "is_labeled": false, "excerpt": "给大家带来最新出炉的重磅 paper，在星际争霸 II 上打败人类选手的 AlphaStar。这篇工作在 10 月 30 日作为封面文章发表在 Nature 上。原文传送门<a href="https://link.zhihu.com/?target=https%3A//www.nature.com/articles/s41586-019-1724-z" class=" wrap external" target="_blank" rel="nofollow noreferrer">Vinyals, Oriol, et al. &#34;Grandmaster level in StarCraft II using multi-agent reinforcement learning.&#34; N…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-fb980efb3737db27af7de09a8f3af9cc_b.jpg", "id": 92543229, "voteup_count": 94, "voting": 0, "title": "【强化学习 99】AlphaStar", "url": "https://zhuanlan.zhihu.com/p/92543229", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1574180845, "comment_count": 13, "image_url": "https://pic1.zhimg.com/v2-fb980efb3737db27af7de09a8f3af9cc_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1572660218, "is_labeled": false, "excerpt": "加速的梯度下降算法。原文传送门<a href="https://link.zhihu.com/?target=https%3A//link.springer.com/article/10.1007/s10107-015-0871-8" class=" wrap external" target="_blank" rel="nofollow noreferrer">Ghadimi, Saeed, and Guanghui Lan. &#34;Accelerated gradient methods for nonconvex nonlinear and stochastic programming.&#34; Mathematical Programming 156.1-2 (2016): 59-99.<\/a>Beck, Amir. First-order methods in optimizat…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-84e401e0468b77377963c133da11eb12_b.jpg", "id": 89746131, "voteup_count": 28, "voting": 0, "title": "【优化】Accelerated Gradient", "url": "https://zhuanlan.zhihu.com/p/89746131", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1572660218, "comment_count": 4, "image_url": "https://pic2.zhimg.com/v2-84e401e0468b77377963c133da11eb12_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1572521753, "is_labeled": false, "excerpt": "这篇文章太经典了，今天在想某个问题的时候需要用到，由推导了一遍，做了个总结。原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1908.00261" class=" wrap external" target="_blank" rel="nofollow noreferrer">Agarwal, Alekh, et al. &#34;Optimality and Approximation with Policy Gradient Methods in Markov Decision Processes.&#34; arXiv preprint arXiv:1908.00261 (2019).<\/a>…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-c358c31d83f7ff8fc3a5874d679b3080_b.jpg", "id": 89529774, "voteup_count": 38, "voting": 0, "title": "【强化学习 98】PG Theory Summary", "url": "https://zhuanlan.zhihu.com/p/89529774", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1572521753, "comment_count": 1, "image_url": "https://pic3.zhimg.com/v2-c358c31d83f7ff8fc3a5874d679b3080_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1572341035, "is_labeled": false, "excerpt": "对于线性 MDP 模型，可以做线性函数拟合。原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1907.05388.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Jin, Chi, et al. &#34;Provably efficient reinforcement learning with linear function approximation.&#34; arXiv preprint arXiv:1907.05388 (2019).<\/a>特色 考虑对价值函数做函数拟合（function approximation…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-a08c7211bce17cd63dcfc91c6b3ff6c7_b.jpg", "id": 88931389, "voteup_count": 19, "voting": 0, "title": "【强化学习 97】Linear MDP", "url": "https://zhuanlan.zhihu.com/p/88931389", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1572341035, "comment_count": 1, "image_url": "https://pic4.zhimg.com/v2-a08c7211bce17cd63dcfc91c6b3ff6c7_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1572009106, "is_labeled": false, "excerpt": "还是继续前面因果推断的话题，这里讲一个从数据中做因果推断的另一种有效的方法——Instrumental variables（IV）。同时，也补充一个用深度学习方法来实现 IV 的一篇论文（ICML 2017）。原文传送门<a href="https://link.zhihu.com/?target=http%3A//www.soderbom.net/lec2n_final.pdf" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">http://www.<\/span><span class="visible">soderbom.net/lec2n_fina<\/span><span class="invisible">l.pdf<\/span><span class="ellipsis"><\/span><\/a><a href="https://link.zhihu.com/?target=http%3A//www3.grips.ac.jp/~yamanota/Lecture%2520Note%25208%2520to%252010%25202SLS%2520%26%2520others.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">http://www3.grips.ac.jp/~yamanota/<\/a><a href="https://link.zhihu.com/?target=http%3A//proceedings.mlr.press/v70/hartford17a/hartford17a.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">H…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-679c8ffef665c4b68e7d4aab6c5e0ba3_b.jpg", "id": 88235983, "voteup_count": 15, "voting": 0, "title": "【统计】Instrumental Variables", "url": "https://zhuanlan.zhihu.com/p/88235983", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1572009106, "comment_count": 2, "image_url": "https://pic4.zhimg.com/v2-679c8ffef665c4b68e7d4aab6c5e0ba3_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1571976522, "is_labeled": false, "excerpt": "还是继续前面因果推断的话题，不过这里更多地来讨论线性模型中的内生性误差（endogeneity bias），一个更通俗的名字叫做 sample selection bias。仍然基于一个网上的 lecture notes。原文传送门<a href="https://link.zhihu.com/?target=http%3A//www.soderbom.net/lec1n_final.pdf" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">http://www.<\/span><span class="visible">soderbom.net/lec1n_fina<\/span><span class="invisible">l.pdf<\/span><span class="ellipsis"><\/span><\/a>摘要在一定条件下，线性回归的系数表征了…", "admin_closed_comment": false, "reason": "", "title_image": "", "id": 88324835, "voteup_count": 12, "voting": 0, "title": "【统计】Endogeneity Bias", "url": "https://zhuanlan.zhihu.com/p/88324835", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1571973476, "comment_count": 0, "image_url": "", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1571882321, "is_labeled": false, "excerpt": "学习一下因果推断，做一个笔记。原文传送门<a href="https://link.zhihu.com/?target=http%3A//www.stat.cmu.edu/~larry/%3Dsml/Causation.pdf" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">http://www.<\/span><span class="visible">stat.cmu.edu/~larry/=sm<\/span><span class="invisible">l/Causation.pdf<\/span><span class="ellipsis"><\/span><\/a>过程一、Prediction 和 causation 的区别现实中遇到的很多问题实际上是因果问题，而不是预测。<b><i>因果问题分为两种<\/i><\/b>：一种是 causal inference，比如给定两个变量 X、Y，希望找到一个衡量它们之间…", "admin_closed_comment": false, "reason": "", "title_image": "", "id": 88173582, "voteup_count": 96, "voting": 0, "title": "【统计】Causal Inference", "url": "https://zhuanlan.zhihu.com/p/88173582", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1571882321, "comment_count": 6, "image_url": "", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1571317237, "is_labeled": false, "excerpt": "提出一种 bandit problem + causal inference 相结合的问题，给出相应的算法。原文传送门<a href="https://link.zhihu.com/?target=https%3A//papers.nips.cc/paper/6195-causal-bandits-learning-good-interventions-via-causal-inference.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Lattimore, Finnian, Tor Lattimore, and Mark D. Reid. &#34;Causal bandits: Learning good interventions via causal inference.&#34; Advances in Neural Information Pro…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-93cc1b5c7e4a555a6f7a5c0d79373f4d_b.jpg", "id": 87200142, "voteup_count": 23, "voting": 0, "title": "【强化学习 96】Causal Bandit", "url": "https://zhuanlan.zhihu.com/p/87200142", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1571317237, "comment_count": 0, "image_url": "https://pic3.zhimg.com/v2-93cc1b5c7e4a555a6f7a5c0d79373f4d_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1571231420, "is_labeled": false, "excerpt": "正则化的 Bellman 算子，导出了一系列的常见算法，比如 TRPO、SQL、SAC、DPP 等。原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1901.11275.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Geist, Matthieu, Bruno Scherrer, and Olivier Pietquin. &#34;A Theory of Regularized Markov Decision Processes.&#34; arXiv preprint arXiv:1901.11275 (2019).<\/a>特色…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-cf7377c5a14bf52f1ff6846fb1d82b62_b.jpg", "id": 86815675, "voteup_count": 26, "voting": 0, "title": "【强化学习 95】Regularized MDP", "url": "https://zhuanlan.zhihu.com/p/86815675", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1571231420, "comment_count": 1, "image_url": "https://pic2.zhimg.com/v2-cf7377c5a14bf52f1ff6846fb1d82b62_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1568899364, "is_labeled": false, "excerpt": "iMAML 全称是 implicit model-agnostic meta learning。原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1909.04630" class=" wrap external" target="_blank" rel="nofollow noreferrer">Rajeswaran, Aravind, et al. &#34;Meta-Learning with Implicit Gradients.&#34; arXiv preprint arXiv:1909.04630 (2019).<\/a><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1703.03400" class=" wrap external" target="_blank" rel="nofollow noreferrer">Finn, Chelsea, Pieter Abbeel, and Sergey Levine. &#34;Model-agnostic met…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-5c259ba1fe53a2bf528b5bffd881ebb6_b.jpg", "id": 83229175, "voteup_count": 54, "voting": 0, "title": "【机器学习 94】iMAML", "url": "https://zhuanlan.zhihu.com/p/83229175", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1568899364, "comment_count": 12, "image_url": "https://pic1.zhimg.com/v2-5c259ba1fe53a2bf528b5bffd881ebb6_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1568775009, "is_labeled": false, "excerpt": "这篇文章把 UCB 和 Q-learning 相结合，得到两种算法 UCB-H 和 UCB-B，这里把它们统记为 UCB + Q-learning。原文传送门<a href="https://link.zhihu.com/?target=https%3A//papers.nips.cc/paper/7735-is-q-learning-provably-efficient.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Jin, Chi, et al. &#34;Is q-learning provably efficient?.&#34; Advances in Neural Information Processing Systems. 2018.<\/a><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1807.03765" class=" wrap external" target="_blank" rel="nofollow noreferrer">Arxiv version (It…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-95e83d7d87e922ba61b18c6a26f9f0ff_b.jpg", "id": 82857779, "voteup_count": 34, "voting": 0, "title": "【强化学习 93】UCB+Q-learning", "url": "https://zhuanlan.zhihu.com/p/82857779", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1568775009, "comment_count": 4, "image_url": "https://pic2.zhimg.com/v2-95e83d7d87e922ba61b18c6a26f9f0ff_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1567047566, "is_labeled": false, "excerpt": "MAB 问题（multi-armed-bandit problem）在 non-stationary reward 设定下的一种算法分析。关于 MAB 问题的具体定义，可以看 Sutton 的书（大概是第二章）。原文传送门<a href="https://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/5378-stochastic-multi-armed-bandit-problem-with-non-stationary-rewards.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Besbes, Omar, Yonatan Gur, and Assaf Zeevi. &#34;Stochastic multi-armed-bandit problem…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-8a21aab080f18c994db59df50b4cd5e7_b.jpg", "id": 80252625, "voteup_count": 12, "voting": 0, "title": "【强化学习 92】Non-stationary MAB", "url": "https://zhuanlan.zhihu.com/p/80252625", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1567047566, "comment_count": 0, "image_url": "https://pic1.zhimg.com/v2-8a21aab080f18c994db59df50b4cd5e7_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1566564839, "is_labeled": false, "excerpt": "这么有名的一篇工作竟然没有笔记，今天重新看了一下，补一下笔记。原文传送门<a href="https://link.zhihu.com/?target=http%3A//homes.cs.washington.edu/~sham/papers/rl/aoarl.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Kakade, Sham, and John Langford. &#34;Approximately optimal approximate reinforcement learning.&#34; ICML. Vol. 2. 2002.<\/a>特色提出了 conservative policy iteration（CPI），在理…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-e2f9fe9a8661630e18826bc8c9290571_b.jpg", "id": 79478298, "voteup_count": 20, "voting": 0, "title": "【强化学习 91】Kakade&Langford 02'", "url": "https://zhuanlan.zhihu.com/p/79478298", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1566564839, "comment_count": 1, "image_url": "https://pic1.zhimg.com/v2-e2f9fe9a8661630e18826bc8c9290571_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1566404165, "is_labeled": false, "excerpt": "是非常新的一篇理论工作，从理论上分析 policy gradient 算法相关的各种性质。这篇文章比较长（有 71 页），我们分两次讲，这是第二部分。原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1908.00261" class=" wrap external" target="_blank" rel="nofollow noreferrer">Agarwal, Alekh, et al. &#34;Optimality and Approximation with Policy Gradient Methods in Markov Decisio…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-fcb9d4df7955b0d86320d3943bcf1dda_b.jpg", "id": 79182573, "voteup_count": 19, "voting": 0, "title": "【强化学习 90】PG Theory 2", "url": "https://zhuanlan.zhihu.com/p/79182573", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1566404165, "comment_count": 5, "image_url": "https://pic4.zhimg.com/v2-fcb9d4df7955b0d86320d3943bcf1dda_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1566404223, "is_labeled": false, "excerpt": "是非常新的一篇理论工作，从理论上分析 policy gradient 算法相关的各种性质。这篇文章比较长（有 71 页），我们分两次讲，这是第一部分。原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1908.00261" class=" wrap external" target="_blank" rel="nofollow noreferrer">Agarwal, Alekh, et al. &#34;Optimality and Approximation with Policy Gradient Methods in Markov Decisio…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-ca6da0474ead68fa57f921a2e5468129_b.jpg", "id": 78919869, "voteup_count": 40, "voting": 0, "title": "【强化学习 89】PG Theory 1", "url": "https://zhuanlan.zhihu.com/p/78919869", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1566297170, "comment_count": 4, "image_url": "https://pic1.zhimg.com/v2-ca6da0474ead68fa57f921a2e5468129_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1566045852, "is_labeled": false, "excerpt": "SPI 全称为 Safe Policy Iteration，ICML 2013。原文传送门<a href="https://link.zhihu.com/?target=http%3A//www.jmlr.org/proceedings/papers/v28/pirotta13.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Pirotta, Matteo, et al. &#34;Safe policy iteration.&#34; International Conference on Machine Learning. 2013.<\/a>特色Policy iteration 分为两步，policy evaluation 和 policy improvement，如果两步都…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-dde47b874973ee5a768fe55fbcc4a31c_b.jpg", "id": 78546794, "voteup_count": 3, "voting": 0, "title": "【强化学习 88】SPI", "url": "https://zhuanlan.zhihu.com/p/78546794", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1566045852, "comment_count": 0, "image_url": "https://pic4.zhimg.com/v2-dde47b874973ee5a768fe55fbcc4a31c_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1565109165, "is_labeled": false, "excerpt": "文章讲的是 non-parametric stochastic contextual bandits。原文传送门<a href="https://link.zhihu.com/?target=https%3A//www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/download/16944/16654" class=" wrap external" target="_blank" rel="nofollow noreferrer">Guan, Melody Y., and Heinrich Jiang. &#34;Nonparametric stochastic contextual bandits.&#34; Thirty-Second AAAI Conference on Artificial Intelligence. 2018.<\/a>特色问题设定：stochastic…", "admin_closed_comment": false, "reason": "", "title_image": "", "id": 76971342, "voteup_count": 7, "voting": 0, "title": "【强化学习 87】Nonparametric Bandits", "url": "https://zhuanlan.zhihu.com/p/76971342", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1565108943, "comment_count": 0, "image_url": "", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1565083646, "is_labeled": false, "excerpt": "一篇 2002 年的理论工作（NIPS），证明了一种能够保证收敛的 approximate policy iteration。原文传送门<a href="https://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/2143-a-convergent-form-of-approximate-policy-iteration.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Perkins, Theodore J., and Doina Precup. &#34;A convergent form of approximate policy iteration.&#34; Advances in neural information processing system…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-337f2356695d928887e2039a9d741111_b.jpg", "id": 76902806, "voteup_count": 12, "voting": 0, "title": "【强化学习 86】ConvergentAPI", "url": "https://zhuanlan.zhihu.com/p/76902806", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1565083565, "comment_count": 0, "image_url": "https://pic4.zhimg.com/v2-337f2356695d928887e2039a9d741111_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1564888830, "is_labeled": false, "excerpt": "算法名字就叫做 Actor-mimic，主要用途为 transfer learning。原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1511.06342" class=" wrap external" target="_blank" rel="nofollow noreferrer">Parisotto, Emilio, Jimmy Lei Ba, and Ruslan Salakhutdinov. &#34;Actor-mimic: Deep multitask and transfer reinforcement learning.&#34; arXiv preprint arXiv:1511.06342 (2015).<\/a>特色A…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-8beb6cce15067ea190d5d8a0efc7e9a3_b.jpg", "id": 76467908, "voteup_count": 15, "voting": 0, "title": "【强化学习 85】Actor-mimic", "url": "https://zhuanlan.zhihu.com/p/76467908", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1564888830, "comment_count": 1, "image_url": "https://pic4.zhimg.com/v2-8beb6cce15067ea190d5d8a0efc7e9a3_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1564796990, "is_labeled": false, "excerpt": "RERPI 不是官方的简称，个人标记一下，算法全称叫做 Relative Entropy Regularized Policy Iteration。原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1812.02256" class=" wrap external" target="_blank" rel="nofollow noreferrer">Abdolmaleki, Abbas, et al. &#34;Relative entropy regularized policy iteration.&#34; arXiv preprint arXiv:1812.02256 (2018).<\/a>特色前一讲做 MPO …", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-4706c7c229d0da31c94cc2575af4015b_b.jpg", "id": 76463750, "voteup_count": 3, "voting": 0, "title": "【强化学习 84】RERPI", "url": "https://zhuanlan.zhihu.com/p/76463750", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1564796990, "comment_count": 0, "image_url": "https://pic1.zhimg.com/v2-4706c7c229d0da31c94cc2575af4015b_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1564794734, "is_labeled": false, "excerpt": "Maximum a-posterior Policy Optimization 简称 MPO，ICLR 2018。原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1806.06920" class=" wrap external" target="_blank" rel="nofollow noreferrer">Abdolmaleki, Abbas, et al. &#34;Maximum a posteriori policy optimisation.&#34; arXiv preprint arXiv:1806.06920 (2018).<\/a>特色之前就见过一族基于 Expectation Maximization（EM）算法…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-29028640fbcc2399530c433f8db3ecf6_b.jpg", "id": 76299368, "voteup_count": 18, "voting": 0, "title": "【强化学习 83】MPO", "url": "https://zhuanlan.zhihu.com/p/76299368", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1564794734, "comment_count": 0, "image_url": "https://pic1.zhimg.com/v2-29028640fbcc2399530c433f8db3ecf6_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1563852604, "is_labeled": false, "excerpt": "这一篇讲第二章：Prediction with Expert Advice。原文传送门Cesa-Bianchi, Nicolo, and Gabor Lugosi.<i>Prediction, learning, and games<\/i>. Cambridge university press, 2006. 由于是图书，就不放链接了，直接 google 就能搜得到 PDF。特色针对前一讲提到的 …", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-d17eddb36dc4f026969547138793ea34_b.jpg", "id": 74722789, "voteup_count": 6, "voting": 0, "title": "【算法】Prediction2", "url": "https://zhuanlan.zhihu.com/p/74722789", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1563852604, "comment_count": 2, "image_url": "https://pic3.zhimg.com/v2-d17eddb36dc4f026969547138793ea34_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1563847859, "is_labeled": false, "excerpt": "之前导师就推荐了 <i>Prediction, learning, and games <\/i>这本书，最近的项目可能涉及相关的东西，所以来看一下。这一篇讲第一章：Introduction。原文传送门Cesa-Bianchi, Nicolo, and Gabor Lugosi.<i>Prediction, learning, and games<\/i>. Cambridge university pres…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-d17eddb36dc4f026969547138793ea34_b.jpg", "id": 74692626, "voteup_count": 30, "voting": 0, "title": "【算法】Prediction1", "url": "https://zhuanlan.zhihu.com/p/74692626", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1563788199, "comment_count": 2, "image_url": "https://pic3.zhimg.com/v2-d17eddb36dc4f026969547138793ea34_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1563677754, "is_labeled": false, "excerpt": "POLITEX 全称是 POLicy ITeration with EXpert advice。原文传送门<a href="https://link.zhihu.com/?target=http%3A//proceedings.mlr.press/v97/lazic19a/lazic19a-supp.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Abbasi-Yadkori, Yasin, et al. &#34;Politex: Regret Bounds for Policy Iteration using Expert Prediction.&#34; (2019).<\/a>特色使用 expert problem 研究中的 exponential weighted average（EWA）…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-8ebbeb1c6b7a7ba82b472a58a7d51e9f_b.jpg", "id": 74512862, "voteup_count": 12, "voting": 0, "title": "【强化学习 82】POLITEX", "url": "https://zhuanlan.zhihu.com/p/74512862", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1563677754, "comment_count": 2, "image_url": "https://pic1.zhimg.com/v2-8ebbeb1c6b7a7ba82b472a58a7d51e9f_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1563158431, "is_labeled": false, "excerpt": "NNQL 全称如标题所示，即 Nearest Neighbor Q-Learning。原文传送门<a href="https://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/7574-q-learning-with-nearest-neighbors.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Shah, Devavrat, and Qiaomin Xie. &#34;Q-learning with nearest neighbors.&#34; Advances in Neural Information Processing Systems. 2018.<\/a>特色设计了一个算法，使用 nearest neighbor regress…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-6bcd8f0845c3a07e1c19806b6af9b201_b.jpg", "id": 73561924, "voteup_count": 10, "voting": 0, "title": "【强化学习 81】NNQL", "url": "https://zhuanlan.zhihu.com/p/73561924", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1563158431, "comment_count": 0, "image_url": "https://pic2.zhimg.com/v2-6bcd8f0845c3a07e1c19806b6af9b201_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1562768588, "is_labeled": false, "excerpt": "DNC 的全称是 differentiable neural computer。原文传送门<a href="https://link.zhihu.com/?target=http%3A//campus.swarma.org/public/ueditor/php/upload/file/20170609/1497019302822809.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Graves, Alex, et al. &#34;Hybrid computing using a neural network with dynamic external memory.&#34; Nature 538.7626 (2016): 471.<\/a>特色2016 年的一篇 nature，主要传达了以下想法。在传统的神经网络…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-42b15a375a89cfb1a37b068e9171d732_b.jpg", "id": 73048250, "voteup_count": 10, "voting": 0, "title": "【强化学习 80】DNC", "url": "https://zhuanlan.zhihu.com/p/73048250", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1562768588, "comment_count": 2, "image_url": "https://pic3.zhimg.com/v2-42b15a375a89cfb1a37b068e9171d732_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1562722691, "is_labeled": false, "excerpt": "比较老的一篇 Exemplar-based，结合了演化算法。原文传送门<a href="https://link.zhihu.com/?target=https%3A//www.semanticscholar.org/paper/Exemplar-based-direct-policy-search-with-Ikeda/8687dd19bac7f8e278e7511d68b5468585f943bd" class=" wrap external" target="_blank" rel="nofollow noreferrer">Ikeda, Kokolo. &#34;Exemplar-based direct policy search with evolutionary optimization.&#34; 2005 IEEE Congress on Evolutionary Computation. Vol. 3. IEEE, 2005.<\/a>特色使用一个 exemplar 的集合来…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-f1183b5c69281e669bb90da97d5bc23c_b.jpg", "id": 72928419, "voteup_count": 8, "voting": 0, "title": "【强化学习 79】Exemplar", "url": "https://zhuanlan.zhihu.com/p/72928419", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1562722691, "comment_count": 0, "image_url": "https://pic1.zhimg.com/v2-f1183b5c69281e669bb90da97d5bc23c_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1562586508, "is_labeled": false, "excerpt": "kd-tree 是一种实现多维 k-nearest neighbor（kNN）的方法。原文传送门<a href="https://link.zhihu.com/?target=https%3A//www.ri.cmu.edu/pub_files/pub1/moore_andrew_1991_1/moore_andrew_1991_1.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Moore, Andrew W. &#34;An intoductory tutorial on kd-trees.&#34; (1991).<\/a>特色一种用来找多维向量最近邻的数据结构和相应算法，可用于 kNN。这篇文章除了讲了基本原理和算法，还给出了扩展性…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-66b24991ed8352c830a93ba4bedc05ef_b.jpg", "id": 72725372, "voteup_count": 21, "voting": 0, "title": "【算法】kd-tree", "url": "https://zhuanlan.zhihu.com/p/72725372", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1562586508, "comment_count": 0, "image_url": "https://pic4.zhimg.com/v2-66b24991ed8352c830a93ba4bedc05ef_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1562340936, "is_labeled": false, "excerpt": "Bayesian optimization，即贝叶斯优化。原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1807.02811.pdf%2520%28https%3A//arxiv.org/pdf/1807.02811.pdf%29" class=" wrap external" target="_blank" rel="nofollow noreferrer">Frazier, Peter I. &#34;A tutorial on bayesian optimization.&#34; arXiv preprint arXiv:1807.02811 (2018).<\/a><a href="https://link.zhihu.com/?target=http%3A//gpss.cc/gpmc17/slides/LancasterMasterclass_1.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Introduction to Bayesian Optimization (slides)<\/a>特色最近有做离子阱实验的同学涉及到一些实验参数的…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-3b4abdecf0be5e384c4443fcbdae5658_b.jpg", "id": 72403538, "voteup_count": 297, "voting": 0, "title": "【算法】Bayesian Optimization", "url": "https://zhuanlan.zhihu.com/p/72403538", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1562340936, "comment_count": 11, "image_url": "https://pic2.zhimg.com/v2-3b4abdecf0be5e384c4443fcbdae5658_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1561949675, "is_labeled": false, "excerpt": "Matching pursuit 是一种贪心算法，本科生的课程就应该学过，可惜我没有学过，现在来补课。原文传送门<a href="https://link.zhihu.com/?target=https%3A//link.springer.com/content/pdf/10.1023/A%3A1013955821559.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Vincent, Pascal, and Yoshua Bengio. &#34;Kernel matching pursuit.&#34; Machine learning 48.1-3 (2002): 165-187.<\/a>特色前面讲到了 RKHS 用于策略网络和价值函…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-df719a7189179b0bcc2ac8739c00fc24_b.jpg", "id": 71670694, "voteup_count": 12, "voting": 0, "title": "【算法】Matching Pursuit", "url": "https://zhuanlan.zhihu.com/p/71670694", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1561949675, "comment_count": 4, "image_url": "https://pic3.zhimg.com/v2-df719a7189179b0bcc2ac8739c00fc24_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1561800056, "is_labeled": false, "excerpt": "RKHS-AC 是 RKHS actor-critic framework 的简称，不是这篇文章自己叫的官方名字，是后续文章引用的时候给安的名字。原文传送门<a href="https://link.zhihu.com/?target=http%3A//www.jmlr.org/proceedings/papers/v38/lever15.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Lever, Guy, and Ronnie Stafford. &#34;Modelling policies in mdps in reproducing kernel hilbert space.&#34; Artificial Intellige…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-25e6011ab35e6f903fff4e9083eb8d49_b.jpg", "id": 71488213, "voteup_count": 11, "voting": 0, "title": "【强化学习 78】RKHS-AC", "url": "https://zhuanlan.zhihu.com/p/71488213", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1561800056, "comment_count": 0, "image_url": "https://pic4.zhimg.com/v2-25e6011ab35e6f903fff4e9083eb8d49_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1561777550, "is_labeled": false, "excerpt": "RKHS 即 reproducing kernel Hilbert space。原文传送门<a href="https://link.zhihu.com/?target=http%3A//www.jmlr.org/proceedings/papers/v38/lever15.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Lever, Guy, and Ronnie Stafford. &#34;Modelling policies in mdps in reproducing kernel hilbert space.&#34; Artificial Intelligence and Statistics. 2015.<\/a><a href="https://link.zhihu.com/?target=http%3A//www.stat.purdue.edu/~jianzhan/STAT598Y/NOTES/slt12.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Reproducing kernel Hilbert space (Lecture …<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-34e85e446b4ecf7b83f011db8ab19359_b.jpg", "id": 71503247, "voteup_count": 22, "voting": 0, "title": "【数学】RKHS", "url": "https://zhuanlan.zhihu.com/p/71503247", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1561777550, "comment_count": 0, "image_url": "https://pic2.zhimg.com/v2-34e85e446b4ecf7b83f011db8ab19359_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1571188293, "is_labeled": false, "excerpt": "DIAYN 算法全称是 Diversity Is All You Need，这里讲它以及同样这一拨人接着它做的一个 meta learning 的工作。原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1802.06070" class=" wrap external" target="_blank" rel="nofollow noreferrer">Eysenbach, Benjamin, et al. &#34;Diversity is all you need: Learning skills without a reward function.&#34; arXiv preprint arXiv:18…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-eed44a122651eebd55fac3e5df0bbdfb_b.jpg", "id": 70914500, "voteup_count": 7, "voting": 0, "title": "【强化学习 77】DIAYN", "url": "https://zhuanlan.zhihu.com/p/70914500", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1561542984, "comment_count": 2, "image_url": "https://pic1.zhimg.com/v2-eed44a122651eebd55fac3e5df0bbdfb_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1561163470, "is_labeled": false, "excerpt": "Neural episodic control 简称 NEC。原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1703.01988.pdf%3Futm_campaign%3DRevue%2520newsletter%26utm_medium%3DNewsletter%26utm_source%3Drevue" class=" wrap external" target="_blank" rel="nofollow noreferrer">Pritzel, Alexander, et al. &#34;Neural episodic control.&#34; Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 2017.<\/a>特色专栏前面讲的一篇综述（<a href="https://zhuanlan.zhihu.com/p/67243264" class="internal">【强化学习 64】Fas…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-e8aa3293270b571d3519b3b6b7edd8d0_b.jpg", "id": 70245337, "voteup_count": 12, "voting": 0, "title": "【强化学习 76】NEC", "url": "https://zhuanlan.zhihu.com/p/70245337", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1561163470, "comment_count": 0, "image_url": "https://pic1.zhimg.com/v2-e8aa3293270b571d3519b3b6b7edd8d0_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1561132776, "is_labeled": false, "excerpt": "AVF 是 adversarial value function 的缩写，这篇工作讲了一个学习 representation 的方法。原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1901.11530" class=" wrap external" target="_blank" rel="nofollow noreferrer">Bellemare, Marc G., et al. &#34;A Geometric Perspective on Optimal Representations for Reinforcement Learning.&#34; arXiv preprint arXiv:1901.11530 (2…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-caa1607bda55ebeef73b791b2968d20d_b.jpg", "id": 70150638, "voteup_count": 7, "voting": 0, "title": "【强化学习 75】AVF", "url": "https://zhuanlan.zhihu.com/p/70150638", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1561132776, "comment_count": 0, "image_url": "https://pic4.zhimg.com/v2-caa1607bda55ebeef73b791b2968d20d_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1561086731, "is_labeled": false, "excerpt": "原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1901.11524" class=" wrap external" target="_blank" rel="nofollow noreferrer">Dadashi, Robert, et al. &#34;The Value Function Polytope in Reinforcement Learning.&#34; arXiv preprint arXiv:1901.11524 (2019).<\/a>特色一篇理论的工作，描述了在 tabular case 下策略空间到价值函数的映射关系。虽然该映射是一个非线性的映射，但是…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-bfea14f4f0f775c0e8373db410a8c9bf_b.jpg", "id": 70027197, "voteup_count": 12, "voting": 0, "title": "【强化学习 74】Value Function Polytope", "url": "https://zhuanlan.zhihu.com/p/70027197", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1561086637, "comment_count": 3, "image_url": "https://pic1.zhimg.com/v2-bfea14f4f0f775c0e8373db410a8c9bf_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1560871525, "is_labeled": false, "excerpt": "强化学习问题的对偶形式。原文传送门<a href="https://link.zhihu.com/?target=https%3A//era.library.ualberta.ca/items/0f63c654-bfb8-4fe9-9bac-33f39b0a3377/view/72619678-d14c-46c1-b527-6f3d04a59971/TR06-26.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Wang, Tao, Michael Bowling, and Dale Schuurmans. &#34;Dual representations for dynamic programming and reinforcement learning.&#34; 2007 IEEE International Symposium on Approximate Dynamic Programming and Reinfor…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-d5bc63a24901a4d15ef44281e85e0cbd_b.jpg", "id": 69697253, "voteup_count": 18, "voting": 0, "title": "【强化学习 73】Dual Representation", "url": "https://zhuanlan.zhihu.com/p/69697253", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1560871525, "comment_count": 11, "image_url": "https://pic1.zhimg.com/v2-d5bc63a24901a4d15ef44281e85e0cbd_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1560740759, "is_labeled": false, "excerpt": "原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1903.00715.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Liu, Ruo-Ze, et al. &#34;Efficient Reinforcement Learning with a Mind-Game for Full-Length StarCraft II.&#34; arXiv preprint arXiv:1903.00715 (2019).<\/a>特色为了求解复杂MDP，有两个最为重要的方式：state abstraction，把庞大的状态空间通过某种…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-172fa49ccf9cf2f1b2618c39af965f85_b.jpg", "id": 69401252, "voteup_count": 9, "voting": 0, "title": "【强化学习 72】MindGame", "url": "https://zhuanlan.zhihu.com/p/69401252", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1560740759, "comment_count": 1, "image_url": "https://pic4.zhimg.com/v2-172fa49ccf9cf2f1b2618c39af965f85_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1560701094, "is_labeled": false, "excerpt": "原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1710.11089" class=" wrap external" target="_blank" rel="nofollow noreferrer">Machado, Marlos C., et al. &#34;Eigenoption discovery through the deep successor representation.&#34; arXiv preprint arXiv:1710.11089 (2017).<\/a>特色之前讲了两篇学习状态表示（representation）的文章，一篇讲PVF（<a href="https://zhuanlan.zhihu.com/p/68326687" class="internal">【强化学习 67】Proto-value Fun…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-65a615eadfc0f86acfd68b57cbf7e6f2_b.jpg", "id": 69324580, "voteup_count": 9, "voting": 0, "title": "【强化学习 71】Successor Representation", "url": "https://zhuanlan.zhihu.com/p/69324580", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1560701094, "comment_count": 4, "image_url": "https://pic2.zhimg.com/v2-65a615eadfc0f86acfd68b57cbf7e6f2_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1560256049, "is_labeled": false, "excerpt": "继续强化学习在金融上的应用调研。原文传送门<a href="https://link.zhihu.com/?target=http%3A//citeseerx.ist.psu.edu/viewdoc/download%3Fdoi%3D10.1.1.231.8113%26rep%3Drep1%26type%3Dpdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Matsui, Tohgoroh, et al. &#34;Compound reinforcement learning: Theory and an application to finance.&#34; European Workshop on Reinforcement Learning. Springer, Berlin, Heidelberg, 2011.<\/a><a href="https://link.zhihu.com/?target=http%3A//citeseerx.ist.psu.edu/viewdoc/download%3Fdoi%3D10.1.1.1.7210%26rep%3Drep1%26type%3Dpdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Moody, John, and M…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-f4ea2b72547402e1da73e8cb6de17584_b.jpg", "id": 68742981, "voteup_count": 15, "voting": 0, "title": "【强化学习应用 70】Finance 1", "url": "https://zhuanlan.zhihu.com/p/68742981", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1560256049, "comment_count": 0, "image_url": "https://pic4.zhimg.com/v2-f4ea2b72547402e1da73e8cb6de17584_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1560222532, "is_labeled": false, "excerpt": "讲强化学习如何应用到高频股票交易上。原文传送门<a href="https://link.zhihu.com/?target=http%3A//www.cis.upenn.edu/~mkearns/papers/rlexec.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Nevmyvaka, Yuriy, Yi Feng, and Michael Kearns. &#34;Reinforcement learning for optimized trade execution.&#34; Proceedings of the 23rd international conference on Machine learning. ACM, 2006.<\/a>特色强化…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-f87200b57a22b1e6431dc9a0bd0edda4_b.jpg", "id": 68654927, "voteup_count": 16, "voting": 0, "title": "【强化学习应用 69】Trade Execution", "url": "https://zhuanlan.zhihu.com/p/68654927", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1560222532, "comment_count": 0, "image_url": "https://pic3.zhimg.com/v2-f87200b57a22b1e6431dc9a0bd0edda4_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1559925490, "is_labeled": false, "excerpt": "DeepMDP可以看做是对于原来MDP的一个抽象。原文传送门<a href="https://link.zhihu.com/?target=http%3A//proceedings.mlr.press/v97/gelada19a/gelada19a.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Gelada, Carles, et al. &#34;DeepMDP: Learning Continuous Latent Space Models for Representation Learning.&#34; International Conference on Machine Learning. 2019.<\/a>特色前面讲了很多state abstraction…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-fe0d56511c9c30d0718b512d07123ecc_b.jpg", "id": 68364144, "voteup_count": 21, "voting": 0, "title": "【强化学习 68】DeepMDP", "url": "https://zhuanlan.zhihu.com/p/68364144", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1559925490, "comment_count": 3, "image_url": "https://pic2.zhimg.com/v2-fe0d56511c9c30d0718b512d07123ecc_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1559911384, "is_labeled": false, "excerpt": "原文传送门<a href="https://link.zhihu.com/?target=http%3A//www.jmlr.org/papers/volume8/mahadevan07a/mahadevan07a.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Mahadevan, Sridhar, and Mauro Maggioni. &#34;Proto-value functions: A Laplacian framework for learning representation and control in Markov decision processes.&#34; Journal of Machine Learning Research 8.Oct (2007): 2169-2231.<\/a>特色本文介…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-da6bc36664dbd8704c19f6607639c8a0_b.jpg", "id": 68326687, "voteup_count": 15, "voting": 0, "title": "【强化学习 67】Proto-value Function", "url": "https://zhuanlan.zhihu.com/p/68326687", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1559911384, "comment_count": 2, "image_url": "https://pic4.zhimg.com/v2-da6bc36664dbd8704c19f6607639c8a0_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1559559389, "is_labeled": false, "excerpt": "这是UIUC姜楠老师开设的<a href="https://link.zhihu.com/?target=http%3A//nanjiang.cs.illinois.edu/cs598/" class=" wrap external" target="_blank" rel="nofollow noreferrer">CS598统计强化学习（理论）课程<\/a>的第六讲，这一讲的主要内容是Fitted Q-iteration。原文传送门<a href="https://link.zhihu.com/?target=http%3A//nanjiang.cs.illinois.edu/files/cs598/note6.pdf" data-draft-node="block" data-draft-type="link-card" class=" wrap external" target="_blank" rel="nofollow noreferrer">CS598 Note6<\/a> 一、Importance sampling1. 估计期望当要估计 \mathbb{E}_{x\sim p}[f(x)] 的时候，如果可以从分布 p 中采样，那么可以直接把…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-f52407083267e425bfee742410a7ee69_b.jpg", "id": 67915561, "voteup_count": 8, "voting": 0, "title": "【强化学习理论 66】StatisticalRL 9", "url": "https://zhuanlan.zhihu.com/p/67915561", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1559559389, "comment_count": 0, "image_url": "https://pic4.zhimg.com/v2-f52407083267e425bfee742410a7ee69_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1565057633, "is_labeled": false, "excerpt": "这是UIUC姜楠老师开设的<a href="https://link.zhihu.com/?target=http%3A//nanjiang.cs.illinois.edu/cs598/" class=" wrap external" target="_blank" rel="nofollow noreferrer">CS598统计强化学习（理论）课程<\/a>的第五讲，这一讲的主要内容是Fitted Q-iteration。原文传送门<a href="https://link.zhihu.com/?target=http%3A//nanjiang.cs.illinois.edu/files/cs598/note5.pdf" data-draft-node="block" data-draft-type="link-card" class=" wrap external" target="_blank" rel="nofollow noreferrer">CS598 Note5<\/a>回顾在很多基础的强化学习书里面我们已经证明了Bellman operator是一个 \gamma -contraction，它说明在<b>tabular case<\/b>和<b>infinite…<\/b>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-3f8565ecf10a95dfc2f93874b0fbfc2e_b.jpg", "id": 67489674, "voteup_count": 4, "voting": 0, "title": "【强化学习理论 65】StatisticalRL 8", "url": "https://zhuanlan.zhihu.com/p/67489674", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1559221276, "comment_count": 2, "image_url": "https://pic2.zhimg.com/v2-3f8565ecf10a95dfc2f93874b0fbfc2e_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1559131030, "is_labeled": false, "excerpt": "这里的Fast and Slow指的是快速的学习或者慢速的学习。原文传送门<a href="https://link.zhihu.com/?target=https%3A//www.sciencedirect.com/science/article/pii/S1364661319300610" class=" wrap external" target="_blank" rel="nofollow noreferrer">Botvinick, Mathew, et al. &#34;Reinforcement Learning, Fast and Slow.&#34; Trends in cognitive sciences (2019).<\/a>特色这是关于强化学习的一篇很有见地的review，这个月才发表的。它还从心理学和…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-fc16d873edf8852d631a7c438df255ac_b.jpg", "id": 67243264, "voteup_count": 26, "voting": 0, "title": "【强化学习 64】Fast and Slow", "url": "https://zhuanlan.zhihu.com/p/67243264", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1559131030, "comment_count": 4, "image_url": "https://pic3.zhimg.com/v2-fc16d873edf8852d631a7c438df255ac_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1559010811, "is_labeled": false, "excerpt": "一篇综述。原文传送门<a href="https://link.zhihu.com/?target=https%3A//ieeexplore.ieee.org/abstract/document/6918520/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Liu, Chunming, Xin Xu, and Dewen Hu. &#34;Multiobjective reinforcement learning: A comprehensive overview.&#34; IEEE Transactions on Systems, Man, and Cybernetics: Systems 45.3 (2014): 385-398.<\/a>特色因为最近想了解一下multiobject…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-9f5f7122f39ae23d1d0871d2a87551a5_b.jpg", "id": 67195729, "voteup_count": 18, "voting": 0, "title": "【强化学习 64】Multiobjective RL", "url": "https://zhuanlan.zhihu.com/p/67195729", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1559010811, "comment_count": 0, "image_url": "https://pic3.zhimg.com/v2-9f5f7122f39ae23d1d0871d2a87551a5_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1558845803, "is_labeled": false, "excerpt": "这是UIUC姜楠老师开设的<a href="https://link.zhihu.com/?target=http%3A//nanjiang.cs.illinois.edu/cs598/" class=" wrap external" target="_blank" rel="nofollow noreferrer">CS598统计强化学习（理论）课程<\/a>的第四讲的第三部分，第四讲主要内容是state abstraction，这一部分主要是对 state abstraction 做 finite sample analysis，即要学习到一个 abstracted MDP 需要多少样本。原文传送门<a href="https://link.zhihu.com/?target=http%3A//nanjiang.cs.illinois.edu/files/cs598/note4.pdf" data-draft-node="block" data-draft-type="link-card" class=" wrap external" target="_blank" rel="nofollow noreferrer">CS598 Note4<\/a>回顾…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-75861aa27ec6b1d1669807857e097097_b.jpg", "id": 67027334, "voteup_count": 7, "voting": 0, "title": "【强化学习理论 63】StatisticalRL 7", "url": "https://zhuanlan.zhihu.com/p/67027334", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1558845803, "comment_count": 0, "image_url": "https://pic2.zhimg.com/v2-75861aa27ec6b1d1669807857e097097_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1558840826, "is_labeled": false, "excerpt": "这是UIUC姜楠老师开设的<a href="https://link.zhihu.com/?target=http%3A//nanjiang.cs.illinois.edu/cs598/" class=" wrap external" target="_blank" rel="nofollow noreferrer">CS598统计强化学习（理论）课程<\/a>的第四讲的第二部分，主要讲的内容是state abstraction。原文传送门<a href="https://link.zhihu.com/?target=http%3A//nanjiang.cs.illinois.edu/files/cs598/note4.pdf" data-draft-node="block" data-draft-type="link-card" class=" wrap external" target="_blank" rel="nofollow noreferrer">CS598 Note4<\/a> 回顾对于如下的定义有以下性质 这几个定理的关系如下要用第二种近似bound第一种近似，即找到一个 \pi 满足第一种近似中…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-eee5bec15a576b9f8b91c813037a3324_b.jpg", "id": 66840574, "voteup_count": 7, "voting": 0, "title": "【强化学习理论 62】StatisticalRL 6", "url": "https://zhuanlan.zhihu.com/p/66840574", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1558754569, "comment_count": 0, "image_url": "https://pic1.zhimg.com/v2-eee5bec15a576b9f8b91c813037a3324_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1558668308, "is_labeled": false, "excerpt": "这是UIUC姜楠老师开设的<a href="https://link.zhihu.com/?target=http%3A//nanjiang.cs.illinois.edu/cs598/" class=" wrap external" target="_blank" rel="nofollow noreferrer">CS598统计强化学习（理论）课程<\/a>的第四讲的第一部分，主要讲的内容是state abstraction。原文传送门<a href="https://link.zhihu.com/?target=http%3A//nanjiang.cs.illinois.edu/files/cs598/note4.pdf" data-draft-node="block" data-draft-type="link-card" class=" wrap external" target="_blank" rel="nofollow noreferrer">CS598 Note4<\/a>导言前一讲里面我们看到，要学习到一个足够好的策略，需要的样本数是和状态空间大小 |\mathcal{S}| 有呈多项式关系的。当…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-4c8eb7307e770fd924eeed70fc40e46a_b.jpg", "id": 65791924, "voteup_count": 10, "voting": 0, "title": "【强化学习理论 61】StatisticalRL 5", "url": "https://zhuanlan.zhihu.com/p/65791924", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1558668308, "comment_count": 4, "image_url": "https://pic4.zhimg.com/v2-4c8eb7307e770fd924eeed70fc40e46a_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1557850704, "is_labeled": false, "excerpt": "这是UIUC姜楠老师开设的<a href="https://link.zhihu.com/?target=http%3A//nanjiang.cs.illinois.edu/cs598/" class=" wrap external" target="_blank" rel="nofollow noreferrer">CS598统计强化学习（理论）课程<\/a>的第三讲。原文传送门<a href="https://link.zhihu.com/?target=http%3A//nanjiang.cs.illinois.edu/files/cs598/note3.pdf" data-draft-node="block" data-draft-type="link-card" class=" wrap external" target="_blank" rel="nofollow noreferrer">CS598 Note3<\/a>摘要这一讲主要讲的是certainty-equivalence及其理论分析，这个名字我也是第一次听说，也没太懂这两个词和所讲的东西是什么关系。MDP模型（主要是dynamics P 和reward …", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-624f0eb7654554063bc62739f0e5b970_b.jpg", "id": 65759756, "voteup_count": 3, "voting": 0, "title": "【强化学习理论 60】StatisticalRL 4", "url": "https://zhuanlan.zhihu.com/p/65759756", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1557850704, "comment_count": 0, "image_url": "https://pic1.zhimg.com/v2-624f0eb7654554063bc62739f0e5b970_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1557827218, "is_labeled": false, "excerpt": "这是UIUC姜楠老师开设的<a href="https://link.zhihu.com/?target=http%3A//nanjiang.cs.illinois.edu/cs598/" class=" wrap external" target="_blank" rel="nofollow noreferrer">CS598统计强化学习（理论）课程<\/a>的第二讲。原文传送门<a data-draft-node="block" data-draft-type="link-card" href="https://link.zhihu.com/?target=http%3A//nanjiang.cs.illinois.edu/files/cs598/note_bandit.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">CS598 Note2<\/a>一、Hoeffding&#39;s Inequality初等的统计学过中心极限定理，它们告诉我们当i.i.d.样本很多的时候，在sample上的统计量就会趋向于真实的统计量。这里就更定量化的告诉我们…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-05121a9ff0cb4654e9229cee7ebb2bda_b.jpg", "id": 65676020, "voteup_count": 5, "voting": 0, "title": "【强化学习理论 59】StatisticalRL 3", "url": "https://zhuanlan.zhihu.com/p/65676020", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1557826656, "comment_count": 0, "image_url": "https://pic3.zhimg.com/v2-05121a9ff0cb4654e9229cee7ebb2bda_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1557796802, "is_labeled": false, "excerpt": "这是UIUC姜楠老师开设的<a href="https://link.zhihu.com/?target=http%3A//nanjiang.cs.illinois.edu/cs598/" class=" wrap external" target="_blank" rel="nofollow noreferrer">CS598统计强化学习（理论）课程<\/a>的第一讲（第二部分），之所以拆成两个部分是因为图片贴多了之后知乎编辑变得特别卡。我们继续。原文传送门<a href="https://link.zhihu.com/?target=http%3A//nanjiang.cs.illinois.edu/files/cs598/note1.pdf" data-draft-node="block" data-draft-type="link-card" class=" wrap external" target="_blank" rel="nofollow noreferrer">CS598 Note1<\/a>二、MDP上的规划规划（Planning）的目标是optimal control即找到最优策略或者最优…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-dd88831d08188edc9831170cff17dbe0_b.jpg", "id": 65620649, "voteup_count": 7, "voting": 0, "title": "【强化学习理论 58】StatisticalRL 2", "url": "https://zhuanlan.zhihu.com/p/65620649", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1557796802, "comment_count": 5, "image_url": "https://pic3.zhimg.com/v2-dd88831d08188edc9831170cff17dbe0_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1557796832, "is_labeled": false, "excerpt": "这是UIUC姜楠老师开设的<a href="https://link.zhihu.com/?target=http%3A//nanjiang.cs.illinois.edu/cs598/" class=" wrap external" target="_blank" rel="nofollow noreferrer">CS598统计强化学习（理论）课程<\/a>的第一讲（第一部分），由于最近在研究state abstraction相关的东西，因此准备借此机会刷一下这个课程，强化一下自己在RL理论方面的水平。原文传送门<a href="https://link.zhihu.com/?target=http%3A//nanjiang.cs.illinois.edu/files/cs598/note1.pdf" data-draft-node="block" data-draft-type="link-card" class=" wrap external" target="_blank" rel="nofollow noreferrer">CS598 Note1<\/a>备注此系列Notes写的很好，如果大家有兴…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-dd88831d08188edc9831170cff17dbe0_b.jpg", "id": 65599582, "voteup_count": 18, "voting": 0, "title": "【强化学习理论 57】StatisticalRL 1", "url": "https://zhuanlan.zhihu.com/p/65599582", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1557747167, "comment_count": 3, "image_url": "https://pic3.zhimg.com/v2-dd88831d08188edc9831170cff17dbe0_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1557315794, "is_labeled": false, "excerpt": "GMN的全称是Graph Matching Network。原文传送门<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1904.12787" class=" wrap external" target="_blank" rel="nofollow noreferrer">Li, Yujia, et al. &#34;Graph Matching Networks for Learning the Similarity of Graph Structured Objects.&#34; arXiv preprint arXiv:1904.12787 (2019).<\/a>特色这篇文章主要提出了两种基于深度学习判断图（graph）…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-f696f9b3ef1f4fe454963efed0992991_b.jpg", "id": 65080269, "voteup_count": 19, "voting": 0, "title": "【深度学习 56】GMN", "url": "https://zhuanlan.zhihu.com/p/65080269", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1557315794, "comment_count": 8, "image_url": "https://pic4.zhimg.com/v2-f696f9b3ef1f4fe454963efed0992991_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1555898583, "is_labeled": false, "excerpt": "一篇综述，把里面有意思的东西摘录一下。<b>原文传送门<\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1803.04706" class=" wrap external" target="_blank" rel="nofollow noreferrer">Sigaud, Olivier, and Freek Stulp. &#34;Policy search in continuous action domains: an overview.&#34; Neural Networks (2019).<\/a><b>特色<\/b>连续控制方向的策略搜索（policy search）综述，该综述比较新，不仅涵盖了…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-19403edf42f26d4a33bd7d55d8bc26bf_b.jpg", "id": 63240355, "voteup_count": 21, "voting": 0, "title": "【强化学习 55】连续控制策略搜索", "url": "https://zhuanlan.zhihu.com/p/63240355", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1555898583, "comment_count": 5, "image_url": "https://pic4.zhimg.com/v2-19403edf42f26d4a33bd7d55d8bc26bf_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1555895885, "is_labeled": false, "excerpt": "AIQN是Autoregressive Implicit Quantile Network的简称。<b>原文传送门<\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1806.05575" class=" wrap external" target="_blank" rel="nofollow noreferrer">Ostrovski, Georg, Will Dabney, and Rémi Munos. &#34;Autoregressive quantile networks for generative modeling.&#34; arXiv preprint arXiv:1806.05575 (2018).<\/a><b>特色<\/b>这是一个做生成模型（gen…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-0c103cc225d6fbbb1fbebddb276417cd_b.jpg", "id": 63177972, "voteup_count": 12, "voting": 0, "title": "【机器学习 54】AIQN", "url": "https://zhuanlan.zhihu.com/p/63177972", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1555895885, "comment_count": 0, "image_url": "https://pic3.zhimg.com/v2-0c103cc225d6fbbb1fbebddb276417cd_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1554898953, "is_labeled": false, "excerpt": "2002年的老文章了，natural policy gradient。<b>原文传送门<\/b><a href="https://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/2073-a-natural-policy-gradient.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Kakade, Sham M. &#34;A natural policy gradient.&#34; Advances in neural information processing systems. 2002.<\/a><b>特色<\/b>Natural gradient用到强化学习策略梯度方法上，搭配TRPO食用效果更好。<b>过程<\/b><b>1. 自然梯度<\/b>…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-9f232a28a9a3110f333b5740586c524a_b.jpg", "id": 62003433, "voteup_count": 6, "voting": 0, "title": "【强化学习 53】Natural PG", "url": "https://zhuanlan.zhihu.com/p/62003433", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1554898953, "comment_count": 4, "image_url": "https://pic1.zhimg.com/v2-9f232a28a9a3110f333b5740586c524a_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1554603402, "is_labeled": false, "excerpt": "NAF是normalized advantage function的简称，可以看做是连续控制版本的Q-learning。<b>原文传送门<\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1603.00748" class=" wrap external" target="_blank" rel="nofollow noreferrer">Gu, Shixiang, et al. &#34;Continuous deep q-learning with model-based acceleration.&#34; International Conference on Machine Learning. 2016.<\/a><b>特色<\/b>本文提出了NAF…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-61e7cff2a19438f4d4c4fb42d5b406b0_b.jpg", "id": 61588665, "voteup_count": 14, "voting": 0, "title": "【强化学习 52】NAF", "url": "https://zhuanlan.zhihu.com/p/61588665", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1554603402, "comment_count": 6, "image_url": "https://pic1.zhimg.com/v2-61e7cff2a19438f4d4c4fb42d5b406b0_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1554426860, "is_labeled": false, "excerpt": "文章提出了一种Experience Replay的改进，叫做Remember and Forget Experience Replay，简称ReF-ER；在此基础上把它应用到了之前的ACER（Actor-critic with Experience Replay），形成RACER。<b>原文传送门<\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1807.05827" class=" wrap external" target="_blank" rel="nofollow noreferrer">Novati, Guido, and Petros Koumoutsakos. &#34;Remember …<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-fde7779c20d884b5742c500ff8763cef_b.jpg", "id": 61392615, "voteup_count": 17, "voting": 0, "title": "【强化学习 51】RACER", "url": "https://zhuanlan.zhihu.com/p/61392615", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1554426860, "comment_count": 8, "image_url": "https://pic2.zhimg.com/v2-fde7779c20d884b5742c500ff8763cef_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1554085403, "is_labeled": false, "excerpt": "全称是Distributed Distributional Deep Deterministic Policy Gradient，简称D4PG。<b>原文传送门<\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1804.08617" class=" wrap external" target="_blank" rel="nofollow noreferrer">Barth-Maron, Gabriel, et al. &#34;Distributed distributional deterministic policy gradients.&#34; arXiv preprint arXiv:1804.08617 (2018).<\/a><b>特色<\/b>本来以为这一篇是…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-bb09b8219ae5debcf17089cdf918c343_b.jpg", "id": 61014409, "voteup_count": 14, "voting": 0, "title": "【强化学习 50】D4PG", "url": "https://zhuanlan.zhihu.com/p/61014409", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1554085403, "comment_count": 5, "image_url": "https://pic3.zhimg.com/v2-bb09b8219ae5debcf17089cdf918c343_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1554040543, "is_labeled": false, "excerpt": "还是接着前两篇的工作，这里讲Implicit Quantile Network。<b>原文传送门<\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1806.06923" class=" wrap external" target="_blank" rel="nofollow noreferrer">Dabney, Will, et al. &#34;Implicit quantile networks for distributional reinforcement learning.&#34; arXiv preprint arXiv:1806.06923 (2018).<\/a><b>特色<\/b>神经网络的输入里面外加一个均匀分布采…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-4253b1dfcd402cfac694c183338387b9_b.jpg", "id": 60949506, "voteup_count": 11, "voting": 0, "title": "【强化学习 49】IQN", "url": "https://zhuanlan.zhihu.com/p/60949506", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1554040189, "comment_count": 2, "image_url": "https://pic3.zhimg.com/v2-4253b1dfcd402cfac694c183338387b9_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1554040326, "is_labeled": false, "excerpt": "紧接着前面Distributional RL做的工作<b>原文传送门<\/b><a href="https://link.zhihu.com/?target=https%3A//www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPDFInterstitial/17184/16590" class=" wrap external" target="_blank" rel="nofollow noreferrer">Dabney, Will, et al. &#34;Distributional reinforcement learning with quantile regression.&#34; Thirty-Second AAAI Conference on Artificial Intelligence. 2018.<\/a><b>特色<\/b>专栏前一篇讲了distributional RL，使用价…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-1e5724a64f5e29e7bb032f3bc393b614_b.jpg", "id": 60912847, "voteup_count": 16, "voting": 0, "title": "【强化学习 48】Quantile Regression", "url": "https://zhuanlan.zhihu.com/p/60912847", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1553960489, "comment_count": 4, "image_url": "https://pic1.zhimg.com/v2-1e5724a64f5e29e7bb032f3bc393b614_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1553821974, "is_labeled": false, "excerpt": "一篇很有启发性的工作，目前主流的强化学习方法主要关注价值函数的均值，这里提出把价值函数的分布也考虑进来。<b>原文传送门<\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1707.06887" class=" wrap external" target="_blank" rel="nofollow noreferrer">Bellemare, Marc G., Will Dabney, and Rémi Munos. &#34;A distributional perspective on reinforcement learning.&#34; Proceedings of t…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-1aa6bd6a904b9c5f502a37a443d7c851_b.jpg", "id": 60632660, "voteup_count": 57, "voting": 0, "title": "【强化学习 47】Distributional RL", "url": "https://zhuanlan.zhihu.com/p/60632660", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1553764474, "comment_count": 3, "image_url": "https://pic1.zhimg.com/v2-1aa6bd6a904b9c5f502a37a443d7c851_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1552480908, "is_labeled": false, "excerpt": "<b>原文传送门<\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1803.07246" class=" wrap external" target="_blank" rel="nofollow noreferrer">Wu, Cathy, et al. &#34;Variance reduction for policy gradient with action-dependent factorized baselines.&#34; arXiv preprint arXiv:1803.07246 (2018). <\/a>（ICLR 2018）<b>特色<\/b>Baseline 是 policy gradient 类方法的一个重要的减小方差的手段，这里针…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-33e2e6f90ea13278691ae95d8af7ebf7_b.jpg", "id": 59171310, "voteup_count": 9, "voting": 0, "title": "【强化学习 46】Action-dependent Baseline", "url": "https://zhuanlan.zhihu.com/p/59171310", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1552480908, "comment_count": 2, "image_url": "https://pic2.zhimg.com/v2-33e2e6f90ea13278691ae95d8af7ebf7_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1566268357, "is_labeled": false, "excerpt": "今天来学一个数学知识，Wasserstein Distance。如果听说过WGAN的话，里面的W就是代表Wasserstein。<b>参考资料<\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1806.05500" class=" wrap external" target="_blank" rel="nofollow noreferrer">Panaretos, Victor M., and Yoav Zemel. &#34;Statistical aspects of Wasserstein distances.&#34; Annual Review of Statistics and Its Application (201…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-645fb1cc16e355c62a450ea09e15a14c_b.jpg", "id": 58506295, "voteup_count": 222, "voting": 0, "title": "【数学】Wasserstein Distance", "url": "https://zhuanlan.zhihu.com/p/58506295", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1551925385, "comment_count": 24, "image_url": "https://pic1.zhimg.com/v2-645fb1cc16e355c62a450ea09e15a14c_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1576792628, "is_labeled": false, "excerpt": "VIN 的全程为 value iteration network，是2016年 NIPS best paper。<b>原文传送门<\/b><a href="https://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/6046-value-iteration-networks.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Tamar, Aviv, et al. &#34;Value iteration networks.&#34; Advances in Neural Information Processing Systems. 2016.<\/a><b>特色<\/b>本文主要设计了一种新的策略表示，这种策略表示仍然是使用神…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-2730d65cf1986ee1aa3b76fe639ff684_b.jpg", "id": 58371146, "voteup_count": 10, "voting": 0, "title": "【强化学习 45】VIN", "url": "https://zhuanlan.zhihu.com/p/58371146", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1551787020, "comment_count": 5, "image_url": "https://pic1.zhimg.com/v2-2730d65cf1986ee1aa3b76fe639ff684_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1551834091, "is_labeled": false, "excerpt": "这篇文章主要讲了两个重要的技术：IMPALA全称是IMPortance weighted Actor-Learner Architecture，V-trace和之前本专栏讲的Retrace类似，只不过Retrace估计的是Q函数，这里估计的是V函数，因此叫V-trace。<b>原文传送门<\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1802.01561" class=" wrap external" target="_blank" rel="nofollow noreferrer">Espeholt, Lasse, et al. &#34;Impala: Scala…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-5dcf9d2d0bad74c3550c99db3523702f_b.jpg", "id": 58226117, "voteup_count": 26, "voting": 0, "title": "【强化学习 44】IMPALA/V-trace", "url": "https://zhuanlan.zhihu.com/p/58226117", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1551695890, "comment_count": 2, "image_url": "https://pic2.zhimg.com/v2-5dcf9d2d0bad74c3550c99db3523702f_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1551584523, "is_labeled": false, "excerpt": "全称为Importance Weighted Evolution Strategies（正如标题）。<b>原文传送门<\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1811.04624" class=" wrap external" target="_blank" rel="nofollow noreferrer">Campos, Víctor, Xavier Giro-i-Nieto, and Jordi Torres. &#34;Importance Weighted Evolution Strategies.&#34; arXiv preprint arXiv:1811.04624 (2018).<\/a><b>特色<\/b>本文之前讲过一篇使用演化…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-fe3d6f380f6ebe39448c16d66c91e608_b.jpg", "id": 58161674, "voteup_count": 8, "voting": 0, "title": "【强化学习 43】IW-ES", "url": "https://zhuanlan.zhihu.com/p/58161674", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1551584523, "comment_count": 0, "image_url": "https://pic1.zhimg.com/v2-fe3d6f380f6ebe39448c16d66c91e608_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1551578558, "is_labeled": false, "excerpt": "随手找的一篇比较近的使用neuroevolution方法做强化学习的文章。<b>原文传送门<\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1703.03864" class=" wrap external" target="_blank" rel="nofollow noreferrer">Salimans, Tim, et al. &#34;Evolution strategies as a scalable alternative to reinforcement learning.&#34; arXiv preprint arXiv:1703.03864 (2017).<\/a><b>特色<\/b>大家来了解一下 Neuroevoluti…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-a6078044a2a95e68987d16d0646bbd04_b.jpg", "id": 58159409, "voteup_count": 8, "voting": 0, "title": "【强化学习 42】Neuroevolution", "url": "https://zhuanlan.zhihu.com/p/58159409", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1551578558, "comment_count": 2, "image_url": "https://pic4.zhimg.com/v2-a6078044a2a95e68987d16d0646bbd04_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1551489453, "is_labeled": false, "excerpt": "Go-Explore是uber团队开发的算法，直观的意思是走到最好的状态（Go），然后从这个状态开始探索（Explore）。<b>原文传送门<\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1901.10995" class=" wrap external" target="_blank" rel="nofollow noreferrer">Ecoffet, Adrien, et al. &#34;Go-Explore: a New Approach for Hard-Exploration Problems.&#34; arXiv preprint arXiv:1901.10995 (2019).<\/a><b>特色<\/b>…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic1.zhimg.com/v2-11210974f862247312ff89351b4edac2_b.jpg", "id": 58053501, "voteup_count": 16, "voting": 0, "title": "【强化学习 41】Go-Explore", "url": "https://zhuanlan.zhihu.com/p/58053501", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1551489453, "comment_count": 2, "image_url": "https://pic1.zhimg.com/v2-11210974f862247312ff89351b4edac2_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1550924486, "is_labeled": false, "excerpt": "Google Brain和DeepMind合作的一个model-based强化学习算法——Deep Planning Network（PlaNet）。<b>原文传送门<\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1811.04551" class=" wrap external" target="_blank" rel="nofollow noreferrer">Hafner, Danijar, et al. &#34;Learning Latent Dynamics for Planning from Pixels.&#34; arXiv preprint arXiv:1811.04551 (2018).<\/a><b>特色<\/b>一种基于模型（mo…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-9f2b42aa87a2d3b1d1939aa41e755dba_b.jpg", "id": 57468070, "voteup_count": 25, "voting": 0, "title": "【强化学习 40】PlaNet", "url": "https://zhuanlan.zhihu.com/p/57468070", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1550924486, "comment_count": 1, "image_url": "https://pic2.zhimg.com/v2-9f2b42aa87a2d3b1d1939aa41e755dba_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1550333678, "is_labeled": false, "excerpt": "春节假期没啥意思，加了几天班，在老丈人家继续追了AlphaStar相关的技术（效率极低，后来演变成每天看一部电影了~流浪地球不错~绝对国产第一部硬科幻电影），然后就看到了这个DeepMind在2016年出的一篇论文。个人觉得这个论文很有用，显然2017年DeepMind出…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-f0310d78b3e9b3ebd074a08cbf9380c9_b.jpg", "id": 56391653, "voteup_count": 30, "voting": 0, "title": "RL Algorithm: Retrace", "url": "https://zhuanlan.zhihu.com/p/56391653", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic2.zhimg.com/a7f705d126a5c3ca8cac811c1ea0f596_{size}.jpg", "uid": "681207051770793984", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-ming-28-20", "id": "cfe3bfe923caa874d68c94bd1de2151d", "description": "不够勤奋的工程师", "name": "starimpact", "is_advertiser": false, "headline": "计算视觉", "gender": 1, "url": "/people/cfe3bfe923caa874d68c94bd1de2151d", "avatar_url": "https://pic2.zhimg.com/a7f705d126a5c3ca8cac811c1ea0f596_l.jpg", "is_org": false, "badge": []}, "state": "published", "created": 1549727267, "comment_count": 8, "image_url": "https://pic4.zhimg.com/v2-f0310d78b3e9b3ebd074a08cbf9380c9_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1550387224, "is_labeled": false, "excerpt": "前两天DeepMind终于爆出了在星际2上的最新进展，我是看着羡慕（详见：<a href="https://link.zhihu.com/?target=https%3A//deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/" class=" wrap external" target="_blank" rel="nofollow noreferrer">AlphaStar: Mastering the Real-Time Strategy Game StarCraft II | DeepMind<\/a>）。里面提到了应用到的各种技术：Transformer, LSTM, pointer network, novel off-policy actor-critic rl,…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-94f9308f50f6183575daed66f99ca160_b.jpg", "id": 56043646, "voteup_count": 68, "voting": 0, "title": "AlphaStar之IMPALA", "url": "https://zhuanlan.zhihu.com/p/56043646", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic2.zhimg.com/a7f705d126a5c3ca8cac811c1ea0f596_{size}.jpg", "uid": "681207051770793984", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-ming-28-20", "id": "cfe3bfe923caa874d68c94bd1de2151d", "description": "不够勤奋的工程师", "name": "starimpact", "is_advertiser": false, "headline": "计算视觉", "gender": 1, "url": "/people/cfe3bfe923caa874d68c94bd1de2151d", "avatar_url": "https://pic2.zhimg.com/a7f705d126a5c3ca8cac811c1ea0f596_l.jpg", "is_org": false, "badge": []}, "state": "published", "created": 1548860860, "comment_count": 10, "image_url": "https://pic4.zhimg.com/v2-94f9308f50f6183575daed66f99ca160_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1549003224, "is_labeled": false, "excerpt": "<b>目录<\/b>让策略梯度形式简单 —— Policy Gradient Theorem用最简单的采样方法来实现 —— REINFORCE两个网络一台戏 —— Actor-Critic应用到高维行动空间 —— DPG策略梯度类也可以玩Atari —— 从DQN到DDPG<b>引言<\/b>强化学习领域最为核心的问题是<b><i>控制问题<\/i><\/b>（control…", "admin_closed_comment": false, "reason": "", "title_image": "", "id": 56128287, "voteup_count": 31, "voting": 0, "title": "【强化学习入门 3】强化学习策略梯度类方法", "url": "https://zhuanlan.zhihu.com/p/56128287", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1549003224, "comment_count": 0, "image_url": "", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1554301309, "is_labeled": false, "excerpt": "<b>目录<\/b>初识时间差分方法 —— TD(0)从少量状态到数不清的状态 —— 函数逼近技术从TD(0)到MC的过渡 —— TD(\lambda)用强化学习来玩游戏 —— DQN<b>引言<\/b>强化学习的目标是找到能够最大化收益的策略，其中一类重要的方法是策略迭代类的方法。这类方法的的主要特征…", "admin_closed_comment": false, "reason": "", "title_image": "", "id": 56058343, "voteup_count": 15, "voting": 0, "title": "【强化学习入门 2】强化学习策略迭代类方法", "url": "https://zhuanlan.zhihu.com/p/56058343", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1548868652, "comment_count": 3, "image_url": "", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1554042933, "is_labeled": false, "excerpt": "<b>目录<\/b>强化学习基本概念马可夫决策模型价值函数Bellman算子Value Iteration和Policy Iteration动态规划方法蒙特卡洛方法<b>引言<\/b>强化学习学习的是一个策略，目前主要有三大类学习的框架，它们分别是<b><i>策略迭代方法<\/i><\/b>（policy iteration method）、<b><i>策略梯度方法<\/i><\/b>（polic…", "admin_closed_comment": false, "reason": "", "title_image": "", "id": 56045177, "voteup_count": 50, "voting": 0, "title": "【强化学习入门 1】从零开始认识强化学习", "url": "https://zhuanlan.zhihu.com/p/56045177", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1548863069, "comment_count": 10, "image_url": "", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1548729560, "is_labeled": false, "excerpt": "这篇文章并没有提出什么新算法，只是考察了一下不用神经网络而是使用一些简单的特征表示（linear or RBF representation）是不是也能在benchmark上有较好的效果。<b>原文传送门<\/b><a href="https://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/7233-towards-generalization-and-simplicity-in-continuous-control.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Rajeswaran, Aravind, et al. &#34;Towards generalization and simplicity in continu…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic4.zhimg.com/v2-ea4c88e2941b3cab9c1daab7e57e19ff_b.jpg", "id": 55936841, "voteup_count": 3, "voting": 0, "title": "【强化学习 39】Linear/RBF Representation", "url": "https://zhuanlan.zhihu.com/p/55936841", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1548729560, "comment_count": 0, "image_url": "https://pic4.zhimg.com/v2-ea4c88e2941b3cab9c1daab7e57e19ff_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1548686184, "is_labeled": false, "excerpt": "这是刚刚发表在Science子刊上的一篇工作，开创性地把强化学习成功应用到了实体的四足机器人ANYmal上。<b>原文传送门<\/b><a href="https://link.zhihu.com/?target=http%3A//robotics.sciencemag.org/content/4/26/eaau5872.abstract" class=" wrap external" target="_blank" rel="nofollow noreferrer">Hwangbo, Jemin, et al. &#34;Learning agile and dynamic motor skills for legged robots.&#34; Science Robotics 4.26 (2019): eaau5872.<\/a><b>特色<\/b>迄今，…", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-a10f8e6e9402ce15f0b0b39f58f5294a_b.jpg", "id": 55906656, "voteup_count": 57, "voting": 0, "title": "【强化学习 38】RL ANYmal", "url": "https://zhuanlan.zhihu.com/p/55906656", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1548686105, "comment_count": 6, "image_url": "https://pic3.zhimg.com/v2-a10f8e6e9402ce15f0b0b39f58f5294a_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1544497909, "is_labeled": false, "excerpt": "PCVI/PCQL分别是Policy-Class Value Iteration和Policy-class Q-learning的简称，是最新出炉的NIPS 2018 best paper。<b>原文传送门<\/b><a href="https://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/8200-non-delusional-q-learning-and-value-iteration.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Lu, Tyler, Dale Schuurmans, and Craig Boutilier. &#34;Non-delusional Q-learning and value-iteration.&#34; Advances in Neural I…<\/a>", "admin_closed_comment": false, "reason": "", "title_image": "https://pic2.zhimg.com/v2-994da736dcad4603786b766cfa443c98_b.jpg", "id": 52026503, "voteup_count": 18, "voting": 0, "title": "【强化学习算法 37】PCVI/PCQL", "url": "https://zhuanlan.zhihu.com/p/52026503", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1544497909, "comment_count": 3, "image_url": "https://pic2.zhimg.com/v2-994da736dcad4603786b766cfa443c98_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}, {"updated": 1558184449, "is_labeled": false, "excerpt": "PPO-CMA算法是一个把PPO和CMA-ES算法相结合的一个model-free强化学习算法。<b>原文传送门<\/b><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1810.02541" class=" wrap external" target="_blank" rel="nofollow noreferrer">Hämäläinen, Perttu, et al. &#34;PPO-CMA: Proximal Policy Optimization with Covariance Matrix Adaptation.&#34; arXiv preprint arXiv:1810.02541 (2018).<\/a>（under …", "admin_closed_comment": false, "reason": "", "title_image": "https://pic3.zhimg.com/v2-aa74f0b4ef682e129bc8d35bfbb1a646_b.jpg", "id": 51611652, "voteup_count": 11, "voting": 0, "title": "【强化学习算法 36】PPO-CMA", "url": "https://zhuanlan.zhihu.com/p/51611652", "comment_permission": "all", "author": {"is_followed": false, "avatar_url_template": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_{size}.jpg", "uid": "35077274730496", "user_type": "people", "is_following": false, "type": "people", "url_token": "zhang-chu-heng", "id": "db39e3e0528520071b0a6e5f6240cfea", "description": "", "name": "张楚珩", "is_advertiser": false, "headline": "强化学习 量化投资", "gender": 1, "url": "/people/db39e3e0528520071b0a6e5f6240cfea", "avatar_url": "https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg", "is_org": false, "badge": [{"topics": [], "type": "identity", "description": "清华大学 交叉信息院博士在读"}]}, "state": "published", "created": 1544000760, "comment_count": 0, "image_url": "https://pic3.zhimg.com/v2-aa74f0b4ef682e129bc8d35bfbb1a646_b.jpg", "excerpt_title": "", "can_comment": {"status": true, "reason": ""}, "type": "article", "suggest_edit": {"status": false, "url": "", "reason": "", "tip": "", "title": ""}}]}