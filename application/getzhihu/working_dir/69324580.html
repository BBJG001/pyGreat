<!doctype html>
<html lang="zh" data-hairline="true" data-theme="light"><head><meta charSet="utf-8"/><title data-react-helmet="true">【强化学习 71】Successor Representation - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"/><meta name="renderer" content="webkit"/><meta name="force-rendering" content="webkit"/><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg"/><meta data-react-helmet="true" name="keywords" content="强化学习 (Reinforcement Learning)"/><meta data-react-helmet="true" name="description" content="原文传送门Machado, Marlos C., et al. &amp;#34;Eigenoption discovery through the deep successor representation.&amp;#34; arXiv preprint arXiv:1710.11089 (2017).特色之前讲了两篇学习状态表示（representation）…"/><meta data-react-helmet="true" property="og:title" content="【强化学习 71】Successor Representation"/><meta data-react-helmet="true" property="og:url" content="https://zhuanlan.zhihu.com/p/69324580"/><meta data-react-helmet="true" property="og:description" content="原文传送门Machado, Marlos C., et al. &amp;#34;Eigenoption discovery through the deep successor representation.&amp;#34; arXiv preprint arXiv:1710.11089 (2017).特色之前讲了两篇学习状态表示（representation）…"/><meta data-react-helmet="true" property="og:image" content="https://pic2.zhimg.com/v2-65a615eadfc0f86acfd68b57cbf7e6f2_b.jpg"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" property="og:site_name" content="知乎专栏"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png" sizes="152x152"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-120.b3e6278d.png" sizes="120x120"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-76.7a750095.png" sizes="76x76"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-60.a4a761d4.png" sizes="60x60"/><link rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/static/favicon.ico"/><link rel="search" type="application/opensearchdescription+xml" href="https://static.zhihu.com/static/search.xml" title="知乎"/><link rel="dns-prefetch" href="//static.zhimg.com"/><link rel="dns-prefetch" href="//pic1.zhimg.com"/><link rel="dns-prefetch" href="//pic2.zhimg.com"/><link rel="dns-prefetch" href="//pic3.zhimg.com"/><link rel="dns-prefetch" href="//pic4.zhimg.com"/><style>
.u-safeAreaInset-top {
  height: constant(safe-area-inset-top) !important;
  height: env(safe-area-inset-top) !important;
  
}
.u-safeAreaInset-bottom {
  height: constant(safe-area-inset-bottom) !important;
  height: env(safe-area-inset-bottom) !important;
  
}
</style><link href="https://static.zhihu.com/heifetz/column.app.a9ced452148fee3a55c8.css" rel="stylesheet"/><script defer="" crossorigin="anonymous" src="https://unpkg.zhimg.com/@cfe/sentry-script@latest/dist/init.js" data-sentry-config="{&quot;dsn&quot;:&quot;https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224&quot;,&quot;sampleRate&quot;:0.1,&quot;release&quot;:&quot;683-127b14ad&quot;,&quot;ignoreErrorNames&quot;:[&quot;NetworkError&quot;,&quot;SecurityError&quot;],&quot;ignoreErrors&quot;:[&quot;origin message&quot;,&quot;Network request failed&quot;,&quot;Loading chunk&quot;,&quot;这个系统不支持该功能。&quot;,&quot;Can&#x27;t find variable: webkit&quot;,&quot;Can&#x27;t find variable: $&quot;,&quot;内存不足&quot;,&quot;out of memory&quot;,&quot;DOM Exception 18&quot;,&quot;The operation is insecure&quot;,&quot;[object Event]&quot;,&quot;[object FileError]&quot;,&quot;[object DOMError]&quot;,&quot;[object Object]&quot;,&quot;拒绝访问。&quot;,&quot;Maximum call stack size exceeded&quot;,&quot;UploadError&quot;,&quot;无法 fetch&quot;,&quot;draft-js&quot;,&quot;缺少 JavaScript 对象&quot;,&quot;componentWillEnter&quot;,&quot;componentWillLeave&quot;,&quot;componentWillAppear&quot;,&quot;getInlineStyleAt&quot;,&quot;getCharacterList&quot;],&quot;whitelistUrls&quot;:[&quot;static.zhihu.com&quot;]}"></script></head><body class="WhiteBg-body"><div id="root"><div class="App"><div class="LoadingBar"></div><main role="main" class="App-main"><div class="Post-content" data-zop-usertoken="{&quot;userToken&quot;:&quot;&quot;}" data-zop="{&quot;authorName&quot;:&quot;张楚珩&quot;,&quot;itemId&quot;:69324580,&quot;title&quot;:&quot;【强化学习 71】Successor Representation&quot;,&quot;type&quot;:&quot;article&quot;}"><div class="ColumnPageHeader-Wrapper"><div><div class="Sticky ColumnPageHeader"><div class="ColumnPageHeader-content"><a href="//www.zhihu.com" aria-label="知乎"><svg viewBox="0 0 200 91" fill="#0084FF" width="64" height="30"><path d="M53.29 80.035l7.32.002 2.41 8.24 13.128-8.24h15.477v-67.98H53.29v67.978zm7.79-60.598h22.756v53.22h-8.73l-8.718 5.473-1.587-5.46-3.72-.012v-53.22zM46.818 43.162h-16.35c.545-8.467.687-16.12.687-22.955h15.987s.615-7.05-2.68-6.97H16.807c1.09-4.1 2.46-8.332 4.1-12.708 0 0-7.523 0-10.085 6.74-1.06 2.78-4.128 13.48-9.592 24.41 1.84-.2 7.927-.37 11.512-6.94.66-1.84.785-2.08 1.605-4.54h9.02c0 3.28-.374 20.9-.526 22.95H6.51c-3.67 0-4.863 7.38-4.863 7.38H22.14C20.765 66.11 13.385 79.24 0 89.62c6.403 1.828 12.784-.29 15.937-3.094 0 0 7.182-6.53 11.12-21.64L43.92 85.18s2.473-8.402-.388-12.496c-2.37-2.788-8.768-10.33-11.496-13.064l-4.57 3.627c1.363-4.368 2.183-8.61 2.46-12.71H49.19s-.027-7.38-2.372-7.38zm128.752-.502c6.51-8.013 14.054-18.302 14.054-18.302s-5.827-4.625-8.556-1.27c-1.874 2.548-11.51 15.063-11.51 15.063l6.012 4.51zm-46.903-18.462c-2.814-2.577-8.096.667-8.096.667s12.35 17.2 12.85 17.953l6.08-4.29s-8.02-11.752-10.83-14.33zM199.99 46.5c-6.18 0-40.908.292-40.953.292v-31.56c1.503 0 3.882-.124 7.14-.376 12.773-.753 21.914-1.25 27.427-1.504 0 0 3.817-8.496-.185-10.45-.96-.37-7.24 1.43-7.24 1.43s-51.63 5.153-72.61 5.64c.5 2.756 2.38 5.336 4.93 6.11 4.16 1.087 7.09.53 15.36.277 7.76-.5 13.65-.76 17.66-.76v31.19h-41.71s.88 6.97 7.97 7.14h33.73v22.16c0 4.364-3.498 6.87-7.65 6.6-4.4.034-8.15-.36-13.027-.566.623 1.24 1.977 4.496 6.035 6.824 3.087 1.502 5.054 2.053 8.13 2.053 9.237 0 14.27-5.4 14.027-14.16V53.93h38.235c3.026 0 2.72-7.432 2.72-7.432z" fill-rule="evenodd"></path></svg></a><i class="ColumnPageHeader-Line"></i><div class="ColumnPageHeader-Title"><a class="ColumnLink ColumnPageHeader-Link" href="/reinforcementlearning"><img class="Avatar Avatar--round" width="30" height="30" src="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_is.jpg" srcSet="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_im.jpg 2x" alt="强化学习前沿"/></a><div class="ColumnPageHeader-TitleName"><span class="ColumnPageHeader-TitleMeta">首发于</span><a class="ColumnLink ColumnPageHeader-TitleColumn" href="/reinforcementlearning">强化学习前沿</a></div></div><div class="ColumnPageHeader-Button"><button type="button" class="Button ColumnPageHeader-WriteButton Button--blue"><svg class="Zi Zi--EditSurround" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M18.453 7.992l-1.833-1.65.964-.978a1.223 1.223 0 0 1 1.73-.012l.005.006a1.24 1.24 0 0 1 .007 1.748l-.873.886zm-1.178 1.194l-5.578 5.66-1.935.697a.393.393 0 0 1-.504-.504l.697-1.935 5.488-5.567 1.832 1.65zM7.58 5.848l5.654.006-1.539 1.991-3.666.012A1.02 1.02 0 0 0 7 8.868v7.993c0 .558.46 1.01 1.029 1.01l7.941-.01c.568 0 1.03-.453 1.03-1.012v-4.061l2-1.442v6.002c0 1.397-1.2 2.501-2.62 2.501H7.574C6.153 19.85 5 18.717 5 17.32V8.35c0-1.397 1.16-2.502 2.58-2.502z"></path></svg>写文章</button></div></div></div></div></div><img class="TitleImage" src="https://pic2.zhimg.com/v2-65a615eadfc0f86acfd68b57cbf7e6f2_1200x500.jpg" alt="【强化学习 71】Successor Representation"/><article class="Post-Main Post-NormalMain" tabindex="-1"><header class="Post-Header"><h1 class="Post-Title">【强化学习 71】Successor Representation</h1><div class="Post-Author"><div class="AuthorInfo" itemProp="author" itemscope="" itemType="http://schema.org/Person"><meta itemProp="name" content="张楚珩"/><meta itemProp="image" content="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg"/><meta itemProp="url" content="https://www.zhihu.com/people/zhang-chu-heng"/><meta itemProp="zhihu:followerCount"/><span class="UserLink AuthorInfo-avatarWrapper"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/zhang-chu-heng"><img class="Avatar Avatar--round AuthorInfo-avatar" width="38" height="38" src="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_xs.jpg" srcSet="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg 2x" alt="张楚珩"/></a></div></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/zhang-chu-heng">张楚珩</a></div></div><style data-emotion-css="1cd9gw4">.css-1cd9gw4{margin-left:.3em;}</style><style data-emotion-css="1pc1mic">.css-1pc1mic{box-sizing:border-box;margin:0;min-width:0;color:#175199;display:inline-block;width:18px;height:18px;margin-left:.3em;}</style><a href="https://www.zhihu.com/question/48510028" target="_blank" class="css-1pc1mic" data-tooltip="已认证的个人" aria-label="已认证的个人"><style data-emotion-css="18biwo">.css-18biwo{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><span class="css-18biwo">​<svg viewBox="0 0 24 24" width="18" height="18"><svg viewBox="0 0 24 24" x="-3" y="-3" fill="#FFFFFF" width="30" height="30"><path d="M3.56231227,13.8535307 C2.40051305,12.768677 2.41398885,11.0669203 3.59484487,9.99979213 L3.59222085,9.99654885 C4.26730143,9.45036719 4.79446755,8.21005186 4.7184197,7.34453784 L4.72305873,7.34412719 C4.66942824,5.75539997 5.8824188,4.56066914 7.47188965,4.64242381 L7.47229112,4.6386236 C8.33515314,4.72977993 9.58467253,4.22534048 10.1426329,3.55925173 L10.1462611,3.56228565 C11.2316055,2.40008701 12.9353108,2.41394456 14.0015072,3.59634088 L14.0047263,3.59374004 C14.5498229,4.26841874 15.7896857,4.79521622 16.6545744,4.71844347 L16.6549836,4.72304294 C18.245027,4.66894057 19.4396947,5.88213996 19.3575031,7.47241135 L19.3623099,7.47292747 C19.2704388,8.3358681 19.7742711,9.58421483 20.4407199,10.1424506 L20.437686,10.1460789 C21.5997217,11.2312209 21.5860695,12.9345218 20.4042441,14.0007396 L20.4072865,14.0045125 C19.7325967,14.5495925 19.2055209,15.7896954 19.2815865,16.6561959 L19.2770449,16.6565978 C19.3315454,18.2453037 18.1173775,19.4393568 16.5274188,19.3571512 L16.5269029,19.3619539 C15.6647098,19.270083 14.415408,19.7741709 13.8573671,20.4403558 L13.8537409,20.4373235 C12.76842,21.5995708 11.0650432,21.5864553 9.99899434,20.4039226 L9.99527367,20.406923 C9.45025436,19.7323399 8.21017638,19.2051872 7.34461983,19.2812352 L7.344304,19.2776405 C5.75448683,19.3312904 4.55977145,18.1170085 4.64254978,16.527117 L4.63769921,16.5265942 C4.72957031,15.6644394 4.22547659,14.4151814 3.55928015,13.8571569 L3.56231227,13.8535307 Z"></path></svg><path d="M2.63951518,13.3895441 C3.70763333,14.2842292 4.44777637,16.1226061 4.30075305,17.5023312 L4.32211542,17.3063047 C4.17509209,18.6910561 5.17786655,19.7063729 6.5613937,19.5844846 L6.364106,19.6008202 C7.75140298,19.4789319 9.57474349,20.2554985 10.4468305,21.3349009 L10.3224262,21.1803415 C11.1982831,22.2647703 12.6257916,22.2723098 13.5167278,21.2079863 L13.3898102,21.3600325 C14.2845162,20.2919393 16.1229361,19.5518136 17.5026934,19.6988334 L17.3054057,19.6774716 C18.6914461,19.8244915 19.7067866,18.8217404 19.5836389,17.4395022 L19.6012314,17.6367853 C19.4793403,16.2482641 20.255925,14.4249662 21.3353526,13.5528995 L21.1807897,13.677301 C22.2639871,12.8014646 22.2727834,11.3739894 21.2084351,10.483074 L21.3604848,10.6099886 C20.2923667,9.71530351 19.5522236,7.87818322 19.6992469,6.49720154 L19.6778846,6.69448464 C19.8249079,5.30847665 18.8221335,4.2944164 17.4386063,4.41630468 L17.635894,4.39871256 C16.248597,4.52185742 14.4252565,3.74529084 13.5531695,2.66588842 L13.6775738,2.81919121 C12.8017169,1.73601905 11.3742084,1.72722299 10.4832722,2.79154644 L10.6101898,2.63950024 C9.71548377,3.70759343 7.87706394,4.44771919 6.49730661,4.30195588 L6.69459432,4.32206116 C5.30855394,4.17504128 4.29447,5.17904888 4.41636114,6.56128713 L4.3987686,6.36400404 C4.52065973,7.75126861 3.74407501,9.57456653 2.66464737,10.4478898 L2.81921035,10.3222318 C1.73601288,11.1993248 1.72721662,12.6255433 2.79156494,13.5164587 L2.63951518,13.3895441 Z" fill="#0084FF"></path><svg class="Zi Zi--Check" fill="#fff" x="6" y="6" viewBox="0 0 24 24" width="12" height="12"><path d="M10.229 17.516c-.318.327-.75.484-1.199.484-.453 0-.884-.16-1.202-.488l-4.335-4.47a1.77 1.77 0 0 1 .007-2.459 1.663 1.663 0 0 1 2.397.01l3.137 3.246 9.072-9.329a1.662 1.662 0 0 1 2.397 0c.663.681.663 1.786 0 2.466L10.23 17.516z" fill-rule="evenodd"></path></svg></svg></span></a></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="AuthorInfo-badgeText">清华大学 交叉信息院博士在读</div></div></div></div></div></div><div><span class="Voters"><button type="button" class="Button Button--plain">9 人<!-- -->赞同了该文章</button></span></div></header><div class="Post-RichTextContainer"><div class="RichText ztext Post-RichText"><h2>原文传送门</h2><p><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1710.11089" class=" wrap external" target="_blank" rel="nofollow noreferrer">Machado, Marlos C., et al. &#34;Eigenoption discovery through the deep successor representation.&#34; arXiv preprint arXiv:1710.11089 (2017).</a></p><h2>特色</h2><p>之前讲了两篇学习状态表示（representation）的文章，一篇讲PVF（<a href="https://zhuanlan.zhihu.com/p/68326687" class="internal">【强化学习 67】Proto-value Function</a>），一篇讲DeepMDP（<a href="https://zhuanlan.zhihu.com/p/68364144" class="internal">【强化学习 68】DeepMDP</a>）。它们都可以看做是对于环境模型的压缩，其中前者只考虑环境本身的动力学特性（dynamics），后者不仅考虑环境的动力学特性，还考虑环境的奖励函数；因此，前者可以用于meta learning，而后者则更贴近要学习的任务，同时理论上能有更直接的关于学到策略性能的bound。</p><p>这里也是想学习一种状态表示，并且这种状态表示只反映环境的特性（即dynamics），不涉及具体的任务（即reward）。这样的表示有以下优势：</p><ul><li>当环境上的任务变化的时候，该方法学到的状态表示依然有用，即适用于meta learning的设定；</li><li>当任务给出的奖励稀疏或者具有误导性的时候，该表示能够探索到环境本身的特性，并且利用学习到的环境性质来指导智能体探索。</li></ul><p>本文就是想从对于MDP的随机采样（stochastic sampling）的样本中学习到这样一种状态表示，进而提取出环境的性质做分层强化学习，详细的介绍见下一部分。</p><h2>过程</h2><h3>1. 总体思路</h3><p>本文先通过在MDP上的随机采样来学习一个表示（successor representation），并且从该表示下得到一个关于环境的刻画（一个状态空间上的diffusion matrix），从而得到与环境有关的辅助奖励函数（eigenpurpose），最大化该奖励函数能够形成相应的更为抽象的行动（eigenoption），进而产生一个基于option的分层强化学习算法（参考<a href="https://zhuanlan.zhihu.com/p/47051292" class="internal">【强化学习算法 20】Option-Critic</a>）。</p><h3>2. 回顾PVF</h3><p>PVF（proto-value function）方法使用不同状态之间的转移关系构建一个状态之间的转移矩阵 <img src="https://www.zhihu.com/equation?tex=W" alt="W" eeimg="1"/> ，使用该转移矩阵构建随机游走的一步转移概率矩阵 <img src="https://www.zhihu.com/equation?tex=T_r" alt="T_r" eeimg="1"/> （或者相应的diffusion model <img src="https://www.zhihu.com/equation?tex=L" alt="L" eeimg="1"/> ），对该矩阵进行特征值分解，其最大的 <img src="https://www.zhihu.com/equation?tex=k" alt="k" eeimg="1"/> 个特征值对应的特征向量可以作为其价值函数的基向量。注，原文用的 <img src="https://www.zhihu.com/equation?tex=P_r" alt="P_r" eeimg="1"/> ，为了和这篇文章统一，就写作 <img src="https://www.zhihu.com/equation?tex=T_r" alt="T_r" eeimg="1"/> 。</p><p>对于一个特征向量 <img src="https://www.zhihu.com/equation?tex=e" alt="e" eeimg="1"/> ，它的每一位表示一个状态的某种性质的数值。回顾PVF里面的两个小房间的例子：比如某特征向量数值大表示该状态位于第一个小房间，否则位于第二个小房间；再比如某特征向量数值大的表示该状态位于房间内距离goal较远的一侧。</p><p>分层强化学习里面的option相当于一个达到特定目的的一连串动作或者子策略，有一些工作里面option的目标是人为定义的，当然最好的情况是能够自动探索并且发现option。PVF里面得到的特征向量提供了一个自动探索option的方法。刚刚说到一个特征向量中各个状态的数值代表着它对于环境某方面性质的刻画，因此自然想到对于一个特征向量，定义一个option，使得该option朝着该特征向量数值较大/小的方向走。这样得到的option也叫eigenoption。eigenoption的定义可以通过定义相应的eigenpurpose（reward）得到，最大化该奖励得到的子策略就是eigenpurpose，由此，容易想到定义它为</p><p><img src="https://www.zhihu.com/equation?tex=r%28s%2Cs%27%29%3De%28s%27%29+-+e%28s%29" alt="r(s,s&#39;)=e(s&#39;) - e(s)" eeimg="1"/> </p><p>option可以避免反复无效的探索，比如随机地一会往左、一会往右，探索很长时间还是几乎在原地，而使用option可以比如先往左走到头，然后在往右走到头，这样能够更好地探索；eigenoption更可以保证若干option之间相互正交，这样自动探索出了的option尽量各不相同。</p><p>文章考虑高维或者连续状态空间，因此实际使用的是一个状态的表示 <img src="https://www.zhihu.com/equation?tex=%5Cphi%28%5Ccdot%29" alt="\phi(\cdot)" eeimg="1"/> ，这样eigenpurpose可以定义为</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-0aa67f69fb2ae7f4ef40557ed512f918_b.png" data-caption="" data-size="normal" data-rawwidth="1676" data-rawheight="106" class="origin_image zh-lightbox-thumb" width="1676" data-original="https://pic1.zhimg.com/v2-0aa67f69fb2ae7f4ef40557ed512f918_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1676&#39; height=&#39;106&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1676" data-rawheight="106" class="origin_image zh-lightbox-thumb lazy" width="1676" data-original="https://pic1.zhimg.com/v2-0aa67f69fb2ae7f4ef40557ed512f918_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-0aa67f69fb2ae7f4ef40557ed512f918_b.png"/></figure><p>离散情况下状态表示 <img src="https://www.zhihu.com/equation?tex=%5Cphi%28%5Ccdot%29" alt="\phi(\cdot)" eeimg="1"/> 就是one-hot向量，这样就和前面写出的定义是一样的。</p><h3>3. Successor representation</h3><p>在PVF中，观察到价值函数 <img src="https://www.zhihu.com/equation?tex=v_%5Cpi+%3D+%28I-%5Cgamma+T_%5Cpi%29%5E%7B-1%7D+r" alt="v_\pi = (I-\gamma T_\pi)^{-1} r" eeimg="1"/> 。如果能得到 <img src="https://www.zhihu.com/equation?tex=T_%5Cpi" alt="T_\pi" eeimg="1"/> 并且对其做特征值分解，找出最大特征值对应的特征向量，就可以对价值函数做近似。考虑到 <img src="https://www.zhihu.com/equation?tex=T_%5Cpi" alt="T_\pi" eeimg="1"/> 不好获取，就用随机游走产生的一步状态概率转移矩阵来近似，即 <img src="https://www.zhihu.com/equation?tex=T_r" alt="T_r" eeimg="1"/> 。再进一步，使用一个diffusion model <img src="https://www.zhihu.com/equation?tex=L" alt="L" eeimg="1"/> 来代替。</p><p>这里更直接一点，希望直接学习 <img src="https://www.zhihu.com/equation?tex=%28I-%5Cgamma+T_%5Cpi%29%5E%7B-1%7D" alt="(I-\gamma T_\pi)^{-1}" eeimg="1"/> ，该矩阵可以改写为 successor representation （SR）</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-4da3dffb5d03c9ca26e4ad8d93ce0efa_b.png" data-caption="" data-size="normal" data-rawwidth="1990" data-rawheight="152" class="origin_image zh-lightbox-thumb" width="1990" data-original="https://pic3.zhimg.com/v2-4da3dffb5d03c9ca26e4ad8d93ce0efa_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1990&#39; height=&#39;152&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1990" data-rawheight="152" class="origin_image zh-lightbox-thumb lazy" width="1990" data-original="https://pic3.zhimg.com/v2-4da3dffb5d03c9ca26e4ad8d93ce0efa_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-4da3dffb5d03c9ca26e4ad8d93ce0efa_b.png"/></figure><p>有如下关系</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-6b35067e84e3890c150ce145177ed7b8_b.png" data-caption="" data-size="normal" data-rawwidth="1770" data-rawheight="134" class="origin_image zh-lightbox-thumb" width="1770" data-original="https://pic1.zhimg.com/v2-6b35067e84e3890c150ce145177ed7b8_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1770&#39; height=&#39;134&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1770" data-rawheight="134" class="origin_image zh-lightbox-thumb lazy" width="1770" data-original="https://pic1.zhimg.com/v2-6b35067e84e3890c150ce145177ed7b8_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-6b35067e84e3890c150ce145177ed7b8_b.png"/></figure><p>其好处是如果用神经网络来表示它，它可以被bootstrap地更新</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-8b48b40df3026509a1d3abc7e4b090a1_b.png" data-caption="" data-size="normal" data-rawwidth="1804" data-rawheight="164" class="origin_image zh-lightbox-thumb" width="1804" data-original="https://pic2.zhimg.com/v2-8b48b40df3026509a1d3abc7e4b090a1_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1804&#39; height=&#39;164&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1804" data-rawheight="164" class="origin_image zh-lightbox-thumb lazy" width="1804" data-original="https://pic2.zhimg.com/v2-8b48b40df3026509a1d3abc7e4b090a1_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-8b48b40df3026509a1d3abc7e4b090a1_b.png"/></figure><p>它与diffusion model <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D" alt="\mathcal{L}" eeimg="1"/> 有如下关系，如果策略为随机游走，即 <img src="https://www.zhihu.com/equation?tex=T+%3D+D%5E%7B-1%7DW" alt="T = D^{-1}W" eeimg="1"/> ，那么其相应的 SR <img src="https://www.zhihu.com/equation?tex=%5CPsi" alt="\Psi" eeimg="1"/> 和 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D" alt="\mathcal{L}" eeimg="1"/> 的特征值和特征向量有如下联系。</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-1788daba143d6fa358af3ab2e19cf7d1_b.jpg" data-caption="" data-size="normal" data-rawwidth="1918" data-rawheight="534" class="origin_image zh-lightbox-thumb" width="1918" data-original="https://pic2.zhimg.com/v2-1788daba143d6fa358af3ab2e19cf7d1_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1918&#39; height=&#39;534&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1918" data-rawheight="534" class="origin_image zh-lightbox-thumb lazy" width="1918" data-original="https://pic2.zhimg.com/v2-1788daba143d6fa358af3ab2e19cf7d1_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-1788daba143d6fa358af3ab2e19cf7d1_b.jpg"/></figure><h3>4. Eigenoption</h3><p>文章完整的做法如下</p><ul><li>Learn representation</li><li>Extract eigenpurpose</li><li>Learn eigenoption</li><li>Solve the task with learned eigenoption</li></ul><p>第一步，学习一个好的状态表示和相应的SR，令一个使用神经网络embedding的状态表示为 <img src="https://www.zhihu.com/equation?tex=%5Cphi%28s%29" alt="\phi(s)" eeimg="1"/> 。想要用神经网络表示SR，本来我以为是输入两个状态，输出 <img src="https://www.zhihu.com/equation?tex=%5CPsi%28s%2Cs%27%29" alt="\Psi(s,s&#39;)" eeimg="1"/> ，但是文章隐含地做了分解 <img src="https://www.zhihu.com/equation?tex=%5CPsi%28s%2Cs%27%29+%3D+%5Cpsi%28%5Cphi%28s%29%29%5ET+%5Cphi%28s%27%29" alt="\Psi(s,s&#39;) = \psi(\phi(s))^T \phi(s&#39;)" eeimg="1"/> ，即另外使用一个神经网络 <img src="https://www.zhihu.com/equation?tex=%5Cpsi%28%5Ccdot%29" alt="\psi(\cdot)" eeimg="1"/> 来完成该表示。网络结构如下</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-dea561aeb7b965fcf617904bc9572a77_b.jpg" data-caption="" data-size="normal" data-rawwidth="1708" data-rawheight="610" class="origin_image zh-lightbox-thumb" width="1708" data-original="https://pic4.zhimg.com/v2-dea561aeb7b965fcf617904bc9572a77_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1708&#39; height=&#39;610&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1708" data-rawheight="610" class="origin_image zh-lightbox-thumb lazy" width="1708" data-original="https://pic4.zhimg.com/v2-dea561aeb7b965fcf617904bc9572a77_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-dea561aeb7b965fcf617904bc9572a77_b.jpg"/></figure><p>目标是学习 <img src="https://www.zhihu.com/equation?tex=%5Cphi%28%5Ccdot%29" alt="\phi(\cdot)" eeimg="1"/> 和 <img src="https://www.zhihu.com/equation?tex=%5Cpsi%28%5Ccdot%29" alt="\psi(\cdot)" eeimg="1"/> ，表示 <img src="https://www.zhihu.com/equation?tex=%5Cphi%28%5Ccdot%29" alt="\phi(\cdot)" eeimg="1"/> 的学习还包括了一个reconstruction module，我猜这一部分可以避免学习出来的表示没有信息量（参加DeepMDP文章中讨论的问题）。</p><p>损失函数为以下两部分的和</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-cf782c44e9f1ecc845c2a32f0261ca81_b.png" data-caption="" data-size="normal" data-rawwidth="1782" data-rawheight="142" class="origin_image zh-lightbox-thumb" width="1782" data-original="https://pic2.zhimg.com/v2-cf782c44e9f1ecc845c2a32f0261ca81_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1782&#39; height=&#39;142&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1782" data-rawheight="142" class="origin_image zh-lightbox-thumb lazy" width="1782" data-original="https://pic2.zhimg.com/v2-cf782c44e9f1ecc845c2a32f0261ca81_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-cf782c44e9f1ecc845c2a32f0261ca81_b.png"/></figure><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-f487e435804fea9d82135fdb894bf85f_b.png" data-caption="" data-size="normal" data-rawwidth="1766" data-rawheight="108" class="origin_image zh-lightbox-thumb" width="1766" data-original="https://pic4.zhimg.com/v2-f487e435804fea9d82135fdb894bf85f_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1766&#39; height=&#39;108&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1766" data-rawheight="108" class="origin_image zh-lightbox-thumb lazy" width="1766" data-original="https://pic4.zhimg.com/v2-f487e435804fea9d82135fdb894bf85f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-f487e435804fea9d82135fdb894bf85f_b.png"/></figure><p>第一个损失函数可以由前面写出来的SR更新公式得到，只需要做替换 <img src="https://www.zhihu.com/equation?tex=%5CPsi%28s%2Cs%27%29+%3D+%5Cpsi%28%5Cphi%28s%29%29%5ET+%5Cphi%28s%27%29" alt="\Psi(s,s&#39;) = \psi(\phi(s))^T \phi(s&#39;)" eeimg="1"/> 即可。</p><p>第二步，从学习好的表示和SR中提取eigenpurpose。观察到eigenpurpose的公式</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-7738cab4541c802e78660ec974f543d6_b.png" data-caption="" data-size="normal" data-rawwidth="1728" data-rawheight="104" class="origin_image zh-lightbox-thumb" width="1728" data-original="https://pic3.zhimg.com/v2-7738cab4541c802e78660ec974f543d6_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1728&#39; height=&#39;104&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1728" data-rawheight="104" class="origin_image zh-lightbox-thumb lazy" width="1728" data-original="https://pic3.zhimg.com/v2-7738cab4541c802e78660ec974f543d6_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-7738cab4541c802e78660ec974f543d6_b.png"/></figure><p>其中 <img src="https://www.zhihu.com/equation?tex=%5Cphi%28s%29%2C%5Cphi%28s%27%29" alt="\phi(s),\phi(s&#39;)" eeimg="1"/> 都很容易得到，只需要过一下学到的神经网络即可。eigenvector <img src="https://www.zhihu.com/equation?tex=e" alt="e" eeimg="1"/> 的需要我们得到一个矩阵 <img src="https://www.zhihu.com/equation?tex=T" alt="T" eeimg="1"/> ，然后对其做特征值分解，取其右特征值作为 <img src="https://www.zhihu.com/equation?tex=e" alt="e" eeimg="1"/> 。矩阵 <img src="https://www.zhihu.com/equation?tex=T" alt="T" eeimg="1"/> 通过如下方式得到，提供一个均匀随机采样的策略得到 <img src="https://www.zhihu.com/equation?tex=t" alt="t" eeimg="1"/> 个状态，对于每个状态计算 <img src="https://www.zhihu.com/equation?tex=%5Cpsi%28%5Cphi%28s%29%29" alt="\psi(\phi(s))" eeimg="1"/> ，然后组成一个 <img src="https://www.zhihu.com/equation?tex=t%5Ctimes+dim%28%5Cpsi%29" alt="t\times dim(\psi)" eeimg="1"/> 的矩阵，其中每一行为相应的SR表示。</p><p>第三步，使用得到的若干个eigenpurpose来学习相应的eigenoption。这一步可以使用标准的RL算法来实现，不过文中使用了更为简单的方法，就是采取行动，使得即时的eigenpurpose最大（即 <img src="https://www.zhihu.com/equation?tex=%5Cgamma+%3D+0" alt="\gamma = 0" eeimg="1"/> ）；当任何行动都不可能产生正的eigenpurpose的时候就终止此option。</p><p>第四步，就是把学习到的若干个eigenoption作为action，来使用标准的RL算法来解决。由于这里的各个eigenoption单独的效果就会比较好（具有明确的目的性），因此，这样学起来会更容易。</p><h2>实验</h2><p>本文做了两个实验。</p><p>第一个实验室一个是四个房间的 Grid World，如下图所示，展示了该方法各个步骤中的中间结果。(a) 展示了环境；(b) 展示了第二步里面产生的特征向量（即 eigenpurpose）；(c) 展示了学习到的相应 eigenoption；(d) 展示了 eigenoption 的效果，即在 eigenoption 中随机采样平均只需要走大概 200 多步（diffusion time）就可以到达目标状态，而在原始的 action 中随机采样平均需要 600 步左右才可以到达目标状态。</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-2cb3a2cf6b3c6300d26c68cb3a7f0c11_b.jpg" data-caption="" data-size="normal" data-rawwidth="836" data-rawheight="340" class="origin_image zh-lightbox-thumb" width="836" data-original="https://pic2.zhimg.com/v2-2cb3a2cf6b3c6300d26c68cb3a7f0c11_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;836&#39; height=&#39;340&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="836" data-rawheight="340" class="origin_image zh-lightbox-thumb lazy" width="836" data-original="https://pic2.zhimg.com/v2-2cb3a2cf6b3c6300d26c68cb3a7f0c11_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-2cb3a2cf6b3c6300d26c68cb3a7f0c11_b.jpg"/></figure><p>如下图所示，使用 eigenoption 学习，相应的 cumulative reward 指标也上升更快。不过值得指出的是，这里的横坐标并不包括学习到 eigenoption 需要的步数，因此该图不是一个公平的比较，只是为了展示学到的 eigenoption 有一定用处。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-9c044818c68a1128546f16be5b316144_b.jpg" data-caption="" data-size="normal" data-rawwidth="801" data-rawheight="347" class="origin_image zh-lightbox-thumb" width="801" data-original="https://pic1.zhimg.com/v2-9c044818c68a1128546f16be5b316144_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;801&#39; height=&#39;347&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="801" data-rawheight="347" class="origin_image zh-lightbox-thumb lazy" width="801" data-original="https://pic1.zhimg.com/v2-9c044818c68a1128546f16be5b316144_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-9c044818c68a1128546f16be5b316144_b.jpg"/></figure><p>第二个实验是在三个在比较实际的游戏中做的。不过，本文没有使用学到的 eigenoption 来学习并且解决任务，只是展示了学习到的 eigenoption 具有一定的含义，即每一个 eigenoption 都会带领 agent 到一个比较有代表性的状态上。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-c7c7ef133e46207bd390ed00cbfcba44_b.jpg" data-caption="" data-size="normal" data-rawwidth="834" data-rawheight="377" class="origin_image zh-lightbox-thumb" width="834" data-original="https://pic1.zhimg.com/v2-c7c7ef133e46207bd390ed00cbfcba44_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;834&#39; height=&#39;377&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="834" data-rawheight="377" class="origin_image zh-lightbox-thumb lazy" width="834" data-original="https://pic1.zhimg.com/v2-c7c7ef133e46207bd390ed00cbfcba44_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-c7c7ef133e46207bd390ed00cbfcba44_b.jpg"/></figure><p></p></div></div><div class="ContentItem-time">发布于 2019-06-17</div><div class="Post-topicsAndReviewer"><div class="TopicList Post-Topics"><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/20039099" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习 (Reinforcement Learning)</div></div></a></span></div></div></div><div><div class="Sticky RichContent-actions is-bottom"><div class="ContentItem-actions"><span><button aria-label="赞同 9 " type="button" class="Button VoteButton VoteButton--up"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleUp VoteButton-TriangleUp" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M2 18.242c0-.326.088-.532.237-.896l7.98-13.203C10.572 3.57 11.086 3 12 3c.915 0 1.429.571 1.784 1.143l7.98 13.203c.15.364.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H3.955c-1.08 0-1.955-.517-1.955-1.9z" fill-rule="evenodd"></path></svg></span>赞同 9</button><button aria-label="反对" type="button" class="Button VoteButton VoteButton--down"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleDown" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M20.044 3H3.956C2.876 3 2 3.517 2 4.9c0 .326.087.533.236.896L10.216 19c.355.571.87 1.143 1.784 1.143s1.429-.572 1.784-1.143l7.98-13.204c.149-.363.236-.57.236-.896 0-1.386-.876-1.9-1.956-1.9z" fill-rule="evenodd"></path></svg></span></button></span><button type="button" class="Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Comment Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M10.241 19.313a.97.97 0 0 0-.77.2 7.908 7.908 0 0 1-3.772 1.482.409.409 0 0 1-.38-.637 5.825 5.825 0 0 0 1.11-2.237.605.605 0 0 0-.227-.59A7.935 7.935 0 0 1 3 11.25C3 6.7 7.03 3 12 3s9 3.7 9 8.25-4.373 9.108-10.759 8.063z" fill-rule="evenodd"></path></svg></span>4 条评论</button><div class="Popover ShareMenu"><div class="ShareMenu-toggler" id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Share Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2.931 7.89c-1.067.24-1.275 1.669-.318 2.207l5.277 2.908 8.168-4.776c.25-.127.477.198.273.39L9.05 14.66l.927 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.242c.584-.892-.212-2.029-1.234-1.796L2.93 7.89z" fill-rule="evenodd"></path></svg></span>分享</button></div></div><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Heart Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2 8.437C2 5.505 4.294 3.094 7.207 3 9.243 3 11.092 4.19 12 6c.823-1.758 2.649-3 4.651-3C19.545 3 22 5.507 22 8.432 22 16.24 13.842 21 12 21 10.158 21 2 16.24 2 8.437z" fill-rule="evenodd"></path></svg></span>喜欢</button><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Star Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5.515 19.64l.918-5.355-3.89-3.792c-.926-.902-.639-1.784.64-1.97L8.56 7.74l2.404-4.871c.572-1.16 1.5-1.16 2.072 0L15.44 7.74l5.377.782c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.219 1.274-.532 1.82-1.676 1.218L12 18.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z" fill-rule="evenodd"></path></svg></span>收藏</button><div class="Post-ActionMenuButton"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Dots Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5 14a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4z" fill-rule="evenodd"></path></svg></span></button></div></div></div></div></div></div></article><div class="Post-Sub Post-NormalSub"><div class="PostIndex-Contributions"><h3 class="BlockTitle">文章被以下专栏收录</h3><ul><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><img class="Avatar Avatar--medium Avatar--round" width="40" height="40" src="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_xs.jpg" srcSet="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_l.jpg 2x" alt="强化学习前沿"/></div></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><a class="ColumnLink ColumnItem-Title" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习前沿</div></div></a></h2><div class="ContentItem-meta">读呀读paper</div></div><div class="ContentItem-extra"><a href="/reinforcementlearning" type="button" class="Button">进入专栏</a></div></div></div></ul></div></div></div></main></div></div><script nonce="fbf8b4f2-0318-4763-a61c-5a2d952bbe50" async="" src="https://www.googletagmanager.com/gtag/js?id=UA-149949619-1"></script><script nonce="fbf8b4f2-0318-4763-a61c-5a2d952bbe50">function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-149949619-1");</script><script id="js-clientConfig" type="text/json">{"host":"zhihu.com","protocol":"https:","wwwHost":"www.zhihu.com","fetchRoot":{"www":"https:\u002F\u002Fwww.zhihu.com","api":"https:\u002F\u002Fapi.zhihu.com","zhuanlan":"https:\u002F\u002Fzhuanlan.zhihu.com"}}</script><script id="js-initialData" type="text/json">{"initialState":{"common":{"ask":{}},"loading":{"global":{"count":0},"local":{"env\u002FgetIpinfo\u002F":false,"article\u002Fget\u002F":false,"brand\u002FgetUrl\u002F":false}},"club":{"tags":{}},"entities":{"users":{"zhang-chu-heng":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"清华大学 交叉信息院博士在读"}],"exposedMedal":{"medalId":"1124316222665379841","medalName":"我的知乎 2019","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2592b0b52e1fac99f69b38e00252413b_r.png","miniAvatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ad363cc3088dc8de7544fd08b1c4987a_is.png","description":"参与「我的知乎 2019」即可获得"}}},"questions":{},"answers":{},"articles":{"69324580":{"trackUrl":["https:\u002F\u002Fsugar.zhihu.com\u002Fplutus_adreaper\u002Fpage_monitor_log?si=__SESSIONID__&ti=__ATOKEN__&at=view&pf=__OS__&ed=__MEMBERID__&idfa=__IDFA__&imei=__IMEI__&androidid=__ANDROIDID__&oaid=__OAID__&ci=__CREATIVEID__"],"id":69324580,"title":"【强化学习 71】Successor Representation","type":"article","excerptTitle":"","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F69324580","imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-65a615eadfc0f86acfd68b57cbf7e6f2_b.jpg","titleImage":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-65a615eadfc0f86acfd68b57cbf7e6f2_b.jpg","excerpt":"\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4da3dffb5d03c9ca26e4ad8d93ce0efa_200x112.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1990\" data-rawheight=\"152\" data-watermark=\"\" data-original-src=\"\" data-watermark-src=\"\" data-private-watermark-src=\"\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4da3dffb5d03c9ca26e4ad8d93ce0efa_r.png\" class=\"origin_image inline-img zh-lightbox-thumb\"\u002F\u003E原文传送门\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fpdf\u002F1710.11089\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EMachado, Marlos C., et al. &#34;Eigenoption discovery through the deep successor representation.&#34; arXiv preprint arXiv:1710.11089 (2017).\u003C\u002Fa\u003E特色之前讲了两篇学习状态表示（representation）的文章，一篇讲PVF（\u003Ca href=\"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F68326687\" class=\"internal\"\u003E【强化学习 67】Proto-value Fun…\u003C\u002Fa\u003E","created":1560701094,"updated":1560701094,"author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"清华大学 交叉信息院博士在读"}],"exposedMedal":{"medalId":"1124316222665379841","medalName":"我的知乎 2019","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2592b0b52e1fac99f69b38e00252413b_r.png","miniAvatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ad363cc3088dc8de7544fd08b1c4987a_is.png","description":"参与「我的知乎 2019」即可获得"}},"commentPermission":"all","state":"published","imageWidth":2100,"imageHeight":848,"content":"\u003Ch2\u003E原文传送门\u003C\u002Fh2\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fpdf\u002F1710.11089\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EMachado, Marlos C., et al. &#34;Eigenoption discovery through the deep successor representation.&#34; arXiv preprint arXiv:1710.11089 (2017).\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Ch2\u003E特色\u003C\u002Fh2\u003E\u003Cp\u003E之前讲了两篇学习状态表示（representation）的文章，一篇讲PVF（\u003Ca href=\"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F68326687\" class=\"internal\"\u003E【强化学习 67】Proto-value Function\u003C\u002Fa\u003E），一篇讲DeepMDP（\u003Ca href=\"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F68364144\" class=\"internal\"\u003E【强化学习 68】DeepMDP\u003C\u002Fa\u003E）。它们都可以看做是对于环境模型的压缩，其中前者只考虑环境本身的动力学特性（dynamics），后者不仅考虑环境的动力学特性，还考虑环境的奖励函数；因此，前者可以用于meta learning，而后者则更贴近要学习的任务，同时理论上能有更直接的关于学到策略性能的bound。\u003C\u002Fp\u003E\u003Cp\u003E这里也是想学习一种状态表示，并且这种状态表示只反映环境的特性（即dynamics），不涉及具体的任务（即reward）。这样的表示有以下优势：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E当环境上的任务变化的时候，该方法学到的状态表示依然有用，即适用于meta learning的设定；\u003C\u002Fli\u003E\u003Cli\u003E当任务给出的奖励稀疏或者具有误导性的时候，该表示能够探索到环境本身的特性，并且利用学习到的环境性质来指导智能体探索。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003E本文就是想从对于MDP的随机采样（stochastic sampling）的样本中学习到这样一种状态表示，进而提取出环境的性质做分层强化学习，详细的介绍见下一部分。\u003C\u002Fp\u003E\u003Ch2\u003E过程\u003C\u002Fh2\u003E\u003Ch3\u003E1. 总体思路\u003C\u002Fh3\u003E\u003Cp\u003E本文先通过在MDP上的随机采样来学习一个表示（successor representation），并且从该表示下得到一个关于环境的刻画（一个状态空间上的diffusion matrix），从而得到与环境有关的辅助奖励函数（eigenpurpose），最大化该奖励函数能够形成相应的更为抽象的行动（eigenoption），进而产生一个基于option的分层强化学习算法（参考\u003Ca href=\"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F47051292\" class=\"internal\"\u003E【强化学习算法 20】Option-Critic\u003C\u002Fa\u003E）。\u003C\u002Fp\u003E\u003Ch3\u003E2. 回顾PVF\u003C\u002Fh3\u003E\u003Cp\u003EPVF（proto-value function）方法使用不同状态之间的转移关系构建一个状态之间的转移矩阵 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=W\" alt=\"W\" eeimg=\"1\"\u002F\u003E ，使用该转移矩阵构建随机游走的一步转移概率矩阵 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=T_r\" alt=\"T_r\" eeimg=\"1\"\u002F\u003E （或者相应的diffusion model \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=L\" alt=\"L\" eeimg=\"1\"\u002F\u003E ），对该矩阵进行特征值分解，其最大的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=k\" alt=\"k\" eeimg=\"1\"\u002F\u003E 个特征值对应的特征向量可以作为其价值函数的基向量。注，原文用的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=P_r\" alt=\"P_r\" eeimg=\"1\"\u002F\u003E ，为了和这篇文章统一，就写作 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=T_r\" alt=\"T_r\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Cp\u003E对于一个特征向量 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=e\" alt=\"e\" eeimg=\"1\"\u002F\u003E ，它的每一位表示一个状态的某种性质的数值。回顾PVF里面的两个小房间的例子：比如某特征向量数值大表示该状态位于第一个小房间，否则位于第二个小房间；再比如某特征向量数值大的表示该状态位于房间内距离goal较远的一侧。\u003C\u002Fp\u003E\u003Cp\u003E分层强化学习里面的option相当于一个达到特定目的的一连串动作或者子策略，有一些工作里面option的目标是人为定义的，当然最好的情况是能够自动探索并且发现option。PVF里面得到的特征向量提供了一个自动探索option的方法。刚刚说到一个特征向量中各个状态的数值代表着它对于环境某方面性质的刻画，因此自然想到对于一个特征向量，定义一个option，使得该option朝着该特征向量数值较大\u002F小的方向走。这样得到的option也叫eigenoption。eigenoption的定义可以通过定义相应的eigenpurpose（reward）得到，最大化该奖励得到的子策略就是eigenpurpose，由此，容易想到定义它为\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=r%28s%2Cs%27%29%3De%28s%27%29+-+e%28s%29\" alt=\"r(s,s&#39;)=e(s&#39;) - e(s)\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003Eoption可以避免反复无效的探索，比如随机地一会往左、一会往右，探索很长时间还是几乎在原地，而使用option可以比如先往左走到头，然后在往右走到头，这样能够更好地探索；eigenoption更可以保证若干option之间相互正交，这样自动探索出了的option尽量各不相同。\u003C\u002Fp\u003E\u003Cp\u003E文章考虑高维或者连续状态空间，因此实际使用的是一个状态的表示 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cphi%28%5Ccdot%29\" alt=\"\\phi(\\cdot)\" eeimg=\"1\"\u002F\u003E ，这样eigenpurpose可以定义为\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-0aa67f69fb2ae7f4ef40557ed512f918_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1676\" data-rawheight=\"106\" class=\"origin_image zh-lightbox-thumb\" width=\"1676\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-0aa67f69fb2ae7f4ef40557ed512f918_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1676&#39; height=&#39;106&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1676\" data-rawheight=\"106\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1676\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-0aa67f69fb2ae7f4ef40557ed512f918_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-0aa67f69fb2ae7f4ef40557ed512f918_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E离散情况下状态表示 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cphi%28%5Ccdot%29\" alt=\"\\phi(\\cdot)\" eeimg=\"1\"\u002F\u003E 就是one-hot向量，这样就和前面写出的定义是一样的。\u003C\u002Fp\u003E\u003Ch3\u003E3. Successor representation\u003C\u002Fh3\u003E\u003Cp\u003E在PVF中，观察到价值函数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=v_%5Cpi+%3D+%28I-%5Cgamma+T_%5Cpi%29%5E%7B-1%7D+r\" alt=\"v_\\pi = (I-\\gamma T_\\pi)^{-1} r\" eeimg=\"1\"\u002F\u003E 。如果能得到 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=T_%5Cpi\" alt=\"T_\\pi\" eeimg=\"1\"\u002F\u003E 并且对其做特征值分解，找出最大特征值对应的特征向量，就可以对价值函数做近似。考虑到 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=T_%5Cpi\" alt=\"T_\\pi\" eeimg=\"1\"\u002F\u003E 不好获取，就用随机游走产生的一步状态概率转移矩阵来近似，即 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=T_r\" alt=\"T_r\" eeimg=\"1\"\u002F\u003E 。再进一步，使用一个diffusion model \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=L\" alt=\"L\" eeimg=\"1\"\u002F\u003E 来代替。\u003C\u002Fp\u003E\u003Cp\u003E这里更直接一点，希望直接学习 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%28I-%5Cgamma+T_%5Cpi%29%5E%7B-1%7D\" alt=\"(I-\\gamma T_\\pi)^{-1}\" eeimg=\"1\"\u002F\u003E ，该矩阵可以改写为 successor representation （SR）\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4da3dffb5d03c9ca26e4ad8d93ce0efa_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1990\" data-rawheight=\"152\" class=\"origin_image zh-lightbox-thumb\" width=\"1990\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4da3dffb5d03c9ca26e4ad8d93ce0efa_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1990&#39; height=&#39;152&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1990\" data-rawheight=\"152\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1990\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4da3dffb5d03c9ca26e4ad8d93ce0efa_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4da3dffb5d03c9ca26e4ad8d93ce0efa_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E有如下关系\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6b35067e84e3890c150ce145177ed7b8_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1770\" data-rawheight=\"134\" class=\"origin_image zh-lightbox-thumb\" width=\"1770\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6b35067e84e3890c150ce145177ed7b8_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1770&#39; height=&#39;134&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1770\" data-rawheight=\"134\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1770\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6b35067e84e3890c150ce145177ed7b8_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6b35067e84e3890c150ce145177ed7b8_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其好处是如果用神经网络来表示它，它可以被bootstrap地更新\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-8b48b40df3026509a1d3abc7e4b090a1_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1804\" data-rawheight=\"164\" class=\"origin_image zh-lightbox-thumb\" width=\"1804\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-8b48b40df3026509a1d3abc7e4b090a1_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1804&#39; height=&#39;164&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1804\" data-rawheight=\"164\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1804\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-8b48b40df3026509a1d3abc7e4b090a1_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-8b48b40df3026509a1d3abc7e4b090a1_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E它与diffusion model \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathcal%7BL%7D\" alt=\"\\mathcal{L}\" eeimg=\"1\"\u002F\u003E 有如下关系，如果策略为随机游走，即 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=T+%3D+D%5E%7B-1%7DW\" alt=\"T = D^{-1}W\" eeimg=\"1\"\u002F\u003E ，那么其相应的 SR \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5CPsi\" alt=\"\\Psi\" eeimg=\"1\"\u002F\u003E 和 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathcal%7BL%7D\" alt=\"\\mathcal{L}\" eeimg=\"1\"\u002F\u003E 的特征值和特征向量有如下联系。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1788daba143d6fa358af3ab2e19cf7d1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1918\" data-rawheight=\"534\" class=\"origin_image zh-lightbox-thumb\" width=\"1918\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1788daba143d6fa358af3ab2e19cf7d1_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1918&#39; height=&#39;534&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1918\" data-rawheight=\"534\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1918\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1788daba143d6fa358af3ab2e19cf7d1_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1788daba143d6fa358af3ab2e19cf7d1_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Ch3\u003E4. Eigenoption\u003C\u002Fh3\u003E\u003Cp\u003E文章完整的做法如下\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003ELearn representation\u003C\u002Fli\u003E\u003Cli\u003EExtract eigenpurpose\u003C\u002Fli\u003E\u003Cli\u003ELearn eigenoption\u003C\u002Fli\u003E\u003Cli\u003ESolve the task with learned eigenoption\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003E第一步，学习一个好的状态表示和相应的SR，令一个使用神经网络embedding的状态表示为 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cphi%28s%29\" alt=\"\\phi(s)\" eeimg=\"1\"\u002F\u003E 。想要用神经网络表示SR，本来我以为是输入两个状态，输出 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5CPsi%28s%2Cs%27%29\" alt=\"\\Psi(s,s&#39;)\" eeimg=\"1\"\u002F\u003E ，但是文章隐含地做了分解 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5CPsi%28s%2Cs%27%29+%3D+%5Cpsi%28%5Cphi%28s%29%29%5ET+%5Cphi%28s%27%29\" alt=\"\\Psi(s,s&#39;) = \\psi(\\phi(s))^T \\phi(s&#39;)\" eeimg=\"1\"\u002F\u003E ，即另外使用一个神经网络 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cpsi%28%5Ccdot%29\" alt=\"\\psi(\\cdot)\" eeimg=\"1\"\u002F\u003E 来完成该表示。网络结构如下\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-dea561aeb7b965fcf617904bc9572a77_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1708\" data-rawheight=\"610\" class=\"origin_image zh-lightbox-thumb\" width=\"1708\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-dea561aeb7b965fcf617904bc9572a77_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1708&#39; height=&#39;610&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1708\" data-rawheight=\"610\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1708\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-dea561aeb7b965fcf617904bc9572a77_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-dea561aeb7b965fcf617904bc9572a77_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E目标是学习 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cphi%28%5Ccdot%29\" alt=\"\\phi(\\cdot)\" eeimg=\"1\"\u002F\u003E 和 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cpsi%28%5Ccdot%29\" alt=\"\\psi(\\cdot)\" eeimg=\"1\"\u002F\u003E ，表示 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cphi%28%5Ccdot%29\" alt=\"\\phi(\\cdot)\" eeimg=\"1\"\u002F\u003E 的学习还包括了一个reconstruction module，我猜这一部分可以避免学习出来的表示没有信息量（参加DeepMDP文章中讨论的问题）。\u003C\u002Fp\u003E\u003Cp\u003E损失函数为以下两部分的和\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-cf782c44e9f1ecc845c2a32f0261ca81_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1782\" data-rawheight=\"142\" class=\"origin_image zh-lightbox-thumb\" width=\"1782\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-cf782c44e9f1ecc845c2a32f0261ca81_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1782&#39; height=&#39;142&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1782\" data-rawheight=\"142\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1782\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-cf782c44e9f1ecc845c2a32f0261ca81_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-cf782c44e9f1ecc845c2a32f0261ca81_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f487e435804fea9d82135fdb894bf85f_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1766\" data-rawheight=\"108\" class=\"origin_image zh-lightbox-thumb\" width=\"1766\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f487e435804fea9d82135fdb894bf85f_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1766&#39; height=&#39;108&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1766\" data-rawheight=\"108\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1766\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f487e435804fea9d82135fdb894bf85f_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f487e435804fea9d82135fdb894bf85f_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E第一个损失函数可以由前面写出来的SR更新公式得到，只需要做替换 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5CPsi%28s%2Cs%27%29+%3D+%5Cpsi%28%5Cphi%28s%29%29%5ET+%5Cphi%28s%27%29\" alt=\"\\Psi(s,s&#39;) = \\psi(\\phi(s))^T \\phi(s&#39;)\" eeimg=\"1\"\u002F\u003E 即可。\u003C\u002Fp\u003E\u003Cp\u003E第二步，从学习好的表示和SR中提取eigenpurpose。观察到eigenpurpose的公式\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-7738cab4541c802e78660ec974f543d6_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1728\" data-rawheight=\"104\" class=\"origin_image zh-lightbox-thumb\" width=\"1728\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-7738cab4541c802e78660ec974f543d6_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1728&#39; height=&#39;104&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1728\" data-rawheight=\"104\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1728\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-7738cab4541c802e78660ec974f543d6_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-7738cab4541c802e78660ec974f543d6_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cphi%28s%29%2C%5Cphi%28s%27%29\" alt=\"\\phi(s),\\phi(s&#39;)\" eeimg=\"1\"\u002F\u003E 都很容易得到，只需要过一下学到的神经网络即可。eigenvector \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=e\" alt=\"e\" eeimg=\"1\"\u002F\u003E 的需要我们得到一个矩阵 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=T\" alt=\"T\" eeimg=\"1\"\u002F\u003E ，然后对其做特征值分解，取其右特征值作为 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=e\" alt=\"e\" eeimg=\"1\"\u002F\u003E 。矩阵 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=T\" alt=\"T\" eeimg=\"1\"\u002F\u003E 通过如下方式得到，提供一个均匀随机采样的策略得到 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=t\" alt=\"t\" eeimg=\"1\"\u002F\u003E 个状态，对于每个状态计算 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cpsi%28%5Cphi%28s%29%29\" alt=\"\\psi(\\phi(s))\" eeimg=\"1\"\u002F\u003E ，然后组成一个 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=t%5Ctimes+dim%28%5Cpsi%29\" alt=\"t\\times dim(\\psi)\" eeimg=\"1\"\u002F\u003E 的矩阵，其中每一行为相应的SR表示。\u003C\u002Fp\u003E\u003Cp\u003E第三步，使用得到的若干个eigenpurpose来学习相应的eigenoption。这一步可以使用标准的RL算法来实现，不过文中使用了更为简单的方法，就是采取行动，使得即时的eigenpurpose最大（即 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cgamma+%3D+0\" alt=\"\\gamma = 0\" eeimg=\"1\"\u002F\u003E ）；当任何行动都不可能产生正的eigenpurpose的时候就终止此option。\u003C\u002Fp\u003E\u003Cp\u003E第四步，就是把学习到的若干个eigenoption作为action，来使用标准的RL算法来解决。由于这里的各个eigenoption单独的效果就会比较好（具有明确的目的性），因此，这样学起来会更容易。\u003C\u002Fp\u003E\u003Ch2\u003E实验\u003C\u002Fh2\u003E\u003Cp\u003E本文做了两个实验。\u003C\u002Fp\u003E\u003Cp\u003E第一个实验室一个是四个房间的 Grid World，如下图所示，展示了该方法各个步骤中的中间结果。(a) 展示了环境；(b) 展示了第二步里面产生的特征向量（即 eigenpurpose）；(c) 展示了学习到的相应 eigenoption；(d) 展示了 eigenoption 的效果，即在 eigenoption 中随机采样平均只需要走大概 200 多步（diffusion time）就可以到达目标状态，而在原始的 action 中随机采样平均需要 600 步左右才可以到达目标状态。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-2cb3a2cf6b3c6300d26c68cb3a7f0c11_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"836\" data-rawheight=\"340\" class=\"origin_image zh-lightbox-thumb\" width=\"836\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-2cb3a2cf6b3c6300d26c68cb3a7f0c11_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;836&#39; height=&#39;340&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"836\" data-rawheight=\"340\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"836\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-2cb3a2cf6b3c6300d26c68cb3a7f0c11_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-2cb3a2cf6b3c6300d26c68cb3a7f0c11_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E如下图所示，使用 eigenoption 学习，相应的 cumulative reward 指标也上升更快。不过值得指出的是，这里的横坐标并不包括学习到 eigenoption 需要的步数，因此该图不是一个公平的比较，只是为了展示学到的 eigenoption 有一定用处。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-9c044818c68a1128546f16be5b316144_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"801\" data-rawheight=\"347\" class=\"origin_image zh-lightbox-thumb\" width=\"801\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-9c044818c68a1128546f16be5b316144_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;801&#39; height=&#39;347&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"801\" data-rawheight=\"347\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"801\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-9c044818c68a1128546f16be5b316144_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-9c044818c68a1128546f16be5b316144_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E第二个实验是在三个在比较实际的游戏中做的。不过，本文没有使用学到的 eigenoption 来学习并且解决任务，只是展示了学习到的 eigenoption 具有一定的含义，即每一个 eigenoption 都会带领 agent 到一个比较有代表性的状态上。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-c7c7ef133e46207bd390ed00cbfcba44_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"834\" data-rawheight=\"377\" class=\"origin_image zh-lightbox-thumb\" width=\"834\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-c7c7ef133e46207bd390ed00cbfcba44_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;834&#39; height=&#39;377&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"834\" data-rawheight=\"377\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"834\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-c7c7ef133e46207bd390ed00cbfcba44_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-c7c7ef133e46207bd390ed00cbfcba44_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003C\u002Fp\u003E","adminClosedComment":false,"topics":[{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F20039099","type":"topic","id":"20039099","name":"强化学习 (Reinforcement Learning)"}],"voteupCount":9,"voting":0,"column":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"},"commentCount":4,"contributions":[{"id":21081967,"state":"accepted","type":"first_publish","column":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}}],"isTitleImageFullScreen":false,"upvotedFollowees":[],"commercialInfo":{"isCommercial":false,"plugin":{}},"suggestEdit":{"status":false,"reason":"","tip":"","url":"","title":""},"reason":"","annotationAction":[],"canTip":false,"tipjarorsCount":0,"isLabeled":false,"hasPublishingDraft":false,"isFavorited":false,"isNormal":true,"status":0,"shareText":"【强化学习 71】Successor Representation - 来自知乎专栏「强化学习前沿」，作者: 张楚珩 https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F69324580 （想看更多？下载 @知乎 App：http:\u002F\u002Fweibo.com\u002Fp\u002F100404711598 ）","canComment":{"status":true,"reason":""},"mcnFpShow":-1,"isVisible":true,"isLiked":false,"likedCount":0,"visibleOnlyToAuthor":false}},"columns":{"reinforcementlearning":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}},"topics":{},"roundtables":{},"favlists":{},"comments":{},"notifications":{},"ebooks":{},"activities":{},"feeds":{},"pins":{},"promotions":{},"drafts":{},"chats":{},"posts":{},"clubs":{},"clubTags":{}},"currentUser":"","account":{"lockLevel":{},"unlockTicketStatus":false,"unlockTicket":null,"challenge":[],"errorStatus":false,"message":"","isFetching":false,"accountInfo":{},"urlToken":{"loading":false}},"settings":{"socialBind":null,"inboxMsg":null,"notification":{},"email":{},"privacyFlag":null,"blockedUsers":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"blockedFollowees":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"ignoredTopics":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"restrictedTopics":null,"laboratory":{}},"notification":{},"people":{"profileStatus":{},"activitiesByUser":{},"answersByUser":{},"answersSortByVotesByUser":{},"answersIncludedByUser":{},"votedAnswersByUser":{},"thankedAnswersByUser":{},"voteAnswersByUser":{},"thankAnswersByUser":{},"topicAnswersByUser":{},"zvideosByUser":{},"articlesByUser":{},"articlesSortByVotesByUser":{},"articlesIncludedByUser":{},"pinsByUser":{},"questionsByUser":{},"commercialQuestionsByUser":{},"favlistsByUser":{},"followingByUser":{},"followersByUser":{},"mutualsByUser":{},"followingColumnsByUser":{},"followingQuestionsByUser":{},"followingFavlistsByUser":{},"followingTopicsByUser":{},"publicationsByUser":{},"columnsByUser":{},"allFavlistsByUser":{},"brands":null,"creationsByUser":{},"creationsSortByVotesByUser":{},"creationsFeed":{}},"env":{"ab":{"config":{"experiments":[{"expId":"launch-gw_mweb_rec-1","expPrefix":"gw_mweb_rec","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-qa_hdpimg-2","expPrefix":"qa_hdpimg","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-us_foltopic_user-10","expPrefix":"us_foltopic_user","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_bullet_second-2","expPrefix":"vd_bullet_second","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_zvideo_link-10","expPrefix":"vd_zvideo_link","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"se_topicfeed-2","expPrefix":"se_topicfeed","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false}],"params":[{"id":"zr_video_rank_nn","type":"String","value":"new_rank","chainId":"_all_"},{"id":"soc_ri_merge","type":"String","value":"0","chainId":"_all_"},{"id":"top_test_4_liguangyi","type":"String","value":"1","chainId":"_all_"},{"id":"zr_search_paid","type":"String","value":"0","chainId":"_all_"},{"id":"se_new_p","type":"String","value":"0","chainId":"_all_"},{"id":"se_websearch","type":"String","value":"3","chainId":"_all_"},{"id":"li_svip_tab_search","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_header","type":"String","value":"1","chainId":"_all_"},{"id":"se_hot_timebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_3","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"soc_bigone","type":"String","value":"0","chainId":"_all_"},{"id":"zr_video_recall","type":"String","value":"current_recall","chainId":"_all_"},{"id":"se_article_icon","type":"String","value":"0","chainId":"_all_"},{"id":"se_aa","type":"String","value":"0","chainId":"_all_"},{"id":"zr_slot_training","type":"String","value":"1","chainId":"_all_"},{"id":"web_unfriendly_comm","type":"String","value":"0"},{"id":"se_new_merger","type":"String","value":"1","chainId":"_all_"},{"id":"se_mobileweb","type":"String","value":"1","chainId":"_all_"},{"id":"soc_wonderuser_recom","type":"String","value":"2","chainId":"_all_"},{"id":"web_upload","type":"String","value":"1"},{"id":"web_question_invite","type":"String","value":"B"},{"id":"zw_payc_qaedit","type":"String","value":"0","chainId":"_all_"},{"id":"soc_userrec","type":"String","value":"0","chainId":"_all_"},{"id":"li_yxzl_new_style_a","type":"String","value":"1","chainId":"_all_"},{"id":"zr_search_sim","type":"String","value":"0","chainId":"_all_"},{"id":"se_sug_entrance","type":"String","value":"1","chainId":"_all_"},{"id":"pf_fuceng","type":"String","value":"1","chainId":"_all_"},{"id":"se_sug","type":"String","value":"1","chainId":"_all_"},{"id":"tp_topic_tab","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adreadline","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_style","type":"String","value":"0","chainId":"_all_"},{"id":"top_v_album","type":"String","value":"1","chainId":"_all_"},{"id":"se_hotsearch","type":"String","value":"0","chainId":"_all_"},{"id":"se_relationship","type":"String","value":"1","chainId":"_all_"},{"id":"se_movietab","type":"String","value":"1","chainId":"_all_"},{"id":"se_sug_term","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_pk","type":"String","value":"1","chainId":"_all_"},{"id":"tp_topic_rec","type":"String","value":"1","chainId":"_all_"},{"id":"soc_yxzl_zcfw","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_section","type":"String","value":"0","chainId":"_all_"},{"id":"se_entity_model_14","type":"String","value":"0","chainId":"_all_"},{"id":"se_hotsearch_num","type":"String","value":"0","chainId":"_all_"},{"id":"web_sec672","type":"String","value":"0"},{"id":"tp_sticky_android","type":"String","value":"2","chainId":"_all_"},{"id":"soc_iospinweight","type":"String","value":"0","chainId":"_all_"},{"id":"se_specialbutton","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iosreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"top_hotcommerce","type":"String","value":"1","chainId":"_all_"},{"id":"se_college","type":"String","value":"default","chainId":"_all_"},{"id":"soc_iosreadline","type":"String","value":"0","chainId":"_all_"},{"id":"se_subtext","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_qa_pic","type":"String","value":"1","chainId":"_all_"},{"id":"gue_video_autoplay","type":"String","value":"0"},{"id":"li_qa_btn_text","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_across","type":"String","value":"1","chainId":"_all_"},{"id":"gue_self_censoring","type":"String","value":"1"},{"id":"tp_club_tab_feed","type":"String","value":"0","chainId":"_all_"},{"id":"ls_fmp4","type":"String","value":"0","chainId":"_all_"},{"id":"web_mini_review","type":"String","value":"0"},{"id":"se_ios_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_4","type":"String","value":"1","chainId":"_all_"},{"id":"gue_zvideo_link","type":"String","value":"1"},{"id":"li_ebook_read","type":"String","value":"0","chainId":"_all_"},{"id":"tp_qa_toast","type":"String","value":"1","chainId":"_all_"},{"id":"web_n_web_msg","type":"String","value":"0"},{"id":"zr_km_feed_nlp","type":"String","value":"old","chainId":"_all_"},{"id":"li_catalog_card","type":"String","value":"1","chainId":"_all_"},{"id":"top_root","type":"String","value":"0","chainId":"_all_"},{"id":"se_topicfeed","type":"String","value":"0","chainId":"_all_"},{"id":"tp_discovery_ab_1","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iossort","type":"String","value":"0","chainId":"_all_"},{"id":"ls_videoad","type":"String","value":"2","chainId":"_all_"},{"id":"se_billboardsearch","type":"String","value":"0","chainId":"_all_"},{"id":"se_cbert_index","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_pic_swiper","type":"String","value":"1","chainId":"_all_"},{"id":"se_wannasearch","type":"String","value":"0","chainId":"_all_"},{"id":"se_payconsult","type":"String","value":"0","chainId":"_all_"},{"id":"se_highlight","type":"String","value":"0","chainId":"_all_"},{"id":"soc_brdcst4","type":"String","value":"3","chainId":"_all_"},{"id":"web_mweb_launch","type":"String","value":"0"},{"id":"zr_training_first","type":"String","value":"false","chainId":"_all_"},{"id":"se_ltr_video","type":"String","value":"0","chainId":"_all_"},{"id":"sem_up_growth","type":"String","value":"in_app","chainId":"_all_"},{"id":"se_cardrank_1","type":"String","value":"0","chainId":"_all_"},{"id":"li_video_section","type":"String","value":"0","chainId":"_all_"},{"id":"se_rf_w","type":"String","value":"0","chainId":"_all_"},{"id":"web_ad_banner","type":"String","value":"0"},{"id":"li_salt_hot","type":"String","value":"1","chainId":"_all_"},{"id":"li_ebook_gen_search","type":"String","value":"0","chainId":"_all_"},{"id":"se_preset_label","type":"String","value":"1","chainId":"_all_"},{"id":"se_famous","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_tab","type":"String","value":"0","chainId":"_all_"},{"id":"qap_article_like","type":"String","value":"1","chainId":"_all_"},{"id":"se_amovietab","type":"String","value":"1","chainId":"_all_"},{"id":"tp_sft_v2","type":"String","value":"d","chainId":"_all_"},{"id":"tp_m_intro_re_topic","type":"String","value":"1","chainId":"_all_"},{"id":"soc_zcfw_broadcast2","type":"String","value":"1","chainId":"_all_"},{"id":"ug_goodcomment_0","type":"String","value":"1","chainId":"_all_"},{"id":"zr_ans_rec","type":"String","value":"gbrank","chainId":"_all_"},{"id":"se_colorfultab","type":"String","value":"1","chainId":"_all_"},{"id":"tp_topic_entry","type":"String","value":"0","chainId":"_all_"},{"id":"qap_payc_invite","type":"String","value":"0","chainId":"_all_"},{"id":"se_hotmore","type":"String","value":"2","chainId":"_all_"},{"id":"se_relation_1","type":"String","value":"0","chainId":"_all_"},{"id":"web_collect","type":"String","value":"0"},{"id":"soc_iosintimacy","type":"String","value":"2","chainId":"_all_"},{"id":"tsp_vote","type":"String","value":"2","chainId":"_all_"},{"id":"zr_rel_search","type":"String","value":"base","chainId":"_all_"},{"id":"se_aa_base","type":"String","value":"0","chainId":"_all_"},{"id":"se_adxtest","type":"String","value":"1","chainId":"_all_"},{"id":"li_se_edu","type":"String","value":"1","chainId":"_all_"},{"id":"gue_zhuantikapian","type":"String","value":"0"},{"id":"gue_card_test","type":"String","value":"1"},{"id":"se_multianswer","type":"String","value":"2","chainId":"_all_"},{"id":"tp_club_join","type":"String","value":"0","chainId":"_all_"},{"id":"pf_foltopic_usernum","type":"String","value":"50","chainId":"_all_"},{"id":"gue_thanks","type":"String","value":"0"},{"id":"qap_ques_invite","type":"String","value":"0","chainId":"_all_"},{"id":"se_timebox_up","type":"String","value":"0","chainId":"_all_"},{"id":"tsp_hotlist_ui","type":"String","value":"1","chainId":"_all_"},{"id":"li_assessment_show","type":"String","value":"1","chainId":"_all_"},{"id":"zr_answer_rec_cp","type":"String","value":"open","chainId":"_all_"},{"id":"zr_article_new","type":"String","value":"close","chainId":"_all_"},{"id":"se_lottery","type":"String","value":"0","chainId":"_all_"},{"id":"tp_discover_copy","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zuichangfangwen","type":"String","value":"0","chainId":"_all_"},{"id":"se_whitelist","type":"String","value":"0","chainId":"_all_"},{"id":"se_ffzx_jushen1","type":"String","value":"0","chainId":"_all_"},{"id":"se_waterfall","type":"String","value":"0","chainId":"_all_"},{"id":"se_content0","type":"String","value":"0","chainId":"_all_"},{"id":"tp_header_style","type":"String","value":"1","chainId":"_all_"},{"id":"top_ebook","type":"String","value":"0","chainId":"_all_"},{"id":"li_qa_new_cover","type":"String","value":"1","chainId":"_all_"},{"id":"zw_sameq_sorce","type":"String","value":"999","chainId":"_all_"},{"id":"se_search_feed","type":"String","value":"N","chainId":"_all_"},{"id":"soc_newfeed","type":"String","value":"2","chainId":"_all_"},{"id":"li_sku_bottom_bar_re","type":"String","value":"0","chainId":"_all_"},{"id":"gue_goods_card","type":"String","value":"0"},{"id":"zr_update_merge_size","type":"String","value":"1","chainId":"_all_"},{"id":"tp_topic_tab_new","type":"String","value":"0-0-0","chainId":"_all_"},{"id":"ug_zero_follow_0","type":"String","value":"0","chainId":"_all_"},{"id":"web_mweb_rec_length","type":"String","value":"1"},{"id":"qap_thanks","type":"String","value":"1","chainId":"_all_"},{"id":"se_webmajorob","type":"String","value":"0","chainId":"_all_"},{"id":"se_auto_syn","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_feed","type":"String","value":"1","chainId":"_all_"},{"id":"soc_bignew","type":"String","value":"1","chainId":"_all_"},{"id":"li_vip_verti_search","type":"String","value":"0","chainId":"_all_"},{"id":"li_answer_label","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_2","type":"String","value":"1","chainId":"_all_"},{"id":"web_audit_01","type":"String","value":"case1"},{"id":"se_p_slideshow","type":"String","value":"0","chainId":"_all_"},{"id":"se_agency","type":"String","value":" 0","chainId":"_all_"},{"id":"top_universalebook","type":"String","value":"1","chainId":"_all_"},{"id":"ug_newtag","type":"String","value":"0","chainId":"_all_"},{"id":"li_ebok_chap","type":"String","value":"0","chainId":"_all_"},{"id":"zr_video_rank","type":"String","value":"new_rank","chainId":"_all_"},{"id":"zr_slotpaidexp","type":"String","value":"1","chainId":"_all_"},{"id":"gue_bullet_guide","type":"String","value":"发个弹幕聊聊…"},{"id":"se_page_quality","type":"String","value":"0","chainId":"_all_"},{"id":"se_site_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_pek_test2","type":"String","value":"1","chainId":"_all_"},{"id":"soc_brdcst3","type":"String","value":"0","chainId":"_all_"},{"id":"soc_authormore2","type":"String","value":"2","chainId":"_all_"},{"id":"li_pay_banner_type","type":"String","value":"6","chainId":"_all_"},{"id":"li_answer_card","type":"String","value":"0","chainId":"_all_"},{"id":"zr_test_aa1","type":"String","value":"0","chainId":"_all_"},{"id":"soc_stickypush","type":"String","value":"1","chainId":"_all_"},{"id":"li_se_heat","type":"String","value":"1","chainId":"_all_"},{"id":"se_searchwiki","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adpinweight","type":"String","value":"0","chainId":"_all_"},{"id":"soc_special","type":"String","value":"0","chainId":"_all_"},{"id":"se_college_cm","type":"String","value":"0","chainId":"_all_"},{"id":"se_time_threshold","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sft","type":"String","value":"a","chainId":"_all_"},{"id":"ug_follow_topic_1","type":"String","value":"2","chainId":"_all_"},{"id":"se_club_post","type":"String","value":"5","chainId":"_all_"},{"id":"se_topiclabel","type":"String","value":"1","chainId":"_all_"},{"id":"soc_authormore","type":"String","value":"2","chainId":"_all_"},{"id":"tsp_videobillboard","type":"String","value":"1","chainId":"_all_"},{"id":"zr_km_answer","type":"String","value":"open_cvr","chainId":"_all_"},{"id":"se_likebutton","type":"String","value":"0","chainId":"_all_"},{"id":"se_use_zitem","type":"String","value":"0","chainId":"_all_"},{"id":"zr_rec_answer_cp","type":"String","value":"close","chainId":"_all_"},{"id":"se_click_club","type":"String","value":"1","chainId":"_all_"},{"id":"se_webtimebox","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zcfw_badcase","type":"String","value":"0","chainId":"_all_"},{"id":"soc_leave_recommend","type":"String","value":"2","chainId":"_all_"},{"id":"li_se_media_icon","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_pic","type":"String","value":"0.6","chainId":"_all_"},{"id":"ug_zero_follow","type":"String","value":"0","chainId":"_all_"},{"id":"tp_discover","type":"String","value":"0","chainId":"_all_"},{"id":"web_heifetz_grow_ad","type":"String","value":"1"},{"id":"web_answer_update","type":"String","value":"0"},{"id":"zr_training_boost","type":"String","value":"false","chainId":"_all_"},{"id":"soc_zcfw_broadcast","type":"String","value":"0","chainId":"_all_"},{"id":"pf_adjust","type":"String","value":"0","chainId":"_all_"},{"id":"web_sem_ab","type":"String","value":"1"},{"id":"li_hot_voted","type":"String","value":"0","chainId":"_all_"},{"id":"zr_slot_cold_start","type":"String","value":"aver","chainId":"_all_"},{"id":"pf_noti_entry_num","type":"String","value":"0","chainId":"_all_"},{"id":"tp_score_1","type":"String","value":"a","chainId":"_all_"},{"id":"top_quality","type":"String","value":"0","chainId":"_all_"},{"id":"pf_creator_card","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_android_feed","type":"String","value":"old","chainId":"_all_"},{"id":"pf_newguide_vertical","type":"String","value":"0","chainId":"_all_"},{"id":"ug_follow_answerer_0","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adsort","type":"String","value":"0","chainId":"_all_"},{"id":"soc_notification","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zcfw_shipinshiti","type":"String","value":"1","chainId":"_all_"},{"id":"top_new_feed","type":"String","value":"5","chainId":"_all_"},{"id":"ug_fw_answ_aut_1","type":"String","value":"0","chainId":"_all_"},{"id":"li_svip_cardshow","type":"String","value":"1","chainId":"_all_"},{"id":"se_ad_index","type":"String","value":"10","chainId":"_all_"},{"id":"se_featured","type":"String","value":"1","chainId":"_all_"},{"id":"se_backsearch","type":"String","value":"0","chainId":"_all_"},{"id":"gue_video_replay","type":"String","value":"0"},{"id":"zr_art_rec","type":"String","value":"base","chainId":"_all_"},{"id":"se_prf","type":"String","value":"0","chainId":"_all_"},{"id":"se_new_topic","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_qa","type":"String","value":"1","chainId":"_all_"},{"id":"ug_follow_answerer","type":"String","value":"0","chainId":"_all_"},{"id":"top_ydyq","type":"String","value":"X","chainId":"_all_"},{"id":"li_education_box","type":"String","value":"0","chainId":"_all_"},{"id":"web_answerlist_ad","type":"String","value":"0"},{"id":"tp_qa_metacard","type":"String","value":"1","chainId":"_all_"},{"id":"tp_topic_head","type":"String","value":"0","chainId":"_all_"},{"id":"qap_question_author","type":"String","value":"0","chainId":"_all_"},{"id":"web_column_auto_invite","type":"String","value":"0"},{"id":"se_zu_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_pek_test3","type":"String","value":"1","chainId":"_all_"},{"id":"tp_qa_metacard_top","type":"String","value":"top","chainId":"_all_"},{"id":"qap_question_visitor","type":"String","value":" 0","chainId":"_all_"},{"id":"se_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"se_pek_test","type":"String","value":"1","chainId":"_all_"},{"id":"se_zu_recommend","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_android_join","type":"String","value":"1","chainId":"_all_"},{"id":"web_hdpimg","type":"String","value":"1"},{"id":"zr_expslotpaid","type":"String","value":"1","chainId":"_all_"},{"id":"se_expired_ob","type":"String","value":"0","chainId":"_all_"},{"id":"se_ctx_rerank","type":"String","value":"1","chainId":"_all_"},{"id":"web_answer_list_ad","type":"String","value":"1"},{"id":"se_related_index","type":"String","value":"3","chainId":"_all_"},{"id":"se_col_boost","type":"String","value":"0","chainId":"_all_"},{"id":"se_cate_l3","type":"String","value":"0","chainId":"_all_"},{"id":"li_paid_answer_exp","type":"String","value":"0","chainId":"_all_"},{"id":"li_answers_link","type":"String","value":"0","chainId":"_all_"},{"id":"se_entity_model","type":"String","value":"0","chainId":"_all_"},{"id":"soc_cardheight","type":"String","value":"2","chainId":"_all_"},{"id":"web_creator_route","type":"String","value":"1"},{"id":"li_purchase_test","type":"String","value":"0","chainId":"_all_"},{"id":"se_dnn_mt_v2","type":"String","value":"0","chainId":"_all_"},{"id":"se_preset_tech","type":"String","value":"0","chainId":"_all_"},{"id":"se_presearch_ab","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_discover","type":"String","value":"0","chainId":"_all_"},{"id":"tp_meta_card","type":"String","value":"0","chainId":"_all_"},{"id":"soc_feed_intimacy","type":"String","value":"2","chainId":"_all_"},{"id":"ls_recommend_test","type":"String","value":"0","chainId":"_all_"},{"id":"gue_new_special_page","type":"String","value":"1"},{"id":"se_webrs","type":"String","value":"1","chainId":"_all_"},{"id":"se_hotsearch_2","type":"String","value":"1","chainId":"_all_"},{"id":"web_ask","type":"String","value":"0"},{"id":"zr_intervene","type":"String","value":"0","chainId":"_all_"},{"id":"gue_bullet_second","type":"String","value":"1"},{"id":"li_android_vip","type":"String","value":"0","chainId":"_all_"},{"id":"soc_update","type":"String","value":"1","chainId":"_all_"}],"chains":[{"chainId":"_all_"}]},"triggers":{}},"userAgent":{"Edge":false,"Wechat":false,"Weibo":false,"QQ":false,"MQQBrowser":false,"Qzone":false,"Mobile":false,"Android":false,"iOS":false,"isAppleDevice":false,"Zhihu":false,"ZhihuHybrid":false,"isBot":false,"Tablet":false,"UC":false,"Sogou":false,"Qihoo":false,"Baidu":false,"BaiduApp":false,"Safari":false,"GoogleBot":false,"AndroidDaily":false,"iOSDaily":false,"isWebView":false,"origin":"Mozilla\u002F5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\u002F537.36 (KHTML, like Gecko) Chrome\u002F80.0.3987.100 Safari\u002F537.36"},"appViewConfig":{},"ctx":{"path":"\u002Fp\u002F69324580","query":{},"href":"http:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F69324580","host":"zhuanlan.zhihu.com"},"trafficSource":"production","edition":{"baidu":false,"sogou":false,"baiduBeijing":false,"sogouBeijing":false,"sogouInput":false},"theme":"light","enableShortcut":true,"referer":"","conf":{},"ipInfo":{"cityName":"德州","countryName":"中国","regionName":"山东","countryCode":"CN"},"logged":false},"me":{"columnContributions":[]},"label":{"recognizerLists":{}},"ecommerce":{},"comments":{"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"parent":{}},"commentsV2":{"stickers":[],"commentWithPicPermission":{},"notificationsComments":{},"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"conversationMore":{},"parent":{}},"pushNotifications":{"default":{"isFetching":false,"isDrained":false,"ids":[]},"follow":{"isFetching":false,"isDrained":false,"ids":[]},"vote_thank":{"isFetching":false,"isDrained":false,"ids":[]},"currentTab":"default","notificationsCount":{"default":0,"follow":0,"vote_thank":0}},"messages":{"data":{},"currentTab":"common","messageCount":0},"register":{"registerValidateSucceeded":null,"registerValidateErrors":{},"registerConfirmError":null,"sendDigitsError":null,"registerConfirmSucceeded":null},"login":{"loginUnregisteredError":false,"loginBindWechatError":false,"loginConfirmError":null,"sendDigitsError":null,"needSMSIdentify":false,"validateDigitsError":false,"loginConfirmSucceeded":null,"qrcodeLoginToken":"","qrcodeLoginScanStatus":0,"qrcodeLoginError":null,"qrcodeLoginReturnNewToken":false},"active":{"sendDigitsError":null,"activeConfirmSucceeded":null,"activeConfirmError":null},"switches":{},"captcha":{"captchaNeeded":false,"captchaValidated":false,"captchaBase64String":null,"captchaValidationMessage":null,"loginCaptchaExpires":false},"sms":{"supportedCountries":[]},"chat":{"chats":{},"inbox":{"recents":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"strangers":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"friends":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"search":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"config":{"newCount":0,"strangerMessageSwitch":false,"strangerMessageUnread":false,"friendCount":0}},"global":{"isChatMqttExisted":false}},"emoticons":{"emoticonGroupList":[],"emoticonGroupDetail":{}},"creator":{"currentCreatorUrlToken":null,"homeData":{"recommendQuestions":[]},"tools":{"question":{"invitationCount":{"questionFolloweeCount":0,"questionTotalCount":0},"goodatTopics":[]},"customPromotion":{"itemLists":{}},"recommend":{"recommendTimes":{}}},"explore":{"academy":{"tabs":[],"article":{}}},"rights":[],"rightsStatus":{},"levelUpperLimit":10,"account":{"growthLevel":{}},"mcn":{},"applyStatus":{}},"recommendation":{"homeRecommendations":[]},"shareTexts":{},"articles":{"voters":{}},"previewPost":{},"favlists":{"relations":{}},"columns":{"voters":{}},"reward":{"answer":{},"article":{},"question":{}},"video":{"data":{},"shareVideoDetail":{},"last":{}},"topstory":{"recommend":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"follow":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followWonderful":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"sidebar":null,"announcement":{},"hotListCategories":[],"hotList":[],"guestFeeds":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followExtra":{"isNewUser":null,"isFetched":false,"followCount":0,"followers":[]}},"readStatus":{},"column":{},"requestColumn":{"categories":[],"error":null},"articleContribution":{"contributeRequests":[],"deleteContributeIdList":[],"handledContributeIdList":[],"recommendedColumns":[],"pinnedColumns":[],"sentContributeRequestsIdList":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"reinforcementlearning"]},"columnContribution":{"contributeRequests":[],"autoInviteEnabled":false,"recommendedContributors":[],"contributionInvitation":null},"draftHistory":{"history":{},"drafts":{}},"upload":{},"articleDraft":{"titleImage":"","titleImageSize":{},"isTitleImageFullScreen":false,"canTitleImageFullScreen":false,"title":"","titleImageUploading":false,"error":"","content":"","draftLoading":false,"updating":false,"globalLoading":false,"pendingVideo":{"resource":null,"error":null},"deleteFail":{"fail":false},"recommendTopics":[],"selectedColumn":0,"articleDisclaimers":[]},"articleDrafts":{"isDrained":false,"isLoading":false,"items":[]},"columnAutocomplete":{"users":[],"friends":[]},"columnCollection":{},"mcn":{"bindInfo":{},"memberCategoryList":[],"producerList":[],"categoryList":[]}},"fetchHost":"www.zhihu.com","subAppName":"column"}</script><script src="https://static.zhihu.com/heifetz/vendor.7b36fae46082fd30a0db.js"></script><script src="https://static.zhihu.com/heifetz/column.app.76e02b16e87eec249f44.js"></script></body><script src="https://hm.baidu.com/hm.js?98beee57fd2ef70ccdd5ca52b9740c49" async=""></script><script src="https://zz.bdstatic.com/linksubmit/push.js" async=""></script></html>