<!doctype html>
<html lang="zh" data-hairline="true" data-theme="light"><head><meta charSet="utf-8"/><title data-react-helmet="true">【强化学习 105】RPI - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"/><meta name="renderer" content="webkit"/><meta name="force-rendering" content="webkit"/><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg"/><meta data-react-helmet="true" name="keywords" content="英文论文,学术论文,强化学习 (Reinforcement Learning)"/><meta data-react-helmet="true" name="description" content="这里想讲一篇长论文，这篇论文提出一种 representation policy iteration （RPI） 的框架；同时还在强化学习表示学习方面做了比较详细的讲述。原文传送门Mahadevan, Sridhar. &amp;#34;Learning representation and co…"/><meta data-react-helmet="true" property="og:title" content="【强化学习 105】RPI"/><meta data-react-helmet="true" property="og:url" content="https://zhuanlan.zhihu.com/p/109952463"/><meta data-react-helmet="true" property="og:description" content="这里想讲一篇长论文，这篇论文提出一种 representation policy iteration （RPI） 的框架；同时还在强化学习表示学习方面做了比较详细的讲述。原文传送门Mahadevan, Sridhar. &amp;#34;Learning representation and co…"/><meta data-react-helmet="true" property="og:image" content="https://pic1.zhimg.com/v2-a58915dc326379660c7a6532c5f1817d_b.jpg"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" property="og:site_name" content="知乎专栏"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png" sizes="152x152"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-120.b3e6278d.png" sizes="120x120"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-76.7a750095.png" sizes="76x76"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-60.a4a761d4.png" sizes="60x60"/><link rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/static/favicon.ico"/><link rel="search" type="application/opensearchdescription+xml" href="https://static.zhihu.com/static/search.xml" title="知乎"/><link rel="dns-prefetch" href="//static.zhimg.com"/><link rel="dns-prefetch" href="//pic1.zhimg.com"/><link rel="dns-prefetch" href="//pic2.zhimg.com"/><link rel="dns-prefetch" href="//pic3.zhimg.com"/><link rel="dns-prefetch" href="//pic4.zhimg.com"/><style>
.u-safeAreaInset-top {
  height: constant(safe-area-inset-top) !important;
  height: env(safe-area-inset-top) !important;
  
}
.u-safeAreaInset-bottom {
  height: constant(safe-area-inset-bottom) !important;
  height: env(safe-area-inset-bottom) !important;
  
}
</style><link href="https://static.zhihu.com/heifetz/column.app.a9ced452148fee3a55c8.css" rel="stylesheet"/><script defer="" crossorigin="anonymous" src="https://unpkg.zhimg.com/@cfe/sentry-script@latest/dist/init.js" data-sentry-config="{&quot;dsn&quot;:&quot;https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224&quot;,&quot;sampleRate&quot;:0.1,&quot;release&quot;:&quot;683-127b14ad&quot;,&quot;ignoreErrorNames&quot;:[&quot;NetworkError&quot;,&quot;SecurityError&quot;],&quot;ignoreErrors&quot;:[&quot;origin message&quot;,&quot;Network request failed&quot;,&quot;Loading chunk&quot;,&quot;这个系统不支持该功能。&quot;,&quot;Can&#x27;t find variable: webkit&quot;,&quot;Can&#x27;t find variable: $&quot;,&quot;内存不足&quot;,&quot;out of memory&quot;,&quot;DOM Exception 18&quot;,&quot;The operation is insecure&quot;,&quot;[object Event]&quot;,&quot;[object FileError]&quot;,&quot;[object DOMError]&quot;,&quot;[object Object]&quot;,&quot;拒绝访问。&quot;,&quot;Maximum call stack size exceeded&quot;,&quot;UploadError&quot;,&quot;无法 fetch&quot;,&quot;draft-js&quot;,&quot;缺少 JavaScript 对象&quot;,&quot;componentWillEnter&quot;,&quot;componentWillLeave&quot;,&quot;componentWillAppear&quot;,&quot;getInlineStyleAt&quot;,&quot;getCharacterList&quot;],&quot;whitelistUrls&quot;:[&quot;static.zhihu.com&quot;]}"></script></head><body class="WhiteBg-body"><div id="root"><div class="App"><div class="LoadingBar"></div><main role="main" class="App-main"><div class="Post-content" data-zop-usertoken="{&quot;userToken&quot;:&quot;&quot;}" data-zop="{&quot;authorName&quot;:&quot;张楚珩&quot;,&quot;itemId&quot;:109952463,&quot;title&quot;:&quot;【强化学习 105】RPI&quot;,&quot;type&quot;:&quot;article&quot;}"><div class="ColumnPageHeader-Wrapper"><div><div class="Sticky ColumnPageHeader"><div class="ColumnPageHeader-content"><a href="//www.zhihu.com" aria-label="知乎"><svg viewBox="0 0 200 91" fill="#0084FF" width="64" height="30"><path d="M53.29 80.035l7.32.002 2.41 8.24 13.128-8.24h15.477v-67.98H53.29v67.978zm7.79-60.598h22.756v53.22h-8.73l-8.718 5.473-1.587-5.46-3.72-.012v-53.22zM46.818 43.162h-16.35c.545-8.467.687-16.12.687-22.955h15.987s.615-7.05-2.68-6.97H16.807c1.09-4.1 2.46-8.332 4.1-12.708 0 0-7.523 0-10.085 6.74-1.06 2.78-4.128 13.48-9.592 24.41 1.84-.2 7.927-.37 11.512-6.94.66-1.84.785-2.08 1.605-4.54h9.02c0 3.28-.374 20.9-.526 22.95H6.51c-3.67 0-4.863 7.38-4.863 7.38H22.14C20.765 66.11 13.385 79.24 0 89.62c6.403 1.828 12.784-.29 15.937-3.094 0 0 7.182-6.53 11.12-21.64L43.92 85.18s2.473-8.402-.388-12.496c-2.37-2.788-8.768-10.33-11.496-13.064l-4.57 3.627c1.363-4.368 2.183-8.61 2.46-12.71H49.19s-.027-7.38-2.372-7.38zm128.752-.502c6.51-8.013 14.054-18.302 14.054-18.302s-5.827-4.625-8.556-1.27c-1.874 2.548-11.51 15.063-11.51 15.063l6.012 4.51zm-46.903-18.462c-2.814-2.577-8.096.667-8.096.667s12.35 17.2 12.85 17.953l6.08-4.29s-8.02-11.752-10.83-14.33zM199.99 46.5c-6.18 0-40.908.292-40.953.292v-31.56c1.503 0 3.882-.124 7.14-.376 12.773-.753 21.914-1.25 27.427-1.504 0 0 3.817-8.496-.185-10.45-.96-.37-7.24 1.43-7.24 1.43s-51.63 5.153-72.61 5.64c.5 2.756 2.38 5.336 4.93 6.11 4.16 1.087 7.09.53 15.36.277 7.76-.5 13.65-.76 17.66-.76v31.19h-41.71s.88 6.97 7.97 7.14h33.73v22.16c0 4.364-3.498 6.87-7.65 6.6-4.4.034-8.15-.36-13.027-.566.623 1.24 1.977 4.496 6.035 6.824 3.087 1.502 5.054 2.053 8.13 2.053 9.237 0 14.27-5.4 14.027-14.16V53.93h38.235c3.026 0 2.72-7.432 2.72-7.432z" fill-rule="evenodd"></path></svg></a><i class="ColumnPageHeader-Line"></i><div class="ColumnPageHeader-Title"><a class="ColumnLink ColumnPageHeader-Link" href="/reinforcementlearning"><img class="Avatar Avatar--round" width="30" height="30" src="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_is.jpg" srcSet="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_im.jpg 2x" alt="强化学习前沿"/></a><div class="ColumnPageHeader-TitleName"><span class="ColumnPageHeader-TitleMeta">首发于</span><a class="ColumnLink ColumnPageHeader-TitleColumn" href="/reinforcementlearning">强化学习前沿</a></div></div><div class="ColumnPageHeader-Button"><button type="button" class="Button ColumnPageHeader-WriteButton Button--blue"><svg class="Zi Zi--EditSurround" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M18.453 7.992l-1.833-1.65.964-.978a1.223 1.223 0 0 1 1.73-.012l.005.006a1.24 1.24 0 0 1 .007 1.748l-.873.886zm-1.178 1.194l-5.578 5.66-1.935.697a.393.393 0 0 1-.504-.504l.697-1.935 5.488-5.567 1.832 1.65zM7.58 5.848l5.654.006-1.539 1.991-3.666.012A1.02 1.02 0 0 0 7 8.868v7.993c0 .558.46 1.01 1.029 1.01l7.941-.01c.568 0 1.03-.453 1.03-1.012v-4.061l2-1.442v6.002c0 1.397-1.2 2.501-2.62 2.501H7.574C6.153 19.85 5 18.717 5 17.32V8.35c0-1.397 1.16-2.502 2.58-2.502z"></path></svg>写文章</button></div></div></div></div></div><img class="TitleImage" src="https://pic1.zhimg.com/v2-a58915dc326379660c7a6532c5f1817d_1200x500.jpg" alt="【强化学习 105】RPI"/><article class="Post-Main Post-NormalMain" tabindex="-1"><header class="Post-Header"><h1 class="Post-Title">【强化学习 105】RPI</h1><div class="Post-Author"><div class="AuthorInfo" itemProp="author" itemscope="" itemType="http://schema.org/Person"><meta itemProp="name" content="张楚珩"/><meta itemProp="image" content="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg"/><meta itemProp="url" content="https://www.zhihu.com/people/zhang-chu-heng"/><meta itemProp="zhihu:followerCount"/><span class="UserLink AuthorInfo-avatarWrapper"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/zhang-chu-heng"><img class="Avatar Avatar--round AuthorInfo-avatar" width="38" height="38" src="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_xs.jpg" srcSet="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg 2x" alt="张楚珩"/></a></div></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/zhang-chu-heng">张楚珩</a></div></div><style data-emotion-css="1cd9gw4">.css-1cd9gw4{margin-left:.3em;}</style><style data-emotion-css="1pc1mic">.css-1pc1mic{box-sizing:border-box;margin:0;min-width:0;color:#175199;display:inline-block;width:18px;height:18px;margin-left:.3em;}</style><a href="https://www.zhihu.com/question/48510028" target="_blank" class="css-1pc1mic" data-tooltip="已认证的个人" aria-label="已认证的个人"><style data-emotion-css="18biwo">.css-18biwo{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><span class="css-18biwo">​<svg viewBox="0 0 24 24" width="18" height="18"><svg viewBox="0 0 24 24" x="-3" y="-3" fill="#FFFFFF" width="30" height="30"><path d="M3.56231227,13.8535307 C2.40051305,12.768677 2.41398885,11.0669203 3.59484487,9.99979213 L3.59222085,9.99654885 C4.26730143,9.45036719 4.79446755,8.21005186 4.7184197,7.34453784 L4.72305873,7.34412719 C4.66942824,5.75539997 5.8824188,4.56066914 7.47188965,4.64242381 L7.47229112,4.6386236 C8.33515314,4.72977993 9.58467253,4.22534048 10.1426329,3.55925173 L10.1462611,3.56228565 C11.2316055,2.40008701 12.9353108,2.41394456 14.0015072,3.59634088 L14.0047263,3.59374004 C14.5498229,4.26841874 15.7896857,4.79521622 16.6545744,4.71844347 L16.6549836,4.72304294 C18.245027,4.66894057 19.4396947,5.88213996 19.3575031,7.47241135 L19.3623099,7.47292747 C19.2704388,8.3358681 19.7742711,9.58421483 20.4407199,10.1424506 L20.437686,10.1460789 C21.5997217,11.2312209 21.5860695,12.9345218 20.4042441,14.0007396 L20.4072865,14.0045125 C19.7325967,14.5495925 19.2055209,15.7896954 19.2815865,16.6561959 L19.2770449,16.6565978 C19.3315454,18.2453037 18.1173775,19.4393568 16.5274188,19.3571512 L16.5269029,19.3619539 C15.6647098,19.270083 14.415408,19.7741709 13.8573671,20.4403558 L13.8537409,20.4373235 C12.76842,21.5995708 11.0650432,21.5864553 9.99899434,20.4039226 L9.99527367,20.406923 C9.45025436,19.7323399 8.21017638,19.2051872 7.34461983,19.2812352 L7.344304,19.2776405 C5.75448683,19.3312904 4.55977145,18.1170085 4.64254978,16.527117 L4.63769921,16.5265942 C4.72957031,15.6644394 4.22547659,14.4151814 3.55928015,13.8571569 L3.56231227,13.8535307 Z"></path></svg><path d="M2.63951518,13.3895441 C3.70763333,14.2842292 4.44777637,16.1226061 4.30075305,17.5023312 L4.32211542,17.3063047 C4.17509209,18.6910561 5.17786655,19.7063729 6.5613937,19.5844846 L6.364106,19.6008202 C7.75140298,19.4789319 9.57474349,20.2554985 10.4468305,21.3349009 L10.3224262,21.1803415 C11.1982831,22.2647703 12.6257916,22.2723098 13.5167278,21.2079863 L13.3898102,21.3600325 C14.2845162,20.2919393 16.1229361,19.5518136 17.5026934,19.6988334 L17.3054057,19.6774716 C18.6914461,19.8244915 19.7067866,18.8217404 19.5836389,17.4395022 L19.6012314,17.6367853 C19.4793403,16.2482641 20.255925,14.4249662 21.3353526,13.5528995 L21.1807897,13.677301 C22.2639871,12.8014646 22.2727834,11.3739894 21.2084351,10.483074 L21.3604848,10.6099886 C20.2923667,9.71530351 19.5522236,7.87818322 19.6992469,6.49720154 L19.6778846,6.69448464 C19.8249079,5.30847665 18.8221335,4.2944164 17.4386063,4.41630468 L17.635894,4.39871256 C16.248597,4.52185742 14.4252565,3.74529084 13.5531695,2.66588842 L13.6775738,2.81919121 C12.8017169,1.73601905 11.3742084,1.72722299 10.4832722,2.79154644 L10.6101898,2.63950024 C9.71548377,3.70759343 7.87706394,4.44771919 6.49730661,4.30195588 L6.69459432,4.32206116 C5.30855394,4.17504128 4.29447,5.17904888 4.41636114,6.56128713 L4.3987686,6.36400404 C4.52065973,7.75126861 3.74407501,9.57456653 2.66464737,10.4478898 L2.81921035,10.3222318 C1.73601288,11.1993248 1.72721662,12.6255433 2.79156494,13.5164587 L2.63951518,13.3895441 Z" fill="#0084FF"></path><svg class="Zi Zi--Check" fill="#fff" x="6" y="6" viewBox="0 0 24 24" width="12" height="12"><path d="M10.229 17.516c-.318.327-.75.484-1.199.484-.453 0-.884-.16-1.202-.488l-4.335-4.47a1.77 1.77 0 0 1 .007-2.459 1.663 1.663 0 0 1 2.397.01l3.137 3.246 9.072-9.329a1.662 1.662 0 0 1 2.397 0c.663.681.663 1.786 0 2.466L10.23 17.516z" fill-rule="evenodd"></path></svg></svg></span></a></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="AuthorInfo-badgeText">清华大学 交叉信息院博士在读</div></div></div></div></div></div><div><span class="Voters"><button type="button" class="Button Button--plain">33 人<!-- -->赞同了该文章</button></span></div></header><div class="Post-RichTextContainer"><div class="RichText ztext Post-RichText"><p>这里想讲一篇长论文，这篇论文提出一种 representation policy iteration （RPI） 的框架；同时还在强化学习表示学习方面做了比较详细的讲述。</p><h2>原文传送门</h2><p><a href="https://link.zhihu.com/?target=https%3A//www.nowpublishers.com/article/DownloadSummary/MAL-003" class=" wrap external" target="_blank" rel="nofollow noreferrer">Mahadevan, Sridhar. &#34;Learning representation and control in Markov decision processes: New frontiers.&#34; Foundations and Trends® in Machine Learning 1.4 (2009): 403-565.</a></p><h2>特色</h2><p>提出 representation policy iteration （RPI），一边学习好的状态空间表示，一边利用所学习到的状态表示来学习策略。把所有的状态看做一个graph，学习状态空间的表示就是要找到这个graph上比较少的几个基函数，使得定义在这个graph上的任意一个函数都尽量可以用这几个基函数来表示。当学习到这样一个状态空间的表示之后，原来较为复杂的MDP就被转化为了一个更简单的MDP，我们可以在这个简单的MDP上求解最优策略。</p><p>当然，注意到这篇文章写在十多年前，不是很新；RPI 收敛的条件不是很清楚（表示是依赖于策略的，策略学习到最优的时候，表示可能只适用于该策略和奖励函数，which is a 1D subspace；关于这一点可以看完之后倒回来思考）；RPI 在复杂问题上的效果不是很清楚。</p><h2>过程</h2><h3>1. 强化学习中的表示学习</h3><p><b><u>动机</u></b></p><p>状态数目较少的时候，可以分别处理每个不同的状态（tabular case），这些强化学习算法的复杂度通常和状态的总数有关；当状态空间特别大的时候就不能再把每个不同的状态分别处理了，而是需要利用一些特征来表示这些状态，从而更有效地解决强化学习问题。</p><p>一些常用的状态表示方法（比如 polynomials、RBFs、NNs）通常从原始的特征出发，构建新的状态表示；这一类表示方法通常依赖于一个先验知识：各种函数相对于原始特征是比较平滑的。本文的方法则把各个状态之间的关系看做一个 graph，其依赖的先验知识则是各种函数在这个 graph 上是比较平滑的。这里提到的各种函数包括：reward function、transition function、value function 和 policy 等。</p><p><b><u>MDP 中的基底构造问题</u></b></p><p>基底构造的目标是找到一组基函数 <img src="https://www.zhihu.com/equation?tex=%5CPhi+%5Cin+%5Cmathbb%7BR%7D%5E%7B%7CS%7C%5Ctimes+k%7D" alt="\Phi \in \mathbb{R}^{|S|\times k}" eeimg="1"/> ，它包括 k 个基函数；我们希望这一组基函数能够以较小的代价近似该 MDP 上的各种函数。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-c1d871d4b5d55f606bf733bd463ff9aa_b.jpg" data-caption="" data-size="normal" data-rawwidth="451" data-rawheight="96" class="origin_image zh-lightbox-thumb" width="451" data-original="https://pic3.zhimg.com/v2-c1d871d4b5d55f606bf733bd463ff9aa_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;451&#39; height=&#39;96&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="451" data-rawheight="96" class="origin_image zh-lightbox-thumb lazy" width="451" data-original="https://pic3.zhimg.com/v2-c1d871d4b5d55f606bf733bd463ff9aa_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-c1d871d4b5d55f606bf733bd463ff9aa_b.jpg"/></figure><p>因此该问题中涉及到一些权衡：基底数目越少，在近似的 MDP 上的问题求解就会更加容易，但同时求解就会更加不精确。因此，我们的目标就是用尽可能少的基底来准确表示 MDP 上的各种函数。</p><p>特别地，在上述提到的各种函数中我们最为关心的是价值函数（value function）的函数拟合问题。我们注意到，即使没有任何先验知识（比如函数需要平滑），也有可能找出一组满足 <img src="https://www.zhihu.com/equation?tex=k%3C%7CS%7C" alt="k&lt;|S|" eeimg="1"/> 的基函数，使得 approximation error 为零。比如，假设这样一组基函数构成了某个空间，该空间内任何函数在 Bellman 算子 <img src="https://www.zhihu.com/equation?tex=T%5E%5Cpi" alt="T^\pi" eeimg="1"/> 的作用后，仍然还在该空间内；我们称这样的空间为 invariant subspace。在这样的空间中，一定存在待求解的价值函数 <img src="https://www.zhihu.com/equation?tex=V%5E%5Cpi" alt="V^\pi" eeimg="1"/> 。</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-9425a3606494c05f83535f70c6da3ecf_b.png" data-caption="" data-size="normal" data-rawwidth="441" data-rawheight="36" class="origin_image zh-lightbox-thumb" width="441" data-original="https://pic4.zhimg.com/v2-9425a3606494c05f83535f70c6da3ecf_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;441&#39; height=&#39;36&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="441" data-rawheight="36" class="origin_image zh-lightbox-thumb lazy" width="441" data-original="https://pic4.zhimg.com/v2-9425a3606494c05f83535f70c6da3ecf_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-9425a3606494c05f83535f70c6da3ecf_b.png"/></figure><p>因此，在这篇文章中，基底构造问题也可以看做是构造这样的 invariant subspace。文章主要介绍了两大类方法来实现这件事情：diagonalization 和 dilation。前者在本专栏里面有提到过，用它来构造状态空间基函数比较著名的方法就是 PVF（<a href="https://zhuanlan.zhihu.com/p/68326687" class="internal">张楚珩：【强化学习 67】Proto-value Function</a>）。后者我们还不太熟悉，dilation 的方法分为两种：一种基于 Krylov space；一种基于 Drazin inverse 和 diffusion wavelet。名字听起来有点复杂，但是我们会在后面展开讲。</p><h3>2. Average-reward MDP 以及 MDP 的结构</h3><p>我们比较熟悉的是 finite horizon 和 infinite horizon + discount 的设定。这篇文章里面还提到了 infinite horizon + average-reward 的设定，这种设定对于马科夫过程的结构关系比较紧密。我们下面考虑一个固定策略下的 MDP，即 Markov reward process （MRP），记做 M=(P, R)。</p><p><u><b>Limiting matrix P*</b></u></p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-ab9bebcde12b8b18bdd4af857cfff283_b.jpg" data-caption="" data-size="normal" data-rawwidth="627" data-rawheight="153" class="origin_image zh-lightbox-thumb" width="627" data-original="https://pic4.zhimg.com/v2-ab9bebcde12b8b18bdd4af857cfff283_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;627&#39; height=&#39;153&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="627" data-rawheight="153" class="origin_image zh-lightbox-thumb lazy" width="627" data-original="https://pic4.zhimg.com/v2-ab9bebcde12b8b18bdd4af857cfff283_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-ab9bebcde12b8b18bdd4af857cfff283_b.jpg"/></figure><p>如果 MRP 是遍历和非周期的，那么该矩阵的每一行都一样，都等于稳态分布（invariant distribution），即</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-4eb5bce417900cb9379d96f6d0f946f6_b.png" data-caption="" data-size="normal" data-rawwidth="469" data-rawheight="42" class="origin_image zh-lightbox-thumb" width="469" data-original="https://pic3.zhimg.com/v2-4eb5bce417900cb9379d96f6d0f946f6_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;469&#39; height=&#39;42&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="469" data-rawheight="42" class="origin_image zh-lightbox-thumb lazy" width="469" data-original="https://pic3.zhimg.com/v2-4eb5bce417900cb9379d96f6d0f946f6_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-4eb5bce417900cb9379d96f6d0f946f6_b.png"/></figure><p><b><u>Invariant distribution <img src="https://www.zhihu.com/equation?tex=%5Crho" alt="\rho" eeimg="1"/></u></b> </p><p>注意到如果 MRP 遍历，那么 P 的最大特征值（即，spectral radius）为 1，相应的左特征向量就是该稳态分布。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-5d5a542b9119591fe75696c200346e0c_b.png" data-caption="" data-size="normal" data-rawwidth="484" data-rawheight="41" class="origin_image zh-lightbox-thumb" width="484" data-original="https://pic1.zhimg.com/v2-5d5a542b9119591fe75696c200346e0c_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;484&#39; height=&#39;41&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="484" data-rawheight="41" class="origin_image zh-lightbox-thumb lazy" width="484" data-original="https://pic1.zhimg.com/v2-5d5a542b9119591fe75696c200346e0c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-5d5a542b9119591fe75696c200346e0c_b.png"/></figure><p><b><u>Gain g and bias h</u></b></p><p>当存在 discount rate 的时候，优化的目标为 discounted cumulative reward，它综合考虑了长远利益和近期的利益，通过一个 discount rate 来把长远利益和近期利益综合为一个指标。而在 average-reward 的设定下，这两种利益则会被分别考虑：其中 gain 表征长期平均利益，bias 表示实际收到利益相对于长期利益的差值的累计。</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-bbe611ec812dc0a9e12142a6e074aeaf_b.png" data-caption="" data-size="normal" data-rawwidth="477" data-rawheight="36" class="origin_image zh-lightbox-thumb" width="477" data-original="https://pic4.zhimg.com/v2-bbe611ec812dc0a9e12142a6e074aeaf_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;477&#39; height=&#39;36&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="477" data-rawheight="36" class="origin_image zh-lightbox-thumb lazy" width="477" data-original="https://pic4.zhimg.com/v2-bbe611ec812dc0a9e12142a6e074aeaf_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-bbe611ec812dc0a9e12142a6e074aeaf_b.png"/></figure><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-a25e2b336488735ed7e2f71e573ccbe1_b.png" data-caption="" data-size="normal" data-rawwidth="477" data-rawheight="56" class="origin_image zh-lightbox-thumb" width="477" data-original="https://pic2.zhimg.com/v2-a25e2b336488735ed7e2f71e573ccbe1_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;477&#39; height=&#39;56&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="477" data-rawheight="56" class="origin_image zh-lightbox-thumb lazy" width="477" data-original="https://pic2.zhimg.com/v2-a25e2b336488735ed7e2f71e573ccbe1_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-a25e2b336488735ed7e2f71e573ccbe1_b.png"/></figure><p>比如 g(s) 表示从状态 s 出发，走无穷多步之后，平均每一步能够获取的平均利益；而在达到这个“无穷多步”之前，每一步获取利益的期望都可能并不等于极限平均利益，把这一部分差值累积起来就得到了 h(s)。当 MRP 遍历的时候，bias 部分还可以写作</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-0bc6b93a08c51ff137f80b2b3197006f_b.png" data-caption="" data-size="normal" data-rawwidth="467" data-rawheight="51" class="origin_image zh-lightbox-thumb" width="467" data-original="https://pic4.zhimg.com/v2-0bc6b93a08c51ff137f80b2b3197006f_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;467&#39; height=&#39;51&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="467" data-rawheight="51" class="origin_image zh-lightbox-thumb lazy" width="467" data-original="https://pic4.zhimg.com/v2-0bc6b93a08c51ff137f80b2b3197006f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-0bc6b93a08c51ff137f80b2b3197006f_b.png"/></figure><p>在 average-reward 的设定下，我们不仅需要最大化 gain 也希望最大化 bias。</p><p><b><u>Bellman equation</u></b></p><p>该设定下同样有 Bellman equation</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-c546d82d248de40679cac61a9b3edbb2_b.jpg" data-caption="" data-size="normal" data-rawwidth="584" data-rawheight="176" class="origin_image zh-lightbox-thumb" width="584" data-original="https://pic3.zhimg.com/v2-c546d82d248de40679cac61a9b3edbb2_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;584&#39; height=&#39;176&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="584" data-rawheight="176" class="origin_image zh-lightbox-thumb lazy" width="584" data-original="https://pic3.zhimg.com/v2-c546d82d248de40679cac61a9b3edbb2_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-c546d82d248de40679cac61a9b3edbb2_b.jpg"/></figure><p>为了便于大家理解，给出一个简单的 MRP 的算例。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-1ae3994f2e35023a57cb3ea43c1d887e_b.jpg" data-caption="" data-size="normal" data-rawwidth="759" data-rawheight="774" class="origin_image zh-lightbox-thumb" width="759" data-original="https://pic3.zhimg.com/v2-1ae3994f2e35023a57cb3ea43c1d887e_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;759&#39; height=&#39;774&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="759" data-rawheight="774" class="origin_image zh-lightbox-thumb lazy" width="759" data-original="https://pic3.zhimg.com/v2-1ae3994f2e35023a57cb3ea43c1d887e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-1ae3994f2e35023a57cb3ea43c1d887e_b.jpg"/></figure><p>3. Generalized Inverse</p><p>如果一个方阵不是满秩的，那么它就不可逆；不过此时我们可以定义广义逆（generalized inverse）。注意到一个真正的逆满足以下所有条件，但当方阵不是满秩时，不能找出一个逆满足这所有的条件，根据逆所满足的不同条件可以定义不同的广义逆。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-9aa22571ec5a14f5a91c93b8ee29d552_b.jpg" data-caption="" data-size="normal" data-rawwidth="548" data-rawheight="273" class="origin_image zh-lightbox-thumb" width="548" data-original="https://pic3.zhimg.com/v2-9aa22571ec5a14f5a91c93b8ee29d552_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;548&#39; height=&#39;273&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="548" data-rawheight="273" class="origin_image zh-lightbox-thumb lazy" width="548" data-original="https://pic3.zhimg.com/v2-9aa22571ec5a14f5a91c93b8ee29d552_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-9aa22571ec5a14f5a91c93b8ee29d552_b.jpg"/></figure><p>非常著名的 Moore-Penrose pseudo-inverse 满足前四条，即 <img src="https://www.zhihu.com/equation?tex=A%5E%5Cdagger+%3D+A%5E%7B%5C%7B1%2C+2%2C3%2C4%5C%7D%7D" alt="A^\dagger = A^{\{1, 2,3,4\}}" eeimg="1"/> ；group inverse 满足其中的三条，即 <img src="https://www.zhihu.com/equation?tex=A%5E%5C%23+%3D+A%5E%7B%5C%7B1%2C2%2C5%5C%7D%7D" alt="A^\# = A^{\{1,2,5\}}" eeimg="1"/> ；Drazin inverse 也满足其中的三条，即 <img src="https://www.zhihu.com/equation?tex=A%5ED+%3D+A%5E%7B%5C%7B2%2C5%2C6%5C%7D%7D" alt="A^D = A^{\{2,5,6\}}" eeimg="1"/> 。</p><h3>3. Laplacian 算子</h3><p>在专栏前面的文章里面我们看到可以在图上定义若干种不同的 Laplacian：</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-d887c5238abd75ce0e8b3f2d0233e337_b.jpg" data-caption="" data-size="normal" data-rawwidth="605" data-rawheight="133" class="origin_image zh-lightbox-thumb" width="605" data-original="https://pic4.zhimg.com/v2-d887c5238abd75ce0e8b3f2d0233e337_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;605&#39; height=&#39;133&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="605" data-rawheight="133" class="origin_image zh-lightbox-thumb lazy" width="605" data-original="https://pic4.zhimg.com/v2-d887c5238abd75ce0e8b3f2d0233e337_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-d887c5238abd75ce0e8b3f2d0233e337_b.jpg"/></figure><p>如果把不同的状态看做图上的节点，当给定一个概率转移矩阵 P 时，就对应了一个 MC；由此，可以定义相应的 random walk Laplacian 算子 <img src="https://www.zhihu.com/equation?tex=%5Cmathbb%7BL%7D+%3D+I-P" alt="\mathbb{L} = I-P" eeimg="1"/> 。同时注意到价值函数可以由相应的 Laplacian 算子表示。</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-196585f471b0dd10dc3ddd919005447d_b.png" data-caption="" data-size="normal" data-rawwidth="584" data-rawheight="93" class="origin_image zh-lightbox-thumb" width="584" data-original="https://pic2.zhimg.com/v2-196585f471b0dd10dc3ddd919005447d_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;584&#39; height=&#39;93&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="584" data-rawheight="93" class="origin_image zh-lightbox-thumb lazy" width="584" data-original="https://pic2.zhimg.com/v2-196585f471b0dd10dc3ddd919005447d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-196585f471b0dd10dc3ddd919005447d_b.png"/></figure><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-730b5b32395e6f55b026fbc1d56b538b_b.jpg" data-caption="" data-size="normal" data-rawwidth="584" data-rawheight="123" class="origin_image zh-lightbox-thumb" width="584" data-original="https://pic4.zhimg.com/v2-730b5b32395e6f55b026fbc1d56b538b_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;584&#39; height=&#39;123&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="584" data-rawheight="123" class="origin_image zh-lightbox-thumb lazy" width="584" data-original="https://pic4.zhimg.com/v2-730b5b32395e6f55b026fbc1d56b538b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-730b5b32395e6f55b026fbc1d56b538b_b.jpg"/></figure><p>Laplacian 算子的 group inverse 可以被写为</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-e30e25763ffd28321ea78c113e2e1d69_b.jpg" data-caption="" data-size="normal" data-rawwidth="537" data-rawheight="107" class="origin_image zh-lightbox-thumb" width="537" data-original="https://pic2.zhimg.com/v2-e30e25763ffd28321ea78c113e2e1d69_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;537&#39; height=&#39;107&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="537" data-rawheight="107" class="origin_image zh-lightbox-thumb lazy" width="537" data-original="https://pic2.zhimg.com/v2-e30e25763ffd28321ea78c113e2e1d69_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-e30e25763ffd28321ea78c113e2e1d69_b.jpg"/></figure><p>其中，中间求逆的部分被称作 fundamental matrix，它是可逆的：</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-b78000de195080cf9d8339e5c2ff0ee0_b.jpg" data-caption="" data-size="normal" data-rawwidth="543" data-rawheight="141" class="origin_image zh-lightbox-thumb" width="543" data-original="https://pic1.zhimg.com/v2-b78000de195080cf9d8339e5c2ff0ee0_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;543&#39; height=&#39;141&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="543" data-rawheight="141" class="origin_image zh-lightbox-thumb lazy" width="543" data-original="https://pic1.zhimg.com/v2-b78000de195080cf9d8339e5c2ff0ee0_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-b78000de195080cf9d8339e5c2ff0ee0_b.jpg"/></figure><p>Laplacian 算子的 Drazin inverse 的计算稍微复杂一点，假设 transition matrix 可以做如下分解</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-dc73c070523827f8a9e2bffe2633246d_b.jpg" data-caption="" data-size="normal" data-rawwidth="531" data-rawheight="215" class="origin_image zh-lightbox-thumb" width="531" data-original="https://pic2.zhimg.com/v2-dc73c070523827f8a9e2bffe2633246d_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;531&#39; height=&#39;215&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="531" data-rawheight="215" class="origin_image zh-lightbox-thumb lazy" width="531" data-original="https://pic2.zhimg.com/v2-dc73c070523827f8a9e2bffe2633246d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-dc73c070523827f8a9e2bffe2633246d_b.jpg"/></figure><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-dd789d59d34945c195d1fdfe8854a1a3_b.png" data-caption="" data-size="normal" data-rawwidth="541" data-rawheight="30" class="origin_image zh-lightbox-thumb" width="541" data-original="https://pic4.zhimg.com/v2-dd789d59d34945c195d1fdfe8854a1a3_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;541&#39; height=&#39;30&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="541" data-rawheight="30" class="origin_image zh-lightbox-thumb lazy" width="541" data-original="https://pic4.zhimg.com/v2-dd789d59d34945c195d1fdfe8854a1a3_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-dd789d59d34945c195d1fdfe8854a1a3_b.png"/></figure><p>那么相应的 Drazin inverse 可以被写为：</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-2ea0ea6e85b33f81562031835d728e6b_b.jpg" data-caption="" data-size="normal" data-rawwidth="514" data-rawheight="114" class="origin_image zh-lightbox-thumb" width="514" data-original="https://pic4.zhimg.com/v2-2ea0ea6e85b33f81562031835d728e6b_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;514&#39; height=&#39;114&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="514" data-rawheight="114" class="origin_image zh-lightbox-thumb lazy" width="514" data-original="https://pic4.zhimg.com/v2-2ea0ea6e85b33f81562031835d728e6b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-2ea0ea6e85b33f81562031835d728e6b_b.jpg"/></figure><p>文章给出了相应的计算 Drazin inverse 的方法，输入 Laplacian 矩阵，输出相应的 Drazin inverse。这里不再贴出来了。</p><p><b>那么我们为什么要计算 Laplacian 的逆呢？</b>因为价值函数可以被表示为 Laplacian 逆的多项式和，而高阶多项式的系数又衰减地比较快，因此可以用 Laplacian 逆对应较大特征值的特征向量来作为我们需要的基底，从而对图上的函数有较好的近似。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-519174ed5ea87d08c53719a938b12324_b.jpg" data-caption="" data-size="normal" data-rawwidth="532" data-rawheight="161" class="origin_image zh-lightbox-thumb" width="532" data-original="https://pic1.zhimg.com/v2-519174ed5ea87d08c53719a938b12324_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;532&#39; height=&#39;161&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="532" data-rawheight="161" class="origin_image zh-lightbox-thumb lazy" width="532" data-original="https://pic1.zhimg.com/v2-519174ed5ea87d08c53719a938b12324_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-519174ed5ea87d08c53719a938b12324_b.jpg"/></figure><h3>4. 希尔伯特空间</h3><p><b><u>在无向图上定义 RKHS</u></b></p><p>通过在无向图上定义 RKHS，说明从数学上应该如何描述函数在图上的平滑性。</p><p>对于一个无向图，其邻接矩阵为 W。Laplacian 算子在图上定义了半范数，“半”是因为它对于任意的常值函数，其范数都为零。</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-9c29436ed20d27c2e3992728599bfb1d_b.jpg" data-caption="" data-size="normal" data-rawwidth="574" data-rawheight="122" class="origin_image zh-lightbox-thumb" width="574" data-original="https://pic2.zhimg.com/v2-9c29436ed20d27c2e3992728599bfb1d_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;574&#39; height=&#39;122&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="574" data-rawheight="122" class="origin_image zh-lightbox-thumb lazy" width="574" data-original="https://pic2.zhimg.com/v2-9c29436ed20d27c2e3992728599bfb1d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-9c29436ed20d27c2e3992728599bfb1d_b.jpg"/></figure><p>这个半范数反映了一个函数在图上的不平滑程度，可以从下面这个公式看出来</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-4aa6ddc67f00beb2dfb360a34c3538f3_b.png" data-caption="" data-size="normal" data-rawwidth="576" data-rawheight="87" class="origin_image zh-lightbox-thumb" width="576" data-original="https://pic4.zhimg.com/v2-4aa6ddc67f00beb2dfb360a34c3538f3_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;576&#39; height=&#39;87&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="576" data-rawheight="87" class="origin_image zh-lightbox-thumb lazy" width="576" data-original="https://pic4.zhimg.com/v2-4aa6ddc67f00beb2dfb360a34c3538f3_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-4aa6ddc67f00beb2dfb360a34c3538f3_b.png"/></figure><p>其中 w 为其邻接矩阵的元素。我们注意到，Laplacian 矩阵一定会有一个或者多个特征值为 0，这表示该图有多少个连通区域。把不同连通区域之间的函数自由组合的自由度排除之后，可以定义在图上的希尔伯特空间。</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-e49cd7cf2e6e4072277e7c528df58e81_b.jpg" data-caption="" data-size="normal" data-rawwidth="533" data-rawheight="136" class="origin_image zh-lightbox-thumb" width="533" data-original="https://pic2.zhimg.com/v2-e49cd7cf2e6e4072277e7c528df58e81_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;533&#39; height=&#39;136&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="533" data-rawheight="136" class="origin_image zh-lightbox-thumb lazy" width="533" data-original="https://pic2.zhimg.com/v2-e49cd7cf2e6e4072277e7c528df58e81_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-e49cd7cf2e6e4072277e7c528df58e81_b.jpg"/></figure><p>由此，定义 Laplacian 矩阵的伪逆，并且该伪逆就是再生希尔伯特空间（RKHS）的再生核。</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-3175e54ed788091bbbc74080126017ab_b.jpg" data-caption="" data-size="normal" data-rawwidth="529" data-rawheight="105" class="origin_image zh-lightbox-thumb" width="529" data-original="https://pic4.zhimg.com/v2-3175e54ed788091bbbc74080126017ab_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;529&#39; height=&#39;105&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="529" data-rawheight="105" class="origin_image zh-lightbox-thumb lazy" width="529" data-original="https://pic4.zhimg.com/v2-3175e54ed788091bbbc74080126017ab_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-3175e54ed788091bbbc74080126017ab_b.jpg"/></figure><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-56c4ed9f5ae680f93f29bf867bdbd9fe_b.png" data-caption="" data-size="normal" data-rawwidth="522" data-rawheight="47" class="origin_image zh-lightbox-thumb" width="522" data-original="https://pic3.zhimg.com/v2-56c4ed9f5ae680f93f29bf867bdbd9fe_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;522&#39; height=&#39;47&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="522" data-rawheight="47" class="origin_image zh-lightbox-thumb lazy" width="522" data-original="https://pic3.zhimg.com/v2-56c4ed9f5ae680f93f29bf867bdbd9fe_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-56c4ed9f5ae680f93f29bf867bdbd9fe_b.png"/></figure><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-367cd6f83262cb662ab61899f24dd418_b.jpg" data-caption="" data-size="normal" data-rawwidth="503" data-rawheight="94" class="origin_image zh-lightbox-thumb" width="503" data-original="https://pic1.zhimg.com/v2-367cd6f83262cb662ab61899f24dd418_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;503&#39; height=&#39;94&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="503" data-rawheight="94" class="origin_image zh-lightbox-thumb lazy" width="503" data-original="https://pic1.zhimg.com/v2-367cd6f83262cb662ab61899f24dd418_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-367cd6f83262cb662ab61899f24dd418_b.jpg"/></figure><p>回忆一下，再生核的含义</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-9576eefe7e918dde279a6bac4e1b119a_b.png" data-caption="" data-size="normal" data-rawwidth="480" data-rawheight="32" class="origin_image zh-lightbox-thumb" width="480" data-original="https://pic3.zhimg.com/v2-9576eefe7e918dde279a6bac4e1b119a_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;480&#39; height=&#39;32&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="480" data-rawheight="32" class="origin_image zh-lightbox-thumb lazy" width="480" data-original="https://pic3.zhimg.com/v2-9576eefe7e918dde279a6bac4e1b119a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-9576eefe7e918dde279a6bac4e1b119a_b.png"/></figure><p>当我们利用 Laplacian 算子在图上定义了一个 RKHS 之后，图上的函数拟合问题的原则就是找到一个最光滑的函数，即 minimum-norm interpretation。（可以参考本专栏前面讲的一个平均场方法求解半监督学习的文章）</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-a990a6186893d3cc06584340ea710d48_b.jpg" data-caption="" data-size="normal" data-rawwidth="508" data-rawheight="113" class="origin_image zh-lightbox-thumb" width="508" data-original="https://pic1.zhimg.com/v2-a990a6186893d3cc06584340ea710d48_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;508&#39; height=&#39;113&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="508" data-rawheight="113" class="origin_image zh-lightbox-thumb lazy" width="508" data-original="https://pic1.zhimg.com/v2-a990a6186893d3cc06584340ea710d48_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-a990a6186893d3cc06584340ea710d48_b.jpg"/></figure><p><b><u>在 MDP 上定义希尔伯特空间</u></b></p><p>通过在 MDP 上定义 RKHS，说明把状态空间上的函数定义为一组特征的线性组合的合理性。</p><p>对于状态空间的任意两个函数，定义这两个函数的内积如下：</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-4da5e15883e7ec4fb3e6cb6902b8dfcb_b.png" data-caption="" data-size="normal" data-rawwidth="528" data-rawheight="52" class="origin_image zh-lightbox-thumb" width="528" data-original="https://pic4.zhimg.com/v2-4da5e15883e7ec4fb3e6cb6902b8dfcb_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;528&#39; height=&#39;52&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="528" data-rawheight="52" class="origin_image zh-lightbox-thumb lazy" width="528" data-original="https://pic4.zhimg.com/v2-4da5e15883e7ec4fb3e6cb6902b8dfcb_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-4da5e15883e7ec4fb3e6cb6902b8dfcb_b.png"/></figure><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-e77ec0750886a216ae1cb546e5de2149_b.jpg" data-caption="" data-size="normal" data-rawwidth="516" data-rawheight="130" class="origin_image zh-lightbox-thumb" width="516" data-original="https://pic2.zhimg.com/v2-e77ec0750886a216ae1cb546e5de2149_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;516&#39; height=&#39;130&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="516" data-rawheight="130" class="origin_image zh-lightbox-thumb lazy" width="516" data-original="https://pic2.zhimg.com/v2-e77ec0750886a216ae1cb546e5de2149_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-e77ec0750886a216ae1cb546e5de2149_b.jpg"/></figure><p>其中，对于每个点都有一个权重的调整，该权重为在该策略下的稳态状态分布（invariant distribution）。任意一个函数可以往，这个希尔伯特空间中的一个子空间做投影</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-64e582fcc9d6c221777240fc98ac6b47_b.jpg" data-caption="" data-size="normal" data-rawwidth="519" data-rawheight="116" class="origin_image zh-lightbox-thumb" width="519" data-original="https://pic4.zhimg.com/v2-64e582fcc9d6c221777240fc98ac6b47_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;519&#39; height=&#39;116&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="519" data-rawheight="116" class="origin_image zh-lightbox-thumb lazy" width="519" data-original="https://pic4.zhimg.com/v2-64e582fcc9d6c221777240fc98ac6b47_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-64e582fcc9d6c221777240fc98ac6b47_b.jpg"/></figure><p>后面文章又讲了 Bellman 算子和该投影算子的复合算子也是 contraction，即在某一个固定的基上可以做 approximated policy evaluation 和 control。</p><p>考虑 RKHS 的定义，一个定义在状态空间上的函数可以用再生核表示出来</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-8eefdada7644c1667f666e8a1e54d22c_b.png" data-caption="" data-size="normal" data-rawwidth="505" data-rawheight="33" class="origin_image zh-lightbox-thumb" width="505" data-original="https://pic1.zhimg.com/v2-8eefdada7644c1667f666e8a1e54d22c_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;505&#39; height=&#39;33&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="505" data-rawheight="33" class="origin_image zh-lightbox-thumb lazy" width="505" data-original="https://pic1.zhimg.com/v2-8eefdada7644c1667f666e8a1e54d22c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-8eefdada7644c1667f666e8a1e54d22c_b.png"/></figure><p>我们可以使用一组状态的特征来表示再生核</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-62ed4dcbe7814e3f79d1073d0e3cc632_b.png" data-caption="" data-size="normal" data-rawwidth="513" data-rawheight="32" class="origin_image zh-lightbox-thumb" width="513" data-original="https://pic3.zhimg.com/v2-62ed4dcbe7814e3f79d1073d0e3cc632_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;513&#39; height=&#39;32&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="513" data-rawheight="32" class="origin_image zh-lightbox-thumb lazy" width="513" data-original="https://pic3.zhimg.com/v2-62ed4dcbe7814e3f79d1073d0e3cc632_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-62ed4dcbe7814e3f79d1073d0e3cc632_b.png"/></figure><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-89a914d951a56e75f8bc76608a01a3a1_b.png" data-caption="" data-size="normal" data-rawwidth="529" data-rawheight="29" class="origin_image zh-lightbox-thumb" width="529" data-original="https://pic2.zhimg.com/v2-89a914d951a56e75f8bc76608a01a3a1_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;529&#39; height=&#39;29&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="529" data-rawheight="29" class="origin_image zh-lightbox-thumb lazy" width="529" data-original="https://pic2.zhimg.com/v2-89a914d951a56e75f8bc76608a01a3a1_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-89a914d951a56e75f8bc76608a01a3a1_b.png"/></figure><p>由此，任意一个函数都可以用一组特征和相应的系数表示</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-35aa484c79723b98a20fbdff4d2b2ed2_b.png" data-caption="" data-size="normal" data-rawwidth="507" data-rawheight="29" class="origin_image zh-lightbox-thumb" width="507" data-original="https://pic3.zhimg.com/v2-35aa484c79723b98a20fbdff4d2b2ed2_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;507&#39; height=&#39;29&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="507" data-rawheight="29" class="origin_image zh-lightbox-thumb lazy" width="507" data-original="https://pic3.zhimg.com/v2-35aa484c79723b98a20fbdff4d2b2ed2_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-35aa484c79723b98a20fbdff4d2b2ed2_b.png"/></figure><h3>5. MDP 上的表示学习问题</h3><p><b><u>状态空间的低维表示使得 MDP 的求解变得容易</u></b></p><p>给定一个 MDP 状态空间上的低维表示和一个固定的策略之后，我们可以定义一个 approximated MRP：</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-54111ec89b988499158b4b96b7dd6b77_b.jpg" data-caption="" data-size="normal" data-rawwidth="514" data-rawheight="151" class="origin_image zh-lightbox-thumb" width="514" data-original="https://pic4.zhimg.com/v2-54111ec89b988499158b4b96b7dd6b77_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;514&#39; height=&#39;151&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="514" data-rawheight="151" class="origin_image zh-lightbox-thumb lazy" width="514" data-original="https://pic4.zhimg.com/v2-54111ec89b988499158b4b96b7dd6b77_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-54111ec89b988499158b4b96b7dd6b77_b.jpg"/></figure><p>我们可以知道，在这个 MRP  上求解的结果等价于在原 MRP 上求解的 fixed point solution 再投影到该低维表示空间上。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-106e289d57663d40ac1bc88f98b166fe_b.jpg" data-caption="" data-size="normal" data-rawwidth="578" data-rawheight="99" class="origin_image zh-lightbox-thumb" width="578" data-original="https://pic3.zhimg.com/v2-106e289d57663d40ac1bc88f98b166fe_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;578&#39; height=&#39;99&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="578" data-rawheight="99" class="origin_image zh-lightbox-thumb lazy" width="578" data-original="https://pic3.zhimg.com/v2-106e289d57663d40ac1bc88f98b166fe_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-106e289d57663d40ac1bc88f98b166fe_b.jpg"/></figure><p>在低维空间上求解的好处是其复杂度更低：</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-cee6eb39fe3582fafb0ad5ac2de814d7_b.jpg" data-caption="" data-size="normal" data-rawwidth="548" data-rawheight="101" class="origin_image zh-lightbox-thumb" width="548" data-original="https://pic4.zhimg.com/v2-cee6eb39fe3582fafb0ad5ac2de814d7_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;548&#39; height=&#39;101&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="548" data-rawheight="101" class="origin_image zh-lightbox-thumb lazy" width="548" data-original="https://pic4.zhimg.com/v2-cee6eb39fe3582fafb0ad5ac2de814d7_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-cee6eb39fe3582fafb0ad5ac2de814d7_b.jpg"/></figure><p><b><u>MDP 表示学习的若干考虑</u></b></p><ul><li>学习过程的复杂度：注意到我们进行表示学习的目的还是为了更好的求解 MDP。因此，如果我们的目标是针对一个特定的 MDP 求解，那么我们显然希望学习到相应表示的复杂度不能高于求解该 MDP 的复杂度；如果我们的表示能够被迁移到其他类似 MDP 上，该条件可以被放宽。</li><li>表示的复杂度：如果学习到的表示的表征能力比较强，当然使用该表示带来的性能损失会比较少，但预测同时在该表示空间内进行求解的复杂度会相应更高。因此，我们的目标就是以较为简单的表示来实现更小的近似误差。相应的方向有：找到更稀疏的表示；针对状态空间的特殊结构做分解，从而更有效地进行状态的表示；本文后面将会提到的，一些更有效的表示方法，比如多层次的小波基（multiscale wavelet bases）；对于连续状态空间，我们一般用一些空间上的样本来进行 non-parametric 的表示，那么我们希望找到好的采样和拟合方法，使得我们储存较少的样本就能达到较好的精度。</li><li>表示适用于单一奖励函数还是多种奖励函数：如果学习到的表示是针对单一奖励函数的，那么该表示可能能够对于特定的子空间做到更有效的表示；如果学习到的表示能够针对多个（或者任意）奖励函数，那么学习到的表示就能够适应于一族学习任务。</li><li>表示是针对单一策略还是多个策略：当策略给定之后，MDP 就退化为 MRP，针对该策略就更容易学习到具有理论保证的状态表示；但与此同时，在 RPI 中，策略是在迭代的，这样学习到的状态表示的生命周期就比较短。</li><li>逐步学习或者是一次性学习（incremental or batch）：文章里面讲的是一组基底中的每一个基底是一个一个构造出来的还是一次性全部构造出来的；而我这里想说的是，表示是一次性就学习到，还是通过一个循环迭代逐渐学习到。比如，在 policy iteration 中，策略就是通过迭代逐步学习。</li></ul><h3>6. 一个古老的算法：adaptive state aggregation</h3><p>说它古老是因为该算法发表于 1988 年 [1]。考虑对状态做 aggregation，即把整个状态空间分为互不相交的 k 个集合，这样基底表示矩阵 <img src="https://www.zhihu.com/equation?tex=%5CPhi" alt="\Phi" eeimg="1"/> 的每行都是 one-hot 向量。该算法的目标是在给定完整的 transition function、 reward function 和固定策略的情况下，找到一个最优的 state aggregation，使得价值函数能够在该 aggregation 基底下较准确地被表示出来。算法的迭代过程如下：</p><ol><li>按照当前的 Bellman residual <img src="https://www.zhihu.com/equation?tex=T%5E%5Cpi+V%5Ek+-+V%5Ek" alt="T^\pi V^k - V^k" eeimg="1"/> 的数值大小，把状态分到不同的集合中，得到表示矩阵 <img src="https://www.zhihu.com/equation?tex=%5CPhi" alt="\Phi" eeimg="1"/> ；</li><li>按照该表示矩阵 <img src="https://www.zhihu.com/equation?tex=%5CPhi" alt="\Phi" eeimg="1"/> ，把当前的价值函数做投影 <img src="https://www.zhihu.com/equation?tex=V%5Ek+%5Cleftarrow+%5CPi_%5CPhi+%28V%5Ek%29" alt="V^k \leftarrow \Pi_\Phi (V^k)" eeimg="1"/> ；</li><li>调整价值函数，将它往奖励更高的方向移动： <img src="https://www.zhihu.com/equation?tex=V%5E%7Bk%2B1%7D+%5Cleftarrow+V%5Ek+%2B+%5CPhi+y%2C%5C+%5C+%5C+y+%3D%28I-%5Cgamma+P%5E%5Cpi_%5CPhi%29%5E%7B-1%7D+R%5E%5Cpi_%5CPhi" alt="V^{k+1} \leftarrow V^k + \Phi y,\ \ \ y =(I-\gamma P^\pi_\Phi)^{-1} R^\pi_\Phi" eeimg="1"/> ，其中</li></ol><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-f39269266af0fc03c3320600b3451d4c_b.png" data-caption="" data-size="normal" data-rawwidth="474" data-rawheight="55" class="origin_image zh-lightbox-thumb" width="474" data-original="https://pic1.zhimg.com/v2-f39269266af0fc03c3320600b3451d4c_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;474&#39; height=&#39;55&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="474" data-rawheight="55" class="origin_image zh-lightbox-thumb lazy" width="474" data-original="https://pic1.zhimg.com/v2-f39269266af0fc03c3320600b3451d4c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-f39269266af0fc03c3320600b3451d4c_b.png"/></figure><p>注意到，这里 <img src="https://www.zhihu.com/equation?tex=R_%5CPhi%5E%5Cpi" alt="R_\Phi^\pi" eeimg="1"/> 是 Bellman residual 的往基底上的投影，MDP 原始的奖励函数隐含在 Bellman 算子 T 中。在第二步中，价值函数在 <img src="https://www.zhihu.com/equation?tex=%5CPhi" alt="\Phi" eeimg="1"/> 张成的空间上；而第三步的修正仍然也在该空间中，因此第三步得到的价值函数仍然在 <img src="https://www.zhihu.com/equation?tex=%5CPhi" alt="\Phi" eeimg="1"/> 张成的空间上。这里比较特别的是，第一步中根据不同点上 Bellman residual 的大小来做 state aggregation 的做法。其原因如下：每步迭代后的误差可以被写作以下两项的和</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-f194a466a179252271f6edd46e77eb01_b.png" data-caption="" data-size="normal" data-rawwidth="514" data-rawheight="83" class="origin_image zh-lightbox-thumb" width="514" data-original="https://pic2.zhimg.com/v2-f194a466a179252271f6edd46e77eb01_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;514&#39; height=&#39;83&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="514" data-rawheight="83" class="origin_image zh-lightbox-thumb lazy" width="514" data-original="https://pic2.zhimg.com/v2-f194a466a179252271f6edd46e77eb01_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-f194a466a179252271f6edd46e77eb01_b.png"/></figure><p>其中，如果 <img src="https://www.zhihu.com/equation?tex=%5CPhi" alt="\Phi" eeimg="1"/> 张成了相对于 P 的 invariant subspace 的话，第二项将会为零，即 <img src="https://www.zhihu.com/equation?tex=%28I-%5CPi%29P%5CPhi+x%3D0%2C+%5Cforall+x" alt="(I-\Pi)P\Phi x=0, \forall x" eeimg="1"/> ，当然，对于 state aggregation 来说很难找到一个 invariant subspace。而第一项可以看做是每一个集合内对应状态的 Bellman residual 相比于其集合内平均的差值；为了减小这一项，自然考虑到把 Bellman residual 相近的状态划分到同一类中。</p><h3>7. Diagonalization</h3><p><u><b>在价值函数表示中，拉普拉斯矩阵的最小特征值对应最重要的特征向量</b></u></p><p>考虑拉普拉斯矩阵的特征值分解</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-1944f0f0ad7426d4c87fedbffbbd22f0_b.png" data-caption="" data-size="normal" data-rawwidth="525" data-rawheight="57" class="origin_image zh-lightbox-thumb" width="525" data-original="https://pic1.zhimg.com/v2-1944f0f0ad7426d4c87fedbffbbd22f0_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;525&#39; height=&#39;57&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="525" data-rawheight="57" class="origin_image zh-lightbox-thumb lazy" width="525" data-original="https://pic1.zhimg.com/v2-1944f0f0ad7426d4c87fedbffbbd22f0_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-1944f0f0ad7426d4c87fedbffbbd22f0_b.png"/></figure><p>同时价值函数也做相应的分解</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-55fff1045d7600386807a65afe2fc1cd_b.png" data-caption="" data-size="normal" data-rawwidth="597" data-rawheight="38" class="origin_image zh-lightbox-thumb" width="597" data-original="https://pic2.zhimg.com/v2-55fff1045d7600386807a65afe2fc1cd_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;597&#39; height=&#39;38&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="597" data-rawheight="38" class="origin_image zh-lightbox-thumb lazy" width="597" data-original="https://pic2.zhimg.com/v2-55fff1045d7600386807a65afe2fc1cd_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-55fff1045d7600386807a65afe2fc1cd_b.png"/></figure><p>不难推导出，价值函数可以被分解为相应特征向量的加权和，而特征值最小的特征向量对应的系数更小，这说明我们可以选用特征值最小的那一些特征向量来作为价值函数的基底</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-5ac4fd6a5defd5fc288b692d08db9f61_b.jpg" data-caption="" data-size="normal" data-rawwidth="639" data-rawheight="162" class="origin_image zh-lightbox-thumb" width="639" data-original="https://pic2.zhimg.com/v2-5ac4fd6a5defd5fc288b692d08db9f61_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;639&#39; height=&#39;162&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="639" data-rawheight="162" class="origin_image zh-lightbox-thumb lazy" width="639" data-original="https://pic2.zhimg.com/v2-5ac4fd6a5defd5fc288b692d08db9f61_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-5ac4fd6a5defd5fc288b692d08db9f61_b.jpg"/></figure><p><b><u>从图论的角度来看，拉普拉斯矩阵的最小特征值对应函数在图上最平滑的分量</u></b></p><p>考虑拉普拉斯算子的特征值 <img src="https://www.zhihu.com/equation?tex=%5Clambda_i" alt="\lambda_i" eeimg="1"/> 和特征向量 <img src="https://www.zhihu.com/equation?tex=%5Cxi_i" alt="\xi_i" eeimg="1"/> ，定义一个函数在图上的 norm</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-58fa3f3d4459f73ad15d7880977a332f_b.png" data-caption="" data-size="normal" data-rawwidth="567" data-rawheight="56" class="origin_image zh-lightbox-thumb" width="567" data-original="https://pic4.zhimg.com/v2-58fa3f3d4459f73ad15d7880977a332f_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;567&#39; height=&#39;56&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="567" data-rawheight="56" class="origin_image zh-lightbox-thumb lazy" width="567" data-original="https://pic4.zhimg.com/v2-58fa3f3d4459f73ad15d7880977a332f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-58fa3f3d4459f73ad15d7880977a332f_b.png"/></figure><p>其中，d 为相应 MC 在图上的稳态分布；一个函数在图上的光滑程度可以通过如下 Sobolev norm 来衡量</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-f2ee9ee08f10be62703894959473205d_b.png" data-caption="" data-size="normal" data-rawwidth="546" data-rawheight="75" class="origin_image zh-lightbox-thumb" width="546" data-original="https://pic2.zhimg.com/v2-f2ee9ee08f10be62703894959473205d_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;546&#39; height=&#39;75&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="546" data-rawheight="75" class="origin_image zh-lightbox-thumb lazy" width="546" data-original="https://pic2.zhimg.com/v2-f2ee9ee08f10be62703894959473205d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-f2ee9ee08f10be62703894959473205d_b.png"/></figure><p>注意到第一项衡量了这个函数的绝对数值大小；第二项衡量这个函数在图上的平滑程度，注意到对于特征向量 <img src="https://www.zhihu.com/equation?tex=%5Cxi_i" alt="\xi_i" eeimg="1"/> ，有 <img src="https://www.zhihu.com/equation?tex=%7C%7C%5Cnabla+%5Cxi_i%7C%7C_2%5E2+%3D+%5Clambda_i" alt="||\nabla \xi_i||_2^2 = \lambda_i" eeimg="1"/> ，由此可见，对于同样的 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon" alt="\epsilon" eeimg="1"/> -approximation</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-5034cd1f2905e8f1ee4b902a3c32f68c_b.png" data-caption="" data-size="normal" data-rawwidth="557" data-rawheight="73" class="origin_image zh-lightbox-thumb" width="557" data-original="https://pic1.zhimg.com/v2-5034cd1f2905e8f1ee4b902a3c32f68c_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;557&#39; height=&#39;73&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="557" data-rawheight="73" class="origin_image zh-lightbox-thumb lazy" width="557" data-original="https://pic1.zhimg.com/v2-5034cd1f2905e8f1ee4b902a3c32f68c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-5034cd1f2905e8f1ee4b902a3c32f68c_b.png"/></figure><p>显然应该尽量让对应特征值更小的特征向量前面的系数更大，这样的拟合产生更平滑的函数。文章中还提到，可以一个一个地来找到最平滑的特征函数，具体做法就是把特征值问题通过 Rayleigh quotient 表示为优化问题，比如</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-6b1e51002699161451c4f4084edc6068_b.png" data-caption="" data-size="normal" data-rawwidth="524" data-rawheight="53" class="origin_image zh-lightbox-thumb" width="524" data-original="https://pic1.zhimg.com/v2-6b1e51002699161451c4f4084edc6068_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;524&#39; height=&#39;53&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="524" data-rawheight="53" class="origin_image zh-lightbox-thumb lazy" width="524" data-original="https://pic1.zhimg.com/v2-6b1e51002699161451c4f4084edc6068_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-6b1e51002699161451c4f4084edc6068_b.png"/></figure><p>这一节后面还讲述了对于具有特定结构的图，可以把图做分解（factor），然后其总的 Laplacian 也可以最相应的分解，从而简化表示；这里我暂时不是很感兴趣，就不写了。</p><h3>8. Dilation</h3><p><b><u>Krylov space</u></b></p><p>一个 Krylov subspace 是由一个算子 T 和一个函数 f 来定义的，它是如下基函数的 span</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-0a4f9ea2eeab8ed7cb96ae80e603f43f_b.jpg" data-caption="" data-size="normal" data-rawwidth="570" data-rawheight="289" class="origin_image zh-lightbox-thumb" width="570" data-original="https://pic4.zhimg.com/v2-0a4f9ea2eeab8ed7cb96ae80e603f43f_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;570&#39; height=&#39;289&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="570" data-rawheight="289" class="origin_image zh-lightbox-thumb lazy" width="570" data-original="https://pic4.zhimg.com/v2-0a4f9ea2eeab8ed7cb96ae80e603f43f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-0a4f9ea2eeab8ed7cb96ae80e603f43f_b.jpg"/></figure><p>文章里面主要讲了两种方法，一种令 <img src="https://www.zhihu.com/equation?tex=T%3D%5Cmathbb%7BL%7D" alt="T=\mathbb{L}" eeimg="1"/> ，即直接把 Laplacian 作为这里的算子 T；另外一种令 <img src="https://www.zhihu.com/equation?tex=T%3D%5Cmathbb%7BL%7D%5ED" alt="T=\mathbb{L}^D" eeimg="1"/> ，即把 Laplacian 的 Drazin inverse 作为这里的算子 T。当然，我们一般不会一直重复直到找到一个 invariant subspace，因此一般来说 invariant subspace 的基底数量是非常多的。我们希望只需要前几项就能够较好的近似整个空间中可能的价值函数。为什么能做这样的近似呢？其主要的原因还是在于价值函数可以做如下的级数展开，因此基底中有几个基，就能够准确拟合前几项的结果。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-c9a1fc9d2593f0061c994366d8267b58_b.png" data-caption="" data-size="normal" data-rawwidth="586" data-rawheight="29" class="origin_image zh-lightbox-thumb" width="586" data-original="https://pic1.zhimg.com/v2-c9a1fc9d2593f0061c994366d8267b58_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;586&#39; height=&#39;29&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="586" data-rawheight="29" class="origin_image zh-lightbox-thumb lazy" width="586" data-original="https://pic1.zhimg.com/v2-c9a1fc9d2593f0061c994366d8267b58_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-c9a1fc9d2593f0061c994366d8267b58_b.png"/></figure><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-f478f09db89a169c13faea989324af1a_b.png" data-caption="" data-size="normal" data-rawwidth="591" data-rawheight="50" class="origin_image zh-lightbox-thumb" width="591" data-original="https://pic3.zhimg.com/v2-f478f09db89a169c13faea989324af1a_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;591&#39; height=&#39;50&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="591" data-rawheight="50" class="origin_image zh-lightbox-thumb lazy" width="591" data-original="https://pic3.zhimg.com/v2-f478f09db89a169c13faea989324af1a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-f478f09db89a169c13faea989324af1a_b.png"/></figure><p>注意到 <img src="https://www.zhihu.com/equation?tex=%28a%2Bx%29%5E%7B-1%7D+%3D+a%5E%7B-1%7D+-+a%5E%7B-1%7Dx+%2B+a%5E%7B-3%7D+x%5E2++%2B+%5Ccdots" alt="(a+x)^{-1} = a^{-1} - a^{-1}x + a^{-3} x^2  + \cdots" eeimg="1"/> ，也可以被写作级数形式，但是注意到当 a&lt;1 时，前几项级数并不能很好的进行拟合；这意味着用 Laplacian 的效果会不如用 Laplacian 的逆的效果，这一点在后面的实验中也可以看到。</p><p><b><u>Dilation using Laplacian</u></b></p><p>这种方法就是按照如下顺序构建基</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-9d5fc87f5fb234a716bcbe67e1577a55_b.jpg" data-caption="" data-size="normal" data-rawwidth="600" data-rawheight="209" class="origin_image zh-lightbox-thumb" width="600" data-original="https://pic2.zhimg.com/v2-9d5fc87f5fb234a716bcbe67e1577a55_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;600&#39; height=&#39;209&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="600" data-rawheight="209" class="origin_image zh-lightbox-thumb lazy" width="600" data-original="https://pic2.zhimg.com/v2-9d5fc87f5fb234a716bcbe67e1577a55_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-9d5fc87f5fb234a716bcbe67e1577a55_b.jpg"/></figure><p>显然，这样构建的各个基底之间不正交。可以利用 Bellman error basis function（BEBF），每次把 Bellman error 作为新的基底</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-49e3ed1ef01984a2c0f63b75f307abc9_b.png" data-caption="" data-size="normal" data-rawwidth="537" data-rawheight="31" class="origin_image zh-lightbox-thumb" width="537" data-original="https://pic2.zhimg.com/v2-49e3ed1ef01984a2c0f63b75f307abc9_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;537&#39; height=&#39;31&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="537" data-rawheight="31" class="origin_image zh-lightbox-thumb lazy" width="537" data-original="https://pic2.zhimg.com/v2-49e3ed1ef01984a2c0f63b75f307abc9_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-49e3ed1ef01984a2c0f63b75f307abc9_b.png"/></figure><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-95afb2e61c689810c46c5d659bef800a_b.png" data-caption="" data-size="normal" data-rawwidth="550" data-rawheight="34" class="origin_image zh-lightbox-thumb" width="550" data-original="https://pic3.zhimg.com/v2-95afb2e61c689810c46c5d659bef800a_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;550&#39; height=&#39;34&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="550" data-rawheight="34" class="origin_image zh-lightbox-thumb lazy" width="550" data-original="https://pic3.zhimg.com/v2-95afb2e61c689810c46c5d659bef800a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-95afb2e61c689810c46c5d659bef800a_b.png"/></figure><p>不难看出，每次构造的新基底都和已有基底张成的空间正交；同时如果这里也从 <img src="https://www.zhihu.com/equation?tex=R%5E%5Cpi" alt="R^\pi" eeimg="1"/> 出发，可以证明上述方法构造出来的基底和用 Laplacian 构造出来的 Krylov space 一致。（另外可以参见本人数学专栏里面讲的 Lanczos 和 conjugate gradient 方法，想法上和这个很类似）</p><p>为了给大家有一个直观的感受，举一个例子：考虑一个一维链式 MRP，有 50 个状态，在第 10 和第 41 个状态上有奖励，策略为最优策略。在这种情况下，基底 Krylov space 的前几个基函数画出来长下面这个样子</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-be46fb9c58a7c23c708c279f11c5550c_b.jpg" data-caption="" data-size="normal" data-rawwidth="804" data-rawheight="472" class="origin_image zh-lightbox-thumb" width="804" data-original="https://pic1.zhimg.com/v2-be46fb9c58a7c23c708c279f11c5550c_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;804&#39; height=&#39;472&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="804" data-rawheight="472" class="origin_image zh-lightbox-thumb lazy" width="804" data-original="https://pic1.zhimg.com/v2-be46fb9c58a7c23c708c279f11c5550c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-be46fb9c58a7c23c708c279f11c5550c_b.jpg"/></figure><p>可以看出，这个基底就是每次按照 Laplacian 把奖励函数往外扩散。直观看起来效率是比较低的。</p><p>再举一个二维的例子，感觉上也是类似的。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-414cb217d513c8d4f2d546d744d27dda_b.jpg" data-caption="" data-size="normal" data-rawwidth="791" data-rawheight="451" class="origin_image zh-lightbox-thumb" width="791" data-original="https://pic3.zhimg.com/v2-414cb217d513c8d4f2d546d744d27dda_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;791&#39; height=&#39;451&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="791" data-rawheight="451" class="origin_image zh-lightbox-thumb lazy" width="791" data-original="https://pic3.zhimg.com/v2-414cb217d513c8d4f2d546d744d27dda_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-414cb217d513c8d4f2d546d744d27dda_b.jpg"/></figure><p><b><u>Dilation using Drazin inverse of Laplacian</u></b></p><p>下面，我们介绍如何使用 Laplacian 的 Drazin inverse 来构造 Krylov space（也叫 Drazin space）。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-8079118f886ecdd4027665e5e7ed44a0_b.jpg" data-caption="" data-size="normal" data-rawwidth="578" data-rawheight="193" class="origin_image zh-lightbox-thumb" width="578" data-original="https://pic1.zhimg.com/v2-8079118f886ecdd4027665e5e7ed44a0_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;578&#39; height=&#39;193&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="578" data-rawheight="193" class="origin_image zh-lightbox-thumb lazy" width="578" data-original="https://pic1.zhimg.com/v2-8079118f886ecdd4027665e5e7ed44a0_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-8079118f886ecdd4027665e5e7ed44a0_b.jpg"/></figure><p>这第一个向量看起来有点奇怪，注意到在 average-reward 的设定下，gain <img src="https://www.zhihu.com/equation?tex=g%5E%5Cpi+%3D+P%5E%2A+R%5E%5Cpi" alt="g^\pi = P^* R^\pi" eeimg="1"/> ，我们把它作为起始的“种子”向量；而接下来的一项 <img src="https://www.zhihu.com/equation?tex=%5Cmathbb%7BL%7D%5ED+g+%3D+%5Cmathbb%7BL%7D%5ED++P%5E%2A+R%3D0" alt="\mathbb{L}^D g = \mathbb{L}^D  P^* R=0" eeimg="1"/> ，因此就把这一项跳过去了。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-aaa63858e842908bfdda9dd714286d8c_b.png" data-caption="" data-size="normal" data-rawwidth="630" data-rawheight="48" class="origin_image zh-lightbox-thumb" width="630" data-original="https://pic1.zhimg.com/v2-aaa63858e842908bfdda9dd714286d8c_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;630&#39; height=&#39;48&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="630" data-rawheight="48" class="origin_image zh-lightbox-thumb lazy" width="630" data-original="https://pic1.zhimg.com/v2-aaa63858e842908bfdda9dd714286d8c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-aaa63858e842908bfdda9dd714286d8c_b.png"/></figure><p>还是前面的例子，把相应的 Drazin space 中前几个基底的图如下所示。可以看出相应的前几个基底更快地“扩散”到状态空间中。后面会看到，这样的基底近似效果会更好</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-4affec8e28201e5709c46962bff7dedc_b.jpg" data-caption="" data-size="normal" data-rawwidth="759" data-rawheight="477" class="origin_image zh-lightbox-thumb" width="759" data-original="https://pic1.zhimg.com/v2-4affec8e28201e5709c46962bff7dedc_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;759&#39; height=&#39;477&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="759" data-rawheight="477" class="origin_image zh-lightbox-thumb lazy" width="759" data-original="https://pic1.zhimg.com/v2-4affec8e28201e5709c46962bff7dedc_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-4affec8e28201e5709c46962bff7dedc_b.jpg"/></figure><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-9425571c48e24c4302d86d7f98604d4f_b.jpg" data-caption="" data-size="normal" data-rawwidth="751" data-rawheight="468" class="origin_image zh-lightbox-thumb" width="751" data-original="https://pic4.zhimg.com/v2-9425571c48e24c4302d86d7f98604d4f_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;751&#39; height=&#39;468&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="751" data-rawheight="468" class="origin_image zh-lightbox-thumb lazy" width="751" data-original="https://pic4.zhimg.com/v2-9425571c48e24c4302d86d7f98604d4f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-9425571c48e24c4302d86d7f98604d4f_b.jpg"/></figure><p><b><u>Diffusion wavelet</u></b></p><p>文章接着后面还讲了使用 diffusion wavelet 的做法来获得多尺度上更好的近似，大致思想上是我们现在不要再一个一个地构造 Drazin space 了，而是要 <img src="https://www.zhihu.com/equation?tex=%5Cmathbb%7BL%7D%5ED+R%2C+%28%5Cmathbb%7BL%7D%5ED%29%5E2+R%2C+%28%5Cmathbb%7BL%7D%5ED%29%5E4+R%2C+%28%5Cmathbb%7BL%7D%5ED%29%5E8+R+%5Ccdots" alt="\mathbb{L}^D R, (\mathbb{L}^D)^2 R, (\mathbb{L}^D)^4 R, (\mathbb{L}^D)^8 R \cdots" eeimg="1"/> 地构造。但是 wavelet 看得我很头痛，并且看懂之后发现这个解决问题的设定我就不是很感兴趣，因此就不再写了。关于 wavelet 的简要介绍见下一篇吧。</p><p>下面贴一下这种方法的实验效果，文章把这种方法和前面的 eigenvalue 的方法进行对比，我们发现只使用 5 个基底，该方法不仅能够很好得近似比较不光滑的函数（比如第一行中的函数），也能够很好地近似比较光滑的函数（比如第二行中的函数）。与此同时，随着基底数量的增加，拟合误差下降地也更快，即这种方法的近似效率更高。</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-28e7b25cc573183abfa8e53c0502bd4f_b.jpg" data-caption="" data-size="normal" data-rawwidth="707" data-rawheight="442" class="origin_image zh-lightbox-thumb" width="707" data-original="https://pic4.zhimg.com/v2-28e7b25cc573183abfa8e53c0502bd4f_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;707&#39; height=&#39;442&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="707" data-rawheight="442" class="origin_image zh-lightbox-thumb lazy" width="707" data-original="https://pic4.zhimg.com/v2-28e7b25cc573183abfa8e53c0502bd4f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-28e7b25cc573183abfa8e53c0502bd4f_b.jpg"/></figure><h3>9. Continuous MDP</h3><p>这里讲一下如何处理连续状态空间的表示学习问题（假设行动还是离散的）。状态空间连续的时候，可以定义相应的 Bellman 方程，称作 Hamilton-Bellman-Jacobi （HBJ）方程：</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-c9ea0ef41d3d25d1f613cc74154a6ede_b.png" data-caption="" data-size="normal" data-rawwidth="555" data-rawheight="50" class="origin_image zh-lightbox-thumb" width="555" data-original="https://pic3.zhimg.com/v2-c9ea0ef41d3d25d1f613cc74154a6ede_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;555&#39; height=&#39;50&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="555" data-rawheight="50" class="origin_image zh-lightbox-thumb lazy" width="555" data-original="https://pic3.zhimg.com/v2-c9ea0ef41d3d25d1f613cc74154a6ede_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-c9ea0ef41d3d25d1f613cc74154a6ede_b.png"/></figure><p>回顾一下，在状态空间离散的时候，可以把每个状态当做图上的节点；我们在前面看到，这个图上对应 Laplacian 的前几个特征向量表示了最平滑的若干个定义在该图上的函数。当状态连续的时候，就不能再把它们看做图上的节点了；这时候我们把它们建模为一个 Riemannian manifold，在这个 manifold 上也可以定义类似的 Laplacian，我们称之为 Laplace-Beltrami 算子，该算子的前几个特征向量同样对应最平滑的函数。下面将简要介绍 Riemannian manifold 和 Laplace-Beltrami 算子。</p><p><b><u>Riemannian manifold</u></b></p><p>这一部分只是看了一下定义，可能个人理解不是特别准确。个人理解，manifold 用来被描述一个在局部和（低维）欧式空间有一些对应关系的结构。除此之外，Riemannian manifold 还要求 manifold 和欧式空间的对应关系是可导的（相当于规定了平滑性），同时还能够通过 Riemannian metric 来定义距离度量。具体地，对于 n 维空间上的 manifold 上的一点 <img src="https://www.zhihu.com/equation?tex=p%5Cin+%5Cmathcal%7BM%7D" alt="p\in \mathcal{M}" eeimg="1"/> ，考虑过这一点的 tangent space <img src="https://www.zhihu.com/equation?tex=T_p+%28%5Cmathcal%7BM%7D%29" alt="T_p (\mathcal{M})" eeimg="1"/> ，在该空间上可以定义内积 <img src="https://www.zhihu.com/equation?tex=g_p%3A+T_p%28%5Cmathcal%7BM%7D%29+%5Ctimes+T_p%28%5Cmathcal%7BM%7D%29+%5Cto+%5Cmathbb%7BR%7D" alt="g_p: T_p(\mathcal{M}) \times T_p(\mathcal{M}) \to \mathbb{R}" eeimg="1"/> ，当然也可以把它写出一个 nxn 的矩阵 <img src="https://www.zhihu.com/equation?tex=G_p" alt="G_p" eeimg="1"/> （Riemannian metric）。对于 tangent space 上的一点 q，可以写出 p、q 两点在 manifold 上的距离度量 <img src="https://www.zhihu.com/equation?tex=%28q-p%29%5ET+G_p+%28q-p%29" alt="(q-p)^T G_p (q-p)" eeimg="1"/> 。比如对于 <img src="https://www.zhihu.com/equation?tex=%5Cmathbb%7BR%7D%5En" alt="\mathbb{R}^n" eeimg="1"/> 本身也可以看做一个 manifold，其在任意点上的 <img src="https://www.zhihu.com/equation?tex=G_p+%3D+I_n" alt="G_p = I_n" eeimg="1"/> ，因此两点之间的距离就是欧氏距离；对于一个 probability distribution <img src="https://www.zhihu.com/equation?tex=P%28X%7C%5Ctheta%29%2C+%5Ctheta+%5Cin+%5Cmathbb%7BR%7D%5En" alt="P(X|\theta), \theta \in \mathbb{R}^n" eeimg="1"/> ，它在某一点的距离度量 <img src="https://www.zhihu.com/equation?tex=G_%5Ctheta+%3D+%5Cmathcal%7BI%7D%28%5Ctheta%29" alt="G_\theta = \mathcal{I}(\theta)" eeimg="1"/> 为 Fisher information matrix。回忆一下，TRPO 里面需要限制参数变化带来的策略空间的变化大小，实际上限制了其 manifold 上的距离 <img src="https://www.zhihu.com/equation?tex=%28%5Ctheta%27+-+%5Ctheta%29%5ET+%5Cmathcal%7BI%7D%28%5Ctheta%29+%28%5Ctheta%27+-+%5Ctheta%29" alt="(\theta&#39; - \theta)^T \mathcal{I}(\theta) (\theta&#39; - \theta)" eeimg="1"/> 。</p><p><b><u>Laplace-Beltrami 算子</u></b></p><p>可以在 manifold 上定义 Laplacian-Beltrami 算子</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-eadf6e39a9acb1811e0e7c3e1072fac9_b.png" data-caption="" data-size="normal" data-rawwidth="524" data-rawheight="56" class="origin_image zh-lightbox-thumb" width="524" data-original="https://pic2.zhimg.com/v2-eadf6e39a9acb1811e0e7c3e1072fac9_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;524&#39; height=&#39;56&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="524" data-rawheight="56" class="origin_image zh-lightbox-thumb lazy" width="524" data-original="https://pic2.zhimg.com/v2-eadf6e39a9acb1811e0e7c3e1072fac9_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-eadf6e39a9acb1811e0e7c3e1072fac9_b.png"/></figure><p>其中 g 就代表前面提到的 Riemannian metric。这个看起来挺复杂的，不过没事，这就是一个定义而已，在 <img src="https://www.zhihu.com/equation?tex=%5Cmathbb%7BR%7D%5En" alt="\mathbb{R}^n" eeimg="1"/> 空间中，它可以被写作</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-a314ec00f3831d3371bba94c9b33dbd2_b.png" data-caption="" data-size="normal" data-rawwidth="86" data-rawheight="29" class="content_image" width="86"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;86&#39; height=&#39;29&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="86" data-rawheight="29" class="content_image lazy" width="86" data-actualsrc="https://pic3.zhimg.com/v2-a314ec00f3831d3371bba94c9b33dbd2_b.png"/></figure><p>满足 <img src="https://www.zhihu.com/equation?tex=%5CDelta+f+%3D+0" alt="\Delta f = 0" eeimg="1"/> 的函数被称为 harmonic functions，比如在 <img src="https://www.zhihu.com/equation?tex=%5Cmathbb%7BR%7D%5E2" alt="\mathbb{R}^2" eeimg="1"/> 空间中，如下函数就是一个 harmonic function。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-5ae6a0f2707256bf3bd091f1fa50e2b6_b.jpg" data-caption="" data-size="normal" data-rawwidth="240" data-rawheight="199" class="content_image" width="240"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;240&#39; height=&#39;199&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="240" data-rawheight="199" class="content_image lazy" width="240" data-actualsrc="https://pic3.zhimg.com/v2-5ae6a0f2707256bf3bd091f1fa50e2b6_b.jpg"/></figure><p>同样，该算子也有相应的特征值和特征向量，即</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-1f7f82669b34dd76f5d191bfd1dd18ad_b.png" data-caption="" data-size="normal" data-rawwidth="498" data-rawheight="32" class="origin_image zh-lightbox-thumb" width="498" data-original="https://pic2.zhimg.com/v2-1f7f82669b34dd76f5d191bfd1dd18ad_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;498&#39; height=&#39;32&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="498" data-rawheight="32" class="origin_image zh-lightbox-thumb lazy" width="498" data-original="https://pic2.zhimg.com/v2-1f7f82669b34dd76f5d191bfd1dd18ad_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-1f7f82669b34dd76f5d191bfd1dd18ad_b.png"/></figure><p>在 manifold 上也可以定义相应的 smoothness functional  <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BH%7D%5E1%28%5Cmathcal%7BM%7D%29" alt="\mathcal{H}^1(\mathcal{M})" eeimg="1"/> -norm </p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-0d8099b1db0d07bfc50eca900df3cfd3_b.png" data-caption="" data-size="normal" data-rawwidth="565" data-rawheight="34" class="origin_image zh-lightbox-thumb" width="565" data-original="https://pic4.zhimg.com/v2-0d8099b1db0d07bfc50eca900df3cfd3_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;565&#39; height=&#39;34&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="565" data-rawheight="34" class="origin_image zh-lightbox-thumb lazy" width="565" data-original="https://pic4.zhimg.com/v2-0d8099b1db0d07bfc50eca900df3cfd3_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-0d8099b1db0d07bfc50eca900df3cfd3_b.png"/></figure><p>其中</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-b59d82fa9ff2a855c6cdf832087f8768_b.png" data-caption="" data-size="normal" data-rawwidth="504" data-rawheight="50" class="origin_image zh-lightbox-thumb" width="504" data-original="https://pic1.zhimg.com/v2-b59d82fa9ff2a855c6cdf832087f8768_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;504&#39; height=&#39;50&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="504" data-rawheight="50" class="origin_image zh-lightbox-thumb lazy" width="504" data-original="https://pic1.zhimg.com/v2-b59d82fa9ff2a855c6cdf832087f8768_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-b59d82fa9ff2a855c6cdf832087f8768_b.png"/></figure><p>不难发现，对于归一化的特征向量 <img src="https://www.zhihu.com/equation?tex=S%28%5Cphi%29+%3D+%5Clambda" alt="S(\phi) = \lambda" eeimg="1"/> 。因此，相应地，要找到 manifold 上平滑的函数就是要找 Laplace-Beltrami 算子对应较小特征值的特征向量们张成的空间。</p><p><b><u>Hodge theorem</u></b></p><p>Hodge theorem 说的是 Laplace-Beltrami 算子对应的特征们能够张成的空间就是 manifold 上所有函数构成的空间，这说明如果我们选用该算子的特征向量来作为状态空间的基，当选用的特征向量足够多的时候，其张成的空间就是状态空间中的所有函数空间，即 asymptotic approximation error = 0。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-d47f040195775ab3b83c7d518f12ef78_b.jpg" data-caption="" data-size="normal" data-rawwidth="537" data-rawheight="114" class="origin_image zh-lightbox-thumb" width="537" data-original="https://pic1.zhimg.com/v2-d47f040195775ab3b83c7d518f12ef78_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;537&#39; height=&#39;114&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="537" data-rawheight="114" class="origin_image zh-lightbox-thumb lazy" width="537" data-original="https://pic1.zhimg.com/v2-d47f040195775ab3b83c7d518f12ef78_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-d47f040195775ab3b83c7d518f12ef78_b.jpg"/></figure><p><b><u>Manifold 的表示方法</u></b></p><p>回顾状态是离散的时候，我们是如何表示学习到的基底的呢？我们使用了一个矩阵 <img src="https://www.zhihu.com/equation?tex=%5CPhi+%5Cin+%5Cmathbb%7BR%7D%5E%7B%7CS%7C%5Ctimes+k%7D" alt="\Phi \in \mathbb{R}^{|S|\times k}" eeimg="1"/> 来表示每一个状态上这 k 个基函数的数值。当状态空间变为连续的时候，我们不能再用这样一个矩阵来表示所学习到的基底了，因为 <img src="https://www.zhihu.com/equation?tex=%7CS%7C%5Cto+%5Cinfty" alt="|S|\to \infty" eeimg="1"/> 。这个时候，我们需要在有限个样本上表示这 k 个基底，并且当出现新的一个状态的时候，我们通过外拓来找到新的状态下各个基底的数值。这涉及到两个问题：如何选择这有限个支撑状态样本；通过何种方式来外拓得到未见过状态的各个基底的数值。</p><p>对于第一个问题，文章说可以纯粹在已有的样本中做 random sample，也可以构造 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon" alt="\epsilon" eeimg="1"/> -net。对于第二个问题，文章提出使用 Nystrom extension</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-71bd6f125dee9a08ea453c689e48329b_b.png" data-caption="" data-size="normal" data-rawwidth="568" data-rawheight="56" class="origin_image zh-lightbox-thumb" width="568" data-original="https://pic4.zhimg.com/v2-71bd6f125dee9a08ea453c689e48329b_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;568&#39; height=&#39;56&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="568" data-rawheight="56" class="origin_image zh-lightbox-thumb lazy" width="568" data-original="https://pic4.zhimg.com/v2-71bd6f125dee9a08ea453c689e48329b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-71bd6f125dee9a08ea453c689e48329b_b.png"/></figure><p>其中，k(x,s) 衡量了这个新数据点到已有数据点的相似性（kernel function），w 为quadrature weight，文章也没说清楚这个东西到底咋算，不过大致不难理解，因为用了很多数据点做 support，那么各个数据点的重要性肯定还是区别的，需要用一个权重来作相应的调整。</p><p><b><u>Remark</u></b>：在离散状态空间中选择一组基底，会优先选择在 Laplacian 描述的这张图上比较光滑的基底，这相当于用到了一个“图上光滑”的先验；当状态空间连续的时候，不仅用到了“图上光滑”的先验，其实还需要用到“原始度量空间中光滑”的先验（考虑上一个公式中的 <img src="https://www.zhihu.com/equation?tex=k%28x%2Cs_i%29" alt="k(x,s_i)" eeimg="1"/> ）。</p><h3>10. Representation policy iteration (RPI)</h3><p><b><u>Model-based RPI</u></b></p><p>在 model-based 的设定中，假设当给定一个策略 <img src="https://www.zhihu.com/equation?tex=%5Cpi" alt="\pi" eeimg="1"/> 之后， <img src="https://www.zhihu.com/equation?tex=P%5E%5Cpi%2C+R%5E%5Cpi" alt="P^\pi, R^\pi" eeimg="1"/> 都已知。针对一个给定的 MDP ，可以通过如下循环来进行求解：</p><ul><li>Representation construction：对于当前策略，构造相应的低维表示，生成一个低维的 MRP；</li><li>Policy evaluation：估计当前策略下的价值函数；</li><li>Policy improvement：在当前价值函数的估计上做一步学习。</li></ul><p>注意到，由于假设模型已知，因此这里只需要对状态价值函数 V 进行低维空间的表示即可；在策略改进的时候，可以利用已知的状态转移矩阵来对计算 after-state 的价值函数，从而实现策略的更新。在模型未知的时候，一般需要学习行动价值函数 Q 的低维表示，这种情况就要再更头疼一些。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-64a4c93bf6fafb214e48820cd64debd0_b.jpg" data-caption="" data-size="normal" data-rawwidth="893" data-rawheight="863" class="origin_image zh-lightbox-thumb" width="893" data-original="https://pic1.zhimg.com/v2-64a4c93bf6fafb214e48820cd64debd0_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;893&#39; height=&#39;863&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="893" data-rawheight="863" class="origin_image zh-lightbox-thumb lazy" width="893" data-original="https://pic1.zhimg.com/v2-64a4c93bf6fafb214e48820cd64debd0_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-64a4c93bf6fafb214e48820cd64debd0_b.jpg"/></figure><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-0d9eac5ad057e8cd9ef9c7e3b4559009_b.jpg" data-caption="" data-size="normal" data-rawwidth="893" data-rawheight="633" class="origin_image zh-lightbox-thumb" width="893" data-original="https://pic2.zhimg.com/v2-0d9eac5ad057e8cd9ef9c7e3b4559009_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;893&#39; height=&#39;633&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="893" data-rawheight="633" class="origin_image zh-lightbox-thumb lazy" width="893" data-original="https://pic2.zhimg.com/v2-0d9eac5ad057e8cd9ef9c7e3b4559009_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-0d9eac5ad057e8cd9ef9c7e3b4559009_b.jpg"/></figure><p><b><u>Model-free RPI</u></b></p><p>这个时候 transition function 不再已知，而是需要通过采集样本来得到。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-9c01552c29a12af333b06f9502028e92_b.jpg" data-caption="" data-size="normal" data-rawwidth="893" data-rawheight="863" class="origin_image zh-lightbox-thumb" width="893" data-original="https://pic3.zhimg.com/v2-9c01552c29a12af333b06f9502028e92_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;893&#39; height=&#39;863&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="893" data-rawheight="863" class="origin_image zh-lightbox-thumb lazy" width="893" data-original="https://pic3.zhimg.com/v2-9c01552c29a12af333b06f9502028e92_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-9c01552c29a12af333b06f9502028e92_b.jpg"/></figure><p><b><u>Remark</u></b>：这里的 model-based 和 model-free 和我们强化学习里面的设定不一样，这里讲的 model-based 其实是我们现在经常讲的 known transition，它就不是 RL 问题；而这里讲的 model-free 其实是我们现在经常讲的 model-based RL。</p><p class="ztext-empty-paragraph"><br/></p><hr/><h3>参考文献</h3><p>[1] Bertsekas, Dimitri P., and David A. Castanon. &#34;Adaptive aggregation methods for infinite horizon dynamic programming.&#34; (1988).</p></div></div><div class="ContentItem-time">编辑于 2020-03-02</div><div class="Post-topicsAndReviewer"><div class="TopicList Post-Topics"><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/19640433" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">英文论文</div></div></a></span></div><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/19632766" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">学术论文</div></div></a></span></div><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/20039099" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习 (Reinforcement Learning)</div></div></a></span></div></div></div><div><div class="Sticky RichContent-actions is-bottom"><div class="ContentItem-actions"><span><button aria-label="赞同 33 " type="button" class="Button VoteButton VoteButton--up"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleUp VoteButton-TriangleUp" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M2 18.242c0-.326.088-.532.237-.896l7.98-13.203C10.572 3.57 11.086 3 12 3c.915 0 1.429.571 1.784 1.143l7.98 13.203c.15.364.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H3.955c-1.08 0-1.955-.517-1.955-1.9z" fill-rule="evenodd"></path></svg></span>赞同 33</button><button aria-label="反对" type="button" class="Button VoteButton VoteButton--down"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleDown" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M20.044 3H3.956C2.876 3 2 3.517 2 4.9c0 .326.087.533.236.896L10.216 19c.355.571.87 1.143 1.784 1.143s1.429-.572 1.784-1.143l7.98-13.204c.149-.363.236-.57.236-.896 0-1.386-.876-1.9-1.956-1.9z" fill-rule="evenodd"></path></svg></span></button></span><button type="button" class="Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Comment Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M10.241 19.313a.97.97 0 0 0-.77.2 7.908 7.908 0 0 1-3.772 1.482.409.409 0 0 1-.38-.637 5.825 5.825 0 0 0 1.11-2.237.605.605 0 0 0-.227-.59A7.935 7.935 0 0 1 3 11.25C3 6.7 7.03 3 12 3s9 3.7 9 8.25-4.373 9.108-10.759 8.063z" fill-rule="evenodd"></path></svg></span>3 条评论</button><div class="Popover ShareMenu"><div class="ShareMenu-toggler" id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Share Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2.931 7.89c-1.067.24-1.275 1.669-.318 2.207l5.277 2.908 8.168-4.776c.25-.127.477.198.273.39L9.05 14.66l.927 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.242c.584-.892-.212-2.029-1.234-1.796L2.93 7.89z" fill-rule="evenodd"></path></svg></span>分享</button></div></div><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Heart Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2 8.437C2 5.505 4.294 3.094 7.207 3 9.243 3 11.092 4.19 12 6c.823-1.758 2.649-3 4.651-3C19.545 3 22 5.507 22 8.432 22 16.24 13.842 21 12 21 10.158 21 2 16.24 2 8.437z" fill-rule="evenodd"></path></svg></span>喜欢</button><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Star Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5.515 19.64l.918-5.355-3.89-3.792c-.926-.902-.639-1.784.64-1.97L8.56 7.74l2.404-4.871c.572-1.16 1.5-1.16 2.072 0L15.44 7.74l5.377.782c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.219 1.274-.532 1.82-1.676 1.218L12 18.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z" fill-rule="evenodd"></path></svg></span>收藏</button><div class="Post-ActionMenuButton"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Dots Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5 14a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4z" fill-rule="evenodd"></path></svg></span></button></div></div></div></div></div></div></article><div class="Post-Sub Post-NormalSub"><div class="PostIndex-Contributions"><h3 class="BlockTitle">文章被以下专栏收录</h3><ul><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><img class="Avatar Avatar--medium Avatar--round" width="40" height="40" src="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_xs.jpg" srcSet="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_l.jpg 2x" alt="强化学习前沿"/></div></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><a class="ColumnLink ColumnItem-Title" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习前沿</div></div></a></h2><div class="ContentItem-meta">读呀读paper</div></div><div class="ContentItem-extra"><a href="/reinforcementlearning" type="button" class="Button">进入专栏</a></div></div></div></ul></div></div></div></main></div></div><script nonce="6cdbe4d5-968e-440b-a9cb-5c1f9ebffdd0" async="" src="https://www.googletagmanager.com/gtag/js?id=UA-149949619-1"></script><script nonce="6cdbe4d5-968e-440b-a9cb-5c1f9ebffdd0">function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-149949619-1");</script><script id="js-clientConfig" type="text/json">{"host":"zhihu.com","protocol":"https:","wwwHost":"www.zhihu.com","fetchRoot":{"www":"https:\u002F\u002Fwww.zhihu.com","api":"https:\u002F\u002Fapi.zhihu.com","zhuanlan":"https:\u002F\u002Fzhuanlan.zhihu.com"}}</script><script id="js-initialData" type="text/json">{"initialState":{"common":{"ask":{}},"loading":{"global":{"count":0},"local":{"env\u002FgetIpinfo\u002F":false,"article\u002Fget\u002F":false,"brand\u002FgetUrl\u002F":false}},"club":{"tags":{}},"entities":{"users":{"zhang-chu-heng":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"清华大学 交叉信息院博士在读"}],"exposedMedal":{"medalId":"1124316222665379841","medalName":"我的知乎 2019","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2592b0b52e1fac99f69b38e00252413b_r.png","miniAvatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ad363cc3088dc8de7544fd08b1c4987a_is.png","description":"参与「我的知乎 2019」即可获得"}}},"questions":{},"answers":{},"articles":{"109952463":{"trackUrl":["https:\u002F\u002Fsugar.zhihu.com\u002Fplutus_adreaper\u002Fpage_monitor_log?si=__SESSIONID__&ti=__ATOKEN__&at=view&pf=__OS__&ed=__MEMBERID__&idfa=__IDFA__&imei=__IMEI__&androidid=__ANDROIDID__&oaid=__OAID__&ci=__CREATIVEID__"],"id":109952463,"title":"【强化学习 105】RPI","type":"article","excerptTitle":"","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F109952463","imageUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-a58915dc326379660c7a6532c5f1817d_b.jpg","titleImage":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-a58915dc326379660c7a6532c5f1817d_b.jpg","excerpt":"\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-f0a627fa7875a76e322a1a183c1779bc_200x112.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"627\" data-rawheight=\"153\" data-watermark=\"watermark\" data-original-src=\"v2-f0a627fa7875a76e322a1a183c1779bc\" data-watermark-src=\"v2-ab9bebcde12b8b18bdd4af857cfff283\" data-private-watermark-src=\"\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-f0a627fa7875a76e322a1a183c1779bc_r.png\" class=\"origin_image inline-img zh-lightbox-thumb\"\u002F\u003E这里想讲一篇长论文，这篇论文提出一种 representation policy iteration （RPI） 的框架；同时还在强化学习表示学习方面做了比较详细的讲述。原文传送门\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fwww.nowpublishers.com\u002Farticle\u002FDownloadSummary\u002FMAL-003\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EMahadevan, Sridhar. &#34;Learning representation and control in Markov decision processes: New fron…\u003C\u002Fa\u003E","created":1583064366,"updated":1583114150,"author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"清华大学 交叉信息院博士在读"}],"exposedMedal":{"medalId":"1124316222665379841","medalName":"我的知乎 2019","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2592b0b52e1fac99f69b38e00252413b_r.png","miniAvatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ad363cc3088dc8de7544fd08b1c4987a_is.png","description":"参与「我的知乎 2019」即可获得"}},"commentPermission":"all","state":"published","imageWidth":780,"imageHeight":233,"content":"\u003Cp\u003E这里想讲一篇长论文，这篇论文提出一种 representation policy iteration （RPI） 的框架；同时还在强化学习表示学习方面做了比较详细的讲述。\u003C\u002Fp\u003E\u003Ch2\u003E原文传送门\u003C\u002Fh2\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fwww.nowpublishers.com\u002Farticle\u002FDownloadSummary\u002FMAL-003\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EMahadevan, Sridhar. &#34;Learning representation and control in Markov decision processes: New frontiers.&#34; Foundations and Trends® in Machine Learning 1.4 (2009): 403-565.\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Ch2\u003E特色\u003C\u002Fh2\u003E\u003Cp\u003E提出 representation policy iteration （RPI），一边学习好的状态空间表示，一边利用所学习到的状态表示来学习策略。把所有的状态看做一个graph，学习状态空间的表示就是要找到这个graph上比较少的几个基函数，使得定义在这个graph上的任意一个函数都尽量可以用这几个基函数来表示。当学习到这样一个状态空间的表示之后，原来较为复杂的MDP就被转化为了一个更简单的MDP，我们可以在这个简单的MDP上求解最优策略。\u003C\u002Fp\u003E\u003Cp\u003E当然，注意到这篇文章写在十多年前，不是很新；RPI 收敛的条件不是很清楚（表示是依赖于策略的，策略学习到最优的时候，表示可能只适用于该策略和奖励函数，which is a 1D subspace；关于这一点可以看完之后倒回来思考）；RPI 在复杂问题上的效果不是很清楚。\u003C\u002Fp\u003E\u003Ch2\u003E过程\u003C\u002Fh2\u003E\u003Ch3\u003E1. 强化学习中的表示学习\u003C\u002Fh3\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003E动机\u003C\u002Fu\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E状态数目较少的时候，可以分别处理每个不同的状态（tabular case），这些强化学习算法的复杂度通常和状态的总数有关；当状态空间特别大的时候就不能再把每个不同的状态分别处理了，而是需要利用一些特征来表示这些状态，从而更有效地解决强化学习问题。\u003C\u002Fp\u003E\u003Cp\u003E一些常用的状态表示方法（比如 polynomials、RBFs、NNs）通常从原始的特征出发，构建新的状态表示；这一类表示方法通常依赖于一个先验知识：各种函数相对于原始特征是比较平滑的。本文的方法则把各个状态之间的关系看做一个 graph，其依赖的先验知识则是各种函数在这个 graph 上是比较平滑的。这里提到的各种函数包括：reward function、transition function、value function 和 policy 等。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003EMDP 中的基底构造问题\u003C\u002Fu\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E基底构造的目标是找到一组基函数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5CPhi+%5Cin+%5Cmathbb%7BR%7D%5E%7B%7CS%7C%5Ctimes+k%7D\" alt=\"\\Phi \\in \\mathbb{R}^{|S|\\times k}\" eeimg=\"1\"\u002F\u003E ，它包括 k 个基函数；我们希望这一组基函数能够以较小的代价近似该 MDP 上的各种函数。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c1d871d4b5d55f606bf733bd463ff9aa_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"451\" data-rawheight=\"96\" class=\"origin_image zh-lightbox-thumb\" width=\"451\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c1d871d4b5d55f606bf733bd463ff9aa_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;451&#39; height=&#39;96&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"451\" data-rawheight=\"96\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"451\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c1d871d4b5d55f606bf733bd463ff9aa_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c1d871d4b5d55f606bf733bd463ff9aa_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E因此该问题中涉及到一些权衡：基底数目越少，在近似的 MDP 上的问题求解就会更加容易，但同时求解就会更加不精确。因此，我们的目标就是用尽可能少的基底来准确表示 MDP 上的各种函数。\u003C\u002Fp\u003E\u003Cp\u003E特别地，在上述提到的各种函数中我们最为关心的是价值函数（value function）的函数拟合问题。我们注意到，即使没有任何先验知识（比如函数需要平滑），也有可能找出一组满足 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=k%3C%7CS%7C\" alt=\"k&lt;|S|\" eeimg=\"1\"\u002F\u003E 的基函数，使得 approximation error 为零。比如，假设这样一组基函数构成了某个空间，该空间内任何函数在 Bellman 算子 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=T%5E%5Cpi\" alt=\"T^\\pi\" eeimg=\"1\"\u002F\u003E 的作用后，仍然还在该空间内；我们称这样的空间为 invariant subspace。在这样的空间中，一定存在待求解的价值函数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=V%5E%5Cpi\" alt=\"V^\\pi\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9425a3606494c05f83535f70c6da3ecf_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"441\" data-rawheight=\"36\" class=\"origin_image zh-lightbox-thumb\" width=\"441\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9425a3606494c05f83535f70c6da3ecf_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;441&#39; height=&#39;36&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"441\" data-rawheight=\"36\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"441\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9425a3606494c05f83535f70c6da3ecf_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9425a3606494c05f83535f70c6da3ecf_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E因此，在这篇文章中，基底构造问题也可以看做是构造这样的 invariant subspace。文章主要介绍了两大类方法来实现这件事情：diagonalization 和 dilation。前者在本专栏里面有提到过，用它来构造状态空间基函数比较著名的方法就是 PVF（\u003Ca href=\"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F68326687\" class=\"internal\"\u003E张楚珩：【强化学习 67】Proto-value Function\u003C\u002Fa\u003E）。后者我们还不太熟悉，dilation 的方法分为两种：一种基于 Krylov space；一种基于 Drazin inverse 和 diffusion wavelet。名字听起来有点复杂，但是我们会在后面展开讲。\u003C\u002Fp\u003E\u003Ch3\u003E2. Average-reward MDP 以及 MDP 的结构\u003C\u002Fh3\u003E\u003Cp\u003E我们比较熟悉的是 finite horizon 和 infinite horizon + discount 的设定。这篇文章里面还提到了 infinite horizon + average-reward 的设定，这种设定对于马科夫过程的结构关系比较紧密。我们下面考虑一个固定策略下的 MDP，即 Markov reward process （MRP），记做 M=(P, R)。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cu\u003E\u003Cb\u003ELimiting matrix P*\u003C\u002Fb\u003E\u003C\u002Fu\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-ab9bebcde12b8b18bdd4af857cfff283_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"627\" data-rawheight=\"153\" class=\"origin_image zh-lightbox-thumb\" width=\"627\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-ab9bebcde12b8b18bdd4af857cfff283_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;627&#39; height=&#39;153&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"627\" data-rawheight=\"153\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"627\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-ab9bebcde12b8b18bdd4af857cfff283_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-ab9bebcde12b8b18bdd4af857cfff283_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E如果 MRP 是遍历和非周期的，那么该矩阵的每一行都一样，都等于稳态分布（invariant distribution），即\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4eb5bce417900cb9379d96f6d0f946f6_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"469\" data-rawheight=\"42\" class=\"origin_image zh-lightbox-thumb\" width=\"469\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4eb5bce417900cb9379d96f6d0f946f6_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;469&#39; height=&#39;42&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"469\" data-rawheight=\"42\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"469\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4eb5bce417900cb9379d96f6d0f946f6_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4eb5bce417900cb9379d96f6d0f946f6_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003EInvariant distribution \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Crho\" alt=\"\\rho\" eeimg=\"1\"\u002F\u003E\u003C\u002Fu\u003E\u003C\u002Fb\u003E \u003C\u002Fp\u003E\u003Cp\u003E注意到如果 MRP 遍历，那么 P 的最大特征值（即，spectral radius）为 1，相应的左特征向量就是该稳态分布。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-5d5a542b9119591fe75696c200346e0c_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"484\" data-rawheight=\"41\" class=\"origin_image zh-lightbox-thumb\" width=\"484\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-5d5a542b9119591fe75696c200346e0c_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;484&#39; height=&#39;41&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"484\" data-rawheight=\"41\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"484\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-5d5a542b9119591fe75696c200346e0c_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-5d5a542b9119591fe75696c200346e0c_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003EGain g and bias h\u003C\u002Fu\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E当存在 discount rate 的时候，优化的目标为 discounted cumulative reward，它综合考虑了长远利益和近期的利益，通过一个 discount rate 来把长远利益和近期利益综合为一个指标。而在 average-reward 的设定下，这两种利益则会被分别考虑：其中 gain 表征长期平均利益，bias 表示实际收到利益相对于长期利益的差值的累计。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-bbe611ec812dc0a9e12142a6e074aeaf_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"477\" data-rawheight=\"36\" class=\"origin_image zh-lightbox-thumb\" width=\"477\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-bbe611ec812dc0a9e12142a6e074aeaf_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;477&#39; height=&#39;36&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"477\" data-rawheight=\"36\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"477\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-bbe611ec812dc0a9e12142a6e074aeaf_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-bbe611ec812dc0a9e12142a6e074aeaf_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a25e2b336488735ed7e2f71e573ccbe1_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"477\" data-rawheight=\"56\" class=\"origin_image zh-lightbox-thumb\" width=\"477\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a25e2b336488735ed7e2f71e573ccbe1_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;477&#39; height=&#39;56&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"477\" data-rawheight=\"56\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"477\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a25e2b336488735ed7e2f71e573ccbe1_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a25e2b336488735ed7e2f71e573ccbe1_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E比如 g(s) 表示从状态 s 出发，走无穷多步之后，平均每一步能够获取的平均利益；而在达到这个“无穷多步”之前，每一步获取利益的期望都可能并不等于极限平均利益，把这一部分差值累积起来就得到了 h(s)。当 MRP 遍历的时候，bias 部分还可以写作\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0bc6b93a08c51ff137f80b2b3197006f_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"467\" data-rawheight=\"51\" class=\"origin_image zh-lightbox-thumb\" width=\"467\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0bc6b93a08c51ff137f80b2b3197006f_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;467&#39; height=&#39;51&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"467\" data-rawheight=\"51\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"467\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0bc6b93a08c51ff137f80b2b3197006f_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0bc6b93a08c51ff137f80b2b3197006f_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E在 average-reward 的设定下，我们不仅需要最大化 gain 也希望最大化 bias。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003EBellman equation\u003C\u002Fu\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E该设定下同样有 Bellman equation\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c546d82d248de40679cac61a9b3edbb2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"584\" data-rawheight=\"176\" class=\"origin_image zh-lightbox-thumb\" width=\"584\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c546d82d248de40679cac61a9b3edbb2_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;584&#39; height=&#39;176&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"584\" data-rawheight=\"176\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"584\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c546d82d248de40679cac61a9b3edbb2_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c546d82d248de40679cac61a9b3edbb2_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E为了便于大家理解，给出一个简单的 MRP 的算例。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1ae3994f2e35023a57cb3ea43c1d887e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"759\" data-rawheight=\"774\" class=\"origin_image zh-lightbox-thumb\" width=\"759\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1ae3994f2e35023a57cb3ea43c1d887e_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;759&#39; height=&#39;774&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"759\" data-rawheight=\"774\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"759\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1ae3994f2e35023a57cb3ea43c1d887e_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1ae3994f2e35023a57cb3ea43c1d887e_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E3. Generalized Inverse\u003C\u002Fp\u003E\u003Cp\u003E如果一个方阵不是满秩的，那么它就不可逆；不过此时我们可以定义广义逆（generalized inverse）。注意到一个真正的逆满足以下所有条件，但当方阵不是满秩时，不能找出一个逆满足这所有的条件，根据逆所满足的不同条件可以定义不同的广义逆。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9aa22571ec5a14f5a91c93b8ee29d552_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"548\" data-rawheight=\"273\" class=\"origin_image zh-lightbox-thumb\" width=\"548\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9aa22571ec5a14f5a91c93b8ee29d552_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;548&#39; height=&#39;273&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"548\" data-rawheight=\"273\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"548\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9aa22571ec5a14f5a91c93b8ee29d552_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9aa22571ec5a14f5a91c93b8ee29d552_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E非常著名的 Moore-Penrose pseudo-inverse 满足前四条，即 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=A%5E%5Cdagger+%3D+A%5E%7B%5C%7B1%2C+2%2C3%2C4%5C%7D%7D\" alt=\"A^\\dagger = A^{\\{1, 2,3,4\\}}\" eeimg=\"1\"\u002F\u003E ；group inverse 满足其中的三条，即 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=A%5E%5C%23+%3D+A%5E%7B%5C%7B1%2C2%2C5%5C%7D%7D\" alt=\"A^\\# = A^{\\{1,2,5\\}}\" eeimg=\"1\"\u002F\u003E ；Drazin inverse 也满足其中的三条，即 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=A%5ED+%3D+A%5E%7B%5C%7B2%2C5%2C6%5C%7D%7D\" alt=\"A^D = A^{\\{2,5,6\\}}\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Ch3\u003E3. Laplacian 算子\u003C\u002Fh3\u003E\u003Cp\u003E在专栏前面的文章里面我们看到可以在图上定义若干种不同的 Laplacian：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d887c5238abd75ce0e8b3f2d0233e337_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"605\" data-rawheight=\"133\" class=\"origin_image zh-lightbox-thumb\" width=\"605\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d887c5238abd75ce0e8b3f2d0233e337_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;605&#39; height=&#39;133&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"605\" data-rawheight=\"133\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"605\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d887c5238abd75ce0e8b3f2d0233e337_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d887c5238abd75ce0e8b3f2d0233e337_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E如果把不同的状态看做图上的节点，当给定一个概率转移矩阵 P 时，就对应了一个 MC；由此，可以定义相应的 random walk Laplacian 算子 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathbb%7BL%7D+%3D+I-P\" alt=\"\\mathbb{L} = I-P\" eeimg=\"1\"\u002F\u003E 。同时注意到价值函数可以由相应的 Laplacian 算子表示。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-196585f471b0dd10dc3ddd919005447d_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"584\" data-rawheight=\"93\" class=\"origin_image zh-lightbox-thumb\" width=\"584\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-196585f471b0dd10dc3ddd919005447d_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;584&#39; height=&#39;93&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"584\" data-rawheight=\"93\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"584\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-196585f471b0dd10dc3ddd919005447d_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-196585f471b0dd10dc3ddd919005447d_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-730b5b32395e6f55b026fbc1d56b538b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"584\" data-rawheight=\"123\" class=\"origin_image zh-lightbox-thumb\" width=\"584\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-730b5b32395e6f55b026fbc1d56b538b_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;584&#39; height=&#39;123&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"584\" data-rawheight=\"123\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"584\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-730b5b32395e6f55b026fbc1d56b538b_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-730b5b32395e6f55b026fbc1d56b538b_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003ELaplacian 算子的 group inverse 可以被写为\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e30e25763ffd28321ea78c113e2e1d69_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"537\" data-rawheight=\"107\" class=\"origin_image zh-lightbox-thumb\" width=\"537\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e30e25763ffd28321ea78c113e2e1d69_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;537&#39; height=&#39;107&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"537\" data-rawheight=\"107\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"537\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e30e25763ffd28321ea78c113e2e1d69_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e30e25763ffd28321ea78c113e2e1d69_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中，中间求逆的部分被称作 fundamental matrix，它是可逆的：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b78000de195080cf9d8339e5c2ff0ee0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"543\" data-rawheight=\"141\" class=\"origin_image zh-lightbox-thumb\" width=\"543\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b78000de195080cf9d8339e5c2ff0ee0_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;543&#39; height=&#39;141&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"543\" data-rawheight=\"141\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"543\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b78000de195080cf9d8339e5c2ff0ee0_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b78000de195080cf9d8339e5c2ff0ee0_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003ELaplacian 算子的 Drazin inverse 的计算稍微复杂一点，假设 transition matrix 可以做如下分解\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-dc73c070523827f8a9e2bffe2633246d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"531\" data-rawheight=\"215\" class=\"origin_image zh-lightbox-thumb\" width=\"531\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-dc73c070523827f8a9e2bffe2633246d_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;531&#39; height=&#39;215&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"531\" data-rawheight=\"215\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"531\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-dc73c070523827f8a9e2bffe2633246d_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-dc73c070523827f8a9e2bffe2633246d_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-dd789d59d34945c195d1fdfe8854a1a3_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"541\" data-rawheight=\"30\" class=\"origin_image zh-lightbox-thumb\" width=\"541\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-dd789d59d34945c195d1fdfe8854a1a3_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;541&#39; height=&#39;30&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"541\" data-rawheight=\"30\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"541\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-dd789d59d34945c195d1fdfe8854a1a3_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-dd789d59d34945c195d1fdfe8854a1a3_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E那么相应的 Drazin inverse 可以被写为：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2ea0ea6e85b33f81562031835d728e6b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"514\" data-rawheight=\"114\" class=\"origin_image zh-lightbox-thumb\" width=\"514\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2ea0ea6e85b33f81562031835d728e6b_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;514&#39; height=&#39;114&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"514\" data-rawheight=\"114\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"514\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2ea0ea6e85b33f81562031835d728e6b_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2ea0ea6e85b33f81562031835d728e6b_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E文章给出了相应的计算 Drazin inverse 的方法，输入 Laplacian 矩阵，输出相应的 Drazin inverse。这里不再贴出来了。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E那么我们为什么要计算 Laplacian 的逆呢？\u003C\u002Fb\u003E因为价值函数可以被表示为 Laplacian 逆的多项式和，而高阶多项式的系数又衰减地比较快，因此可以用 Laplacian 逆对应较大特征值的特征向量来作为我们需要的基底，从而对图上的函数有较好的近似。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-519174ed5ea87d08c53719a938b12324_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"532\" data-rawheight=\"161\" class=\"origin_image zh-lightbox-thumb\" width=\"532\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-519174ed5ea87d08c53719a938b12324_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;532&#39; height=&#39;161&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"532\" data-rawheight=\"161\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"532\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-519174ed5ea87d08c53719a938b12324_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-519174ed5ea87d08c53719a938b12324_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Ch3\u003E4. 希尔伯特空间\u003C\u002Fh3\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003E在无向图上定义 RKHS\u003C\u002Fu\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E通过在无向图上定义 RKHS，说明从数学上应该如何描述函数在图上的平滑性。\u003C\u002Fp\u003E\u003Cp\u003E对于一个无向图，其邻接矩阵为 W。Laplacian 算子在图上定义了半范数，“半”是因为它对于任意的常值函数，其范数都为零。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9c29436ed20d27c2e3992728599bfb1d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"574\" data-rawheight=\"122\" class=\"origin_image zh-lightbox-thumb\" width=\"574\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9c29436ed20d27c2e3992728599bfb1d_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;574&#39; height=&#39;122&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"574\" data-rawheight=\"122\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"574\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9c29436ed20d27c2e3992728599bfb1d_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9c29436ed20d27c2e3992728599bfb1d_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E这个半范数反映了一个函数在图上的不平滑程度，可以从下面这个公式看出来\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-4aa6ddc67f00beb2dfb360a34c3538f3_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"576\" data-rawheight=\"87\" class=\"origin_image zh-lightbox-thumb\" width=\"576\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-4aa6ddc67f00beb2dfb360a34c3538f3_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;576&#39; height=&#39;87&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"576\" data-rawheight=\"87\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"576\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-4aa6ddc67f00beb2dfb360a34c3538f3_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-4aa6ddc67f00beb2dfb360a34c3538f3_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中 w 为其邻接矩阵的元素。我们注意到，Laplacian 矩阵一定会有一个或者多个特征值为 0，这表示该图有多少个连通区域。把不同连通区域之间的函数自由组合的自由度排除之后，可以定义在图上的希尔伯特空间。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e49cd7cf2e6e4072277e7c528df58e81_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"533\" data-rawheight=\"136\" class=\"origin_image zh-lightbox-thumb\" width=\"533\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e49cd7cf2e6e4072277e7c528df58e81_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;533&#39; height=&#39;136&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"533\" data-rawheight=\"136\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"533\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e49cd7cf2e6e4072277e7c528df58e81_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e49cd7cf2e6e4072277e7c528df58e81_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E由此，定义 Laplacian 矩阵的伪逆，并且该伪逆就是再生希尔伯特空间（RKHS）的再生核。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-3175e54ed788091bbbc74080126017ab_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"529\" data-rawheight=\"105\" class=\"origin_image zh-lightbox-thumb\" width=\"529\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-3175e54ed788091bbbc74080126017ab_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;529&#39; height=&#39;105&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"529\" data-rawheight=\"105\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"529\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-3175e54ed788091bbbc74080126017ab_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-3175e54ed788091bbbc74080126017ab_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-56c4ed9f5ae680f93f29bf867bdbd9fe_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"522\" data-rawheight=\"47\" class=\"origin_image zh-lightbox-thumb\" width=\"522\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-56c4ed9f5ae680f93f29bf867bdbd9fe_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;522&#39; height=&#39;47&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"522\" data-rawheight=\"47\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"522\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-56c4ed9f5ae680f93f29bf867bdbd9fe_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-56c4ed9f5ae680f93f29bf867bdbd9fe_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-367cd6f83262cb662ab61899f24dd418_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"503\" data-rawheight=\"94\" class=\"origin_image zh-lightbox-thumb\" width=\"503\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-367cd6f83262cb662ab61899f24dd418_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;503&#39; height=&#39;94&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"503\" data-rawheight=\"94\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"503\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-367cd6f83262cb662ab61899f24dd418_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-367cd6f83262cb662ab61899f24dd418_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E回忆一下，再生核的含义\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9576eefe7e918dde279a6bac4e1b119a_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"480\" data-rawheight=\"32\" class=\"origin_image zh-lightbox-thumb\" width=\"480\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9576eefe7e918dde279a6bac4e1b119a_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;480&#39; height=&#39;32&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"480\" data-rawheight=\"32\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"480\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9576eefe7e918dde279a6bac4e1b119a_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9576eefe7e918dde279a6bac4e1b119a_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E当我们利用 Laplacian 算子在图上定义了一个 RKHS 之后，图上的函数拟合问题的原则就是找到一个最光滑的函数，即 minimum-norm interpretation。（可以参考本专栏前面讲的一个平均场方法求解半监督学习的文章）\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-a990a6186893d3cc06584340ea710d48_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"508\" data-rawheight=\"113\" class=\"origin_image zh-lightbox-thumb\" width=\"508\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-a990a6186893d3cc06584340ea710d48_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;508&#39; height=&#39;113&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"508\" data-rawheight=\"113\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"508\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-a990a6186893d3cc06584340ea710d48_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-a990a6186893d3cc06584340ea710d48_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003E在 MDP 上定义希尔伯特空间\u003C\u002Fu\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E通过在 MDP 上定义 RKHS，说明把状态空间上的函数定义为一组特征的线性组合的合理性。\u003C\u002Fp\u003E\u003Cp\u003E对于状态空间的任意两个函数，定义这两个函数的内积如下：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-4da5e15883e7ec4fb3e6cb6902b8dfcb_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"528\" data-rawheight=\"52\" class=\"origin_image zh-lightbox-thumb\" width=\"528\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-4da5e15883e7ec4fb3e6cb6902b8dfcb_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;528&#39; height=&#39;52&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"528\" data-rawheight=\"52\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"528\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-4da5e15883e7ec4fb3e6cb6902b8dfcb_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-4da5e15883e7ec4fb3e6cb6902b8dfcb_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e77ec0750886a216ae1cb546e5de2149_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"516\" data-rawheight=\"130\" class=\"origin_image zh-lightbox-thumb\" width=\"516\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e77ec0750886a216ae1cb546e5de2149_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;516&#39; height=&#39;130&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"516\" data-rawheight=\"130\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"516\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e77ec0750886a216ae1cb546e5de2149_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e77ec0750886a216ae1cb546e5de2149_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中，对于每个点都有一个权重的调整，该权重为在该策略下的稳态状态分布（invariant distribution）。任意一个函数可以往，这个希尔伯特空间中的一个子空间做投影\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-64e582fcc9d6c221777240fc98ac6b47_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"519\" data-rawheight=\"116\" class=\"origin_image zh-lightbox-thumb\" width=\"519\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-64e582fcc9d6c221777240fc98ac6b47_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;519&#39; height=&#39;116&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"519\" data-rawheight=\"116\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"519\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-64e582fcc9d6c221777240fc98ac6b47_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-64e582fcc9d6c221777240fc98ac6b47_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E后面文章又讲了 Bellman 算子和该投影算子的复合算子也是 contraction，即在某一个固定的基上可以做 approximated policy evaluation 和 control。\u003C\u002Fp\u003E\u003Cp\u003E考虑 RKHS 的定义，一个定义在状态空间上的函数可以用再生核表示出来\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-8eefdada7644c1667f666e8a1e54d22c_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"505\" data-rawheight=\"33\" class=\"origin_image zh-lightbox-thumb\" width=\"505\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-8eefdada7644c1667f666e8a1e54d22c_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;505&#39; height=&#39;33&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"505\" data-rawheight=\"33\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"505\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-8eefdada7644c1667f666e8a1e54d22c_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-8eefdada7644c1667f666e8a1e54d22c_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E我们可以使用一组状态的特征来表示再生核\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-62ed4dcbe7814e3f79d1073d0e3cc632_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"513\" data-rawheight=\"32\" class=\"origin_image zh-lightbox-thumb\" width=\"513\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-62ed4dcbe7814e3f79d1073d0e3cc632_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;513&#39; height=&#39;32&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"513\" data-rawheight=\"32\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"513\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-62ed4dcbe7814e3f79d1073d0e3cc632_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-62ed4dcbe7814e3f79d1073d0e3cc632_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-89a914d951a56e75f8bc76608a01a3a1_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"529\" data-rawheight=\"29\" class=\"origin_image zh-lightbox-thumb\" width=\"529\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-89a914d951a56e75f8bc76608a01a3a1_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;529&#39; height=&#39;29&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"529\" data-rawheight=\"29\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"529\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-89a914d951a56e75f8bc76608a01a3a1_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-89a914d951a56e75f8bc76608a01a3a1_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E由此，任意一个函数都可以用一组特征和相应的系数表示\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-35aa484c79723b98a20fbdff4d2b2ed2_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"507\" data-rawheight=\"29\" class=\"origin_image zh-lightbox-thumb\" width=\"507\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-35aa484c79723b98a20fbdff4d2b2ed2_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;507&#39; height=&#39;29&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"507\" data-rawheight=\"29\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"507\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-35aa484c79723b98a20fbdff4d2b2ed2_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-35aa484c79723b98a20fbdff4d2b2ed2_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Ch3\u003E5. MDP 上的表示学习问题\u003C\u002Fh3\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003E状态空间的低维表示使得 MDP 的求解变得容易\u003C\u002Fu\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E给定一个 MDP 状态空间上的低维表示和一个固定的策略之后，我们可以定义一个 approximated MRP：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-54111ec89b988499158b4b96b7dd6b77_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"514\" data-rawheight=\"151\" class=\"origin_image zh-lightbox-thumb\" width=\"514\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-54111ec89b988499158b4b96b7dd6b77_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;514&#39; height=&#39;151&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"514\" data-rawheight=\"151\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"514\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-54111ec89b988499158b4b96b7dd6b77_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-54111ec89b988499158b4b96b7dd6b77_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E我们可以知道，在这个 MRP  上求解的结果等价于在原 MRP 上求解的 fixed point solution 再投影到该低维表示空间上。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-106e289d57663d40ac1bc88f98b166fe_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"578\" data-rawheight=\"99\" class=\"origin_image zh-lightbox-thumb\" width=\"578\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-106e289d57663d40ac1bc88f98b166fe_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;578&#39; height=&#39;99&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"578\" data-rawheight=\"99\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"578\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-106e289d57663d40ac1bc88f98b166fe_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-106e289d57663d40ac1bc88f98b166fe_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E在低维空间上求解的好处是其复杂度更低：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-cee6eb39fe3582fafb0ad5ac2de814d7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"548\" data-rawheight=\"101\" class=\"origin_image zh-lightbox-thumb\" width=\"548\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-cee6eb39fe3582fafb0ad5ac2de814d7_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;548&#39; height=&#39;101&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"548\" data-rawheight=\"101\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"548\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-cee6eb39fe3582fafb0ad5ac2de814d7_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-cee6eb39fe3582fafb0ad5ac2de814d7_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003EMDP 表示学习的若干考虑\u003C\u002Fu\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E学习过程的复杂度：注意到我们进行表示学习的目的还是为了更好的求解 MDP。因此，如果我们的目标是针对一个特定的 MDP 求解，那么我们显然希望学习到相应表示的复杂度不能高于求解该 MDP 的复杂度；如果我们的表示能够被迁移到其他类似 MDP 上，该条件可以被放宽。\u003C\u002Fli\u003E\u003Cli\u003E表示的复杂度：如果学习到的表示的表征能力比较强，当然使用该表示带来的性能损失会比较少，但预测同时在该表示空间内进行求解的复杂度会相应更高。因此，我们的目标就是以较为简单的表示来实现更小的近似误差。相应的方向有：找到更稀疏的表示；针对状态空间的特殊结构做分解，从而更有效地进行状态的表示；本文后面将会提到的，一些更有效的表示方法，比如多层次的小波基（multiscale wavelet bases）；对于连续状态空间，我们一般用一些空间上的样本来进行 non-parametric 的表示，那么我们希望找到好的采样和拟合方法，使得我们储存较少的样本就能达到较好的精度。\u003C\u002Fli\u003E\u003Cli\u003E表示适用于单一奖励函数还是多种奖励函数：如果学习到的表示是针对单一奖励函数的，那么该表示可能能够对于特定的子空间做到更有效的表示；如果学习到的表示能够针对多个（或者任意）奖励函数，那么学习到的表示就能够适应于一族学习任务。\u003C\u002Fli\u003E\u003Cli\u003E表示是针对单一策略还是多个策略：当策略给定之后，MDP 就退化为 MRP，针对该策略就更容易学习到具有理论保证的状态表示；但与此同时，在 RPI 中，策略是在迭代的，这样学习到的状态表示的生命周期就比较短。\u003C\u002Fli\u003E\u003Cli\u003E逐步学习或者是一次性学习（incremental or batch）：文章里面讲的是一组基底中的每一个基底是一个一个构造出来的还是一次性全部构造出来的；而我这里想说的是，表示是一次性就学习到，还是通过一个循环迭代逐渐学习到。比如，在 policy iteration 中，策略就是通过迭代逐步学习。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Ch3\u003E6. 一个古老的算法：adaptive state aggregation\u003C\u002Fh3\u003E\u003Cp\u003E说它古老是因为该算法发表于 1988 年 [1]。考虑对状态做 aggregation，即把整个状态空间分为互不相交的 k 个集合，这样基底表示矩阵 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5CPhi\" alt=\"\\Phi\" eeimg=\"1\"\u002F\u003E 的每行都是 one-hot 向量。该算法的目标是在给定完整的 transition function、 reward function 和固定策略的情况下，找到一个最优的 state aggregation，使得价值函数能够在该 aggregation 基底下较准确地被表示出来。算法的迭代过程如下：\u003C\u002Fp\u003E\u003Col\u003E\u003Cli\u003E按照当前的 Bellman residual \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=T%5E%5Cpi+V%5Ek+-+V%5Ek\" alt=\"T^\\pi V^k - V^k\" eeimg=\"1\"\u002F\u003E 的数值大小，把状态分到不同的集合中，得到表示矩阵 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5CPhi\" alt=\"\\Phi\" eeimg=\"1\"\u002F\u003E ；\u003C\u002Fli\u003E\u003Cli\u003E按照该表示矩阵 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5CPhi\" alt=\"\\Phi\" eeimg=\"1\"\u002F\u003E ，把当前的价值函数做投影 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=V%5Ek+%5Cleftarrow+%5CPi_%5CPhi+%28V%5Ek%29\" alt=\"V^k \\leftarrow \\Pi_\\Phi (V^k)\" eeimg=\"1\"\u002F\u003E ；\u003C\u002Fli\u003E\u003Cli\u003E调整价值函数，将它往奖励更高的方向移动： \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=V%5E%7Bk%2B1%7D+%5Cleftarrow+V%5Ek+%2B+%5CPhi+y%2C%5C+%5C+%5C+y+%3D%28I-%5Cgamma+P%5E%5Cpi_%5CPhi%29%5E%7B-1%7D+R%5E%5Cpi_%5CPhi\" alt=\"V^{k+1} \\leftarrow V^k + \\Phi y,\\ \\ \\ y =(I-\\gamma P^\\pi_\\Phi)^{-1} R^\\pi_\\Phi\" eeimg=\"1\"\u002F\u003E ，其中\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-f39269266af0fc03c3320600b3451d4c_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"474\" data-rawheight=\"55\" class=\"origin_image zh-lightbox-thumb\" width=\"474\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-f39269266af0fc03c3320600b3451d4c_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;474&#39; height=&#39;55&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"474\" data-rawheight=\"55\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"474\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-f39269266af0fc03c3320600b3451d4c_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-f39269266af0fc03c3320600b3451d4c_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E注意到，这里 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=R_%5CPhi%5E%5Cpi\" alt=\"R_\\Phi^\\pi\" eeimg=\"1\"\u002F\u003E 是 Bellman residual 的往基底上的投影，MDP 原始的奖励函数隐含在 Bellman 算子 T 中。在第二步中，价值函数在 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5CPhi\" alt=\"\\Phi\" eeimg=\"1\"\u002F\u003E 张成的空间上；而第三步的修正仍然也在该空间中，因此第三步得到的价值函数仍然在 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5CPhi\" alt=\"\\Phi\" eeimg=\"1\"\u002F\u003E 张成的空间上。这里比较特别的是，第一步中根据不同点上 Bellman residual 的大小来做 state aggregation 的做法。其原因如下：每步迭代后的误差可以被写作以下两项的和\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-f194a466a179252271f6edd46e77eb01_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"514\" data-rawheight=\"83\" class=\"origin_image zh-lightbox-thumb\" width=\"514\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-f194a466a179252271f6edd46e77eb01_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;514&#39; height=&#39;83&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"514\" data-rawheight=\"83\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"514\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-f194a466a179252271f6edd46e77eb01_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-f194a466a179252271f6edd46e77eb01_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中，如果 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5CPhi\" alt=\"\\Phi\" eeimg=\"1\"\u002F\u003E 张成了相对于 P 的 invariant subspace 的话，第二项将会为零，即 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%28I-%5CPi%29P%5CPhi+x%3D0%2C+%5Cforall+x\" alt=\"(I-\\Pi)P\\Phi x=0, \\forall x\" eeimg=\"1\"\u002F\u003E ，当然，对于 state aggregation 来说很难找到一个 invariant subspace。而第一项可以看做是每一个集合内对应状态的 Bellman residual 相比于其集合内平均的差值；为了减小这一项，自然考虑到把 Bellman residual 相近的状态划分到同一类中。\u003C\u002Fp\u003E\u003Ch3\u003E7. Diagonalization\u003C\u002Fh3\u003E\u003Cp\u003E\u003Cu\u003E\u003Cb\u003E在价值函数表示中，拉普拉斯矩阵的最小特征值对应最重要的特征向量\u003C\u002Fb\u003E\u003C\u002Fu\u003E\u003C\u002Fp\u003E\u003Cp\u003E考虑拉普拉斯矩阵的特征值分解\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-1944f0f0ad7426d4c87fedbffbbd22f0_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"525\" data-rawheight=\"57\" class=\"origin_image zh-lightbox-thumb\" width=\"525\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-1944f0f0ad7426d4c87fedbffbbd22f0_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;525&#39; height=&#39;57&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"525\" data-rawheight=\"57\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"525\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-1944f0f0ad7426d4c87fedbffbbd22f0_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-1944f0f0ad7426d4c87fedbffbbd22f0_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E同时价值函数也做相应的分解\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-55fff1045d7600386807a65afe2fc1cd_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"597\" data-rawheight=\"38\" class=\"origin_image zh-lightbox-thumb\" width=\"597\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-55fff1045d7600386807a65afe2fc1cd_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;597&#39; height=&#39;38&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"597\" data-rawheight=\"38\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"597\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-55fff1045d7600386807a65afe2fc1cd_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-55fff1045d7600386807a65afe2fc1cd_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E不难推导出，价值函数可以被分解为相应特征向量的加权和，而特征值最小的特征向量对应的系数更小，这说明我们可以选用特征值最小的那一些特征向量来作为价值函数的基底\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5ac4fd6a5defd5fc288b692d08db9f61_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"639\" data-rawheight=\"162\" class=\"origin_image zh-lightbox-thumb\" width=\"639\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5ac4fd6a5defd5fc288b692d08db9f61_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;639&#39; height=&#39;162&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"639\" data-rawheight=\"162\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"639\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5ac4fd6a5defd5fc288b692d08db9f61_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5ac4fd6a5defd5fc288b692d08db9f61_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003E从图论的角度来看，拉普拉斯矩阵的最小特征值对应函数在图上最平滑的分量\u003C\u002Fu\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E考虑拉普拉斯算子的特征值 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Clambda_i\" alt=\"\\lambda_i\" eeimg=\"1\"\u002F\u003E 和特征向量 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cxi_i\" alt=\"\\xi_i\" eeimg=\"1\"\u002F\u003E ，定义一个函数在图上的 norm\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-58fa3f3d4459f73ad15d7880977a332f_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"567\" data-rawheight=\"56\" class=\"origin_image zh-lightbox-thumb\" width=\"567\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-58fa3f3d4459f73ad15d7880977a332f_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;567&#39; height=&#39;56&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"567\" data-rawheight=\"56\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"567\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-58fa3f3d4459f73ad15d7880977a332f_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-58fa3f3d4459f73ad15d7880977a332f_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中，d 为相应 MC 在图上的稳态分布；一个函数在图上的光滑程度可以通过如下 Sobolev norm 来衡量\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-f2ee9ee08f10be62703894959473205d_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"546\" data-rawheight=\"75\" class=\"origin_image zh-lightbox-thumb\" width=\"546\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-f2ee9ee08f10be62703894959473205d_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;546&#39; height=&#39;75&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"546\" data-rawheight=\"75\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"546\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-f2ee9ee08f10be62703894959473205d_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-f2ee9ee08f10be62703894959473205d_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E注意到第一项衡量了这个函数的绝对数值大小；第二项衡量这个函数在图上的平滑程度，注意到对于特征向量 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cxi_i\" alt=\"\\xi_i\" eeimg=\"1\"\u002F\u003E ，有 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%7C%7C%5Cnabla+%5Cxi_i%7C%7C_2%5E2+%3D+%5Clambda_i\" alt=\"||\\nabla \\xi_i||_2^2 = \\lambda_i\" eeimg=\"1\"\u002F\u003E ，由此可见，对于同样的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cepsilon\" alt=\"\\epsilon\" eeimg=\"1\"\u002F\u003E -approximation\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-5034cd1f2905e8f1ee4b902a3c32f68c_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"557\" data-rawheight=\"73\" class=\"origin_image zh-lightbox-thumb\" width=\"557\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-5034cd1f2905e8f1ee4b902a3c32f68c_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;557&#39; height=&#39;73&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"557\" data-rawheight=\"73\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"557\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-5034cd1f2905e8f1ee4b902a3c32f68c_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-5034cd1f2905e8f1ee4b902a3c32f68c_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E显然应该尽量让对应特征值更小的特征向量前面的系数更大，这样的拟合产生更平滑的函数。文章中还提到，可以一个一个地来找到最平滑的特征函数，具体做法就是把特征值问题通过 Rayleigh quotient 表示为优化问题，比如\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6b1e51002699161451c4f4084edc6068_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"524\" data-rawheight=\"53\" class=\"origin_image zh-lightbox-thumb\" width=\"524\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6b1e51002699161451c4f4084edc6068_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;524&#39; height=&#39;53&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"524\" data-rawheight=\"53\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"524\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6b1e51002699161451c4f4084edc6068_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6b1e51002699161451c4f4084edc6068_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E这一节后面还讲述了对于具有特定结构的图，可以把图做分解（factor），然后其总的 Laplacian 也可以最相应的分解，从而简化表示；这里我暂时不是很感兴趣，就不写了。\u003C\u002Fp\u003E\u003Ch3\u003E8. Dilation\u003C\u002Fh3\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003EKrylov space\u003C\u002Fu\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E一个 Krylov subspace 是由一个算子 T 和一个函数 f 来定义的，它是如下基函数的 span\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0a4f9ea2eeab8ed7cb96ae80e603f43f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"570\" data-rawheight=\"289\" class=\"origin_image zh-lightbox-thumb\" width=\"570\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0a4f9ea2eeab8ed7cb96ae80e603f43f_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;570&#39; height=&#39;289&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"570\" data-rawheight=\"289\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"570\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0a4f9ea2eeab8ed7cb96ae80e603f43f_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0a4f9ea2eeab8ed7cb96ae80e603f43f_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E文章里面主要讲了两种方法，一种令 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=T%3D%5Cmathbb%7BL%7D\" alt=\"T=\\mathbb{L}\" eeimg=\"1\"\u002F\u003E ，即直接把 Laplacian 作为这里的算子 T；另外一种令 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=T%3D%5Cmathbb%7BL%7D%5ED\" alt=\"T=\\mathbb{L}^D\" eeimg=\"1\"\u002F\u003E ，即把 Laplacian 的 Drazin inverse 作为这里的算子 T。当然，我们一般不会一直重复直到找到一个 invariant subspace，因此一般来说 invariant subspace 的基底数量是非常多的。我们希望只需要前几项就能够较好的近似整个空间中可能的价值函数。为什么能做这样的近似呢？其主要的原因还是在于价值函数可以做如下的级数展开，因此基底中有几个基，就能够准确拟合前几项的结果。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-c9a1fc9d2593f0061c994366d8267b58_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"586\" data-rawheight=\"29\" class=\"origin_image zh-lightbox-thumb\" width=\"586\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-c9a1fc9d2593f0061c994366d8267b58_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;586&#39; height=&#39;29&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"586\" data-rawheight=\"29\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"586\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-c9a1fc9d2593f0061c994366d8267b58_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-c9a1fc9d2593f0061c994366d8267b58_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f478f09db89a169c13faea989324af1a_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"591\" data-rawheight=\"50\" class=\"origin_image zh-lightbox-thumb\" width=\"591\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f478f09db89a169c13faea989324af1a_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;591&#39; height=&#39;50&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"591\" data-rawheight=\"50\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"591\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f478f09db89a169c13faea989324af1a_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f478f09db89a169c13faea989324af1a_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E注意到 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%28a%2Bx%29%5E%7B-1%7D+%3D+a%5E%7B-1%7D+-+a%5E%7B-1%7Dx+%2B+a%5E%7B-3%7D+x%5E2++%2B+%5Ccdots\" alt=\"(a+x)^{-1} = a^{-1} - a^{-1}x + a^{-3} x^2  + \\cdots\" eeimg=\"1\"\u002F\u003E ，也可以被写作级数形式，但是注意到当 a&lt;1 时，前几项级数并不能很好的进行拟合；这意味着用 Laplacian 的效果会不如用 Laplacian 的逆的效果，这一点在后面的实验中也可以看到。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003EDilation using Laplacian\u003C\u002Fu\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E这种方法就是按照如下顺序构建基\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9d5fc87f5fb234a716bcbe67e1577a55_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"209\" class=\"origin_image zh-lightbox-thumb\" width=\"600\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9d5fc87f5fb234a716bcbe67e1577a55_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;600&#39; height=&#39;209&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"209\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"600\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9d5fc87f5fb234a716bcbe67e1577a55_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9d5fc87f5fb234a716bcbe67e1577a55_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E显然，这样构建的各个基底之间不正交。可以利用 Bellman error basis function（BEBF），每次把 Bellman error 作为新的基底\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-49e3ed1ef01984a2c0f63b75f307abc9_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"537\" data-rawheight=\"31\" class=\"origin_image zh-lightbox-thumb\" width=\"537\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-49e3ed1ef01984a2c0f63b75f307abc9_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;537&#39; height=&#39;31&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"537\" data-rawheight=\"31\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"537\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-49e3ed1ef01984a2c0f63b75f307abc9_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-49e3ed1ef01984a2c0f63b75f307abc9_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-95afb2e61c689810c46c5d659bef800a_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"550\" data-rawheight=\"34\" class=\"origin_image zh-lightbox-thumb\" width=\"550\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-95afb2e61c689810c46c5d659bef800a_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;550&#39; height=&#39;34&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"550\" data-rawheight=\"34\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"550\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-95afb2e61c689810c46c5d659bef800a_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-95afb2e61c689810c46c5d659bef800a_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E不难看出，每次构造的新基底都和已有基底张成的空间正交；同时如果这里也从 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=R%5E%5Cpi\" alt=\"R^\\pi\" eeimg=\"1\"\u002F\u003E 出发，可以证明上述方法构造出来的基底和用 Laplacian 构造出来的 Krylov space 一致。（另外可以参见本人数学专栏里面讲的 Lanczos 和 conjugate gradient 方法，想法上和这个很类似）\u003C\u002Fp\u003E\u003Cp\u003E为了给大家有一个直观的感受，举一个例子：考虑一个一维链式 MRP，有 50 个状态，在第 10 和第 41 个状态上有奖励，策略为最优策略。在这种情况下，基底 Krylov space 的前几个基函数画出来长下面这个样子\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-be46fb9c58a7c23c708c279f11c5550c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"804\" data-rawheight=\"472\" class=\"origin_image zh-lightbox-thumb\" width=\"804\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-be46fb9c58a7c23c708c279f11c5550c_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;804&#39; height=&#39;472&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"804\" data-rawheight=\"472\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"804\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-be46fb9c58a7c23c708c279f11c5550c_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-be46fb9c58a7c23c708c279f11c5550c_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E可以看出，这个基底就是每次按照 Laplacian 把奖励函数往外扩散。直观看起来效率是比较低的。\u003C\u002Fp\u003E\u003Cp\u003E再举一个二维的例子，感觉上也是类似的。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-414cb217d513c8d4f2d546d744d27dda_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"791\" data-rawheight=\"451\" class=\"origin_image zh-lightbox-thumb\" width=\"791\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-414cb217d513c8d4f2d546d744d27dda_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;791&#39; height=&#39;451&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"791\" data-rawheight=\"451\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"791\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-414cb217d513c8d4f2d546d744d27dda_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-414cb217d513c8d4f2d546d744d27dda_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003EDilation using Drazin inverse of Laplacian\u003C\u002Fu\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E下面，我们介绍如何使用 Laplacian 的 Drazin inverse 来构造 Krylov space（也叫 Drazin space）。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-8079118f886ecdd4027665e5e7ed44a0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"578\" data-rawheight=\"193\" class=\"origin_image zh-lightbox-thumb\" width=\"578\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-8079118f886ecdd4027665e5e7ed44a0_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;578&#39; height=&#39;193&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"578\" data-rawheight=\"193\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"578\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-8079118f886ecdd4027665e5e7ed44a0_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-8079118f886ecdd4027665e5e7ed44a0_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E这第一个向量看起来有点奇怪，注意到在 average-reward 的设定下，gain \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=g%5E%5Cpi+%3D+P%5E%2A+R%5E%5Cpi\" alt=\"g^\\pi = P^* R^\\pi\" eeimg=\"1\"\u002F\u003E ，我们把它作为起始的“种子”向量；而接下来的一项 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathbb%7BL%7D%5ED+g+%3D+%5Cmathbb%7BL%7D%5ED++P%5E%2A+R%3D0\" alt=\"\\mathbb{L}^D g = \\mathbb{L}^D  P^* R=0\" eeimg=\"1\"\u002F\u003E ，因此就把这一项跳过去了。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-aaa63858e842908bfdda9dd714286d8c_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"630\" data-rawheight=\"48\" class=\"origin_image zh-lightbox-thumb\" width=\"630\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-aaa63858e842908bfdda9dd714286d8c_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;630&#39; height=&#39;48&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"630\" data-rawheight=\"48\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"630\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-aaa63858e842908bfdda9dd714286d8c_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-aaa63858e842908bfdda9dd714286d8c_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E还是前面的例子，把相应的 Drazin space 中前几个基底的图如下所示。可以看出相应的前几个基底更快地“扩散”到状态空间中。后面会看到，这样的基底近似效果会更好\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4affec8e28201e5709c46962bff7dedc_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"759\" data-rawheight=\"477\" class=\"origin_image zh-lightbox-thumb\" width=\"759\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4affec8e28201e5709c46962bff7dedc_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;759&#39; height=&#39;477&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"759\" data-rawheight=\"477\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"759\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4affec8e28201e5709c46962bff7dedc_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4affec8e28201e5709c46962bff7dedc_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9425571c48e24c4302d86d7f98604d4f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"751\" data-rawheight=\"468\" class=\"origin_image zh-lightbox-thumb\" width=\"751\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9425571c48e24c4302d86d7f98604d4f_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;751&#39; height=&#39;468&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"751\" data-rawheight=\"468\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"751\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9425571c48e24c4302d86d7f98604d4f_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9425571c48e24c4302d86d7f98604d4f_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003EDiffusion wavelet\u003C\u002Fu\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E文章接着后面还讲了使用 diffusion wavelet 的做法来获得多尺度上更好的近似，大致思想上是我们现在不要再一个一个地构造 Drazin space 了，而是要 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathbb%7BL%7D%5ED+R%2C+%28%5Cmathbb%7BL%7D%5ED%29%5E2+R%2C+%28%5Cmathbb%7BL%7D%5ED%29%5E4+R%2C+%28%5Cmathbb%7BL%7D%5ED%29%5E8+R+%5Ccdots\" alt=\"\\mathbb{L}^D R, (\\mathbb{L}^D)^2 R, (\\mathbb{L}^D)^4 R, (\\mathbb{L}^D)^8 R \\cdots\" eeimg=\"1\"\u002F\u003E 地构造。但是 wavelet 看得我很头痛，并且看懂之后发现这个解决问题的设定我就不是很感兴趣，因此就不再写了。关于 wavelet 的简要介绍见下一篇吧。\u003C\u002Fp\u003E\u003Cp\u003E下面贴一下这种方法的实验效果，文章把这种方法和前面的 eigenvalue 的方法进行对比，我们发现只使用 5 个基底，该方法不仅能够很好得近似比较不光滑的函数（比如第一行中的函数），也能够很好地近似比较光滑的函数（比如第二行中的函数）。与此同时，随着基底数量的增加，拟合误差下降地也更快，即这种方法的近似效率更高。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-28e7b25cc573183abfa8e53c0502bd4f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"707\" data-rawheight=\"442\" class=\"origin_image zh-lightbox-thumb\" width=\"707\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-28e7b25cc573183abfa8e53c0502bd4f_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;707&#39; height=&#39;442&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"707\" data-rawheight=\"442\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"707\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-28e7b25cc573183abfa8e53c0502bd4f_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-28e7b25cc573183abfa8e53c0502bd4f_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Ch3\u003E9. Continuous MDP\u003C\u002Fh3\u003E\u003Cp\u003E这里讲一下如何处理连续状态空间的表示学习问题（假设行动还是离散的）。状态空间连续的时候，可以定义相应的 Bellman 方程，称作 Hamilton-Bellman-Jacobi （HBJ）方程：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c9ea0ef41d3d25d1f613cc74154a6ede_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"555\" data-rawheight=\"50\" class=\"origin_image zh-lightbox-thumb\" width=\"555\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c9ea0ef41d3d25d1f613cc74154a6ede_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;555&#39; height=&#39;50&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"555\" data-rawheight=\"50\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"555\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c9ea0ef41d3d25d1f613cc74154a6ede_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c9ea0ef41d3d25d1f613cc74154a6ede_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E回顾一下，在状态空间离散的时候，可以把每个状态当做图上的节点；我们在前面看到，这个图上对应 Laplacian 的前几个特征向量表示了最平滑的若干个定义在该图上的函数。当状态连续的时候，就不能再把它们看做图上的节点了；这时候我们把它们建模为一个 Riemannian manifold，在这个 manifold 上也可以定义类似的 Laplacian，我们称之为 Laplace-Beltrami 算子，该算子的前几个特征向量同样对应最平滑的函数。下面将简要介绍 Riemannian manifold 和 Laplace-Beltrami 算子。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003ERiemannian manifold\u003C\u002Fu\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E这一部分只是看了一下定义，可能个人理解不是特别准确。个人理解，manifold 用来被描述一个在局部和（低维）欧式空间有一些对应关系的结构。除此之外，Riemannian manifold 还要求 manifold 和欧式空间的对应关系是可导的（相当于规定了平滑性），同时还能够通过 Riemannian metric 来定义距离度量。具体地，对于 n 维空间上的 manifold 上的一点 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=p%5Cin+%5Cmathcal%7BM%7D\" alt=\"p\\in \\mathcal{M}\" eeimg=\"1\"\u002F\u003E ，考虑过这一点的 tangent space \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=T_p+%28%5Cmathcal%7BM%7D%29\" alt=\"T_p (\\mathcal{M})\" eeimg=\"1\"\u002F\u003E ，在该空间上可以定义内积 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=g_p%3A+T_p%28%5Cmathcal%7BM%7D%29+%5Ctimes+T_p%28%5Cmathcal%7BM%7D%29+%5Cto+%5Cmathbb%7BR%7D\" alt=\"g_p: T_p(\\mathcal{M}) \\times T_p(\\mathcal{M}) \\to \\mathbb{R}\" eeimg=\"1\"\u002F\u003E ，当然也可以把它写出一个 nxn 的矩阵 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=G_p\" alt=\"G_p\" eeimg=\"1\"\u002F\u003E （Riemannian metric）。对于 tangent space 上的一点 q，可以写出 p、q 两点在 manifold 上的距离度量 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%28q-p%29%5ET+G_p+%28q-p%29\" alt=\"(q-p)^T G_p (q-p)\" eeimg=\"1\"\u002F\u003E 。比如对于 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathbb%7BR%7D%5En\" alt=\"\\mathbb{R}^n\" eeimg=\"1\"\u002F\u003E 本身也可以看做一个 manifold，其在任意点上的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=G_p+%3D+I_n\" alt=\"G_p = I_n\" eeimg=\"1\"\u002F\u003E ，因此两点之间的距离就是欧氏距离；对于一个 probability distribution \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=P%28X%7C%5Ctheta%29%2C+%5Ctheta+%5Cin+%5Cmathbb%7BR%7D%5En\" alt=\"P(X|\\theta), \\theta \\in \\mathbb{R}^n\" eeimg=\"1\"\u002F\u003E ，它在某一点的距离度量 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=G_%5Ctheta+%3D+%5Cmathcal%7BI%7D%28%5Ctheta%29\" alt=\"G_\\theta = \\mathcal{I}(\\theta)\" eeimg=\"1\"\u002F\u003E 为 Fisher information matrix。回忆一下，TRPO 里面需要限制参数变化带来的策略空间的变化大小，实际上限制了其 manifold 上的距离 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%28%5Ctheta%27+-+%5Ctheta%29%5ET+%5Cmathcal%7BI%7D%28%5Ctheta%29+%28%5Ctheta%27+-+%5Ctheta%29\" alt=\"(\\theta&#39; - \\theta)^T \\mathcal{I}(\\theta) (\\theta&#39; - \\theta)\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003ELaplace-Beltrami 算子\u003C\u002Fu\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E可以在 manifold 上定义 Laplacian-Beltrami 算子\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-eadf6e39a9acb1811e0e7c3e1072fac9_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"524\" data-rawheight=\"56\" class=\"origin_image zh-lightbox-thumb\" width=\"524\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-eadf6e39a9acb1811e0e7c3e1072fac9_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;524&#39; height=&#39;56&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"524\" data-rawheight=\"56\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"524\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-eadf6e39a9acb1811e0e7c3e1072fac9_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-eadf6e39a9acb1811e0e7c3e1072fac9_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中 g 就代表前面提到的 Riemannian metric。这个看起来挺复杂的，不过没事，这就是一个定义而已，在 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathbb%7BR%7D%5En\" alt=\"\\mathbb{R}^n\" eeimg=\"1\"\u002F\u003E 空间中，它可以被写作\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-a314ec00f3831d3371bba94c9b33dbd2_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"86\" data-rawheight=\"29\" class=\"content_image\" width=\"86\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;86&#39; height=&#39;29&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"86\" data-rawheight=\"29\" class=\"content_image lazy\" width=\"86\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-a314ec00f3831d3371bba94c9b33dbd2_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E满足 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5CDelta+f+%3D+0\" alt=\"\\Delta f = 0\" eeimg=\"1\"\u002F\u003E 的函数被称为 harmonic functions，比如在 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathbb%7BR%7D%5E2\" alt=\"\\mathbb{R}^2\" eeimg=\"1\"\u002F\u003E 空间中，如下函数就是一个 harmonic function。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-5ae6a0f2707256bf3bd091f1fa50e2b6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"240\" data-rawheight=\"199\" class=\"content_image\" width=\"240\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;240&#39; height=&#39;199&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"240\" data-rawheight=\"199\" class=\"content_image lazy\" width=\"240\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-5ae6a0f2707256bf3bd091f1fa50e2b6_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E同样，该算子也有相应的特征值和特征向量，即\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1f7f82669b34dd76f5d191bfd1dd18ad_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"498\" data-rawheight=\"32\" class=\"origin_image zh-lightbox-thumb\" width=\"498\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1f7f82669b34dd76f5d191bfd1dd18ad_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;498&#39; height=&#39;32&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"498\" data-rawheight=\"32\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"498\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1f7f82669b34dd76f5d191bfd1dd18ad_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1f7f82669b34dd76f5d191bfd1dd18ad_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E在 manifold 上也可以定义相应的 smoothness functional  \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathcal%7BH%7D%5E1%28%5Cmathcal%7BM%7D%29\" alt=\"\\mathcal{H}^1(\\mathcal{M})\" eeimg=\"1\"\u002F\u003E -norm \u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0d8099b1db0d07bfc50eca900df3cfd3_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"565\" data-rawheight=\"34\" class=\"origin_image zh-lightbox-thumb\" width=\"565\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0d8099b1db0d07bfc50eca900df3cfd3_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;565&#39; height=&#39;34&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"565\" data-rawheight=\"34\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"565\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0d8099b1db0d07bfc50eca900df3cfd3_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0d8099b1db0d07bfc50eca900df3cfd3_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b59d82fa9ff2a855c6cdf832087f8768_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"504\" data-rawheight=\"50\" class=\"origin_image zh-lightbox-thumb\" width=\"504\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b59d82fa9ff2a855c6cdf832087f8768_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;504&#39; height=&#39;50&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"504\" data-rawheight=\"50\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"504\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b59d82fa9ff2a855c6cdf832087f8768_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b59d82fa9ff2a855c6cdf832087f8768_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E不难发现，对于归一化的特征向量 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=S%28%5Cphi%29+%3D+%5Clambda\" alt=\"S(\\phi) = \\lambda\" eeimg=\"1\"\u002F\u003E 。因此，相应地，要找到 manifold 上平滑的函数就是要找 Laplace-Beltrami 算子对应较小特征值的特征向量们张成的空间。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003EHodge theorem\u003C\u002Fu\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003EHodge theorem 说的是 Laplace-Beltrami 算子对应的特征们能够张成的空间就是 manifold 上所有函数构成的空间，这说明如果我们选用该算子的特征向量来作为状态空间的基，当选用的特征向量足够多的时候，其张成的空间就是状态空间中的所有函数空间，即 asymptotic approximation error = 0。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-d47f040195775ab3b83c7d518f12ef78_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"537\" data-rawheight=\"114\" class=\"origin_image zh-lightbox-thumb\" width=\"537\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-d47f040195775ab3b83c7d518f12ef78_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;537&#39; height=&#39;114&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"537\" data-rawheight=\"114\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"537\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-d47f040195775ab3b83c7d518f12ef78_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-d47f040195775ab3b83c7d518f12ef78_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003EManifold 的表示方法\u003C\u002Fu\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E回顾状态是离散的时候，我们是如何表示学习到的基底的呢？我们使用了一个矩阵 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5CPhi+%5Cin+%5Cmathbb%7BR%7D%5E%7B%7CS%7C%5Ctimes+k%7D\" alt=\"\\Phi \\in \\mathbb{R}^{|S|\\times k}\" eeimg=\"1\"\u002F\u003E 来表示每一个状态上这 k 个基函数的数值。当状态空间变为连续的时候，我们不能再用这样一个矩阵来表示所学习到的基底了，因为 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%7CS%7C%5Cto+%5Cinfty\" alt=\"|S|\\to \\infty\" eeimg=\"1\"\u002F\u003E 。这个时候，我们需要在有限个样本上表示这 k 个基底，并且当出现新的一个状态的时候，我们通过外拓来找到新的状态下各个基底的数值。这涉及到两个问题：如何选择这有限个支撑状态样本；通过何种方式来外拓得到未见过状态的各个基底的数值。\u003C\u002Fp\u003E\u003Cp\u003E对于第一个问题，文章说可以纯粹在已有的样本中做 random sample，也可以构造 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cepsilon\" alt=\"\\epsilon\" eeimg=\"1\"\u002F\u003E -net。对于第二个问题，文章提出使用 Nystrom extension\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-71bd6f125dee9a08ea453c689e48329b_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"568\" data-rawheight=\"56\" class=\"origin_image zh-lightbox-thumb\" width=\"568\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-71bd6f125dee9a08ea453c689e48329b_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;568&#39; height=&#39;56&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"568\" data-rawheight=\"56\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"568\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-71bd6f125dee9a08ea453c689e48329b_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-71bd6f125dee9a08ea453c689e48329b_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中，k(x,s) 衡量了这个新数据点到已有数据点的相似性（kernel function），w 为quadrature weight，文章也没说清楚这个东西到底咋算，不过大致不难理解，因为用了很多数据点做 support，那么各个数据点的重要性肯定还是区别的，需要用一个权重来作相应的调整。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003ERemark\u003C\u002Fu\u003E\u003C\u002Fb\u003E：在离散状态空间中选择一组基底，会优先选择在 Laplacian 描述的这张图上比较光滑的基底，这相当于用到了一个“图上光滑”的先验；当状态空间连续的时候，不仅用到了“图上光滑”的先验，其实还需要用到“原始度量空间中光滑”的先验（考虑上一个公式中的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=k%28x%2Cs_i%29\" alt=\"k(x,s_i)\" eeimg=\"1\"\u002F\u003E ）。\u003C\u002Fp\u003E\u003Ch3\u003E10. Representation policy iteration (RPI)\u003C\u002Fh3\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003EModel-based RPI\u003C\u002Fu\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E在 model-based 的设定中，假设当给定一个策略 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cpi\" alt=\"\\pi\" eeimg=\"1\"\u002F\u003E 之后， \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=P%5E%5Cpi%2C+R%5E%5Cpi\" alt=\"P^\\pi, R^\\pi\" eeimg=\"1\"\u002F\u003E 都已知。针对一个给定的 MDP ，可以通过如下循环来进行求解：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003ERepresentation construction：对于当前策略，构造相应的低维表示，生成一个低维的 MRP；\u003C\u002Fli\u003E\u003Cli\u003EPolicy evaluation：估计当前策略下的价值函数；\u003C\u002Fli\u003E\u003Cli\u003EPolicy improvement：在当前价值函数的估计上做一步学习。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003E注意到，由于假设模型已知，因此这里只需要对状态价值函数 V 进行低维空间的表示即可；在策略改进的时候，可以利用已知的状态转移矩阵来对计算 after-state 的价值函数，从而实现策略的更新。在模型未知的时候，一般需要学习行动价值函数 Q 的低维表示，这种情况就要再更头疼一些。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-64a4c93bf6fafb214e48820cd64debd0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"893\" data-rawheight=\"863\" class=\"origin_image zh-lightbox-thumb\" width=\"893\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-64a4c93bf6fafb214e48820cd64debd0_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;893&#39; height=&#39;863&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"893\" data-rawheight=\"863\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"893\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-64a4c93bf6fafb214e48820cd64debd0_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-64a4c93bf6fafb214e48820cd64debd0_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-0d9eac5ad057e8cd9ef9c7e3b4559009_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"893\" data-rawheight=\"633\" class=\"origin_image zh-lightbox-thumb\" width=\"893\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-0d9eac5ad057e8cd9ef9c7e3b4559009_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;893&#39; height=&#39;633&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"893\" data-rawheight=\"633\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"893\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-0d9eac5ad057e8cd9ef9c7e3b4559009_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-0d9eac5ad057e8cd9ef9c7e3b4559009_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003EModel-free RPI\u003C\u002Fu\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E这个时候 transition function 不再已知，而是需要通过采集样本来得到。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9c01552c29a12af333b06f9502028e92_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"893\" data-rawheight=\"863\" class=\"origin_image zh-lightbox-thumb\" width=\"893\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9c01552c29a12af333b06f9502028e92_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;893&#39; height=&#39;863&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"893\" data-rawheight=\"863\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"893\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9c01552c29a12af333b06f9502028e92_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9c01552c29a12af333b06f9502028e92_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003ERemark\u003C\u002Fu\u003E\u003C\u002Fb\u003E：这里的 model-based 和 model-free 和我们强化学习里面的设定不一样，这里讲的 model-based 其实是我们现在经常讲的 known transition，它就不是 RL 问题；而这里讲的 model-free 其实是我们现在经常讲的 model-based RL。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Chr\u002F\u003E\u003Ch3\u003E参考文献\u003C\u002Fh3\u003E\u003Cp\u003E[1] Bertsekas, Dimitri P., and David A. Castanon. &#34;Adaptive aggregation methods for infinite horizon dynamic programming.&#34; (1988).\u003C\u002Fp\u003E","adminClosedComment":false,"topics":[{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F19640433","type":"topic","id":"19640433","name":"英文论文"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F19632766","type":"topic","id":"19632766","name":"学术论文"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F20039099","type":"topic","id":"20039099","name":"强化学习 (Reinforcement Learning)"}],"voteupCount":33,"voting":0,"column":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"},"commentCount":3,"contributions":[{"id":23151905,"state":"accepted","type":"first_publish","column":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}}],"isTitleImageFullScreen":false,"upvotedFollowees":[],"commercialInfo":{"isCommercial":false,"plugin":{}},"suggestEdit":{"status":false,"reason":"","tip":"","url":"","title":""},"reason":"","annotationAction":[],"canTip":false,"tipjarorsCount":0,"isLabeled":false,"hasPublishingDraft":false,"isFavorited":false,"isNormal":true,"status":0,"shareText":"【强化学习 105】RPI - 来自知乎专栏「强化学习前沿」，作者: 张楚珩 https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F109952463 （想看更多？下载 @知乎 App：http:\u002F\u002Fweibo.com\u002Fp\u002F100404711598 ）","canComment":{"status":true,"reason":""},"mcnFpShow":-1,"isVisible":true,"isLiked":false,"likedCount":1,"visibleOnlyToAuthor":false}},"columns":{"reinforcementlearning":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}},"topics":{},"roundtables":{},"favlists":{},"comments":{},"notifications":{},"ebooks":{},"activities":{},"feeds":{},"pins":{},"promotions":{},"drafts":{},"chats":{},"posts":{},"clubs":{},"clubTags":{}},"currentUser":"","account":{"lockLevel":{},"unlockTicketStatus":false,"unlockTicket":null,"challenge":[],"errorStatus":false,"message":"","isFetching":false,"accountInfo":{},"urlToken":{"loading":false}},"settings":{"socialBind":null,"inboxMsg":null,"notification":{},"email":{},"privacyFlag":null,"blockedUsers":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"blockedFollowees":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"ignoredTopics":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"restrictedTopics":null,"laboratory":{}},"notification":{},"people":{"profileStatus":{},"activitiesByUser":{},"answersByUser":{},"answersSortByVotesByUser":{},"answersIncludedByUser":{},"votedAnswersByUser":{},"thankedAnswersByUser":{},"voteAnswersByUser":{},"thankAnswersByUser":{},"topicAnswersByUser":{},"zvideosByUser":{},"articlesByUser":{},"articlesSortByVotesByUser":{},"articlesIncludedByUser":{},"pinsByUser":{},"questionsByUser":{},"commercialQuestionsByUser":{},"favlistsByUser":{},"followingByUser":{},"followersByUser":{},"mutualsByUser":{},"followingColumnsByUser":{},"followingQuestionsByUser":{},"followingFavlistsByUser":{},"followingTopicsByUser":{},"publicationsByUser":{},"columnsByUser":{},"allFavlistsByUser":{},"brands":null,"creationsByUser":{},"creationsSortByVotesByUser":{},"creationsFeed":{}},"env":{"ab":{"config":{"experiments":[{"expId":"launch-gw_mweb_rec-1","expPrefix":"gw_mweb_rec","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-qa_hdpimg-2","expPrefix":"qa_hdpimg","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-us_foltopic_user-10","expPrefix":"us_foltopic_user","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_bullet_second-2","expPrefix":"vd_bullet_second","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_zvideo_link-10","expPrefix":"vd_zvideo_link","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false}],"params":[{"id":"web_mini_review","type":"String","value":"0"},{"id":"li_ebook_gen_search","type":"String","value":"0","chainId":"_all_"},{"id":"li_assessment_show","type":"String","value":"1","chainId":"_all_"},{"id":"zw_sameq_sorce","type":"String","value":"999","chainId":"_all_"},{"id":"se_webtimebox","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"gue_thanks","type":"String","value":"0"},{"id":"se_pek_test2","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_pk","type":"String","value":"1","chainId":"_all_"},{"id":"tp_discover_copy","type":"String","value":"0","chainId":"_all_"},{"id":"soc_wonderuser_recom","type":"String","value":"2","chainId":"_all_"},{"id":"top_quality","type":"String","value":"0","chainId":"_all_"},{"id":"gue_bullet_guide","type":"String","value":"发个弹幕聊聊…"},{"id":"li_salt_hot","type":"String","value":"1","chainId":"_all_"},{"id":"web_ask","type":"String","value":"0"},{"id":"zr_ans_rec","type":"String","value":"gbrank","chainId":"_all_"},{"id":"tp_topic_style","type":"String","value":"0","chainId":"_all_"},{"id":"se_entity_model_14","type":"String","value":"0","chainId":"_all_"},{"id":"soc_authormore2","type":"String","value":"2","chainId":"_all_"},{"id":"ug_follow_answerer","type":"String","value":"0","chainId":"_all_"},{"id":"se_prf","type":"String","value":"0","chainId":"_all_"},{"id":"se_use_zitem","type":"String","value":"0","chainId":"_all_"},{"id":"gue_video_autoplay","type":"String","value":"0"},{"id":"zr_video_rank_nn","type":"String","value":"new_rank","chainId":"_all_"},{"id":"se_auto_syn","type":"String","value":"0","chainId":"_all_"},{"id":"top_root","type":"String","value":"0","chainId":"_all_"},{"id":"se_movietab","type":"String","value":"1","chainId":"_all_"},{"id":"soc_iospinweight","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_qa_pic","type":"String","value":"1","chainId":"_all_"},{"id":"soc_brdcst4","type":"String","value":"3","chainId":"_all_"},{"id":"li_qa_btn_text","type":"String","value":"0","chainId":"_all_"},{"id":"gue_goods_card","type":"String","value":"0"},{"id":"zr_km_answer","type":"String","value":"open_cvr","chainId":"_all_"},{"id":"zr_slot_training","type":"String","value":"1","chainId":"_all_"},{"id":"se_wannasearch","type":"String","value":"0","chainId":"_all_"},{"id":"soc_leave_recommend","type":"String","value":"2","chainId":"_all_"},{"id":"pf_newguide_vertical","type":"String","value":"0","chainId":"_all_"},{"id":"zr_intervene","type":"String","value":"0","chainId":"_all_"},{"id":"se_pek_test","type":"String","value":"1","chainId":"_all_"},{"id":"tp_header_style","type":"String","value":"1","chainId":"_all_"},{"id":"soc_update","type":"String","value":"1","chainId":"_all_"},{"id":"tsp_vote","type":"String","value":"2","chainId":"_all_"},{"id":"li_yxzl_new_style_a","type":"String","value":"1","chainId":"_all_"},{"id":"se_relation_1","type":"String","value":"0","chainId":"_all_"},{"id":"se_whitelist","type":"String","value":"0","chainId":"_all_"},{"id":"tp_score_1","type":"String","value":"a","chainId":"_all_"},{"id":"web_mweb_launch","type":"String","value":"0"},{"id":"se_webrs","type":"String","value":"1","chainId":"_all_"},{"id":"se_new_topic","type":"String","value":"0","chainId":"_all_"},{"id":"zr_video_recall","type":"String","value":"current_recall","chainId":"_all_"},{"id":"tp_qa_metacard","type":"String","value":"1","chainId":"_all_"},{"id":"web_answerlist_ad","type":"String","value":"0"},{"id":"se_ad_index","type":"String","value":"10","chainId":"_all_"},{"id":"se_waterfall","type":"String","value":"0","chainId":"_all_"},{"id":"li_catalog_card","type":"String","value":"1","chainId":"_all_"},{"id":"se_websearch","type":"String","value":"3","chainId":"_all_"},{"id":"zr_article_new","type":"String","value":"close","chainId":"_all_"},{"id":"se_agency","type":"String","value":" 0","chainId":"_all_"},{"id":"tp_club_tab_feed","type":"String","value":"0","chainId":"_all_"},{"id":"ug_fw_answ_aut_1","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_edu","type":"String","value":"1","chainId":"_all_"},{"id":"soc_userrec","type":"String","value":"0","chainId":"_all_"},{"id":"soc_bignew","type":"String","value":"1","chainId":"_all_"},{"id":"soc_zcfw_shipinshiti","type":"String","value":"1","chainId":"_all_"},{"id":"top_v_album","type":"String","value":"1","chainId":"_all_"},{"id":"se_hotmore","type":"String","value":"2","chainId":"_all_"},{"id":"se_specialbutton","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_4","type":"String","value":"1","chainId":"_all_"},{"id":"soc_iosreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adreadline","type":"String","value":"0","chainId":"_all_"},{"id":"zr_rec_answer_cp","type":"String","value":"close","chainId":"_all_"},{"id":"se_preset_tech","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_android_feed","type":"String","value":"old","chainId":"_all_"},{"id":"gue_zvideo_link","type":"String","value":"1"},{"id":"ls_videoad","type":"String","value":"2","chainId":"_all_"},{"id":"gue_zhuantikapian","type":"String","value":"0"},{"id":"se_featured","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_discover","type":"String","value":"0","chainId":"_all_"},{"id":"top_test_4_liguangyi","type":"String","value":"1","chainId":"_all_"},{"id":"li_se_heat","type":"String","value":"1","chainId":"_all_"},{"id":"se_ios_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"se_aa_base","type":"String","value":"0","chainId":"_all_"},{"id":"tp_discovery_ab_1","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zuichangfangwen","type":"String","value":"0","chainId":"_all_"},{"id":"ug_zero_follow","type":"String","value":"0","chainId":"_all_"},{"id":"qap_question_visitor","type":"String","value":" 0","chainId":"_all_"},{"id":"se_amovietab","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_feed","type":"String","value":"1","chainId":"_all_"},{"id":"soc_zcfw_badcase","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zcfw_broadcast2","type":"String","value":"1","chainId":"_all_"},{"id":"web_creator_route","type":"String","value":"1"},{"id":"zr_slot_cold_start","type":"String","value":"aver","chainId":"_all_"},{"id":"se_entity_model","type":"String","value":"0","chainId":"_all_"},{"id":"se_mobileweb","type":"String","value":"1","chainId":"_all_"},{"id":"soc_adsort","type":"String","value":"0","chainId":"_all_"},{"id":"li_android_vip","type":"String","value":"0","chainId":"_all_"},{"id":"se_hotsearch_2","type":"String","value":"1","chainId":"_all_"},{"id":"se_colorfultab","type":"String","value":"1","chainId":"_all_"},{"id":"se_article_icon","type":"String","value":"0","chainId":"_all_"},{"id":"se_ltr_video","type":"String","value":"0","chainId":"_all_"},{"id":"li_answers_link","type":"String","value":"0","chainId":"_all_"},{"id":"se_ffzx_jushen1","type":"String","value":"0","chainId":"_all_"},{"id":"se_adxtest","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_tab","type":"String","value":"0","chainId":"_all_"},{"id":"web_collect","type":"String","value":"0"},{"id":"se_preset_label","type":"String","value":"1","chainId":"_all_"},{"id":"top_universalebook","type":"String","value":"1","chainId":"_all_"},{"id":"top_new_feed","type":"String","value":"5","chainId":"_all_"},{"id":"ug_follow_topic_1","type":"String","value":"2","chainId":"_all_"},{"id":"se_click_club","type":"String","value":"1","chainId":"_all_"},{"id":"se_rf_w","type":"String","value":"0","chainId":"_all_"},{"id":"se_page_quality","type":"String","value":"0","chainId":"_all_"},{"id":"se_site_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_famous","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_pic_swiper","type":"String","value":"1","chainId":"_all_"},{"id":"tp_discover","type":"String","value":"0","chainId":"_all_"},{"id":"ug_newtag","type":"String","value":"0","chainId":"_all_"},{"id":"gue_bullet_second","type":"String","value":"1"},{"id":"li_ebok_chap","type":"String","value":"0","chainId":"_all_"},{"id":"web_question_invite","type":"String","value":"B"},{"id":"top_hotcommerce","type":"String","value":"1","chainId":"_all_"},{"id":"web_n_web_msg","type":"String","value":"0"},{"id":"web_ad_banner","type":"String","value":"0"},{"id":"web_mweb_rec_length","type":"String","value":"1"},{"id":"se_college_cm","type":"String","value":"0","chainId":"_all_"},{"id":"gue_card_test","type":"String","value":"1"},{"id":"li_hot_voted","type":"String","value":"0","chainId":"_all_"},{"id":"zr_rel_search","type":"String","value":"base","chainId":"_all_"},{"id":"se_subtext","type":"String","value":"0","chainId":"_all_"},{"id":"web_sem_ab","type":"String","value":"1"},{"id":"zr_test_aa1","type":"String","value":"0","chainId":"_all_"},{"id":"se_cbert_index","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iossort","type":"String","value":"0","chainId":"_all_"},{"id":"pf_fuceng","type":"String","value":"1","chainId":"_all_"},{"id":"pf_foltopic_usernum","type":"String","value":"50","chainId":"_all_"},{"id":"li_purchase_test","type":"String","value":"0","chainId":"_all_"},{"id":"web_hdpimg","type":"String","value":"1"},{"id":"zr_slotpaidexp","type":"String","value":"1","chainId":"_all_"},{"id":"se_likebutton","type":"String","value":"0","chainId":"_all_"},{"id":"se_time_threshold","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_head","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iosreadline","type":"String","value":"0","chainId":"_all_"},{"id":"se_dnn_mt_v2","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zcfw_broadcast","type":"String","value":"0","chainId":"_all_"},{"id":"ug_follow_answerer_0","type":"String","value":"0","chainId":"_all_"},{"id":"li_education_box","type":"String","value":"0","chainId":"_all_"},{"id":"gue_self_censoring","type":"String","value":"1"},{"id":"se_webmajorob","type":"String","value":"0","chainId":"_all_"},{"id":"se_sug_term","type":"String","value":"0","chainId":"_all_"},{"id":"li_answer_card","type":"String","value":"0","chainId":"_all_"},{"id":"tp_meta_card","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sft_v2","type":"String","value":"d","chainId":"_all_"},{"id":"zr_art_rec","type":"String","value":"base","chainId":"_all_"},{"id":"tsp_hotlist_ui","type":"String","value":"1","chainId":"_all_"},{"id":"li_answer_label","type":"String","value":"0","chainId":"_all_"},{"id":"li_video_section","type":"String","value":"0","chainId":"_all_"},{"id":"qap_ques_invite","type":"String","value":"0","chainId":"_all_"},{"id":"zr_answer_rec_cp","type":"String","value":"open","chainId":"_all_"},{"id":"se_hotsearch","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adpinweight","type":"String","value":"0","chainId":"_all_"},{"id":"soc_authormore","type":"String","value":"2","chainId":"_all_"},{"id":"zr_video_rank","type":"String","value":"new_rank","chainId":"_all_"},{"id":"se_expired_ob","type":"String","value":"0","chainId":"_all_"},{"id":"se_col_boost","type":"String","value":"0","chainId":"_all_"},{"id":"se_p_slideshow","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_pic","type":"String","value":"0.6","chainId":"_all_"},{"id":"li_pay_banner_type","type":"String","value":"6","chainId":"_all_"},{"id":"se_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"se_pek_test3","type":"String","value":"1","chainId":"_all_"},{"id":"se_college","type":"String","value":"default","chainId":"_all_"},{"id":"tp_qa_toast","type":"String","value":"1","chainId":"_all_"},{"id":"top_ydyq","type":"String","value":"X","chainId":"_all_"},{"id":"web_answer_update","type":"String","value":"0"},{"id":"web_upload","type":"String","value":"1"},{"id":"li_paid_answer_exp","type":"String","value":"0","chainId":"_all_"},{"id":"qap_article_like","type":"String","value":"1","chainId":"_all_"},{"id":"se_topiclabel","type":"String","value":"1","chainId":"_all_"},{"id":"se_backsearch","type":"String","value":"0","chainId":"_all_"},{"id":"se_multianswer","type":"String","value":"2","chainId":"_all_"},{"id":"ug_goodcomment_0","type":"String","value":"1","chainId":"_all_"},{"id":"li_se_media_icon","type":"String","value":"1","chainId":"_all_"},{"id":"zw_payc_qaedit","type":"String","value":"0","chainId":"_all_"},{"id":"se_billboardsearch","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_tab_new","type":"String","value":"0-0-0","chainId":"_all_"},{"id":"soc_feed_intimacy","type":"String","value":"2","chainId":"_all_"},{"id":"li_se_section","type":"String","value":"0","chainId":"_all_"},{"id":"gue_new_special_page","type":"String","value":"1"},{"id":"zr_km_feed_nlp","type":"String","value":"old","chainId":"_all_"},{"id":"se_payconsult","type":"String","value":"0","chainId":"_all_"},{"id":"ls_fmp4","type":"String","value":"0","chainId":"_all_"},{"id":"soc_brdcst3","type":"String","value":"0","chainId":"_all_"},{"id":"se_hotsearch_num","type":"String","value":"0","chainId":"_all_"},{"id":"se_search_feed","type":"String","value":"N","chainId":"_all_"},{"id":"se_aa","type":"String","value":"0","chainId":"_all_"},{"id":"se_sug","type":"String","value":"1","chainId":"_all_"},{"id":"se_highlight","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_header","type":"String","value":"1","chainId":"_all_"},{"id":"tp_m_intro_re_topic","type":"String","value":"1","chainId":"_all_"},{"id":"ls_recommend_test","type":"String","value":"0","chainId":"_all_"},{"id":"li_vip_verti_search","type":"String","value":"0","chainId":"_all_"},{"id":"se_hot_timebox","type":"String","value":"0","chainId":"_all_"},{"id":"soc_ri_merge","type":"String","value":"0","chainId":"_all_"},{"id":"ug_zero_follow_0","type":"String","value":"0","chainId":"_all_"},{"id":"li_qa_new_cover","type":"String","value":"1","chainId":"_all_"},{"id":"se_timebox_up","type":"String","value":"0","chainId":"_all_"},{"id":"soc_notification","type":"String","value":"0","chainId":"_all_"},{"id":"zr_update_merge_size","type":"String","value":"1","chainId":"_all_"},{"id":"zr_training_first","type":"String","value":"false","chainId":"_all_"},{"id":"se_new_p","type":"String","value":"0","chainId":"_all_"},{"id":"qap_payc_invite","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_join","type":"String","value":"0","chainId":"_all_"},{"id":"web_heifetz_grow_ad","type":"String","value":"1"},{"id":"li_sku_bottom_bar_re","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_2","type":"String","value":"1","chainId":"_all_"},{"id":"se_new_merger","type":"String","value":"1","chainId":"_all_"},{"id":"se_presearch_ab","type":"String","value":"0","chainId":"_all_"},{"id":"zr_expslotpaid","type":"String","value":"1","chainId":"_all_"},{"id":"se_related_index","type":"String","value":"3","chainId":"_all_"},{"id":"se_zu_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sft","type":"String","value":"a","chainId":"_all_"},{"id":"tp_topic_entry","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_tab","type":"String","value":"0","chainId":"_all_"},{"id":"pf_noti_entry_num","type":"String","value":"0","chainId":"_all_"},{"id":"qap_thanks","type":"String","value":"1","chainId":"_all_"},{"id":"web_column_auto_invite","type":"String","value":"0"},{"id":"se_cardrank_1","type":"String","value":"0","chainId":"_all_"},{"id":"soc_stickypush","type":"String","value":"1","chainId":"_all_"},{"id":"soc_cardheight","type":"String","value":"2","chainId":"_all_"},{"id":"tsp_videobillboard","type":"String","value":"1","chainId":"_all_"},{"id":"pf_creator_card","type":"String","value":"1","chainId":"_all_"},{"id":"li_ebook_read","type":"String","value":"0","chainId":"_all_"},{"id":"li_svip_tab_search","type":"String","value":"0","chainId":"_all_"},{"id":"soc_yxzl_zcfw","type":"String","value":"0","chainId":"_all_"},{"id":"top_ebook","type":"String","value":"0","chainId":"_all_"},{"id":"sem_up_growth","type":"String","value":"in_app","chainId":"_all_"},{"id":"zr_search_sim","type":"String","value":"0","chainId":"_all_"},{"id":"web_audit_01","type":"String","value":"case1"},{"id":"soc_iosintimacy","type":"String","value":"2","chainId":"_all_"},{"id":"li_svip_cardshow","type":"String","value":"1","chainId":"_all_"},{"id":"web_unfriendly_comm","type":"String","value":"0"},{"id":"se_zu_recommend","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_qa","type":"String","value":"1","chainId":"_all_"},{"id":"se_cate_l3","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_3","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_android_join","type":"String","value":"1","chainId":"_all_"},{"id":"qap_question_author","type":"String","value":"0","chainId":"_all_"},{"id":"web_answer_list_ad","type":"String","value":"1"},{"id":"pf_adjust","type":"String","value":"0","chainId":"_all_"},{"id":"gue_video_replay","type":"String","value":"0"},{"id":"web_sec672","type":"String","value":"0"},{"id":"se_topicfeed","type":"String","value":"0","chainId":"_all_"},{"id":"tp_qa_metacard_top","type":"String","value":"top","chainId":"_all_"},{"id":"zr_training_boost","type":"String","value":"false","chainId":"_all_"},{"id":"se_relationship","type":"String","value":"1","chainId":"_all_"},{"id":"se_content0","type":"String","value":"0","chainId":"_all_"},{"id":"soc_newfeed","type":"String","value":"2","chainId":"_all_"},{"id":"soc_bigone","type":"String","value":"0","chainId":"_all_"},{"id":"se_sug_entrance","type":"String","value":"1","chainId":"_all_"},{"id":"li_se_across","type":"String","value":"1","chainId":"_all_"},{"id":"tp_topic_rec","type":"String","value":"1","chainId":"_all_"},{"id":"se_ctx_rerank","type":"String","value":"1","chainId":"_all_"},{"id":"se_searchwiki","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sticky_android","type":"String","value":"2","chainId":"_all_"},{"id":"zr_search_paid","type":"String","value":"0","chainId":"_all_"},{"id":"se_club_post","type":"String","value":"5","chainId":"_all_"},{"id":"se_lottery","type":"String","value":"0","chainId":"_all_"},{"id":"soc_special","type":"String","value":"0","chainId":"_all_"}],"chains":[{"chainId":"_all_"}]},"triggers":{}},"userAgent":{"Edge":false,"Wechat":false,"Weibo":false,"QQ":false,"MQQBrowser":false,"Qzone":false,"Mobile":false,"Android":false,"iOS":false,"isAppleDevice":false,"Zhihu":false,"ZhihuHybrid":false,"isBot":false,"Tablet":false,"UC":false,"Sogou":false,"Qihoo":false,"Baidu":false,"BaiduApp":false,"Safari":false,"GoogleBot":false,"AndroidDaily":false,"iOSDaily":false,"isWebView":false,"origin":"Mozilla\u002F5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\u002F537.36 (KHTML, like Gecko) Chrome\u002F80.0.3987.100 Safari\u002F537.36"},"appViewConfig":{},"ctx":{"path":"\u002Fp\u002F109952463","query":{},"href":"http:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F109952463","host":"zhuanlan.zhihu.com"},"trafficSource":"production","edition":{"baidu":false,"sogou":false,"baiduBeijing":false,"sogouBeijing":false,"sogouInput":false},"theme":"light","enableShortcut":true,"referer":"","conf":{},"ipInfo":{"cityName":"德州","countryName":"中国","regionName":"山东","countryCode":"CN"},"logged":false},"me":{"columnContributions":[]},"label":{"recognizerLists":{}},"ecommerce":{},"comments":{"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"parent":{}},"commentsV2":{"stickers":[],"commentWithPicPermission":{},"notificationsComments":{},"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"conversationMore":{},"parent":{}},"pushNotifications":{"default":{"isFetching":false,"isDrained":false,"ids":[]},"follow":{"isFetching":false,"isDrained":false,"ids":[]},"vote_thank":{"isFetching":false,"isDrained":false,"ids":[]},"currentTab":"default","notificationsCount":{"default":0,"follow":0,"vote_thank":0}},"messages":{"data":{},"currentTab":"common","messageCount":0},"register":{"registerValidateSucceeded":null,"registerValidateErrors":{},"registerConfirmError":null,"sendDigitsError":null,"registerConfirmSucceeded":null},"login":{"loginUnregisteredError":false,"loginBindWechatError":false,"loginConfirmError":null,"sendDigitsError":null,"needSMSIdentify":false,"validateDigitsError":false,"loginConfirmSucceeded":null,"qrcodeLoginToken":"","qrcodeLoginScanStatus":0,"qrcodeLoginError":null,"qrcodeLoginReturnNewToken":false},"active":{"sendDigitsError":null,"activeConfirmSucceeded":null,"activeConfirmError":null},"switches":{},"captcha":{"captchaNeeded":false,"captchaValidated":false,"captchaBase64String":null,"captchaValidationMessage":null,"loginCaptchaExpires":false},"sms":{"supportedCountries":[]},"chat":{"chats":{},"inbox":{"recents":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"strangers":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"friends":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"search":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"config":{"newCount":0,"strangerMessageSwitch":false,"strangerMessageUnread":false,"friendCount":0}},"global":{"isChatMqttExisted":false}},"emoticons":{"emoticonGroupList":[],"emoticonGroupDetail":{}},"creator":{"currentCreatorUrlToken":null,"homeData":{"recommendQuestions":[]},"tools":{"question":{"invitationCount":{"questionFolloweeCount":0,"questionTotalCount":0},"goodatTopics":[]},"customPromotion":{"itemLists":{}},"recommend":{"recommendTimes":{}}},"explore":{"academy":{"tabs":[],"article":{}}},"rights":[],"rightsStatus":{},"levelUpperLimit":10,"account":{"growthLevel":{}},"mcn":{},"applyStatus":{}},"recommendation":{"homeRecommendations":[]},"shareTexts":{},"articles":{"voters":{}},"previewPost":{},"favlists":{"relations":{}},"columns":{"voters":{}},"reward":{"answer":{},"article":{},"question":{}},"video":{"data":{},"shareVideoDetail":{},"last":{}},"topstory":{"recommend":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"follow":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followWonderful":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"sidebar":null,"announcement":{},"hotListCategories":[],"hotList":[],"guestFeeds":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followExtra":{"isNewUser":null,"isFetched":false,"followCount":0,"followers":[]}},"readStatus":{},"column":{},"requestColumn":{"categories":[],"error":null},"articleContribution":{"contributeRequests":[],"deleteContributeIdList":[],"handledContributeIdList":[],"recommendedColumns":[],"pinnedColumns":[],"sentContributeRequestsIdList":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"reinforcementlearning"]},"columnContribution":{"contributeRequests":[],"autoInviteEnabled":false,"recommendedContributors":[],"contributionInvitation":null},"draftHistory":{"history":{},"drafts":{}},"upload":{},"articleDraft":{"titleImage":"","titleImageSize":{},"isTitleImageFullScreen":false,"canTitleImageFullScreen":false,"title":"","titleImageUploading":false,"error":"","content":"","draftLoading":false,"updating":false,"globalLoading":false,"pendingVideo":{"resource":null,"error":null},"deleteFail":{"fail":false},"recommendTopics":[],"selectedColumn":0,"articleDisclaimers":[]},"articleDrafts":{"isDrained":false,"isLoading":false,"items":[]},"columnAutocomplete":{"users":[],"friends":[]},"columnCollection":{},"mcn":{"bindInfo":{},"memberCategoryList":[],"producerList":[],"categoryList":[]}},"fetchHost":"www.zhihu.com","subAppName":"column"}</script><script src="https://static.zhihu.com/heifetz/vendor.7b36fae46082fd30a0db.js"></script><script src="https://static.zhihu.com/heifetz/column.app.76e02b16e87eec249f44.js"></script></body><script src="https://hm.baidu.com/hm.js?98beee57fd2ef70ccdd5ca52b9740c49" async=""></script><script src="https://zz.bdstatic.com/linksubmit/push.js" async=""></script></html>