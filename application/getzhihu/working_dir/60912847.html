<!doctype html>
<html lang="zh" data-hairline="true" data-theme="light"><head><meta charSet="utf-8"/><title data-react-helmet="true">【强化学习 48】Quantile Regression - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"/><meta name="renderer" content="webkit"/><meta name="force-rendering" content="webkit"/><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg"/><meta data-react-helmet="true" name="keywords" content="强化学习 (Reinforcement Learning)"/><meta data-react-helmet="true" name="description" content="紧接着前面Distributional RL做的工作原文传送门Dabney, Will, et al. &amp;#34;Distributional reinforcement learning with quantile regression.&amp;#34; Thirty-Second AAAI Conference on Artificial Intelligence. …"/><meta data-react-helmet="true" property="og:title" content="【强化学习 48】Quantile Regression"/><meta data-react-helmet="true" property="og:url" content="https://zhuanlan.zhihu.com/p/60912847"/><meta data-react-helmet="true" property="og:description" content="紧接着前面Distributional RL做的工作原文传送门Dabney, Will, et al. &amp;#34;Distributional reinforcement learning with quantile regression.&amp;#34; Thirty-Second AAAI Conference on Artificial Intelligence. …"/><meta data-react-helmet="true" property="og:image" content="https://pic1.zhimg.com/v2-1e5724a64f5e29e7bb032f3bc393b614_b.jpg"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" property="og:site_name" content="知乎专栏"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png" sizes="152x152"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-120.b3e6278d.png" sizes="120x120"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-76.7a750095.png" sizes="76x76"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-60.a4a761d4.png" sizes="60x60"/><link rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/static/favicon.ico"/><link rel="search" type="application/opensearchdescription+xml" href="https://static.zhihu.com/static/search.xml" title="知乎"/><link rel="dns-prefetch" href="//static.zhimg.com"/><link rel="dns-prefetch" href="//pic1.zhimg.com"/><link rel="dns-prefetch" href="//pic2.zhimg.com"/><link rel="dns-prefetch" href="//pic3.zhimg.com"/><link rel="dns-prefetch" href="//pic4.zhimg.com"/><style>
.u-safeAreaInset-top {
  height: constant(safe-area-inset-top) !important;
  height: env(safe-area-inset-top) !important;
  
}
.u-safeAreaInset-bottom {
  height: constant(safe-area-inset-bottom) !important;
  height: env(safe-area-inset-bottom) !important;
  
}
</style><link href="https://static.zhihu.com/heifetz/column.app.a9ced452148fee3a55c8.css" rel="stylesheet"/><script defer="" crossorigin="anonymous" src="https://unpkg.zhimg.com/@cfe/sentry-script@latest/dist/init.js" data-sentry-config="{&quot;dsn&quot;:&quot;https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224&quot;,&quot;sampleRate&quot;:0.1,&quot;release&quot;:&quot;683-127b14ad&quot;,&quot;ignoreErrorNames&quot;:[&quot;NetworkError&quot;,&quot;SecurityError&quot;],&quot;ignoreErrors&quot;:[&quot;origin message&quot;,&quot;Network request failed&quot;,&quot;Loading chunk&quot;,&quot;这个系统不支持该功能。&quot;,&quot;Can&#x27;t find variable: webkit&quot;,&quot;Can&#x27;t find variable: $&quot;,&quot;内存不足&quot;,&quot;out of memory&quot;,&quot;DOM Exception 18&quot;,&quot;The operation is insecure&quot;,&quot;[object Event]&quot;,&quot;[object FileError]&quot;,&quot;[object DOMError]&quot;,&quot;[object Object]&quot;,&quot;拒绝访问。&quot;,&quot;Maximum call stack size exceeded&quot;,&quot;UploadError&quot;,&quot;无法 fetch&quot;,&quot;draft-js&quot;,&quot;缺少 JavaScript 对象&quot;,&quot;componentWillEnter&quot;,&quot;componentWillLeave&quot;,&quot;componentWillAppear&quot;,&quot;getInlineStyleAt&quot;,&quot;getCharacterList&quot;],&quot;whitelistUrls&quot;:[&quot;static.zhihu.com&quot;]}"></script></head><body class="WhiteBg-body"><div id="root"><div class="App"><div class="LoadingBar"></div><main role="main" class="App-main"><div class="Post-content" data-zop-usertoken="{&quot;userToken&quot;:&quot;&quot;}" data-zop="{&quot;authorName&quot;:&quot;张楚珩&quot;,&quot;itemId&quot;:60912847,&quot;title&quot;:&quot;【强化学习 48】Quantile Regression&quot;,&quot;type&quot;:&quot;article&quot;}"><div class="ColumnPageHeader-Wrapper"><div><div class="Sticky ColumnPageHeader"><div class="ColumnPageHeader-content"><a href="//www.zhihu.com" aria-label="知乎"><svg viewBox="0 0 200 91" fill="#0084FF" width="64" height="30"><path d="M53.29 80.035l7.32.002 2.41 8.24 13.128-8.24h15.477v-67.98H53.29v67.978zm7.79-60.598h22.756v53.22h-8.73l-8.718 5.473-1.587-5.46-3.72-.012v-53.22zM46.818 43.162h-16.35c.545-8.467.687-16.12.687-22.955h15.987s.615-7.05-2.68-6.97H16.807c1.09-4.1 2.46-8.332 4.1-12.708 0 0-7.523 0-10.085 6.74-1.06 2.78-4.128 13.48-9.592 24.41 1.84-.2 7.927-.37 11.512-6.94.66-1.84.785-2.08 1.605-4.54h9.02c0 3.28-.374 20.9-.526 22.95H6.51c-3.67 0-4.863 7.38-4.863 7.38H22.14C20.765 66.11 13.385 79.24 0 89.62c6.403 1.828 12.784-.29 15.937-3.094 0 0 7.182-6.53 11.12-21.64L43.92 85.18s2.473-8.402-.388-12.496c-2.37-2.788-8.768-10.33-11.496-13.064l-4.57 3.627c1.363-4.368 2.183-8.61 2.46-12.71H49.19s-.027-7.38-2.372-7.38zm128.752-.502c6.51-8.013 14.054-18.302 14.054-18.302s-5.827-4.625-8.556-1.27c-1.874 2.548-11.51 15.063-11.51 15.063l6.012 4.51zm-46.903-18.462c-2.814-2.577-8.096.667-8.096.667s12.35 17.2 12.85 17.953l6.08-4.29s-8.02-11.752-10.83-14.33zM199.99 46.5c-6.18 0-40.908.292-40.953.292v-31.56c1.503 0 3.882-.124 7.14-.376 12.773-.753 21.914-1.25 27.427-1.504 0 0 3.817-8.496-.185-10.45-.96-.37-7.24 1.43-7.24 1.43s-51.63 5.153-72.61 5.64c.5 2.756 2.38 5.336 4.93 6.11 4.16 1.087 7.09.53 15.36.277 7.76-.5 13.65-.76 17.66-.76v31.19h-41.71s.88 6.97 7.97 7.14h33.73v22.16c0 4.364-3.498 6.87-7.65 6.6-4.4.034-8.15-.36-13.027-.566.623 1.24 1.977 4.496 6.035 6.824 3.087 1.502 5.054 2.053 8.13 2.053 9.237 0 14.27-5.4 14.027-14.16V53.93h38.235c3.026 0 2.72-7.432 2.72-7.432z" fill-rule="evenodd"></path></svg></a><i class="ColumnPageHeader-Line"></i><div class="ColumnPageHeader-Title"><a class="ColumnLink ColumnPageHeader-Link" href="/reinforcementlearning"><img class="Avatar Avatar--round" width="30" height="30" src="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_is.jpg" srcSet="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_im.jpg 2x" alt="强化学习前沿"/></a><div class="ColumnPageHeader-TitleName"><span class="ColumnPageHeader-TitleMeta">首发于</span><a class="ColumnLink ColumnPageHeader-TitleColumn" href="/reinforcementlearning">强化学习前沿</a></div></div><div class="ColumnPageHeader-Button"><button type="button" class="Button ColumnPageHeader-WriteButton Button--blue"><svg class="Zi Zi--EditSurround" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M18.453 7.992l-1.833-1.65.964-.978a1.223 1.223 0 0 1 1.73-.012l.005.006a1.24 1.24 0 0 1 .007 1.748l-.873.886zm-1.178 1.194l-5.578 5.66-1.935.697a.393.393 0 0 1-.504-.504l.697-1.935 5.488-5.567 1.832 1.65zM7.58 5.848l5.654.006-1.539 1.991-3.666.012A1.02 1.02 0 0 0 7 8.868v7.993c0 .558.46 1.01 1.029 1.01l7.941-.01c.568 0 1.03-.453 1.03-1.012v-4.061l2-1.442v6.002c0 1.397-1.2 2.501-2.62 2.501H7.574C6.153 19.85 5 18.717 5 17.32V8.35c0-1.397 1.16-2.502 2.58-2.502z"></path></svg>写文章</button></div></div></div></div></div><img class="TitleImage" src="https://pic1.zhimg.com/v2-1e5724a64f5e29e7bb032f3bc393b614_1200x500.jpg" alt="【强化学习 48】Quantile Regression"/><article class="Post-Main Post-NormalMain" tabindex="-1"><header class="Post-Header"><h1 class="Post-Title">【强化学习 48】Quantile Regression</h1><div class="Post-Author"><div class="AuthorInfo" itemProp="author" itemscope="" itemType="http://schema.org/Person"><meta itemProp="name" content="张楚珩"/><meta itemProp="image" content="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg"/><meta itemProp="url" content="https://www.zhihu.com/people/zhang-chu-heng"/><meta itemProp="zhihu:followerCount"/><span class="UserLink AuthorInfo-avatarWrapper"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/zhang-chu-heng"><img class="Avatar Avatar--round AuthorInfo-avatar" width="38" height="38" src="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_xs.jpg" srcSet="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg 2x" alt="张楚珩"/></a></div></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/zhang-chu-heng">张楚珩</a></div></div><style data-emotion-css="1cd9gw4">.css-1cd9gw4{margin-left:.3em;}</style><style data-emotion-css="1pc1mic">.css-1pc1mic{box-sizing:border-box;margin:0;min-width:0;color:#175199;display:inline-block;width:18px;height:18px;margin-left:.3em;}</style><a href="https://www.zhihu.com/question/48510028" target="_blank" class="css-1pc1mic" data-tooltip="已认证的个人" aria-label="已认证的个人"><style data-emotion-css="18biwo">.css-18biwo{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><span class="css-18biwo">​<svg viewBox="0 0 24 24" width="18" height="18"><svg viewBox="0 0 24 24" x="-3" y="-3" fill="#FFFFFF" width="30" height="30"><path d="M3.56231227,13.8535307 C2.40051305,12.768677 2.41398885,11.0669203 3.59484487,9.99979213 L3.59222085,9.99654885 C4.26730143,9.45036719 4.79446755,8.21005186 4.7184197,7.34453784 L4.72305873,7.34412719 C4.66942824,5.75539997 5.8824188,4.56066914 7.47188965,4.64242381 L7.47229112,4.6386236 C8.33515314,4.72977993 9.58467253,4.22534048 10.1426329,3.55925173 L10.1462611,3.56228565 C11.2316055,2.40008701 12.9353108,2.41394456 14.0015072,3.59634088 L14.0047263,3.59374004 C14.5498229,4.26841874 15.7896857,4.79521622 16.6545744,4.71844347 L16.6549836,4.72304294 C18.245027,4.66894057 19.4396947,5.88213996 19.3575031,7.47241135 L19.3623099,7.47292747 C19.2704388,8.3358681 19.7742711,9.58421483 20.4407199,10.1424506 L20.437686,10.1460789 C21.5997217,11.2312209 21.5860695,12.9345218 20.4042441,14.0007396 L20.4072865,14.0045125 C19.7325967,14.5495925 19.2055209,15.7896954 19.2815865,16.6561959 L19.2770449,16.6565978 C19.3315454,18.2453037 18.1173775,19.4393568 16.5274188,19.3571512 L16.5269029,19.3619539 C15.6647098,19.270083 14.415408,19.7741709 13.8573671,20.4403558 L13.8537409,20.4373235 C12.76842,21.5995708 11.0650432,21.5864553 9.99899434,20.4039226 L9.99527367,20.406923 C9.45025436,19.7323399 8.21017638,19.2051872 7.34461983,19.2812352 L7.344304,19.2776405 C5.75448683,19.3312904 4.55977145,18.1170085 4.64254978,16.527117 L4.63769921,16.5265942 C4.72957031,15.6644394 4.22547659,14.4151814 3.55928015,13.8571569 L3.56231227,13.8535307 Z"></path></svg><path d="M2.63951518,13.3895441 C3.70763333,14.2842292 4.44777637,16.1226061 4.30075305,17.5023312 L4.32211542,17.3063047 C4.17509209,18.6910561 5.17786655,19.7063729 6.5613937,19.5844846 L6.364106,19.6008202 C7.75140298,19.4789319 9.57474349,20.2554985 10.4468305,21.3349009 L10.3224262,21.1803415 C11.1982831,22.2647703 12.6257916,22.2723098 13.5167278,21.2079863 L13.3898102,21.3600325 C14.2845162,20.2919393 16.1229361,19.5518136 17.5026934,19.6988334 L17.3054057,19.6774716 C18.6914461,19.8244915 19.7067866,18.8217404 19.5836389,17.4395022 L19.6012314,17.6367853 C19.4793403,16.2482641 20.255925,14.4249662 21.3353526,13.5528995 L21.1807897,13.677301 C22.2639871,12.8014646 22.2727834,11.3739894 21.2084351,10.483074 L21.3604848,10.6099886 C20.2923667,9.71530351 19.5522236,7.87818322 19.6992469,6.49720154 L19.6778846,6.69448464 C19.8249079,5.30847665 18.8221335,4.2944164 17.4386063,4.41630468 L17.635894,4.39871256 C16.248597,4.52185742 14.4252565,3.74529084 13.5531695,2.66588842 L13.6775738,2.81919121 C12.8017169,1.73601905 11.3742084,1.72722299 10.4832722,2.79154644 L10.6101898,2.63950024 C9.71548377,3.70759343 7.87706394,4.44771919 6.49730661,4.30195588 L6.69459432,4.32206116 C5.30855394,4.17504128 4.29447,5.17904888 4.41636114,6.56128713 L4.3987686,6.36400404 C4.52065973,7.75126861 3.74407501,9.57456653 2.66464737,10.4478898 L2.81921035,10.3222318 C1.73601288,11.1993248 1.72721662,12.6255433 2.79156494,13.5164587 L2.63951518,13.3895441 Z" fill="#0084FF"></path><svg class="Zi Zi--Check" fill="#fff" x="6" y="6" viewBox="0 0 24 24" width="12" height="12"><path d="M10.229 17.516c-.318.327-.75.484-1.199.484-.453 0-.884-.16-1.202-.488l-4.335-4.47a1.77 1.77 0 0 1 .007-2.459 1.663 1.663 0 0 1 2.397.01l3.137 3.246 9.072-9.329a1.662 1.662 0 0 1 2.397 0c.663.681.663 1.786 0 2.466L10.23 17.516z" fill-rule="evenodd"></path></svg></svg></span></a></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="AuthorInfo-badgeText">清华大学 交叉信息院博士在读</div></div></div></div></div></div><div><span class="Voters"><button type="button" class="Button Button--plain">16 人<!-- -->赞同了该文章</button></span></div></header><div class="Post-RichTextContainer"><div class="RichText ztext Post-RichText"><p>紧接着前面Distributional RL做的工作</p><h2><b>原文传送门</b></h2><p><a href="https://link.zhihu.com/?target=https%3A//www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPDFInterstitial/17184/16590" class=" wrap external" target="_blank" rel="nofollow noreferrer">Dabney, Will, et al. &#34;Distributional reinforcement learning with quantile regression.&#34; Thirty-Second AAAI Conference on Artificial Intelligence. 2018.</a></p><h2><b>特色</b></h2><p>专栏前一篇讲了distributional RL，使用价值函数分布而不仅是价值函数期望值来做强化学习，之前文章对于分布的近似方式是把概率密度函数用格子来近似（categorical representation），这里使用了更加有效的近似方式（quantile representation），同时理论上也更有保证。</p><h2><b>过程</b></h2><h3><b>1. 为什么要使用quantile representation？</b></h3><p>这里主要研究的问题是价值函数的分布应该如何来表示。</p><p><b><i>理论上</i></b>，任何的实际的表示方式都不能完全准确表示一个任意概率分布，因此任何概率分布的表示方式都可以看做真实分布向所能表示的空间上投影（基于从真实概率分布中采集样本集）。理论上关心两件事情。第一件事情，在policy evaluation下Bellman算子多轮迭代后能够收敛，但是它联合与表示有关的投影算子后（即 <img src="https://www.zhihu.com/equation?tex=%5CPi+%5C++%5Cmathcal%7BT%7D%5E%5Cpi" alt="\Pi \  \mathcal{T}^\pi" eeimg="1"/> ）是否还能在Wasserstein距离度量下收敛呢；第二件事情，考虑采样之后，其实是在缩小所表示的概率分布和样本集所代表分布之间的距离，当所表示的概率分布和样本集上距离最小的时候，它是否也和真实分布距离最小。</p><p>categorical representation在这里提到的两件事情上都不能保证（但可以证明在Cramer距离度量下 <img src="https://www.zhihu.com/equation?tex=%5CPi_%7B%5Cmathcal%7BC%7D%7D+%5C++%5Cmathcal%7BT%7D%5E%5Cpi" alt="\Pi_{\mathcal{C}} \  \mathcal{T}^\pi" eeimg="1"/> 是contraction[1]）；而quantile representation在第一件事情上能保证收敛，即能够证明 <img src="https://www.zhihu.com/equation?tex=%5CPi+%5C++%5Cmathcal%7BT%7D%5E%5Cpi" alt="\Pi \  \mathcal{T}^\pi" eeimg="1"/> 算子是Wasserstein距离下的contraction。</p><p><b><i>实际操作上</i></b>，categorical representation需要实现确定价值函数值所在的区间 <img src="https://www.zhihu.com/equation?tex=%5BV_%5Cmin%2C+V_%5Cmax%5D" alt="[V_\min, V_\max]" eeimg="1"/> ，这引入了超参数；同时，对于某些状态价值函数分布范围相对于 <img src="https://www.zhihu.com/equation?tex=%5BV_%5Cmin%2C+V_%5Cmax%5D" alt="[V_\min, V_\max]" eeimg="1"/> 很小的情况下，近似非常不准确。而quantile representation就不存在此问题。</p><h3><b>2. Quantile Representation</b></h3><p>考虑一个分布的CDF（如下图），categorical representation相当于在横轴上均匀分出若干格子，然后表示每个各自里面CDF增大的量；而quantile representation相当于在纵轴上划分出若干个各自，然后表示每个各自中对应的价值函数值是多少。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-1724ba5d5df778faf657dbd9c8f9bc6e_b.jpg" data-caption="" data-size="normal" data-rawwidth="757" data-rawheight="566" class="origin_image zh-lightbox-thumb" width="757" data-original="https://pic3.zhimg.com/v2-1724ba5d5df778faf657dbd9c8f9bc6e_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;757&#39; height=&#39;566&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="757" data-rawheight="566" class="origin_image zh-lightbox-thumb lazy" width="757" data-original="https://pic3.zhimg.com/v2-1724ba5d5df778faf657dbd9c8f9bc6e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-1724ba5d5df778faf657dbd9c8f9bc6e_b.jpg"/></figure><p>考虑 <img src="https://www.zhihu.com/equation?tex=%5Ctau_i%3Di%2FN%2C+i%5Cin%5BN%5D%5Cquad+%5Ctau_0+%3D+0" alt="\tau_i=i/N, i\in[N]\quad \tau_0 = 0" eeimg="1"/> ，quantile representation相当于对于概率分布做了如下建模，其中 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_i%28x%2Ca%29" alt="\theta_i(x,a)" eeimg="1"/> 可以用神经网络来表示。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-e55c6567a0740a0d9c9beb7009a567fa_b.png" data-caption="" data-size="normal" data-rawwidth="910" data-rawheight="150" class="origin_image zh-lightbox-thumb" width="910" data-original="https://pic3.zhimg.com/v2-e55c6567a0740a0d9c9beb7009a567fa_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;910&#39; height=&#39;150&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="910" data-rawheight="150" class="origin_image zh-lightbox-thumb lazy" width="910" data-original="https://pic3.zhimg.com/v2-e55c6567a0740a0d9c9beb7009a567fa_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-e55c6567a0740a0d9c9beb7009a567fa_b.png"/></figure><p>把任意一个概率分布表示出来相当于就是往上面这个quantile模型上做投影。这里使用了1-Wasserstein距离。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-0faf4b96351df25737591c9bcd8deb18_b.png" data-caption="" data-size="normal" data-rawwidth="944" data-rawheight="65" class="origin_image zh-lightbox-thumb" width="944" data-original="https://pic1.zhimg.com/v2-0faf4b96351df25737591c9bcd8deb18_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;944&#39; height=&#39;65&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="944" data-rawheight="65" class="origin_image zh-lightbox-thumb lazy" width="944" data-original="https://pic1.zhimg.com/v2-0faf4b96351df25737591c9bcd8deb18_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-0faf4b96351df25737591c9bcd8deb18_b.png"/></figure><p>可以证明，在1-Wasserstein距离下，其最优表示 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_i+%3D+F_Z%5E%7B-1%7D%28%5Cdfrac%7B%5Ctau_%7Bi-1%7D%2B%5Ctau_i%7D%7B2%7D%29" alt="\theta_i = F_Z^{-1}(\dfrac{\tau_{i-1}+\tau_i}{2})" eeimg="1"/> 。但是实际中，真实分布函数及其CDF反函数都是得不到的，因此，我们需要quantile regression来从样本中学习到相应的表示参数。</p><h3><b>3. Quantile Regression</b></h3><p>对于给定的样本 <img src="https://www.zhihu.com/equation?tex=%5Chat%7BZ%7D" alt="\hat{Z}" eeimg="1"/> 和参数 <img src="https://www.zhihu.com/equation?tex=%5Ctau" alt="\tau" eeimg="1"/> ，相应的分位数 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="\theta" eeimg="1"/> 可以通过对如下损失函数做梯度下降得到。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-07506f4c9dc6d1a32e7ce7de306202cc_b.png" data-caption="" data-size="normal" data-rawwidth="974" data-rawheight="100" class="origin_image zh-lightbox-thumb" width="974" data-original="https://pic1.zhimg.com/v2-07506f4c9dc6d1a32e7ce7de306202cc_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;974&#39; height=&#39;100&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="974" data-rawheight="100" class="origin_image zh-lightbox-thumb lazy" width="974" data-original="https://pic1.zhimg.com/v2-07506f4c9dc6d1a32e7ce7de306202cc_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-07506f4c9dc6d1a32e7ce7de306202cc_b.png"/></figure><p>怎样理解这个损失函数呢，即，当样本 <img src="https://www.zhihu.com/equation?tex=%5Chat%7BZ%7D" alt="\hat{Z}" eeimg="1"/> 小于当前分位数 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="\theta" eeimg="1"/> 的时候，线性惩罚系数为 <img src="https://www.zhihu.com/equation?tex=1-%5Ctau" alt="1-\tau" eeimg="1"/> ；当样本 <img src="https://www.zhihu.com/equation?tex=%5Chat%7BZ%7D" alt="\hat{Z}" eeimg="1"/> 大于当前分位数 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="\theta" eeimg="1"/> 的时候，线性惩罚系数为 <img src="https://www.zhihu.com/equation?tex=%5Ctau" alt="\tau" eeimg="1"/> 。这样当分位数 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="\theta" eeimg="1"/> 估计准确的时候，这个损失函数刚好不会提供增大或者减小方向的梯度。</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-852dc9f0c435b8e3257d8601f6cbd02d_b.jpg" data-caption="" data-size="normal" data-rawwidth="731" data-rawheight="357" class="origin_image zh-lightbox-thumb" width="731" data-original="https://pic2.zhimg.com/v2-852dc9f0c435b8e3257d8601f6cbd02d_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;731&#39; height=&#39;357&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="731" data-rawheight="357" class="origin_image zh-lightbox-thumb lazy" width="731" data-original="https://pic2.zhimg.com/v2-852dc9f0c435b8e3257d8601f6cbd02d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-852dc9f0c435b8e3257d8601f6cbd02d_b.jpg"/></figure><p>Quantile loss在零点处导数不连续，计算上不太稳定，这里又提出了一种平滑的方案，即quantile Huber loss。</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-b8a2f2ddcd66afa331a587da52db7b09_b.png" data-caption="" data-size="normal" data-rawwidth="953" data-rawheight="102" class="origin_image zh-lightbox-thumb" width="953" data-original="https://pic2.zhimg.com/v2-b8a2f2ddcd66afa331a587da52db7b09_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;953&#39; height=&#39;102&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="953" data-rawheight="102" class="origin_image zh-lightbox-thumb lazy" width="953" data-original="https://pic2.zhimg.com/v2-b8a2f2ddcd66afa331a587da52db7b09_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-b8a2f2ddcd66afa331a587da52db7b09_b.png"/></figure><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-08c9d3243fdb30cba6ab14bd3e147086_b.png" data-caption="" data-size="normal" data-rawwidth="925" data-rawheight="93" class="origin_image zh-lightbox-thumb" width="925" data-original="https://pic3.zhimg.com/v2-08c9d3243fdb30cba6ab14bd3e147086_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;925&#39; height=&#39;93&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="925" data-rawheight="93" class="origin_image zh-lightbox-thumb lazy" width="925" data-original="https://pic3.zhimg.com/v2-08c9d3243fdb30cba6ab14bd3e147086_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-08c9d3243fdb30cba6ab14bd3e147086_b.png"/></figure><p>可以看到它会更平滑。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-26a07e1ca576a3b02a832d736082cd62_b.jpg" data-caption="" data-size="normal" data-rawwidth="734" data-rawheight="388" class="origin_image zh-lightbox-thumb" width="734" data-original="https://pic3.zhimg.com/v2-26a07e1ca576a3b02a832d736082cd62_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;388&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="734" data-rawheight="388" class="origin_image zh-lightbox-thumb lazy" width="734" data-original="https://pic3.zhimg.com/v2-26a07e1ca576a3b02a832d736082cd62_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-26a07e1ca576a3b02a832d736082cd62_b.jpg"/></figure><h3><b>4. 算法</b></h3><p>文章还提了一个做policy evaluation的quantile TD的算法，这里不说。仿照DQN，文章提出了quantile regression Q-learning。</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-84351ce2c15c77f2483bd06c8159d523_b.jpg" data-caption="" data-size="normal" data-rawwidth="943" data-rawheight="375" class="origin_image zh-lightbox-thumb" width="943" data-original="https://pic4.zhimg.com/v2-84351ce2c15c77f2483bd06c8159d523_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;943&#39; height=&#39;375&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="943" data-rawheight="375" class="origin_image zh-lightbox-thumb lazy" width="943" data-original="https://pic4.zhimg.com/v2-84351ce2c15c77f2483bd06c8159d523_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-84351ce2c15c77f2483bd06c8159d523_b.jpg"/></figure><p>其中 <img src="https://www.zhihu.com/equation?tex=q_j" alt="q_j" eeimg="1"/> 有点没懂，但这一行应该是求期望，即估计到的各个分位数的价值函数的均值。最后一行里面的 <img src="https://www.zhihu.com/equation?tex=%5Cmathbb%7BE%7D_j+%5B%5Ccdots+%5Cmathcal%7BT%7D%5Ctheta_j+%5Ccdots%5D" alt="\mathbb{E}_j [\cdots \mathcal{T}\theta_j \cdots]" eeimg="1"/> 就相当于是前面损失函数里面对于真是分布的采样 <img src="https://www.zhihu.com/equation?tex=%5Cmathbb%7BE%7D_%7B%5Chat%7BZ%7D%5Csim+Z%7D+%5B%5Ccdots+%5Chat%7BZ%7D+%5Ccdots%5D" alt="\mathbb{E}_{\hat{Z}\sim Z} [\cdots \hat{Z} \cdots]" eeimg="1"/> 。</p><h3><b>5. 理论结果</b></h3><p><b>5.1. categorical representation在样本上的最优不等于相对于真实分布的最优</b></p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-75e61aa7f40467cc48bc2435007582c9_b.jpg" data-caption="" data-size="normal" data-rawwidth="964" data-rawheight="342" class="origin_image zh-lightbox-thumb" width="964" data-original="https://pic2.zhimg.com/v2-75e61aa7f40467cc48bc2435007582c9_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;964&#39; height=&#39;342&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="964" data-rawheight="342" class="origin_image zh-lightbox-thumb lazy" width="964" data-original="https://pic2.zhimg.com/v2-75e61aa7f40467cc48bc2435007582c9_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-75e61aa7f40467cc48bc2435007582c9_b.jpg"/></figure><p><b>5.2. 考虑policy evaluation，categorical representation的投影联合Bellman算子，在Cramer距离度量下是contraction [1]</b></p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-966d16665bddcd38c5edba83b1cde602_b.jpg" data-caption="" data-size="normal" data-rawwidth="902" data-rawheight="231" class="origin_image zh-lightbox-thumb" width="902" data-original="https://pic3.zhimg.com/v2-966d16665bddcd38c5edba83b1cde602_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;902&#39; height=&#39;231&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="902" data-rawheight="231" class="origin_image zh-lightbox-thumb lazy" width="902" data-original="https://pic3.zhimg.com/v2-966d16665bddcd38c5edba83b1cde602_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-966d16665bddcd38c5edba83b1cde602_b.jpg"/></figure><p>其中 <img src="https://www.zhihu.com/equation?tex=%5CPi_%7B%5Cmathcal%7BC%7D%7D" alt="\Pi_{\mathcal{C}}" eeimg="1"/> 表示categorical representation的投影算子，Cramer距离的定义如下</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-9d01bfe47027e6b07ae856605b73e9f7_b.jpg" data-caption="" data-size="normal" data-rawwidth="867" data-rawheight="413" class="origin_image zh-lightbox-thumb" width="867" data-original="https://pic4.zhimg.com/v2-9d01bfe47027e6b07ae856605b73e9f7_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;867&#39; height=&#39;413&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="867" data-rawheight="413" class="origin_image zh-lightbox-thumb lazy" width="867" data-original="https://pic4.zhimg.com/v2-9d01bfe47027e6b07ae856605b73e9f7_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-9d01bfe47027e6b07ae856605b73e9f7_b.jpg"/></figure><p><b>5.3. quantile representation在样本上的最优也不等于相对于真实分布的最优</b></p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-944a51f63f5aab7ba05346940c92abd6_b.jpg" data-caption="" data-size="normal" data-rawwidth="951" data-rawheight="176" class="origin_image zh-lightbox-thumb" width="951" data-original="https://pic3.zhimg.com/v2-944a51f63f5aab7ba05346940c92abd6_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;951&#39; height=&#39;176&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="951" data-rawheight="176" class="origin_image zh-lightbox-thumb lazy" width="951" data-original="https://pic3.zhimg.com/v2-944a51f63f5aab7ba05346940c92abd6_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-944a51f63f5aab7ba05346940c92abd6_b.jpg"/></figure><p><i>证明方式是举反例，就设真实分布 </i><img src="https://www.zhihu.com/equation?tex=Z%3D%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5EN+%5Cdelta_i" alt="Z=\frac{1}{N}\sum_{i=1}^N \delta_i" eeimg="1"/><i> ，这样采样得到的样本里面最小值或者是1，或者大于1。假设估计分布的第一个参数已经最优了，即 </i><img src="https://www.zhihu.com/equation?tex=%5Ctheta_1+%3D+1" alt="\theta_1 = 1" eeimg="1"/><i> ，那么这个目标对于 </i><img src="https://www.zhihu.com/equation?tex=%5Ctheta_1" alt="\theta_1" eeimg="1"/><i> 求导应该为零。但实际情况是当样本的最小值等于1时，导数为零；大于1的时候，导数小于零。因此其导数的期望一定为负，因此， </i><img src="https://www.zhihu.com/equation?tex=%5Ctheta_1" alt="\theta_1" eeimg="1"/><i> 最后肯定会收敛到比 </i><img src="https://www.zhihu.com/equation?tex=1" alt="1" eeimg="1"/><i> 更大的某个位置。</i></p><p><b>5.4. 最优quantile representation存在并且合理</b></p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-5d9994ac37bfea00585e7dc551774376_b.jpg" data-caption="" data-size="normal" data-rawwidth="1272" data-rawheight="614" class="origin_image zh-lightbox-thumb" width="1272" data-original="https://pic3.zhimg.com/v2-5d9994ac37bfea00585e7dc551774376_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1272&#39; height=&#39;614&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1272" data-rawheight="614" class="origin_image zh-lightbox-thumb lazy" width="1272" data-original="https://pic3.zhimg.com/v2-5d9994ac37bfea00585e7dc551774376_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-5d9994ac37bfea00585e7dc551774376_b.jpg"/></figure><p>观察到优化目标是凸函数，因此直接找梯度为零的点即可解得。</p><p><b>5.5. 考虑policy evaluation，quantile representation的投影联合Bellman算子，仍然能形成contraction</b></p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-d40b462affcbd90f356e6c89dd58ea7e_b.jpg" data-caption="" data-size="normal" data-rawwidth="1282" data-rawheight="314" class="origin_image zh-lightbox-thumb" width="1282" data-original="https://pic3.zhimg.com/v2-d40b462affcbd90f356e6c89dd58ea7e_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1282&#39; height=&#39;314&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1282" data-rawheight="314" class="origin_image zh-lightbox-thumb lazy" width="1282" data-original="https://pic3.zhimg.com/v2-d40b462affcbd90f356e6c89dd58ea7e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-d40b462affcbd90f356e6c89dd58ea7e_b.jpg"/></figure><p><i>其证明过程先考虑如下不影响问题实质的简化：1）认为 </i><img src="https://www.zhihu.com/equation?tex=r%3D0" alt="r=0" eeimg="1"/><i> ，原因是奖励只是把概率分布做平移，在quantile表示下，这一点完全不影响；2）系数 </i><img src="https://www.zhihu.com/equation?tex=%5Cgamma%3D1" alt="\gamma=1" eeimg="1"/><i> ，这不影响推导；3）仅针对特定的 </i><img src="https://www.zhihu.com/equation?tex=%5Ctau" alt="\tau" eeimg="1"/><i> 分位，不同分位的投影算子互不影响，因此只需要分析一个即可；4）原来的分布任务是单dirac分布，其他情况可以看做该分布的加和。</i></p><p>这样可以简化为如下引理</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-e90729aff2d4f125659676add5855c6a_b.jpg" data-caption="" data-size="normal" data-rawwidth="970" data-rawheight="295" class="origin_image zh-lightbox-thumb" width="970" data-original="https://pic3.zhimg.com/v2-e90729aff2d4f125659676add5855c6a_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;970&#39; height=&#39;295&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="970" data-rawheight="295" class="origin_image zh-lightbox-thumb lazy" width="970" data-original="https://pic3.zhimg.com/v2-e90729aff2d4f125659676add5855c6a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-e90729aff2d4f125659676add5855c6a_b.jpg"/></figure><p><i>首先左手边可以只考虑一个状态 </i><img src="https://www.zhihu.com/equation?tex=%28x%27%2Ca%27%29" alt="(x&#39;,a&#39;)" eeimg="1"/><i> ，这样右手边只需要考虑其一步可达的状态 </i><img src="https://www.zhihu.com/equation?tex=%5C%7B%28x_i%2C+a_i%29%5C%7D_%7Bi%5Cin+I%7D" alt="\{(x_i, a_i)\}_{i\in I}" eeimg="1"/><i> 。由于 </i><img src="https://www.zhihu.com/equation?tex=Z%2CY" alt="Z,Y" eeimg="1"/><i> 都是单个的dirac分布，右手边就可以直接写成 </i><img src="https://www.zhihu.com/equation?tex=%5Cmax_i+%7C%5Ctheta_i-%5Cpsi_i%7C" alt="\max_i |\theta_i-\psi_i|" eeimg="1"/><i> ， </i><img src="https://www.zhihu.com/equation?tex=%5Ctheta_i%2C%5Cpsi_i" alt="\theta_i,\psi_i" eeimg="1"/><i> 分布代表不同状态随机变量 </i><img src="https://www.zhihu.com/equation?tex=Z%2CY" alt="Z,Y" eeimg="1"/><i> 的分布。通过算子作用之后， </i><img src="https://www.zhihu.com/equation?tex=+%5Cmathcal%7BT%7D%5E%5Cpi+Z%2C++%5Cmathcal%7BT%7D%5E%5Cpi+Y" alt=" \mathcal{T}^\pi Z,  \mathcal{T}^\pi Y" eeimg="1"/><i> 变成了多个dirac分布的加权和。使用反证法，即左手边大于 </i><img src="https://www.zhihu.com/equation?tex=+%7C%5Ctheta_i-%5Cpsi_i%7C%2C+%5Cforall+i" alt=" |\theta_i-\psi_i|, \forall i" eeimg="1"/><i> ，那么左手边选出来的分位数肯定来自右手边不同的状态，但考虑到左手边都按照相同的 </i><img src="https://www.zhihu.com/equation?tex=%5Ctau" alt="\tau" eeimg="1"/><i> 取分位数，可以推出矛盾。</i></p><p><i>该引理可以这么理解，Bellman算子相当于是把各个不同状态的分布做了加权和，不同分布的加权和只会让分位数更加收缩。</i></p><h2><b>实验</b></h2><p>Policy evaluation 实验使用 gridworld 环境，说明 quantile regression 能够很好地拟合出多模的概率分布；Control 的实验使用 Atari 环境，效果相比之前有些提升。</p><hr/><h2><b>参考文献</b></h2><p>[1] Rowland, Mark, et al. &#34;An analysis of categorical distributional reinforcement learning.&#34;<i>arXiv preprint arXiv:1802.08163</i>(2018).</p></div></div><div class="ContentItem-time">编辑于 2019-03-31</div><div class="Post-topicsAndReviewer"><div class="TopicList Post-Topics"><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/20039099" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习 (Reinforcement Learning)</div></div></a></span></div></div></div><div><div class="Sticky RichContent-actions is-bottom"><div class="ContentItem-actions"><span><button aria-label="赞同 16 " type="button" class="Button VoteButton VoteButton--up"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleUp VoteButton-TriangleUp" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M2 18.242c0-.326.088-.532.237-.896l7.98-13.203C10.572 3.57 11.086 3 12 3c.915 0 1.429.571 1.784 1.143l7.98 13.203c.15.364.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H3.955c-1.08 0-1.955-.517-1.955-1.9z" fill-rule="evenodd"></path></svg></span>赞同 16</button><button aria-label="反对" type="button" class="Button VoteButton VoteButton--down"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleDown" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M20.044 3H3.956C2.876 3 2 3.517 2 4.9c0 .326.087.533.236.896L10.216 19c.355.571.87 1.143 1.784 1.143s1.429-.572 1.784-1.143l7.98-13.204c.149-.363.236-.57.236-.896 0-1.386-.876-1.9-1.956-1.9z" fill-rule="evenodd"></path></svg></span></button></span><button type="button" class="Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Comment Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M10.241 19.313a.97.97 0 0 0-.77.2 7.908 7.908 0 0 1-3.772 1.482.409.409 0 0 1-.38-.637 5.825 5.825 0 0 0 1.11-2.237.605.605 0 0 0-.227-.59A7.935 7.935 0 0 1 3 11.25C3 6.7 7.03 3 12 3s9 3.7 9 8.25-4.373 9.108-10.759 8.063z" fill-rule="evenodd"></path></svg></span>4 条评论</button><div class="Popover ShareMenu"><div class="ShareMenu-toggler" id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Share Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2.931 7.89c-1.067.24-1.275 1.669-.318 2.207l5.277 2.908 8.168-4.776c.25-.127.477.198.273.39L9.05 14.66l.927 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.242c.584-.892-.212-2.029-1.234-1.796L2.93 7.89z" fill-rule="evenodd"></path></svg></span>分享</button></div></div><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Heart Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2 8.437C2 5.505 4.294 3.094 7.207 3 9.243 3 11.092 4.19 12 6c.823-1.758 2.649-3 4.651-3C19.545 3 22 5.507 22 8.432 22 16.24 13.842 21 12 21 10.158 21 2 16.24 2 8.437z" fill-rule="evenodd"></path></svg></span>喜欢</button><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Star Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5.515 19.64l.918-5.355-3.89-3.792c-.926-.902-.639-1.784.64-1.97L8.56 7.74l2.404-4.871c.572-1.16 1.5-1.16 2.072 0L15.44 7.74l5.377.782c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.219 1.274-.532 1.82-1.676 1.218L12 18.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z" fill-rule="evenodd"></path></svg></span>收藏</button><div class="Post-ActionMenuButton"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Dots Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5 14a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4z" fill-rule="evenodd"></path></svg></span></button></div></div></div></div></div></div></article><div class="Post-Sub Post-NormalSub"><div class="PostIndex-Contributions"><h3 class="BlockTitle">文章被以下专栏收录</h3><ul><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><img class="Avatar Avatar--medium Avatar--round" width="40" height="40" src="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_xs.jpg" srcSet="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_l.jpg 2x" alt="强化学习前沿"/></div></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><a class="ColumnLink ColumnItem-Title" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习前沿</div></div></a></h2><div class="ContentItem-meta">读呀读paper</div></div><div class="ContentItem-extra"><a href="/reinforcementlearning" type="button" class="Button">进入专栏</a></div></div></div></ul></div></div></div></main></div></div><script nonce="b02e8a95-622a-4fc5-b76b-8517b3459b76" async="" src="https://www.googletagmanager.com/gtag/js?id=UA-149949619-1"></script><script nonce="b02e8a95-622a-4fc5-b76b-8517b3459b76">function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-149949619-1");</script><script id="js-clientConfig" type="text/json">{"host":"zhihu.com","protocol":"https:","wwwHost":"www.zhihu.com","fetchRoot":{"www":"https:\u002F\u002Fwww.zhihu.com","api":"https:\u002F\u002Fapi.zhihu.com","zhuanlan":"https:\u002F\u002Fzhuanlan.zhihu.com"}}</script><script id="js-initialData" type="text/json">{"initialState":{"common":{"ask":{}},"loading":{"global":{"count":0},"local":{"env\u002FgetIpinfo\u002F":false,"article\u002Fget\u002F":false,"brand\u002FgetUrl\u002F":false}},"club":{"tags":{}},"entities":{"users":{"zhang-chu-heng":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"清华大学 交叉信息院博士在读"}],"exposedMedal":{"medalId":"1124316222665379841","medalName":"我的知乎 2019","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2592b0b52e1fac99f69b38e00252413b_r.png","miniAvatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ad363cc3088dc8de7544fd08b1c4987a_is.png","description":"参与「我的知乎 2019」即可获得"}}},"questions":{},"answers":{},"articles":{"60912847":{"trackUrl":["https:\u002F\u002Fsugar.zhihu.com\u002Fplutus_adreaper\u002Fpage_monitor_log?si=__SESSIONID__&ti=__ATOKEN__&at=view&pf=__OS__&ed=__MEMBERID__&idfa=__IDFA__&imei=__IMEI__&androidid=__ANDROIDID__&oaid=__OAID__&ci=__CREATIVEID__"],"id":60912847,"title":"【强化学习 48】Quantile Regression","type":"article","excerptTitle":"","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F60912847","imageUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-1e5724a64f5e29e7bb032f3bc393b614_b.jpg","titleImage":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-1e5724a64f5e29e7bb032f3bc393b614_b.jpg","excerpt":"\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-36cc1ea86533a61964fd9bb2ef5bb053_200x112.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"757\" data-rawheight=\"566\" data-watermark=\"watermark\" data-original-src=\"v2-36cc1ea86533a61964fd9bb2ef5bb053\" data-watermark-src=\"v2-1724ba5d5df778faf657dbd9c8f9bc6e\" data-private-watermark-src=\"\" class=\"origin_image inline-img zh-lightbox-thumb\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-36cc1ea86533a61964fd9bb2ef5bb053_r.png\"\u002F\u003E紧接着前面Distributional RL做的工作\u003Cb\u003E原文传送门\u003C\u002Fb\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fwww.aaai.org\u002Focs\u002Findex.php\u002FAAAI\u002FAAAI18\u002Fpaper\u002FviewPDFInterstitial\u002F17184\u002F16590\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EDabney, Will, et al. &#34;Distributional reinforcement learning with quantile regression.&#34; Thirty-Second AAAI Conference on Artificial Intelligence. 2018.\u003C\u002Fa\u003E\u003Cb\u003E特色\u003C\u002Fb\u003E专栏前一篇讲了distributional RL，使用价…","created":1553960489,"updated":1554040326,"author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"清华大学 交叉信息院博士在读"}],"exposedMedal":{"medalId":"1124316222665379841","medalName":"我的知乎 2019","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2592b0b52e1fac99f69b38e00252413b_r.png","miniAvatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ad363cc3088dc8de7544fd08b1c4987a_is.png","description":"参与「我的知乎 2019」即可获得"}},"commentPermission":"all","state":"published","imageWidth":1573,"imageHeight":529,"content":"\u003Cp\u003E紧接着前面Distributional RL做的工作\u003C\u002Fp\u003E\u003Ch2\u003E\u003Cb\u003E原文传送门\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fwww.aaai.org\u002Focs\u002Findex.php\u002FAAAI\u002FAAAI18\u002Fpaper\u002FviewPDFInterstitial\u002F17184\u002F16590\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EDabney, Will, et al. &#34;Distributional reinforcement learning with quantile regression.&#34; Thirty-Second AAAI Conference on Artificial Intelligence. 2018.\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Ch2\u003E\u003Cb\u003E特色\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E专栏前一篇讲了distributional RL，使用价值函数分布而不仅是价值函数期望值来做强化学习，之前文章对于分布的近似方式是把概率密度函数用格子来近似（categorical representation），这里使用了更加有效的近似方式（quantile representation），同时理论上也更有保证。\u003C\u002Fp\u003E\u003Ch2\u003E\u003Cb\u003E过程\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Ch3\u003E\u003Cb\u003E1. 为什么要使用quantile representation？\u003C\u002Fb\u003E\u003C\u002Fh3\u003E\u003Cp\u003E这里主要研究的问题是价值函数的分布应该如何来表示。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E\u003Ci\u003E理论上\u003C\u002Fi\u003E\u003C\u002Fb\u003E，任何的实际的表示方式都不能完全准确表示一个任意概率分布，因此任何概率分布的表示方式都可以看做真实分布向所能表示的空间上投影（基于从真实概率分布中采集样本集）。理论上关心两件事情。第一件事情，在policy evaluation下Bellman算子多轮迭代后能够收敛，但是它联合与表示有关的投影算子后（即 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5CPi+%5C++%5Cmathcal%7BT%7D%5E%5Cpi\" alt=\"\\Pi \\  \\mathcal{T}^\\pi\" eeimg=\"1\"\u002F\u003E ）是否还能在Wasserstein距离度量下收敛呢；第二件事情，考虑采样之后，其实是在缩小所表示的概率分布和样本集所代表分布之间的距离，当所表示的概率分布和样本集上距离最小的时候，它是否也和真实分布距离最小。\u003C\u002Fp\u003E\u003Cp\u003Ecategorical representation在这里提到的两件事情上都不能保证（但可以证明在Cramer距离度量下 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5CPi_%7B%5Cmathcal%7BC%7D%7D+%5C++%5Cmathcal%7BT%7D%5E%5Cpi\" alt=\"\\Pi_{\\mathcal{C}} \\  \\mathcal{T}^\\pi\" eeimg=\"1\"\u002F\u003E 是contraction[1]）；而quantile representation在第一件事情上能保证收敛，即能够证明 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5CPi+%5C++%5Cmathcal%7BT%7D%5E%5Cpi\" alt=\"\\Pi \\  \\mathcal{T}^\\pi\" eeimg=\"1\"\u002F\u003E 算子是Wasserstein距离下的contraction。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E\u003Ci\u003E实际操作上\u003C\u002Fi\u003E\u003C\u002Fb\u003E，categorical representation需要实现确定价值函数值所在的区间 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5BV_%5Cmin%2C+V_%5Cmax%5D\" alt=\"[V_\\min, V_\\max]\" eeimg=\"1\"\u002F\u003E ，这引入了超参数；同时，对于某些状态价值函数分布范围相对于 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5BV_%5Cmin%2C+V_%5Cmax%5D\" alt=\"[V_\\min, V_\\max]\" eeimg=\"1\"\u002F\u003E 很小的情况下，近似非常不准确。而quantile representation就不存在此问题。\u003C\u002Fp\u003E\u003Ch3\u003E\u003Cb\u003E2. Quantile Representation\u003C\u002Fb\u003E\u003C\u002Fh3\u003E\u003Cp\u003E考虑一个分布的CDF（如下图），categorical representation相当于在横轴上均匀分出若干格子，然后表示每个各自里面CDF增大的量；而quantile representation相当于在纵轴上划分出若干个各自，然后表示每个各自中对应的价值函数值是多少。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1724ba5d5df778faf657dbd9c8f9bc6e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"757\" data-rawheight=\"566\" class=\"origin_image zh-lightbox-thumb\" width=\"757\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1724ba5d5df778faf657dbd9c8f9bc6e_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;757&#39; height=&#39;566&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"757\" data-rawheight=\"566\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"757\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1724ba5d5df778faf657dbd9c8f9bc6e_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1724ba5d5df778faf657dbd9c8f9bc6e_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E考虑 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctau_i%3Di%2FN%2C+i%5Cin%5BN%5D%5Cquad+%5Ctau_0+%3D+0\" alt=\"\\tau_i=i\u002FN, i\\in[N]\\quad \\tau_0 = 0\" eeimg=\"1\"\u002F\u003E ，quantile representation相当于对于概率分布做了如下建模，其中 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctheta_i%28x%2Ca%29\" alt=\"\\theta_i(x,a)\" eeimg=\"1\"\u002F\u003E 可以用神经网络来表示。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-e55c6567a0740a0d9c9beb7009a567fa_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"910\" data-rawheight=\"150\" class=\"origin_image zh-lightbox-thumb\" width=\"910\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-e55c6567a0740a0d9c9beb7009a567fa_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;910&#39; height=&#39;150&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"910\" data-rawheight=\"150\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"910\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-e55c6567a0740a0d9c9beb7009a567fa_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-e55c6567a0740a0d9c9beb7009a567fa_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E把任意一个概率分布表示出来相当于就是往上面这个quantile模型上做投影。这里使用了1-Wasserstein距离。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-0faf4b96351df25737591c9bcd8deb18_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"944\" data-rawheight=\"65\" class=\"origin_image zh-lightbox-thumb\" width=\"944\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-0faf4b96351df25737591c9bcd8deb18_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;944&#39; height=&#39;65&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"944\" data-rawheight=\"65\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"944\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-0faf4b96351df25737591c9bcd8deb18_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-0faf4b96351df25737591c9bcd8deb18_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E可以证明，在1-Wasserstein距离下，其最优表示 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctheta_i+%3D+F_Z%5E%7B-1%7D%28%5Cdfrac%7B%5Ctau_%7Bi-1%7D%2B%5Ctau_i%7D%7B2%7D%29\" alt=\"\\theta_i = F_Z^{-1}(\\dfrac{\\tau_{i-1}+\\tau_i}{2})\" eeimg=\"1\"\u002F\u003E 。但是实际中，真实分布函数及其CDF反函数都是得不到的，因此，我们需要quantile regression来从样本中学习到相应的表示参数。\u003C\u002Fp\u003E\u003Ch3\u003E\u003Cb\u003E3. Quantile Regression\u003C\u002Fb\u003E\u003C\u002Fh3\u003E\u003Cp\u003E对于给定的样本 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Chat%7BZ%7D\" alt=\"\\hat{Z}\" eeimg=\"1\"\u002F\u003E 和参数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctau\" alt=\"\\tau\" eeimg=\"1\"\u002F\u003E ，相应的分位数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"\u002F\u003E 可以通过对如下损失函数做梯度下降得到。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-07506f4c9dc6d1a32e7ce7de306202cc_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"974\" data-rawheight=\"100\" class=\"origin_image zh-lightbox-thumb\" width=\"974\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-07506f4c9dc6d1a32e7ce7de306202cc_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;974&#39; height=&#39;100&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"974\" data-rawheight=\"100\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"974\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-07506f4c9dc6d1a32e7ce7de306202cc_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-07506f4c9dc6d1a32e7ce7de306202cc_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E怎样理解这个损失函数呢，即，当样本 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Chat%7BZ%7D\" alt=\"\\hat{Z}\" eeimg=\"1\"\u002F\u003E 小于当前分位数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"\u002F\u003E 的时候，线性惩罚系数为 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=1-%5Ctau\" alt=\"1-\\tau\" eeimg=\"1\"\u002F\u003E ；当样本 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Chat%7BZ%7D\" alt=\"\\hat{Z}\" eeimg=\"1\"\u002F\u003E 大于当前分位数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"\u002F\u003E 的时候，线性惩罚系数为 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctau\" alt=\"\\tau\" eeimg=\"1\"\u002F\u003E 。这样当分位数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"\u002F\u003E 估计准确的时候，这个损失函数刚好不会提供增大或者减小方向的梯度。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-852dc9f0c435b8e3257d8601f6cbd02d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"731\" data-rawheight=\"357\" class=\"origin_image zh-lightbox-thumb\" width=\"731\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-852dc9f0c435b8e3257d8601f6cbd02d_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;731&#39; height=&#39;357&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"731\" data-rawheight=\"357\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"731\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-852dc9f0c435b8e3257d8601f6cbd02d_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-852dc9f0c435b8e3257d8601f6cbd02d_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EQuantile loss在零点处导数不连续，计算上不太稳定，这里又提出了一种平滑的方案，即quantile Huber loss。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-b8a2f2ddcd66afa331a587da52db7b09_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"953\" data-rawheight=\"102\" class=\"origin_image zh-lightbox-thumb\" width=\"953\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-b8a2f2ddcd66afa331a587da52db7b09_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;953&#39; height=&#39;102&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"953\" data-rawheight=\"102\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"953\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-b8a2f2ddcd66afa331a587da52db7b09_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-b8a2f2ddcd66afa331a587da52db7b09_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-08c9d3243fdb30cba6ab14bd3e147086_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"925\" data-rawheight=\"93\" class=\"origin_image zh-lightbox-thumb\" width=\"925\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-08c9d3243fdb30cba6ab14bd3e147086_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;925&#39; height=&#39;93&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"925\" data-rawheight=\"93\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"925\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-08c9d3243fdb30cba6ab14bd3e147086_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-08c9d3243fdb30cba6ab14bd3e147086_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E可以看到它会更平滑。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-26a07e1ca576a3b02a832d736082cd62_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"388\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-26a07e1ca576a3b02a832d736082cd62_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;734&#39; height=&#39;388&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"388\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-26a07e1ca576a3b02a832d736082cd62_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-26a07e1ca576a3b02a832d736082cd62_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Ch3\u003E\u003Cb\u003E4. 算法\u003C\u002Fb\u003E\u003C\u002Fh3\u003E\u003Cp\u003E文章还提了一个做policy evaluation的quantile TD的算法，这里不说。仿照DQN，文章提出了quantile regression Q-learning。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-84351ce2c15c77f2483bd06c8159d523_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"943\" data-rawheight=\"375\" class=\"origin_image zh-lightbox-thumb\" width=\"943\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-84351ce2c15c77f2483bd06c8159d523_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;943&#39; height=&#39;375&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"943\" data-rawheight=\"375\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"943\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-84351ce2c15c77f2483bd06c8159d523_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-84351ce2c15c77f2483bd06c8159d523_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=q_j\" alt=\"q_j\" eeimg=\"1\"\u002F\u003E 有点没懂，但这一行应该是求期望，即估计到的各个分位数的价值函数的均值。最后一行里面的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathbb%7BE%7D_j+%5B%5Ccdots+%5Cmathcal%7BT%7D%5Ctheta_j+%5Ccdots%5D\" alt=\"\\mathbb{E}_j [\\cdots \\mathcal{T}\\theta_j \\cdots]\" eeimg=\"1\"\u002F\u003E 就相当于是前面损失函数里面对于真是分布的采样 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathbb%7BE%7D_%7B%5Chat%7BZ%7D%5Csim+Z%7D+%5B%5Ccdots+%5Chat%7BZ%7D+%5Ccdots%5D\" alt=\"\\mathbb{E}_{\\hat{Z}\\sim Z} [\\cdots \\hat{Z} \\cdots]\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Ch3\u003E\u003Cb\u003E5. 理论结果\u003C\u002Fb\u003E\u003C\u002Fh3\u003E\u003Cp\u003E\u003Cb\u003E5.1. categorical representation在样本上的最优不等于相对于真实分布的最优\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-75e61aa7f40467cc48bc2435007582c9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"964\" data-rawheight=\"342\" class=\"origin_image zh-lightbox-thumb\" width=\"964\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-75e61aa7f40467cc48bc2435007582c9_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;964&#39; height=&#39;342&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"964\" data-rawheight=\"342\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"964\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-75e61aa7f40467cc48bc2435007582c9_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-75e61aa7f40467cc48bc2435007582c9_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cb\u003E5.2. 考虑policy evaluation，categorical representation的投影联合Bellman算子，在Cramer距离度量下是contraction [1]\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-966d16665bddcd38c5edba83b1cde602_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"902\" data-rawheight=\"231\" class=\"origin_image zh-lightbox-thumb\" width=\"902\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-966d16665bddcd38c5edba83b1cde602_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;902&#39; height=&#39;231&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"902\" data-rawheight=\"231\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"902\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-966d16665bddcd38c5edba83b1cde602_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-966d16665bddcd38c5edba83b1cde602_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5CPi_%7B%5Cmathcal%7BC%7D%7D\" alt=\"\\Pi_{\\mathcal{C}}\" eeimg=\"1\"\u002F\u003E 表示categorical representation的投影算子，Cramer距离的定义如下\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9d01bfe47027e6b07ae856605b73e9f7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"867\" data-rawheight=\"413\" class=\"origin_image zh-lightbox-thumb\" width=\"867\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9d01bfe47027e6b07ae856605b73e9f7_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;867&#39; height=&#39;413&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"867\" data-rawheight=\"413\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"867\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9d01bfe47027e6b07ae856605b73e9f7_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9d01bfe47027e6b07ae856605b73e9f7_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cb\u003E5.3. quantile representation在样本上的最优也不等于相对于真实分布的最优\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-944a51f63f5aab7ba05346940c92abd6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"951\" data-rawheight=\"176\" class=\"origin_image zh-lightbox-thumb\" width=\"951\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-944a51f63f5aab7ba05346940c92abd6_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;951&#39; height=&#39;176&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"951\" data-rawheight=\"176\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"951\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-944a51f63f5aab7ba05346940c92abd6_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-944a51f63f5aab7ba05346940c92abd6_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Ci\u003E证明方式是举反例，就设真实分布 \u003C\u002Fi\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=Z%3D%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5EN+%5Cdelta_i\" alt=\"Z=\\frac{1}{N}\\sum_{i=1}^N \\delta_i\" eeimg=\"1\"\u002F\u003E\u003Ci\u003E ，这样采样得到的样本里面最小值或者是1，或者大于1。假设估计分布的第一个参数已经最优了，即 \u003C\u002Fi\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctheta_1+%3D+1\" alt=\"\\theta_1 = 1\" eeimg=\"1\"\u002F\u003E\u003Ci\u003E ，那么这个目标对于 \u003C\u002Fi\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctheta_1\" alt=\"\\theta_1\" eeimg=\"1\"\u002F\u003E\u003Ci\u003E 求导应该为零。但实际情况是当样本的最小值等于1时，导数为零；大于1的时候，导数小于零。因此其导数的期望一定为负，因此， \u003C\u002Fi\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctheta_1\" alt=\"\\theta_1\" eeimg=\"1\"\u002F\u003E\u003Ci\u003E 最后肯定会收敛到比 \u003C\u002Fi\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=1\" alt=\"1\" eeimg=\"1\"\u002F\u003E\u003Ci\u003E 更大的某个位置。\u003C\u002Fi\u003E\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E5.4. 最优quantile representation存在并且合理\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-5d9994ac37bfea00585e7dc551774376_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1272\" data-rawheight=\"614\" class=\"origin_image zh-lightbox-thumb\" width=\"1272\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-5d9994ac37bfea00585e7dc551774376_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1272&#39; height=&#39;614&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1272\" data-rawheight=\"614\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1272\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-5d9994ac37bfea00585e7dc551774376_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-5d9994ac37bfea00585e7dc551774376_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E观察到优化目标是凸函数，因此直接找梯度为零的点即可解得。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E5.5. 考虑policy evaluation，quantile representation的投影联合Bellman算子，仍然能形成contraction\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-d40b462affcbd90f356e6c89dd58ea7e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1282\" data-rawheight=\"314\" class=\"origin_image zh-lightbox-thumb\" width=\"1282\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-d40b462affcbd90f356e6c89dd58ea7e_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1282&#39; height=&#39;314&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1282\" data-rawheight=\"314\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1282\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-d40b462affcbd90f356e6c89dd58ea7e_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-d40b462affcbd90f356e6c89dd58ea7e_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Ci\u003E其证明过程先考虑如下不影响问题实质的简化：1）认为 \u003C\u002Fi\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=r%3D0\" alt=\"r=0\" eeimg=\"1\"\u002F\u003E\u003Ci\u003E ，原因是奖励只是把概率分布做平移，在quantile表示下，这一点完全不影响；2）系数 \u003C\u002Fi\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cgamma%3D1\" alt=\"\\gamma=1\" eeimg=\"1\"\u002F\u003E\u003Ci\u003E ，这不影响推导；3）仅针对特定的 \u003C\u002Fi\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctau\" alt=\"\\tau\" eeimg=\"1\"\u002F\u003E\u003Ci\u003E 分位，不同分位的投影算子互不影响，因此只需要分析一个即可；4）原来的分布任务是单dirac分布，其他情况可以看做该分布的加和。\u003C\u002Fi\u003E\u003C\u002Fp\u003E\u003Cp\u003E这样可以简化为如下引理\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-e90729aff2d4f125659676add5855c6a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"970\" data-rawheight=\"295\" class=\"origin_image zh-lightbox-thumb\" width=\"970\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-e90729aff2d4f125659676add5855c6a_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;970&#39; height=&#39;295&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"970\" data-rawheight=\"295\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"970\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-e90729aff2d4f125659676add5855c6a_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-e90729aff2d4f125659676add5855c6a_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Ci\u003E首先左手边可以只考虑一个状态 \u003C\u002Fi\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%28x%27%2Ca%27%29\" alt=\"(x&#39;,a&#39;)\" eeimg=\"1\"\u002F\u003E\u003Ci\u003E ，这样右手边只需要考虑其一步可达的状态 \u003C\u002Fi\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5C%7B%28x_i%2C+a_i%29%5C%7D_%7Bi%5Cin+I%7D\" alt=\"\\{(x_i, a_i)\\}_{i\\in I}\" eeimg=\"1\"\u002F\u003E\u003Ci\u003E 。由于 \u003C\u002Fi\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=Z%2CY\" alt=\"Z,Y\" eeimg=\"1\"\u002F\u003E\u003Ci\u003E 都是单个的dirac分布，右手边就可以直接写成 \u003C\u002Fi\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmax_i+%7C%5Ctheta_i-%5Cpsi_i%7C\" alt=\"\\max_i |\\theta_i-\\psi_i|\" eeimg=\"1\"\u002F\u003E\u003Ci\u003E ， \u003C\u002Fi\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctheta_i%2C%5Cpsi_i\" alt=\"\\theta_i,\\psi_i\" eeimg=\"1\"\u002F\u003E\u003Ci\u003E 分布代表不同状态随机变量 \u003C\u002Fi\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=Z%2CY\" alt=\"Z,Y\" eeimg=\"1\"\u002F\u003E\u003Ci\u003E 的分布。通过算子作用之后， \u003C\u002Fi\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=+%5Cmathcal%7BT%7D%5E%5Cpi+Z%2C++%5Cmathcal%7BT%7D%5E%5Cpi+Y\" alt=\" \\mathcal{T}^\\pi Z,  \\mathcal{T}^\\pi Y\" eeimg=\"1\"\u002F\u003E\u003Ci\u003E 变成了多个dirac分布的加权和。使用反证法，即左手边大于 \u003C\u002Fi\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=+%7C%5Ctheta_i-%5Cpsi_i%7C%2C+%5Cforall+i\" alt=\" |\\theta_i-\\psi_i|, \\forall i\" eeimg=\"1\"\u002F\u003E\u003Ci\u003E ，那么左手边选出来的分位数肯定来自右手边不同的状态，但考虑到左手边都按照相同的 \u003C\u002Fi\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctau\" alt=\"\\tau\" eeimg=\"1\"\u002F\u003E\u003Ci\u003E 取分位数，可以推出矛盾。\u003C\u002Fi\u003E\u003C\u002Fp\u003E\u003Cp\u003E\u003Ci\u003E该引理可以这么理解，Bellman算子相当于是把各个不同状态的分布做了加权和，不同分布的加权和只会让分位数更加收缩。\u003C\u002Fi\u003E\u003C\u002Fp\u003E\u003Ch2\u003E\u003Cb\u003E实验\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003EPolicy evaluation 实验使用 gridworld 环境，说明 quantile regression 能够很好地拟合出多模的概率分布；Control 的实验使用 Atari 环境，效果相比之前有些提升。\u003C\u002Fp\u003E\u003Chr\u002F\u003E\u003Ch2\u003E\u003Cb\u003E参考文献\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E[1] Rowland, Mark, et al. &#34;An analysis of categorical distributional reinforcement learning.&#34;\u003Ci\u003EarXiv preprint arXiv:1802.08163\u003C\u002Fi\u003E(2018).\u003C\u002Fp\u003E","adminClosedComment":false,"topics":[{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F20039099","type":"topic","id":"20039099","name":"强化学习 (Reinforcement Learning)"}],"voteupCount":16,"voting":0,"column":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"},"commentCount":4,"contributions":[{"id":20528276,"state":"accepted","type":"first_publish","column":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}}],"isTitleImageFullScreen":false,"upvotedFollowees":[],"commercialInfo":{"isCommercial":false,"plugin":{}},"suggestEdit":{"status":false,"reason":"","tip":"","url":"","title":""},"reason":"","annotationAction":[],"canTip":false,"tipjarorsCount":0,"isLabeled":false,"hasPublishingDraft":false,"isFavorited":false,"isNormal":true,"status":0,"shareText":"【强化学习 48】Quantile Regression - 来自知乎专栏「强化学习前沿」，作者: 张楚珩 https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F60912847 （想看更多？下载 @知乎 App：http:\u002F\u002Fweibo.com\u002Fp\u002F100404711598 ）","canComment":{"status":true,"reason":""},"mcnFpShow":-1,"isVisible":true,"isLiked":false,"likedCount":0,"visibleOnlyToAuthor":false}},"columns":{"reinforcementlearning":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}},"topics":{},"roundtables":{},"favlists":{},"comments":{},"notifications":{},"ebooks":{},"activities":{},"feeds":{},"pins":{},"promotions":{},"drafts":{},"chats":{},"posts":{},"clubs":{},"clubTags":{}},"currentUser":"","account":{"lockLevel":{},"unlockTicketStatus":false,"unlockTicket":null,"challenge":[],"errorStatus":false,"message":"","isFetching":false,"accountInfo":{},"urlToken":{"loading":false}},"settings":{"socialBind":null,"inboxMsg":null,"notification":{},"email":{},"privacyFlag":null,"blockedUsers":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"blockedFollowees":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"ignoredTopics":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"restrictedTopics":null,"laboratory":{}},"notification":{},"people":{"profileStatus":{},"activitiesByUser":{},"answersByUser":{},"answersSortByVotesByUser":{},"answersIncludedByUser":{},"votedAnswersByUser":{},"thankedAnswersByUser":{},"voteAnswersByUser":{},"thankAnswersByUser":{},"topicAnswersByUser":{},"zvideosByUser":{},"articlesByUser":{},"articlesSortByVotesByUser":{},"articlesIncludedByUser":{},"pinsByUser":{},"questionsByUser":{},"commercialQuestionsByUser":{},"favlistsByUser":{},"followingByUser":{},"followersByUser":{},"mutualsByUser":{},"followingColumnsByUser":{},"followingQuestionsByUser":{},"followingFavlistsByUser":{},"followingTopicsByUser":{},"publicationsByUser":{},"columnsByUser":{},"allFavlistsByUser":{},"brands":null,"creationsByUser":{},"creationsSortByVotesByUser":{},"creationsFeed":{}},"env":{"ab":{"config":{"experiments":[{"expId":"launch-gw_mweb_rec-1","expPrefix":"gw_mweb_rec","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-qa_hdpimg-2","expPrefix":"qa_hdpimg","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-us_foltopic_user-10","expPrefix":"us_foltopic_user","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_bullet_second-2","expPrefix":"vd_bullet_second","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_zvideo_link-10","expPrefix":"vd_zvideo_link","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false}],"params":[{"id":"se_preset_label","type":"String","value":"1","chainId":"_all_"},{"id":"soc_zcfw_broadcast","type":"String","value":"0","chainId":"_all_"},{"id":"zr_slotpaidexp","type":"String","value":"1","chainId":"_all_"},{"id":"se_webrs","type":"String","value":"1","chainId":"_all_"},{"id":"se_agency","type":"String","value":" 0","chainId":"_all_"},{"id":"se_lottery","type":"String","value":"0","chainId":"_all_"},{"id":"se_timebox_up","type":"String","value":"0","chainId":"_all_"},{"id":"se_search_feed","type":"String","value":"N","chainId":"_all_"},{"id":"soc_yxzl_zcfw","type":"String","value":"0","chainId":"_all_"},{"id":"li_svip_cardshow","type":"String","value":"1","chainId":"_all_"},{"id":"li_sku_bottom_bar_re","type":"String","value":"0","chainId":"_all_"},{"id":"zr_video_rank","type":"String","value":"new_rank","chainId":"_all_"},{"id":"web_sem_ab","type":"String","value":"1"},{"id":"se_movietab","type":"String","value":"1","chainId":"_all_"},{"id":"se_hotsearch_2","type":"String","value":"1","chainId":"_all_"},{"id":"soc_zuichangfangwen","type":"String","value":"0","chainId":"_all_"},{"id":"top_hotcommerce","type":"String","value":"1","chainId":"_all_"},{"id":"se_webtimebox","type":"String","value":"0","chainId":"_all_"},{"id":"qap_ques_invite","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_3","type":"String","value":"0","chainId":"_all_"},{"id":"ls_recommend_test","type":"String","value":"0","chainId":"_all_"},{"id":"zr_rel_search","type":"String","value":"base","chainId":"_all_"},{"id":"se_dnn_mt_v2","type":"String","value":"0","chainId":"_all_"},{"id":"se_ffzx_jushen1","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_android_join","type":"String","value":"1","chainId":"_all_"},{"id":"gue_zvideo_link","type":"String","value":"1"},{"id":"zr_update_merge_size","type":"String","value":"1","chainId":"_all_"},{"id":"se_colorfultab","type":"String","value":"1","chainId":"_all_"},{"id":"soc_adreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"ug_follow_answerer","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_1","type":"String","value":"0","chainId":"_all_"},{"id":"se_ltr_video","type":"String","value":"0","chainId":"_all_"},{"id":"se_waterfall","type":"String","value":"0","chainId":"_all_"},{"id":"se_hot_timebox","type":"String","value":"0","chainId":"_all_"},{"id":"tp_discover_copy","type":"String","value":"0","chainId":"_all_"},{"id":"zr_slot_cold_start","type":"String","value":"aver","chainId":"_all_"},{"id":"se_college","type":"String","value":"default","chainId":"_all_"},{"id":"se_multianswer","type":"String","value":"2","chainId":"_all_"},{"id":"tp_topic_entry","type":"String","value":"0","chainId":"_all_"},{"id":"li_answer_card","type":"String","value":"0","chainId":"_all_"},{"id":"zr_video_rank_nn","type":"String","value":"new_rank","chainId":"_all_"},{"id":"se_ctx_rerank","type":"String","value":"1","chainId":"_all_"},{"id":"se_time_threshold","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iospinweight","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iosreadline","type":"String","value":"0","chainId":"_all_"},{"id":"ug_follow_topic_1","type":"String","value":"2","chainId":"_all_"},{"id":"gue_bullet_guide","type":"String","value":"发个弹幕聊聊…"},{"id":"li_yxzl_new_style_a","type":"String","value":"1","chainId":"_all_"},{"id":"qap_payc_invite","type":"String","value":"0","chainId":"_all_"},{"id":"se_ios_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"se_cbert_index","type":"String","value":"0","chainId":"_all_"},{"id":"se_use_zitem","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_tab_feed","type":"String","value":"0","chainId":"_all_"},{"id":"tp_discover","type":"String","value":"0","chainId":"_all_"},{"id":"soc_wonderuser_recom","type":"String","value":"2","chainId":"_all_"},{"id":"ls_videoad","type":"String","value":"2","chainId":"_all_"},{"id":"li_se_media_icon","type":"String","value":"1","chainId":"_all_"},{"id":"zr_test_aa1","type":"String","value":"0","chainId":"_all_"},{"id":"se_prf","type":"String","value":"0","chainId":"_all_"},{"id":"se_backsearch","type":"String","value":"0","chainId":"_all_"},{"id":"tp_qa_toast","type":"String","value":"1","chainId":"_all_"},{"id":"sem_up_growth","type":"String","value":"in_app","chainId":"_all_"},{"id":"qap_question_visitor","type":"String","value":" 0","chainId":"_all_"},{"id":"soc_update","type":"String","value":"1","chainId":"_all_"},{"id":"top_ebook","type":"String","value":"0","chainId":"_all_"},{"id":"zr_article_new","type":"String","value":"close","chainId":"_all_"},{"id":"se_cate_l3","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_pic_swiper","type":"String","value":"1","chainId":"_all_"},{"id":"zw_sameq_sorce","type":"String","value":"999","chainId":"_all_"},{"id":"se_likebutton","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iosintimacy","type":"String","value":"2","chainId":"_all_"},{"id":"li_qa_btn_text","type":"String","value":"0","chainId":"_all_"},{"id":"li_video_section","type":"String","value":"0","chainId":"_all_"},{"id":"zr_art_rec","type":"String","value":"base","chainId":"_all_"},{"id":"se_topicfeed","type":"String","value":"0","chainId":"_all_"},{"id":"se_ad_index","type":"String","value":"10","chainId":"_all_"},{"id":"se_college_cm","type":"String","value":"0","chainId":"_all_"},{"id":"soc_newfeed","type":"String","value":"2","chainId":"_all_"},{"id":"gue_bullet_second","type":"String","value":"1"},{"id":"li_vip_verti_search","type":"String","value":"0","chainId":"_all_"},{"id":"li_catalog_card","type":"String","value":"1","chainId":"_all_"},{"id":"li_answers_link","type":"String","value":"0","chainId":"_all_"},{"id":"se_new_p","type":"String","value":"0","chainId":"_all_"},{"id":"se_relationship","type":"String","value":"1","chainId":"_all_"},{"id":"ug_zero_follow","type":"String","value":"0","chainId":"_all_"},{"id":"gue_goods_card","type":"String","value":"0"},{"id":"se_p_slideshow","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_rec","type":"String","value":"1","chainId":"_all_"},{"id":"tp_qa_metacard","type":"String","value":"1","chainId":"_all_"},{"id":"soc_adsort","type":"String","value":"0","chainId":"_all_"},{"id":"pf_noti_entry_num","type":"String","value":"0","chainId":"_all_"},{"id":"li_ebok_chap","type":"String","value":"0","chainId":"_all_"},{"id":"zr_training_first","type":"String","value":"false","chainId":"_all_"},{"id":"se_zu_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"tp_header_style","type":"String","value":"1","chainId":"_all_"},{"id":"li_purchase_test","type":"String","value":"0","chainId":"_all_"},{"id":"se_webmajorob","type":"String","value":"0","chainId":"_all_"},{"id":"se_content0","type":"String","value":"0","chainId":"_all_"},{"id":"tp_m_intro_re_topic","type":"String","value":"1","chainId":"_all_"},{"id":"li_ebook_gen_search","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_section","type":"String","value":"0","chainId":"_all_"},{"id":"se_relation_1","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_qa","type":"String","value":"1","chainId":"_all_"},{"id":"soc_adpinweight","type":"String","value":"0","chainId":"_all_"},{"id":"tsp_hotlist_ui","type":"String","value":"1","chainId":"_all_"},{"id":"zr_training_boost","type":"String","value":"false","chainId":"_all_"},{"id":"se_auto_syn","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sticky_android","type":"String","value":"2","chainId":"_all_"},{"id":"tp_topic_style","type":"String","value":"0","chainId":"_all_"},{"id":"tsp_vote","type":"String","value":"2","chainId":"_all_"},{"id":"gue_new_special_page","type":"String","value":"1"},{"id":"zr_rec_answer_cp","type":"String","value":"close","chainId":"_all_"},{"id":"tp_club_pk","type":"String","value":"1","chainId":"_all_"},{"id":"soc_stickypush","type":"String","value":"1","chainId":"_all_"},{"id":"top_universalebook","type":"String","value":"1","chainId":"_all_"},{"id":"se_new_merger","type":"String","value":"1","chainId":"_all_"},{"id":"web_answerlist_ad","type":"String","value":"0"},{"id":"zr_intervene","type":"String","value":"0","chainId":"_all_"},{"id":"se_sug_term","type":"String","value":"0","chainId":"_all_"},{"id":"tp_discovery_ab_1","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_header","type":"String","value":"1","chainId":"_all_"},{"id":"soc_leave_recommend","type":"String","value":"2","chainId":"_all_"},{"id":"se_entity_model","type":"String","value":"0","chainId":"_all_"},{"id":"se_featured","type":"String","value":"1","chainId":"_all_"},{"id":"soc_authormore","type":"String","value":"2","chainId":"_all_"},{"id":"gue_video_replay","type":"String","value":"0"},{"id":"gue_card_test","type":"String","value":"1"},{"id":"web_collect","type":"String","value":"0"},{"id":"se_payconsult","type":"String","value":"0","chainId":"_all_"},{"id":"soc_bignew","type":"String","value":"1","chainId":"_all_"},{"id":"soc_authormore2","type":"String","value":"2","chainId":"_all_"},{"id":"qap_question_author","type":"String","value":"0","chainId":"_all_"},{"id":"se_expired_ob","type":"String","value":"0","chainId":"_all_"},{"id":"se_related_index","type":"String","value":"3","chainId":"_all_"},{"id":"se_aa","type":"String","value":"0","chainId":"_all_"},{"id":"gue_self_censoring","type":"String","value":"1"},{"id":"se_specialbutton","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zcfw_broadcast2","type":"String","value":"1","chainId":"_all_"},{"id":"tsp_videobillboard","type":"String","value":"1","chainId":"_all_"},{"id":"li_education_box","type":"String","value":"0","chainId":"_all_"},{"id":"se_col_boost","type":"String","value":"0","chainId":"_all_"},{"id":"se_pek_test2","type":"String","value":"1","chainId":"_all_"},{"id":"soc_zcfw_shipinshiti","type":"String","value":"1","chainId":"_all_"},{"id":"pf_adjust","type":"String","value":"0","chainId":"_all_"},{"id":"zr_answer_rec_cp","type":"String","value":"open","chainId":"_all_"},{"id":"se_article_icon","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sft","type":"String","value":"a","chainId":"_all_"},{"id":"li_salt_hot","type":"String","value":"1","chainId":"_all_"},{"id":"li_se_heat","type":"String","value":"1","chainId":"_all_"},{"id":"se_cardrank_2","type":"String","value":"1","chainId":"_all_"},{"id":"se_new_topic","type":"String","value":"0","chainId":"_all_"},{"id":"se_amovietab","type":"String","value":"1","chainId":"_all_"},{"id":"se_mobileweb","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_qa_pic","type":"String","value":"1","chainId":"_all_"},{"id":"pf_foltopic_usernum","type":"String","value":"50","chainId":"_all_"},{"id":"li_paid_answer_exp","type":"String","value":"0","chainId":"_all_"},{"id":"zr_slot_training","type":"String","value":"1","chainId":"_all_"},{"id":"se_cardrank_4","type":"String","value":"1","chainId":"_all_"},{"id":"ug_follow_answerer_0","type":"String","value":"0","chainId":"_all_"},{"id":"web_mweb_rec_length","type":"String","value":"1"},{"id":"gue_zhuantikapian","type":"String","value":"0"},{"id":"zr_km_feed_nlp","type":"String","value":"old","chainId":"_all_"},{"id":"web_unfriendly_comm","type":"String","value":"0"},{"id":"se_zu_recommend","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iossort","type":"String","value":"0","chainId":"_all_"},{"id":"top_quality","type":"String","value":"0","chainId":"_all_"},{"id":"pf_fuceng","type":"String","value":"1","chainId":"_all_"},{"id":"web_upload","type":"String","value":"1"},{"id":"zr_search_sim","type":"String","value":"0","chainId":"_all_"},{"id":"se_preset_tech","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_tab","type":"String","value":"0","chainId":"_all_"},{"id":"zw_payc_qaedit","type":"String","value":"0","chainId":"_all_"},{"id":"zr_search_paid","type":"String","value":"0","chainId":"_all_"},{"id":"se_hotsearch_num","type":"String","value":"0","chainId":"_all_"},{"id":"se_highlight","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zcfw_badcase","type":"String","value":"0","chainId":"_all_"},{"id":"top_root","type":"String","value":"0","chainId":"_all_"},{"id":"top_test_4_liguangyi","type":"String","value":"1","chainId":"_all_"},{"id":"li_answer_label","type":"String","value":"0","chainId":"_all_"},{"id":"se_click_club","type":"String","value":"1","chainId":"_all_"},{"id":"se_wannasearch","type":"String","value":"0","chainId":"_all_"},{"id":"se_famous","type":"String","value":"1","chainId":"_all_"},{"id":"li_qa_new_cover","type":"String","value":"1","chainId":"_all_"},{"id":"web_answer_list_ad","type":"String","value":"1"},{"id":"zr_video_recall","type":"String","value":"current_recall","chainId":"_all_"},{"id":"web_ad_banner","type":"String","value":"0"},{"id":"web_heifetz_grow_ad","type":"String","value":"1"},{"id":"li_se_across","type":"String","value":"1","chainId":"_all_"},{"id":"tp_meta_card","type":"String","value":"0","chainId":"_all_"},{"id":"web_column_auto_invite","type":"String","value":"0"},{"id":"se_whitelist","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_join","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iosreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"se_presearch_ab","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_pic","type":"String","value":"0.6","chainId":"_all_"},{"id":"qap_thanks","type":"String","value":"1","chainId":"_all_"},{"id":"zr_ans_rec","type":"String","value":"gbrank","chainId":"_all_"},{"id":"se_websearch","type":"String","value":"3","chainId":"_all_"},{"id":"gue_video_autoplay","type":"String","value":"0"},{"id":"tp_club_discover","type":"String","value":"0","chainId":"_all_"},{"id":"soc_feed_intimacy","type":"String","value":"2","chainId":"_all_"},{"id":"web_ask","type":"String","value":"0"},{"id":"zr_km_answer","type":"String","value":"open_cvr","chainId":"_all_"},{"id":"se_club_post","type":"String","value":"5","chainId":"_all_"},{"id":"se_page_quality","type":"String","value":"0","chainId":"_all_"},{"id":"se_billboardsearch","type":"String","value":"0","chainId":"_all_"},{"id":"soc_brdcst3","type":"String","value":"0","chainId":"_all_"},{"id":"soc_ri_merge","type":"String","value":"0","chainId":"_all_"},{"id":"pf_newguide_vertical","type":"String","value":"0","chainId":"_all_"},{"id":"se_topiclabel","type":"String","value":"1","chainId":"_all_"},{"id":"tp_topic_tab_new","type":"String","value":"0-0-0","chainId":"_all_"},{"id":"ug_newtag","type":"String","value":"0","chainId":"_all_"},{"id":"li_ebook_read","type":"String","value":"0","chainId":"_all_"},{"id":"se_entity_model_14","type":"String","value":"0","chainId":"_all_"},{"id":"se_pek_test3","type":"String","value":"1","chainId":"_all_"},{"id":"se_aa_base","type":"String","value":"0","chainId":"_all_"},{"id":"se_searchwiki","type":"String","value":"0","chainId":"_all_"},{"id":"se_sug","type":"String","value":"1","chainId":"_all_"},{"id":"se_adxtest","type":"String","value":"1","chainId":"_all_"},{"id":"ug_goodcomment_0","type":"String","value":"1","chainId":"_all_"},{"id":"li_se_edu","type":"String","value":"1","chainId":"_all_"},{"id":"li_pay_banner_type","type":"String","value":"6","chainId":"_all_"},{"id":"tp_score_1","type":"String","value":"a","chainId":"_all_"},{"id":"soc_userrec","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adreadline","type":"String","value":"0","chainId":"_all_"},{"id":"soc_brdcst4","type":"String","value":"3","chainId":"_all_"},{"id":"zr_expslotpaid","type":"String","value":"1","chainId":"_all_"},{"id":"tp_sft_v2","type":"String","value":"d","chainId":"_all_"},{"id":"pf_creator_card","type":"String","value":"1","chainId":"_all_"},{"id":"li_android_vip","type":"String","value":"0","chainId":"_all_"},{"id":"li_assessment_show","type":"String","value":"1","chainId":"_all_"},{"id":"tp_topic_head","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_feed","type":"String","value":"1","chainId":"_all_"},{"id":"ls_fmp4","type":"String","value":"0","chainId":"_all_"},{"id":"web_sec672","type":"String","value":"0"},{"id":"web_hdpimg","type":"String","value":"1"},{"id":"tp_club_tab","type":"String","value":"0","chainId":"_all_"},{"id":"soc_bigone","type":"String","value":"0","chainId":"_all_"},{"id":"top_v_album","type":"String","value":"1","chainId":"_all_"},{"id":"web_creator_route","type":"String","value":"1"},{"id":"soc_special","type":"String","value":"0","chainId":"_all_"},{"id":"soc_notification","type":"String","value":"0","chainId":"_all_"},{"id":"ug_fw_answ_aut_1","type":"String","value":"0","chainId":"_all_"},{"id":"li_svip_tab_search","type":"String","value":"0","chainId":"_all_"},{"id":"li_hot_voted","type":"String","value":"0","chainId":"_all_"},{"id":"web_question_invite","type":"String","value":"B"},{"id":"se_rf_w","type":"String","value":"0","chainId":"_all_"},{"id":"ug_zero_follow_0","type":"String","value":"0","chainId":"_all_"},{"id":"web_answer_update","type":"String","value":"0"},{"id":"se_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"soc_cardheight","type":"String","value":"2","chainId":"_all_"},{"id":"web_mweb_launch","type":"String","value":"0"},{"id":"se_site_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"tp_qa_metacard_top","type":"String","value":"top","chainId":"_all_"},{"id":"top_new_feed","type":"String","value":"5","chainId":"_all_"},{"id":"top_ydyq","type":"String","value":"X","chainId":"_all_"},{"id":"web_mini_review","type":"String","value":"0"},{"id":"gue_thanks","type":"String","value":"0"},{"id":"qap_article_like","type":"String","value":"1","chainId":"_all_"},{"id":"se_subtext","type":"String","value":"0","chainId":"_all_"},{"id":"web_n_web_msg","type":"String","value":"0"},{"id":"web_audit_01","type":"String","value":"case1"},{"id":"se_hotmore","type":"String","value":"2","chainId":"_all_"},{"id":"se_hotsearch","type":"String","value":"0","chainId":"_all_"},{"id":"se_sug_entrance","type":"String","value":"1","chainId":"_all_"},{"id":"se_pek_test","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_android_feed","type":"String","value":"old","chainId":"_all_"}],"chains":[{"chainId":"_all_"}]},"triggers":{}},"userAgent":{"Edge":false,"Wechat":false,"Weibo":false,"QQ":false,"MQQBrowser":false,"Qzone":false,"Mobile":false,"Android":false,"iOS":false,"isAppleDevice":false,"Zhihu":false,"ZhihuHybrid":false,"isBot":false,"Tablet":false,"UC":false,"Sogou":false,"Qihoo":false,"Baidu":false,"BaiduApp":false,"Safari":false,"GoogleBot":false,"AndroidDaily":false,"iOSDaily":false,"isWebView":false,"origin":"Mozilla\u002F5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\u002F537.36 (KHTML, like Gecko) Chrome\u002F80.0.3987.100 Safari\u002F537.36"},"appViewConfig":{},"ctx":{"path":"\u002Fp\u002F60912847","query":{},"href":"http:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F60912847","host":"zhuanlan.zhihu.com"},"trafficSource":"production","edition":{"baidu":false,"sogou":false,"baiduBeijing":false,"sogouBeijing":false,"sogouInput":false},"theme":"light","enableShortcut":true,"referer":"","conf":{},"ipInfo":{"cityName":"德州","countryName":"中国","regionName":"山东","countryCode":"CN"},"logged":false},"me":{"columnContributions":[]},"label":{"recognizerLists":{}},"ecommerce":{},"comments":{"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"parent":{}},"commentsV2":{"stickers":[],"commentWithPicPermission":{},"notificationsComments":{},"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"conversationMore":{},"parent":{}},"pushNotifications":{"default":{"isFetching":false,"isDrained":false,"ids":[]},"follow":{"isFetching":false,"isDrained":false,"ids":[]},"vote_thank":{"isFetching":false,"isDrained":false,"ids":[]},"currentTab":"default","notificationsCount":{"default":0,"follow":0,"vote_thank":0}},"messages":{"data":{},"currentTab":"common","messageCount":0},"register":{"registerValidateSucceeded":null,"registerValidateErrors":{},"registerConfirmError":null,"sendDigitsError":null,"registerConfirmSucceeded":null},"login":{"loginUnregisteredError":false,"loginBindWechatError":false,"loginConfirmError":null,"sendDigitsError":null,"needSMSIdentify":false,"validateDigitsError":false,"loginConfirmSucceeded":null,"qrcodeLoginToken":"","qrcodeLoginScanStatus":0,"qrcodeLoginError":null,"qrcodeLoginReturnNewToken":false},"active":{"sendDigitsError":null,"activeConfirmSucceeded":null,"activeConfirmError":null},"switches":{},"captcha":{"captchaNeeded":false,"captchaValidated":false,"captchaBase64String":null,"captchaValidationMessage":null,"loginCaptchaExpires":false},"sms":{"supportedCountries":[]},"chat":{"chats":{},"inbox":{"recents":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"strangers":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"friends":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"search":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"config":{"newCount":0,"strangerMessageSwitch":false,"strangerMessageUnread":false,"friendCount":0}},"global":{"isChatMqttExisted":false}},"emoticons":{"emoticonGroupList":[],"emoticonGroupDetail":{}},"creator":{"currentCreatorUrlToken":null,"homeData":{"recommendQuestions":[]},"tools":{"question":{"invitationCount":{"questionFolloweeCount":0,"questionTotalCount":0},"goodatTopics":[]},"customPromotion":{"itemLists":{}},"recommend":{"recommendTimes":{}}},"explore":{"academy":{"tabs":[],"article":{}}},"rights":[],"rightsStatus":{},"levelUpperLimit":10,"account":{"growthLevel":{}},"mcn":{},"applyStatus":{}},"recommendation":{"homeRecommendations":[]},"shareTexts":{},"articles":{"voters":{}},"previewPost":{},"favlists":{"relations":{}},"columns":{"voters":{}},"reward":{"answer":{},"article":{},"question":{}},"video":{"data":{},"shareVideoDetail":{},"last":{}},"topstory":{"recommend":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"follow":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followWonderful":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"sidebar":null,"announcement":{},"hotListCategories":[],"hotList":[],"guestFeeds":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followExtra":{"isNewUser":null,"isFetched":false,"followCount":0,"followers":[]}},"readStatus":{},"column":{},"requestColumn":{"categories":[],"error":null},"articleContribution":{"contributeRequests":[],"deleteContributeIdList":[],"handledContributeIdList":[],"recommendedColumns":[],"pinnedColumns":[],"sentContributeRequestsIdList":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"reinforcementlearning"]},"columnContribution":{"contributeRequests":[],"autoInviteEnabled":false,"recommendedContributors":[],"contributionInvitation":null},"draftHistory":{"history":{},"drafts":{}},"upload":{},"articleDraft":{"titleImage":"","titleImageSize":{},"isTitleImageFullScreen":false,"canTitleImageFullScreen":false,"title":"","titleImageUploading":false,"error":"","content":"","draftLoading":false,"updating":false,"globalLoading":false,"pendingVideo":{"resource":null,"error":null},"deleteFail":{"fail":false},"recommendTopics":[],"selectedColumn":0,"articleDisclaimers":[]},"articleDrafts":{"isDrained":false,"isLoading":false,"items":[]},"columnAutocomplete":{"users":[],"friends":[]},"columnCollection":{},"mcn":{"bindInfo":{},"memberCategoryList":[],"producerList":[],"categoryList":[]}},"fetchHost":"www.zhihu.com","subAppName":"column"}</script><script src="https://static.zhihu.com/heifetz/vendor.7b36fae46082fd30a0db.js"></script><script src="https://static.zhihu.com/heifetz/column.app.76e02b16e87eec249f44.js"></script></body><script src="https://hm.baidu.com/hm.js?98beee57fd2ef70ccdd5ca52b9740c49" async=""></script><script src="https://zz.bdstatic.com/linksubmit/push.js" async=""></script></html>