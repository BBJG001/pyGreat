<!doctype html>
<html lang="zh" data-hairline="true" data-theme="light"><head><meta charSet="utf-8"/><title data-react-helmet="true">【强化学习 93】UCB+Q-learning - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"/><meta name="renderer" content="webkit"/><meta name="force-rendering" content="webkit"/><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg"/><meta data-react-helmet="true" name="keywords" content="强化学习 (Reinforcement Learning)"/><meta data-react-helmet="true" name="description" content="这篇文章把 UCB 和 Q-learning 相结合，得到两种算法 UCB-H 和 UCB-B，这里把它们统记为 UCB + Q-learning。原文传送门Jin, Chi, et al. &amp;#34;Is q-learning provably efficient?.&amp;#34; Advances in Neural Inform…"/><meta data-react-helmet="true" property="og:title" content="【强化学习 93】UCB+Q-learning"/><meta data-react-helmet="true" property="og:url" content="https://zhuanlan.zhihu.com/p/82857779"/><meta data-react-helmet="true" property="og:description" content="这篇文章把 UCB 和 Q-learning 相结合，得到两种算法 UCB-H 和 UCB-B，这里把它们统记为 UCB + Q-learning。原文传送门Jin, Chi, et al. &amp;#34;Is q-learning provably efficient?.&amp;#34; Advances in Neural Inform…"/><meta data-react-helmet="true" property="og:image" content="https://pic1.zhimg.com/v2-95e83d7d87e922ba61b18c6a26f9f0ff_b.jpg"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" property="og:site_name" content="知乎专栏"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png" sizes="152x152"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-120.b3e6278d.png" sizes="120x120"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-76.7a750095.png" sizes="76x76"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-60.a4a761d4.png" sizes="60x60"/><link rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/static/favicon.ico"/><link rel="search" type="application/opensearchdescription+xml" href="https://static.zhihu.com/static/search.xml" title="知乎"/><link rel="dns-prefetch" href="//static.zhimg.com"/><link rel="dns-prefetch" href="//pic1.zhimg.com"/><link rel="dns-prefetch" href="//pic2.zhimg.com"/><link rel="dns-prefetch" href="//pic3.zhimg.com"/><link rel="dns-prefetch" href="//pic4.zhimg.com"/><style>
.u-safeAreaInset-top {
  height: constant(safe-area-inset-top) !important;
  height: env(safe-area-inset-top) !important;
  
}
.u-safeAreaInset-bottom {
  height: constant(safe-area-inset-bottom) !important;
  height: env(safe-area-inset-bottom) !important;
  
}
</style><link href="https://static.zhihu.com/heifetz/column.app.a9ced452148fee3a55c8.css" rel="stylesheet"/><script defer="" crossorigin="anonymous" src="https://unpkg.zhimg.com/@cfe/sentry-script@latest/dist/init.js" data-sentry-config="{&quot;dsn&quot;:&quot;https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224&quot;,&quot;sampleRate&quot;:0.1,&quot;release&quot;:&quot;683-127b14ad&quot;,&quot;ignoreErrorNames&quot;:[&quot;NetworkError&quot;,&quot;SecurityError&quot;],&quot;ignoreErrors&quot;:[&quot;origin message&quot;,&quot;Network request failed&quot;,&quot;Loading chunk&quot;,&quot;这个系统不支持该功能。&quot;,&quot;Can&#x27;t find variable: webkit&quot;,&quot;Can&#x27;t find variable: $&quot;,&quot;内存不足&quot;,&quot;out of memory&quot;,&quot;DOM Exception 18&quot;,&quot;The operation is insecure&quot;,&quot;[object Event]&quot;,&quot;[object FileError]&quot;,&quot;[object DOMError]&quot;,&quot;[object Object]&quot;,&quot;拒绝访问。&quot;,&quot;Maximum call stack size exceeded&quot;,&quot;UploadError&quot;,&quot;无法 fetch&quot;,&quot;draft-js&quot;,&quot;缺少 JavaScript 对象&quot;,&quot;componentWillEnter&quot;,&quot;componentWillLeave&quot;,&quot;componentWillAppear&quot;,&quot;getInlineStyleAt&quot;,&quot;getCharacterList&quot;],&quot;whitelistUrls&quot;:[&quot;static.zhihu.com&quot;]}"></script></head><body class="WhiteBg-body"><div id="root"><div class="App"><div class="LoadingBar"></div><main role="main" class="App-main"><div class="Post-content" data-zop-usertoken="{&quot;userToken&quot;:&quot;&quot;}" data-zop="{&quot;authorName&quot;:&quot;张楚珩&quot;,&quot;itemId&quot;:82857779,&quot;title&quot;:&quot;【强化学习 93】UCB+Q-learning&quot;,&quot;type&quot;:&quot;article&quot;}"><div class="ColumnPageHeader-Wrapper"><div><div class="Sticky ColumnPageHeader"><div class="ColumnPageHeader-content"><a href="//www.zhihu.com" aria-label="知乎"><svg viewBox="0 0 200 91" fill="#0084FF" width="64" height="30"><path d="M53.29 80.035l7.32.002 2.41 8.24 13.128-8.24h15.477v-67.98H53.29v67.978zm7.79-60.598h22.756v53.22h-8.73l-8.718 5.473-1.587-5.46-3.72-.012v-53.22zM46.818 43.162h-16.35c.545-8.467.687-16.12.687-22.955h15.987s.615-7.05-2.68-6.97H16.807c1.09-4.1 2.46-8.332 4.1-12.708 0 0-7.523 0-10.085 6.74-1.06 2.78-4.128 13.48-9.592 24.41 1.84-.2 7.927-.37 11.512-6.94.66-1.84.785-2.08 1.605-4.54h9.02c0 3.28-.374 20.9-.526 22.95H6.51c-3.67 0-4.863 7.38-4.863 7.38H22.14C20.765 66.11 13.385 79.24 0 89.62c6.403 1.828 12.784-.29 15.937-3.094 0 0 7.182-6.53 11.12-21.64L43.92 85.18s2.473-8.402-.388-12.496c-2.37-2.788-8.768-10.33-11.496-13.064l-4.57 3.627c1.363-4.368 2.183-8.61 2.46-12.71H49.19s-.027-7.38-2.372-7.38zm128.752-.502c6.51-8.013 14.054-18.302 14.054-18.302s-5.827-4.625-8.556-1.27c-1.874 2.548-11.51 15.063-11.51 15.063l6.012 4.51zm-46.903-18.462c-2.814-2.577-8.096.667-8.096.667s12.35 17.2 12.85 17.953l6.08-4.29s-8.02-11.752-10.83-14.33zM199.99 46.5c-6.18 0-40.908.292-40.953.292v-31.56c1.503 0 3.882-.124 7.14-.376 12.773-.753 21.914-1.25 27.427-1.504 0 0 3.817-8.496-.185-10.45-.96-.37-7.24 1.43-7.24 1.43s-51.63 5.153-72.61 5.64c.5 2.756 2.38 5.336 4.93 6.11 4.16 1.087 7.09.53 15.36.277 7.76-.5 13.65-.76 17.66-.76v31.19h-41.71s.88 6.97 7.97 7.14h33.73v22.16c0 4.364-3.498 6.87-7.65 6.6-4.4.034-8.15-.36-13.027-.566.623 1.24 1.977 4.496 6.035 6.824 3.087 1.502 5.054 2.053 8.13 2.053 9.237 0 14.27-5.4 14.027-14.16V53.93h38.235c3.026 0 2.72-7.432 2.72-7.432z" fill-rule="evenodd"></path></svg></a><i class="ColumnPageHeader-Line"></i><div class="ColumnPageHeader-Title"><a class="ColumnLink ColumnPageHeader-Link" href="/reinforcementlearning"><img class="Avatar Avatar--round" width="30" height="30" src="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_is.jpg" srcSet="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_im.jpg 2x" alt="强化学习前沿"/></a><div class="ColumnPageHeader-TitleName"><span class="ColumnPageHeader-TitleMeta">首发于</span><a class="ColumnLink ColumnPageHeader-TitleColumn" href="/reinforcementlearning">强化学习前沿</a></div></div><div class="ColumnPageHeader-Button"><button type="button" class="Button ColumnPageHeader-WriteButton Button--blue"><svg class="Zi Zi--EditSurround" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M18.453 7.992l-1.833-1.65.964-.978a1.223 1.223 0 0 1 1.73-.012l.005.006a1.24 1.24 0 0 1 .007 1.748l-.873.886zm-1.178 1.194l-5.578 5.66-1.935.697a.393.393 0 0 1-.504-.504l.697-1.935 5.488-5.567 1.832 1.65zM7.58 5.848l5.654.006-1.539 1.991-3.666.012A1.02 1.02 0 0 0 7 8.868v7.993c0 .558.46 1.01 1.029 1.01l7.941-.01c.568 0 1.03-.453 1.03-1.012v-4.061l2-1.442v6.002c0 1.397-1.2 2.501-2.62 2.501H7.574C6.153 19.85 5 18.717 5 17.32V8.35c0-1.397 1.16-2.502 2.58-2.502z"></path></svg>写文章</button></div></div></div></div></div><img class="TitleImage" src="https://pic1.zhimg.com/v2-95e83d7d87e922ba61b18c6a26f9f0ff_1200x500.jpg" alt="【强化学习 93】UCB+Q-learning"/><article class="Post-Main Post-NormalMain" tabindex="-1"><header class="Post-Header"><h1 class="Post-Title">【强化学习 93】UCB+Q-learning</h1><div class="Post-Author"><div class="AuthorInfo" itemProp="author" itemscope="" itemType="http://schema.org/Person"><meta itemProp="name" content="张楚珩"/><meta itemProp="image" content="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg"/><meta itemProp="url" content="https://www.zhihu.com/people/zhang-chu-heng"/><meta itemProp="zhihu:followerCount"/><span class="UserLink AuthorInfo-avatarWrapper"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/zhang-chu-heng"><img class="Avatar Avatar--round AuthorInfo-avatar" width="38" height="38" src="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_xs.jpg" srcSet="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg 2x" alt="张楚珩"/></a></div></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/zhang-chu-heng">张楚珩</a></div></div><style data-emotion-css="1cd9gw4">.css-1cd9gw4{margin-left:.3em;}</style><style data-emotion-css="1pc1mic">.css-1pc1mic{box-sizing:border-box;margin:0;min-width:0;color:#175199;display:inline-block;width:18px;height:18px;margin-left:.3em;}</style><a href="https://www.zhihu.com/question/48510028" target="_blank" class="css-1pc1mic" data-tooltip="已认证的个人" aria-label="已认证的个人"><style data-emotion-css="18biwo">.css-18biwo{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><span class="css-18biwo">​<svg viewBox="0 0 24 24" width="18" height="18"><svg viewBox="0 0 24 24" x="-3" y="-3" fill="#FFFFFF" width="30" height="30"><path d="M3.56231227,13.8535307 C2.40051305,12.768677 2.41398885,11.0669203 3.59484487,9.99979213 L3.59222085,9.99654885 C4.26730143,9.45036719 4.79446755,8.21005186 4.7184197,7.34453784 L4.72305873,7.34412719 C4.66942824,5.75539997 5.8824188,4.56066914 7.47188965,4.64242381 L7.47229112,4.6386236 C8.33515314,4.72977993 9.58467253,4.22534048 10.1426329,3.55925173 L10.1462611,3.56228565 C11.2316055,2.40008701 12.9353108,2.41394456 14.0015072,3.59634088 L14.0047263,3.59374004 C14.5498229,4.26841874 15.7896857,4.79521622 16.6545744,4.71844347 L16.6549836,4.72304294 C18.245027,4.66894057 19.4396947,5.88213996 19.3575031,7.47241135 L19.3623099,7.47292747 C19.2704388,8.3358681 19.7742711,9.58421483 20.4407199,10.1424506 L20.437686,10.1460789 C21.5997217,11.2312209 21.5860695,12.9345218 20.4042441,14.0007396 L20.4072865,14.0045125 C19.7325967,14.5495925 19.2055209,15.7896954 19.2815865,16.6561959 L19.2770449,16.6565978 C19.3315454,18.2453037 18.1173775,19.4393568 16.5274188,19.3571512 L16.5269029,19.3619539 C15.6647098,19.270083 14.415408,19.7741709 13.8573671,20.4403558 L13.8537409,20.4373235 C12.76842,21.5995708 11.0650432,21.5864553 9.99899434,20.4039226 L9.99527367,20.406923 C9.45025436,19.7323399 8.21017638,19.2051872 7.34461983,19.2812352 L7.344304,19.2776405 C5.75448683,19.3312904 4.55977145,18.1170085 4.64254978,16.527117 L4.63769921,16.5265942 C4.72957031,15.6644394 4.22547659,14.4151814 3.55928015,13.8571569 L3.56231227,13.8535307 Z"></path></svg><path d="M2.63951518,13.3895441 C3.70763333,14.2842292 4.44777637,16.1226061 4.30075305,17.5023312 L4.32211542,17.3063047 C4.17509209,18.6910561 5.17786655,19.7063729 6.5613937,19.5844846 L6.364106,19.6008202 C7.75140298,19.4789319 9.57474349,20.2554985 10.4468305,21.3349009 L10.3224262,21.1803415 C11.1982831,22.2647703 12.6257916,22.2723098 13.5167278,21.2079863 L13.3898102,21.3600325 C14.2845162,20.2919393 16.1229361,19.5518136 17.5026934,19.6988334 L17.3054057,19.6774716 C18.6914461,19.8244915 19.7067866,18.8217404 19.5836389,17.4395022 L19.6012314,17.6367853 C19.4793403,16.2482641 20.255925,14.4249662 21.3353526,13.5528995 L21.1807897,13.677301 C22.2639871,12.8014646 22.2727834,11.3739894 21.2084351,10.483074 L21.3604848,10.6099886 C20.2923667,9.71530351 19.5522236,7.87818322 19.6992469,6.49720154 L19.6778846,6.69448464 C19.8249079,5.30847665 18.8221335,4.2944164 17.4386063,4.41630468 L17.635894,4.39871256 C16.248597,4.52185742 14.4252565,3.74529084 13.5531695,2.66588842 L13.6775738,2.81919121 C12.8017169,1.73601905 11.3742084,1.72722299 10.4832722,2.79154644 L10.6101898,2.63950024 C9.71548377,3.70759343 7.87706394,4.44771919 6.49730661,4.30195588 L6.69459432,4.32206116 C5.30855394,4.17504128 4.29447,5.17904888 4.41636114,6.56128713 L4.3987686,6.36400404 C4.52065973,7.75126861 3.74407501,9.57456653 2.66464737,10.4478898 L2.81921035,10.3222318 C1.73601288,11.1993248 1.72721662,12.6255433 2.79156494,13.5164587 L2.63951518,13.3895441 Z" fill="#0084FF"></path><svg class="Zi Zi--Check" fill="#fff" x="6" y="6" viewBox="0 0 24 24" width="12" height="12"><path d="M10.229 17.516c-.318.327-.75.484-1.199.484-.453 0-.884-.16-1.202-.488l-4.335-4.47a1.77 1.77 0 0 1 .007-2.459 1.663 1.663 0 0 1 2.397.01l3.137 3.246 9.072-9.329a1.662 1.662 0 0 1 2.397 0c.663.681.663 1.786 0 2.466L10.23 17.516z" fill-rule="evenodd"></path></svg></svg></span></a></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="AuthorInfo-badgeText">清华大学 交叉信息院博士在读</div></div></div></div></div></div><div><span class="Voters"><button type="button" class="Button Button--plain">34 人<!-- -->赞同了该文章</button></span></div></header><div class="Post-RichTextContainer"><div class="RichText ztext Post-RichText"><p>这篇文章把 UCB 和 Q-learning 相结合，得到两种算法 UCB-H 和 UCB-B，这里把它们统记为 UCB + Q-learning。</p><h2>原文传送门</h2><p><a href="https://link.zhihu.com/?target=https%3A//papers.nips.cc/paper/7735-is-q-learning-provably-efficient.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Jin, Chi, et al. &#34;Is q-learning provably efficient?.&#34; Advances in Neural Information Processing Systems. 2018.</a></p><p><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1807.03765" class=" wrap external" target="_blank" rel="nofollow noreferrer">Arxiv version (It is also a best paper in ICML 2018 workshop &#34;Exploration in RL&#34;)</a></p><h2>特色</h2><p>前面有两讲讲了 PG theory，里面提到要得到一个有效的强化学习算法，探索是一个必不可少的环节。不同于常用的 epsilon-greedy 的探索形式，这里使用 upper confidence bound（UCB） 来做探索。UCB 是 MAB 问题中一个有效的解法，本来以为 UCB+Q-learning 应该是很早就有人做了的，但是这篇还算比较近，在 NIPS 2018 。</p><p>Ps，看到作者才想到去年的这个时候 Michael Jordan 来清华讲课的时候，提到过这一篇；今天大佬又来了，但是今天懒了，没去。</p><h2>过程</h2><h3>1. 背景</h3><p>在 RL 方面，文章使用 finite horizon （每个 episode 都固定 H 步）+ cumulated reward （no discount）的设定。</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-e6f937a6446cadb78c62bfe032d1e9df_b.jpg" data-caption="" data-size="normal" data-rawwidth="2350" data-rawheight="1272" class="origin_image zh-lightbox-thumb" width="2350" data-original="https://pic4.zhimg.com/v2-e6f937a6446cadb78c62bfe032d1e9df_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2350&#39; height=&#39;1272&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2350" data-rawheight="1272" class="origin_image zh-lightbox-thumb lazy" width="2350" data-original="https://pic4.zhimg.com/v2-e6f937a6446cadb78c62bfe032d1e9df_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-e6f937a6446cadb78c62bfe032d1e9df_b.jpg"/></figure><p>上表中 T 表示 sample complexity；S 和 A 分别代表状态空间和动作空间的大小；H 表示一个回合有多少步。注意到，当 H=1 时就是一个普通的 contextual MAB 问题，因此这里可以看做是一个有 H 『层』的 contextual MAP 问题。</p><p>从 regret 上来说，model-based 方法之前有 <img src="https://www.zhihu.com/equation?tex=O%28%5Csqrt%7BT%7D%29" alt="O(\sqrt{T})" eeimg="1"/> 的结果，但是这类方法需要估计一个 model，这样需要一个比较大的存储空间；model-free 的方法就只需要 online 地更新，只需要存一个价值函数或者策略即可，空间上的复杂度会更低。</p><p>Ps，文章讲了两种算法，我暂时只看了正文里面讲的 UCB-H 方法，UCB-B 方法在附录中讲的，主要额外估计了 variance 并使用它来计算 upper confidence，从而得到更好的结果。没有仔细看，因此这里不讲了。</p><h3>2. Q-learning combined with UCB</h3><p>文章最核心的想法可以从如下公式看出：</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-a5b337a2afb82779014ddc9071464acd_b.png" data-caption="" data-size="normal" data-rawwidth="2236" data-rawheight="92" class="origin_image zh-lightbox-thumb" width="2236" data-original="https://pic2.zhimg.com/v2-a5b337a2afb82779014ddc9071464acd_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2236&#39; height=&#39;92&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2236" data-rawheight="92" class="origin_image zh-lightbox-thumb lazy" width="2236" data-original="https://pic2.zhimg.com/v2-a5b337a2afb82779014ddc9071464acd_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-a5b337a2afb82779014ddc9071464acd_b.png"/></figure><p>其核心就是 Q-value 每次更新的 target 都会加上一个 exploration bonus <img src="https://www.zhihu.com/equation?tex=b_t" alt="b_t" eeimg="1"/> ，而这里的 <img src="https://www.zhihu.com/equation?tex=t+%3D+N_h%28x%2Ca%29" alt="t = N_h(x,a)" eeimg="1"/> ，表示该 <img src="https://www.zhihu.com/equation?tex=%28h%2Cx%2Ca%29" alt="(h,x,a)" eeimg="1"/> 之前遇到过多少次。文章的关键就是给出了 <img src="https://www.zhihu.com/equation?tex=%5Calpha_t%2C+b_t" alt="\alpha_t, b_t" eeimg="1"/> 的具体函数关系，并且导出了这样函数关系下相应的 regret。</p><p>UCB-H 算法如下：</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-5c973196a020acfba29d334253c53c9d_b.jpg" data-caption="" data-size="normal" data-rawwidth="2342" data-rawheight="764" class="origin_image zh-lightbox-thumb" width="2342" data-original="https://pic2.zhimg.com/v2-5c973196a020acfba29d334253c53c9d_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2342&#39; height=&#39;764&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2342" data-rawheight="764" class="origin_image zh-lightbox-thumb lazy" width="2342" data-original="https://pic2.zhimg.com/v2-5c973196a020acfba29d334253c53c9d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-5c973196a020acfba29d334253c53c9d_b.jpg"/></figure><p>该算法中，选择 <img src="https://www.zhihu.com/equation?tex=b_t+%3D+c+%5Csqrt%7BH%5E3+%5Ciota+%2F+t%7D" alt="b_t = c \sqrt{H^3 \iota / t}" eeimg="1"/> ， <img src="https://www.zhihu.com/equation?tex=%5Calpha_t+%3D+%5Cdfrac%7BH%2B1%7D%7BH%2Bt%7D" alt="\alpha_t = \dfrac{H+1}{H+t}" eeimg="1"/> 。</p><p>该算法相应的 regret 有如下保证：</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-8d935d6b0b97884cc9386339e9194e23_b.png" data-caption="" data-size="normal" data-rawwidth="2256" data-rawheight="230" class="origin_image zh-lightbox-thumb" width="2256" data-original="https://pic4.zhimg.com/v2-8d935d6b0b97884cc9386339e9194e23_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2256&#39; height=&#39;230&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2256" data-rawheight="230" class="origin_image zh-lightbox-thumb lazy" width="2256" data-original="https://pic4.zhimg.com/v2-8d935d6b0b97884cc9386339e9194e23_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-8d935d6b0b97884cc9386339e9194e23_b.png"/></figure><h3>3. 证明</h3><p>证明分为如下几个步骤：</p><ul><li>第一步：给定的是 Q-learning 的更新公式，更新公式是 bootstrap 的形式，即新的 Q 值依赖于旧的 Q 值。因此，<b><i>第一步需要把这样的『递推公式』写成『通项公式』的形式</i></b>。这其中需要到一个 tradeoff：如果过度依赖于最新的 Q 值，估计会更为 unbiased，但是 variance 会比较大（因为参考的样本数目较少）；如果过度依赖以前的 Q 值，就会产生更大的 bias。 <img src="https://www.zhihu.com/equation?tex=%5Calpha_t" alt="\alpha_t" eeimg="1"/> 的选取方式就是在平衡这样一个 tradeoff。</li><li>第二步：虽然最后我们需要的 regret 是比较最优策略的性能和每一轮策略的性能，但是策略是依赖于所估计的 Q 函数值的，因此在<b><i>第二步中需要先 bound 所估计的 Q 函数值和最优 Q 函数值的差距，即 <img src="https://www.zhihu.com/equation?tex=Q%5Ek+-+Q%5E%2A" alt="Q^k - Q^*" eeimg="1"/> </i></b>。这一步中最为核心的想法是，如果某一个 <img src="https://www.zhihu.com/equation?tex=%28h%2Cx%2Ca%29" alt="(h,x,a)" eeimg="1"/> 被访问的次数多（ <img src="https://www.zhihu.com/equation?tex=t" alt="t" eeimg="1"/> 比较大），那么对它的估计就更准确，相应地，可以匹配一个较小的 exploration bonus <img src="https://www.zhihu.com/equation?tex=b_t" alt="b_t" eeimg="1"/> ；反之，就需要一个更大的 exploration bonus 来鼓励探索。这一步依赖于前一步中写出的『通项公式』。</li><li>第三步：<b><i>把 regret 写出来，并且进行缩放改写，最后利用前述性质推导其上界</i></b>。其中核心的想法是，regret 关心的是 <img src="https://www.zhihu.com/equation?tex=V_1%28x_1%29" alt="V_1(x_1)" eeimg="1"/> 的差值，然而它的差值又可以写作后一个状态价值函数 <img src="https://www.zhihu.com/equation?tex=V_2%28x_2%29" alt="V_2(x_2)" eeimg="1"/> 的差值，以此类推，到最后（第 <img src="https://www.zhihu.com/equation?tex=H%2B1" alt="H+1" eeimg="1"/> 步）各个价值函数又是相同的了（即，误差为零）。因此，误差是从 <img src="https://www.zhihu.com/equation?tex=H" alt="H" eeimg="1"/> 步往回累加起来的。因此，需要注意误差传递的途径，然后写出最后的 regret 形式。</li></ul><p><b><i>预备：更新公式</i></b></p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-9945d5d8face81b2e415a425d6f5fd3e_b.png" data-caption="" data-size="normal" data-rawwidth="1896" data-rawheight="164" class="origin_image zh-lightbox-thumb" width="1896" data-original="https://pic3.zhimg.com/v2-9945d5d8face81b2e415a425d6f5fd3e_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1896&#39; height=&#39;164&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1896" data-rawheight="164" class="origin_image zh-lightbox-thumb lazy" width="1896" data-original="https://pic3.zhimg.com/v2-9945d5d8face81b2e415a425d6f5fd3e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-9945d5d8face81b2e415a425d6f5fd3e_b.png"/></figure><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-5a2e050f01fcd9175518d840a35b72f2_b.png" data-caption="" data-size="normal" data-rawwidth="1874" data-rawheight="102" class="origin_image zh-lightbox-thumb" width="1874" data-original="https://pic3.zhimg.com/v2-5a2e050f01fcd9175518d840a35b72f2_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1874&#39; height=&#39;102&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1874" data-rawheight="102" class="origin_image zh-lightbox-thumb lazy" width="1874" data-original="https://pic3.zhimg.com/v2-5a2e050f01fcd9175518d840a35b72f2_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-5a2e050f01fcd9175518d840a35b72f2_b.png"/></figure><p>其中上标 <img src="https://www.zhihu.com/equation?tex=k%5Cin%5BK%5D" alt="k\in[K]" eeimg="1"/> 表示是第 k 个 episode，而下标 <img src="https://www.zhihu.com/equation?tex=h%5Cin%5BH%5D" alt="h\in[H]" eeimg="1"/> 表示是 episode 中的第几步。注意到，每一步的奖励在 <img src="https://www.zhihu.com/equation?tex=%5B0%2C1%5D" alt="[0,1]" eeimg="1"/> 之间，因此价值函数不超过 H，因此状态价值函数会使用 H 来截断。</p><p><b><i>预备： <img src="https://www.zhihu.com/equation?tex=%5Calpha_t" alt="\alpha_t" eeimg="1"/> 的性质</i></b></p><p>文章选择 <img src="https://www.zhihu.com/equation?tex=%5Calpha_t+%3D+%5Cdfrac%7BH%2B1%7D%7BH%2Bt%7D" alt="\alpha_t = \dfrac{H+1}{H+t}" eeimg="1"/> ，如果定义</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-c293366fa19b104b9419e54491c3c753_b.png" data-caption="" data-size="normal" data-rawwidth="1894" data-rawheight="102" class="origin_image zh-lightbox-thumb" width="1894" data-original="https://pic4.zhimg.com/v2-c293366fa19b104b9419e54491c3c753_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1894&#39; height=&#39;102&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1894" data-rawheight="102" class="origin_image zh-lightbox-thumb lazy" width="1894" data-original="https://pic4.zhimg.com/v2-c293366fa19b104b9419e54491c3c753_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-c293366fa19b104b9419e54491c3c753_b.png"/></figure><p>容易验证它具有如下性质。上述定义的作用后面将会看到。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-1d5ad86b5044bb070d419d8ae56241fa_b.jpg" data-caption="" data-size="normal" data-rawwidth="1604" data-rawheight="324" class="origin_image zh-lightbox-thumb" width="1604" data-original="https://pic3.zhimg.com/v2-1d5ad86b5044bb070d419d8ae56241fa_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1604&#39; height=&#39;324&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1604" data-rawheight="324" class="origin_image zh-lightbox-thumb lazy" width="1604" data-original="https://pic3.zhimg.com/v2-1d5ad86b5044bb070d419d8ae56241fa_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-1d5ad86b5044bb070d419d8ae56241fa_b.jpg"/></figure><p><b><i>第一步：价值函数的通项公式</i></b></p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-17a3f2efeb69571fe64c0d7b44db52e0_b.png" data-caption="" data-size="normal" data-rawwidth="1902" data-rawheight="146" class="origin_image zh-lightbox-thumb" width="1902" data-original="https://pic1.zhimg.com/v2-17a3f2efeb69571fe64c0d7b44db52e0_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1902&#39; height=&#39;146&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1902" data-rawheight="146" class="origin_image zh-lightbox-thumb lazy" width="1902" data-original="https://pic1.zhimg.com/v2-17a3f2efeb69571fe64c0d7b44db52e0_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-17a3f2efeb69571fe64c0d7b44db52e0_b.png"/></figure><p>这里我们就能观察到刚刚所定义的 <img src="https://www.zhihu.com/equation?tex=%5Calpha_t%5Ei" alt="\alpha_t^i" eeimg="1"/> 的作用了，它其实是在第 t 步时各项实际的权重。前面说到 <img src="https://www.zhihu.com/equation?tex=%5Calpha_t" alt="\alpha_t" eeimg="1"/> 的设置涉及到一个 bias-variance tradeoff：如果对于一个固定的 t， <img src="https://www.zhihu.com/equation?tex=%5Calpha_t%5Ei" alt="\alpha_t^i" eeimg="1"/> 特别倾向于最新的 target Q value（上式方括号中的式子），那么就会产生较大的 variance；对于一个固定的 t， <img src="https://www.zhihu.com/equation?tex=%5Calpha_t%5Ei" alt="\alpha_t^i" eeimg="1"/> 比较平均地对历史上遇到的 target Q value 加权，那么会导致较大的 bias。文章采取的这种加权方案能够使得不管 t 为多少，都几乎只考虑最后的 <img src="https://www.zhihu.com/equation?tex=1%2FH" alt="1/H" eeimg="1"/>  份的样本，而最开始的 <img src="https://www.zhihu.com/equation?tex=1-1%2FH" alt="1-1/H" eeimg="1"/> 份样本会被『遗忘』。从下图可以看出这一点。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-0c23203fc97b20fa2af32fbb8f6f5318_b.jpg" data-caption="" data-size="normal" data-rawwidth="2012" data-rawheight="588" class="origin_image zh-lightbox-thumb" width="2012" data-original="https://pic1.zhimg.com/v2-0c23203fc97b20fa2af32fbb8f6f5318_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2012&#39; height=&#39;588&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2012" data-rawheight="588" class="origin_image zh-lightbox-thumb lazy" width="2012" data-original="https://pic1.zhimg.com/v2-0c23203fc97b20fa2af32fbb8f6f5318_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-0c23203fc97b20fa2af32fbb8f6f5318_b.jpg"/></figure><p>注意到，第 h 层的价值函数依赖于第 h+1 层的价值函数，即价值函数是一层层传递过来的，因此总体上来看，所有的样本都能够得到有效地利用。</p><p><b><i>第二步：估计价值函数和最优价值函数的差距</i></b></p><p>首先可以得到，如下式子</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-77e05ac0ebcdbf467aff4c3c9f4ada5a_b.png" data-caption="" data-size="normal" data-rawwidth="1892" data-rawheight="292" class="origin_image zh-lightbox-thumb" width="1892" data-original="https://pic3.zhimg.com/v2-77e05ac0ebcdbf467aff4c3c9f4ada5a_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1892&#39; height=&#39;292&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1892" data-rawheight="292" class="origin_image zh-lightbox-thumb lazy" width="1892" data-original="https://pic3.zhimg.com/v2-77e05ac0ebcdbf467aff4c3c9f4ada5a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-77e05ac0ebcdbf467aff4c3c9f4ada5a_b.png"/></figure><p>注意到</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-4a732d8ec207d2c565536b607fa4aa2f_b.png" data-caption="" data-size="normal" data-rawwidth="1650" data-rawheight="62" class="origin_image zh-lightbox-thumb" width="1650" data-original="https://pic4.zhimg.com/v2-4a732d8ec207d2c565536b607fa4aa2f_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1650&#39; height=&#39;62&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1650" data-rawheight="62" class="origin_image zh-lightbox-thumb lazy" width="1650" data-original="https://pic4.zhimg.com/v2-4a732d8ec207d2c565536b607fa4aa2f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-4a732d8ec207d2c565536b607fa4aa2f_b.png"/></figure><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-6acd04aed2e11aa619cb81ce7cec80d4_b.png" data-caption="" data-size="normal" data-rawwidth="1596" data-rawheight="82" class="origin_image zh-lightbox-thumb" width="1596" data-original="https://pic1.zhimg.com/v2-6acd04aed2e11aa619cb81ce7cec80d4_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1596&#39; height=&#39;82&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1596" data-rawheight="82" class="origin_image zh-lightbox-thumb lazy" width="1596" data-original="https://pic1.zhimg.com/v2-6acd04aed2e11aa619cb81ce7cec80d4_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-6acd04aed2e11aa619cb81ce7cec80d4_b.png"/></figure><p>接下来，考虑到 <img src="https://www.zhihu.com/equation?tex=%5Chat%7B%5Cmathbb%7BP%7D%7D-%5Cmathbb%7BP%7D" alt="\hat{\mathbb{P}}-\mathbb{P}" eeimg="1"/> 其实就是 sample mean - true mean，可以使用 concentration inequality 来 bound 这一项；直观来说，就是越多的样本估计的越准确。</p><p>由此，可以得到如下引理：</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-c028c4b510755e07490fc7e35e495c7d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1912" data-rawheight="432" class="origin_image zh-lightbox-thumb" width="1912" data-original="https://pic2.zhimg.com/v2-c028c4b510755e07490fc7e35e495c7d_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1912&#39; height=&#39;432&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1912" data-rawheight="432" class="origin_image zh-lightbox-thumb lazy" width="1912" data-original="https://pic2.zhimg.com/v2-c028c4b510755e07490fc7e35e495c7d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-c028c4b510755e07490fc7e35e495c7d_b.jpg"/></figure><p>文章中写 <img src="https://www.zhihu.com/equation?tex=%5Ciota+%3D+%5Clog%28SAT%2Fp%29" alt="\iota = \log(SAT/p)" eeimg="1"/> ，但是我推导了半天感觉是 <img src="https://www.zhihu.com/equation?tex=%5Ciota+%3D+%5Clog%28%7BSAH%2Fp%7D%29" alt="\iota = \log({SAH/p})" eeimg="1"/> 。。。反正，最重要的就是对于每一个 <img src="https://www.zhihu.com/equation?tex=%28h%2Cx%2Ca%29" alt="(h,x,a)" eeimg="1"/> 应用 Azuma-Hoeffding，然后再加 union bound 合起来，这样就能得到 <img src="https://www.zhihu.com/equation?tex=%5Chat%7B%5Cmathbb%7BP%7D%7D-%5Cmathbb%7BP%7D" alt="\hat{\mathbb{P}}-\mathbb{P}" eeimg="1"/> 项的界，接下来就需要设置 <img src="https://www.zhihu.com/equation?tex=b_t" alt="b_t" eeimg="1"/> 来匹配相应的界，使得所估计的 Q 值大概率是 <img src="https://www.zhihu.com/equation?tex=Q%5E%2A" alt="Q^*" eeimg="1"/> 的上界，但是同时也比较紧（不会比 <img src="https://www.zhihu.com/equation?tex=Q%5E%2A" alt="Q^*" eeimg="1"/> 大太多）。</p><p><b><i>第三步：计算 regret</i></b></p><p>首先注意到：由于估计的 Q 值是 upper confidence，因此第 k 轮估计的 Q 值 <img src="https://www.zhihu.com/equation?tex=Q_h%5Ek" alt="Q_h^k" eeimg="1"/> 、最优 Q 值 <img src="https://www.zhihu.com/equation?tex=Q_h%5E%2A" alt="Q_h^*" eeimg="1"/> 和实际策略的 Q 值 <img src="https://www.zhihu.com/equation?tex=Q_h%5E%7B%5Cpi_k%7D" alt="Q_h^{\pi_k}" eeimg="1"/> 的关系大致为： <img src="https://www.zhihu.com/equation?tex=Q_h%5Ek+%3EQ_h%5E%2A%3EQ_h%5E%7B%5Cpi_k%7D" alt="Q_h^k &gt;Q_h^*&gt;Q_h^{\pi_k}" eeimg="1"/> 。定义</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-36bc0c23ddccaf1edd2c2ec67535644c_b.png" data-caption="" data-size="normal" data-rawwidth="1872" data-rawheight="70" class="origin_image zh-lightbox-thumb" width="1872" data-original="https://pic1.zhimg.com/v2-36bc0c23ddccaf1edd2c2ec67535644c_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1872&#39; height=&#39;70&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1872" data-rawheight="70" class="origin_image zh-lightbox-thumb lazy" width="1872" data-original="https://pic1.zhimg.com/v2-36bc0c23ddccaf1edd2c2ec67535644c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-36bc0c23ddccaf1edd2c2ec67535644c_b.png"/></figure><p>因此，regret 可以被 bound 为</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-757274c333f3f736ba1e61a2093e03b7_b.png" data-caption="" data-size="normal" data-rawwidth="1906" data-rawheight="106" class="origin_image zh-lightbox-thumb" width="1906" data-original="https://pic4.zhimg.com/v2-757274c333f3f736ba1e61a2093e03b7_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1906&#39; height=&#39;106&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1906" data-rawheight="106" class="origin_image zh-lightbox-thumb lazy" width="1906" data-original="https://pic4.zhimg.com/v2-757274c333f3f736ba1e61a2093e03b7_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-757274c333f3f736ba1e61a2093e03b7_b.png"/></figure><p>而 <img src="https://www.zhihu.com/equation?tex=%5Cdelta_h" alt="\delta_h" eeimg="1"/> 和后续的 <img src="https://www.zhihu.com/equation?tex=%5Cdelta_%7Bh%2B1%7D" alt="\delta_{h+1}" eeimg="1"/> 又具有一定的联系</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-ec8a0eb07fa1f4876b36b330092a1971_b.jpg" data-caption="" data-size="normal" data-rawwidth="1870" data-rawheight="350" class="origin_image zh-lightbox-thumb" width="1870" data-original="https://pic2.zhimg.com/v2-ec8a0eb07fa1f4876b36b330092a1971_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1870&#39; height=&#39;350&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1870" data-rawheight="350" class="origin_image zh-lightbox-thumb lazy" width="1870" data-original="https://pic2.zhimg.com/v2-ec8a0eb07fa1f4876b36b330092a1971_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-ec8a0eb07fa1f4876b36b330092a1971_b.jpg"/></figure><p>① 中的小于等于号是由于 estimated V 定义中有一个 clip 操作，同时策略就是确定性地选择 <img src="https://www.zhihu.com/equation?tex=a_h%5Ek" alt="a_h^k" eeimg="1"/> ，因此 <img src="https://www.zhihu.com/equation?tex=V_h%5E%7B%5Cpi_k%7D%28s_h%5Ek%29+%3D+Q%5E%7B%5Cpi_k%7D%28s_h%5Ek%2C+%5Cpi_k%29+%3D+Q%5E%7B%5Cpi_k%7D%28s_h%5Ek%2C+a_h%5Ek%29" alt="V_h^{\pi_k}(s_h^k) = Q^{\pi_k}(s_h^k, \pi_k) = Q^{\pi_k}(s_h^k, a_h^k)" eeimg="1"/> 。② 用到了前一步的结论，以及 <img src="https://www.zhihu.com/equation?tex=%5Cmathbb%7BP%7D_h" alt="\mathbb{P}_h" eeimg="1"/> 算子的定义。③ 是恒等变化，需要注意到 <img src="https://www.zhihu.com/equation?tex=%5Chat%7B%5Cmathbb%7BP%7D%7D_h" alt="\hat{\mathbb{P}}_h" eeimg="1"/> 算子的定义，其中</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-e622769cca2fbb935c2e4438c8dfc1f5_b.png" data-caption="" data-size="normal" data-rawwidth="2106" data-rawheight="64" class="origin_image zh-lightbox-thumb" width="2106" data-original="https://pic2.zhimg.com/v2-e622769cca2fbb935c2e4438c8dfc1f5_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2106&#39; height=&#39;64&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2106" data-rawheight="64" class="origin_image zh-lightbox-thumb lazy" width="2106" data-original="https://pic2.zhimg.com/v2-e622769cca2fbb935c2e4438c8dfc1f5_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-e622769cca2fbb935c2e4438c8dfc1f5_b.png"/></figure><p>绿框部分：注意到 <img src="https://www.zhihu.com/equation?tex=Q_h%5Ek+%3EQ_h%5E%2A%3EQ_h%5E%7B%5Cpi_k%7D" alt="Q_h^k &gt;Q_h^*&gt;Q_h^{\pi_k}" eeimg="1"/> ，这里其实是把 optimal V - policy V，放大成了 estimated V - policy V；但是看似矛盾的是，后面又拆成了 (estimated Q - optimal Q) + (optimal Q - policy Q)。但其实不矛盾的，一步过来的话，① 中的小于等于号是不成立的。</p><p>其中第一项</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-b9515394ff728f17c2376f34b55551eb_b.png" data-caption="" data-size="normal" data-rawwidth="1920" data-rawheight="178" class="origin_image zh-lightbox-thumb" width="1920" data-original="https://pic4.zhimg.com/v2-b9515394ff728f17c2376f34b55551eb_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1920&#39; height=&#39;178&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1920" data-rawheight="178" class="origin_image zh-lightbox-thumb lazy" width="1920" data-original="https://pic4.zhimg.com/v2-b9515394ff728f17c2376f34b55551eb_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-b9515394ff728f17c2376f34b55551eb_b.png"/></figure><p>第二项</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-8ff8ef4c70c317e0b9c543e2eb6d41cc_b.png" data-caption="" data-size="normal" data-rawwidth="1910" data-rawheight="166" class="origin_image zh-lightbox-thumb" width="1910" data-original="https://pic1.zhimg.com/v2-8ff8ef4c70c317e0b9c543e2eb6d41cc_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1910&#39; height=&#39;166&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1910" data-rawheight="166" class="origin_image zh-lightbox-thumb lazy" width="1910" data-original="https://pic1.zhimg.com/v2-8ff8ef4c70c317e0b9c543e2eb6d41cc_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-8ff8ef4c70c317e0b9c543e2eb6d41cc_b.png"/></figure><p>根据 <img src="https://www.zhihu.com/equation?tex=%5Cdelta_h%5Ek+%5Cge+%5Cphi_h%5Ek+" alt="\delta_h^k \ge \phi_h^k " eeimg="1"/> ，有</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-1775fc8faeb6d2a952e62c9776a179ae_b.png" data-caption="" data-size="normal" data-rawwidth="1882" data-rawheight="304" class="origin_image zh-lightbox-thumb" width="1882" data-original="https://pic3.zhimg.com/v2-1775fc8faeb6d2a952e62c9776a179ae_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1882&#39; height=&#39;304&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1882" data-rawheight="304" class="origin_image zh-lightbox-thumb lazy" width="1882" data-original="https://pic3.zhimg.com/v2-1775fc8faeb6d2a952e62c9776a179ae_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-1775fc8faeb6d2a952e62c9776a179ae_b.png"/></figure><p>根据递推关系，能够得到</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-4f85cd72942cac212f0bd653f7883740_b.png" data-caption="" data-size="normal" data-rawwidth="1880" data-rawheight="162" class="origin_image zh-lightbox-thumb" width="1880" data-original="https://pic1.zhimg.com/v2-4f85cd72942cac212f0bd653f7883740_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1880&#39; height=&#39;162&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1880" data-rawheight="162" class="origin_image zh-lightbox-thumb lazy" width="1880" data-original="https://pic1.zhimg.com/v2-4f85cd72942cac212f0bd653f7883740_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-4f85cd72942cac212f0bd653f7883740_b.png"/></figure><p>最后 bound <img src="https://www.zhihu.com/equation?tex=%5Cbeta" alt="\beta" eeimg="1"/> 项和 <img src="https://www.zhihu.com/equation?tex=%5Cxi" alt="\xi" eeimg="1"/> 项即可：</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-55da71515bfbeb21ea158ed621cfd353_b.png" data-caption="" data-size="normal" data-rawwidth="1930" data-rawheight="180" class="origin_image zh-lightbox-thumb" width="1930" data-original="https://pic4.zhimg.com/v2-55da71515bfbeb21ea158ed621cfd353_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1930&#39; height=&#39;180&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1930" data-rawheight="180" class="origin_image zh-lightbox-thumb lazy" width="1930" data-original="https://pic4.zhimg.com/v2-55da71515bfbeb21ea158ed621cfd353_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-55da71515bfbeb21ea158ed621cfd353_b.png"/></figure><p>其中，① 需要注意到 <img src="https://www.zhihu.com/equation?tex=%5Csum_%7Bx%2Ca%7D+N_h%5Ek%28x%2Ca%29%3DK" alt="\sum_{x,a} N_h^k(x,a)=K" eeimg="1"/> ，因此取 <img src="https://www.zhihu.com/equation?tex=N_h%5Ek%28x%2Ca%29%3DK%2FSA%2C+%5Cforall+h%2C+x%2C+a" alt="N_h^k(x,a)=K/SA, \forall h, x, a" eeimg="1"/> 时能得到 upper bound。同时用积分来 bound 级数，有 <img src="https://www.zhihu.com/equation?tex=%5Csum_%7Bi%3D1%7D%5En+%5Cdfrac%7B1%7D%7B%5Csqrt%7Bi%7D%7D+%5Cle+1%2B%5Cint_1%5En+%5Cdfrac%7B1%7D%7B%5Csqrt%7Bx%7D%7D+dx+%3D+2%5Csqrt%7Bn%7D" alt="\sum_{i=1}^n \dfrac{1}{\sqrt{i}} \le 1+\int_1^n \dfrac{1}{\sqrt{x}} dx = 2\sqrt{n}" eeimg="1"/> 。</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-7c772a8a2f770bfce0d53f5ba77854bd_b.png" data-caption="" data-size="normal" data-rawwidth="1902" data-rawheight="162" class="origin_image zh-lightbox-thumb" width="1902" data-original="https://pic2.zhimg.com/v2-7c772a8a2f770bfce0d53f5ba77854bd_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1902&#39; height=&#39;162&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1902" data-rawheight="162" class="origin_image zh-lightbox-thumb lazy" width="1902" data-original="https://pic2.zhimg.com/v2-7c772a8a2f770bfce0d53f5ba77854bd_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-7c772a8a2f770bfce0d53f5ba77854bd_b.png"/></figure><p>注意到 <img src="https://www.zhihu.com/equation?tex=%5Cxi" alt="\xi" eeimg="1"/> 是 martingale difference sequence，使用 Azuma-Hoeffding 就可以得到上式。</p><p>最后得到：</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-9305d4b98e37d92af3aa6e1d66ff0048_b.png" data-caption="" data-size="normal" data-rawwidth="1870" data-rawheight="62" class="origin_image zh-lightbox-thumb" width="1870" data-original="https://pic1.zhimg.com/v2-9305d4b98e37d92af3aa6e1d66ff0048_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1870&#39; height=&#39;62&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1870" data-rawheight="62" class="origin_image zh-lightbox-thumb lazy" width="1870" data-original="https://pic1.zhimg.com/v2-9305d4b98e37d92af3aa6e1d66ff0048_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-9305d4b98e37d92af3aa6e1d66ff0048_b.png"/></figure><hr/><h3>Azuma-Hoeffding Inequality</h3><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-ab14efb569a2b055ccafd566be1a3200_b.jpg" data-caption="" data-size="normal" data-rawwidth="943" data-rawheight="255" class="origin_image zh-lightbox-thumb" width="943" data-original="https://pic1.zhimg.com/v2-ab14efb569a2b055ccafd566be1a3200_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;943&#39; height=&#39;255&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="943" data-rawheight="255" class="origin_image zh-lightbox-thumb lazy" width="943" data-original="https://pic1.zhimg.com/v2-ab14efb569a2b055ccafd566be1a3200_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-ab14efb569a2b055ccafd566be1a3200_b.jpg"/></figure><p>各种 paper 里面比较喜欢写成如下形式：</p><p>With probability at least <img src="https://www.zhihu.com/equation?tex=1-p" alt="1-p" eeimg="1"/> ,  <img src="https://www.zhihu.com/equation?tex=%7CS_n%7C+%5Cle+%5Csqrt%7B2+%5Clog%28%5Cdfrac%7B2%7D%7Bp%7D%29+%5Csum_%7Bj%3D1%7D%5En+%5Csigma_j%5E2%7D" alt="|S_n| \le \sqrt{2 \log(\dfrac{2}{p}) \sum_{j=1}^n \sigma_j^2}" eeimg="1"/> .</p><hr/><h3>Regret 和 PAC Guarantee 的关系</h3><p>前面说到分析 regret 和分析 PAC（或者应该也可以叫做 finite sample analysis）是等价的。这里给出具体的等价关系。</p><p>PAC 分析的是需要多少样本能够找到一个 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon" alt="\epsilon" eeimg="1"/> -optimal 的策略，即 <img src="https://www.zhihu.com/equation?tex=V_1%5E%2A%28x_1%29-V_1%5E%5Cpi%28x_1%29+%5Cle+%5Cepsilon" alt="V_1^*(x_1)-V_1^\pi(x_1) \le \epsilon" eeimg="1"/> ；regret 分析的结论通常可以表示为 <img src="https://www.zhihu.com/equation?tex=%5Csum_%7Bk%3D1%7D%5EK%5BV_1%5E%2A%28x_1%29+-+V_1%5E%7B%5Cpi_k%7D%28x_1%29%5D+%5Cle+C+%5Ccdot+T%5E%7B1-%5Calpha%7D+%3D+CHK+T%5E%7B-%5Calpha%7D" alt="\sum_{k=1}^K[V_1^*(x_1) - V_1^{\pi_k}(x_1)] \le C \cdot T^{1-\alpha} = CHK T^{-\alpha}" eeimg="1"/> 。</p><ul><li>从 regret 到 PAC：随机取一个 <img src="https://www.zhihu.com/equation?tex=%5Cpi+%3D%5Cpi_k%2C+k%5Cin%5BK%5D" alt="\pi =\pi_k, k\in[K]" eeimg="1"/> ，大概率地有 <img src="https://www.zhihu.com/equation?tex=V_1%5E%2A%28x_1%29+-+V%5E%5Cpi_1%28x_1%29+%5Cle+nC+H+T%5E%7B-%5Calpha%7D%2C+n+%3E1" alt="V_1^*(x_1) - V^\pi_1(x_1) \le nC H T^{-\alpha}, n &gt;1" eeimg="1"/> ，因此找到一个 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon" alt="\epsilon" eeimg="1"/> -optimal 的策略需要的样本大概是 <img src="https://www.zhihu.com/equation?tex=T%3DO%5Cleft%28%5Cleft%28%5Cdfrac%7BCH%7D%7B%5Cepsilon%7D%5Cright%29%5E%7B1%2F%5Calpha%7D%5Cright%29" alt="T=O\left(\left(\dfrac{CH}{\epsilon}\right)^{1/\alpha}\right)" eeimg="1"/> 。比如文章的 UCB-H、UCB-B 的 sample complexity 分别是 <img src="https://www.zhihu.com/equation?tex=%5Ctilde+O%28H%5E5SA%2F%5Cepsilon%5E2%29" alt="\tilde O(H^5SA/\epsilon^2)" eeimg="1"/> 和 <img src="https://www.zhihu.com/equation?tex=%5Ctilde+O%28H%5E4SA%2F%5Cepsilon%5E2%29" alt="\tilde O(H^4SA/\epsilon^2)" eeimg="1"/> 。</li><li>从 PAC 到 regret：如果用 <img src="https://www.zhihu.com/equation?tex=T_1%3DC+%5Cepsilon%5E%7B-%5Cbeta%7D" alt="T_1=C \epsilon^{-\beta}" eeimg="1"/> 的样本找到了一个 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon" alt="\epsilon" eeimg="1"/> -optimal 的策略，那么可以用剩下的 <img src="https://www.zhihu.com/equation?tex=T-T_1" alt="T-T_1" eeimg="1"/> 步继续这个策略，从而得到总 regret = <img src="https://www.zhihu.com/equation?tex=O%28T_1+%2B+%5Cepsilon+%28T-T_1%29%2FH%29" alt="O(T_1 + \epsilon (T-T_1)/H)" eeimg="1"/> ，选择合适的 <img src="https://www.zhihu.com/equation?tex=T_1" alt="T_1" eeimg="1"/> 使得 regret 最小，可以得到最小的 regret 为 <img src="https://www.zhihu.com/equation?tex=O%28C%5E%7B1%2B%5Cbeta%7D+%28T%2FH%29%5E%7B%5Cbeta%2F1%2B%5Cbeta%7D%29" alt="O(C^{1+\beta} (T/H)^{\beta/1+\beta})" eeimg="1"/> 。比如，如果 sample complexity <img src="https://www.zhihu.com/equation?tex=%5Cpropto+1%2F%5Cepsilon%5E4" alt="\propto 1/\epsilon^4" eeimg="1"/> ，则 regret <img src="https://www.zhihu.com/equation?tex=%5Cpropto+T%5E%7B4%2F5%7D" alt="\propto T^{4/5}" eeimg="1"/> 。</li></ul><hr/><h3>疑问</h3><p>这篇文章的推导总感觉有点问题（也可能是我自己搞错了），在这里记录一下，如果之后需要用，需要核实一下。同时有些地方也怪怪的，也记录一下，有空再想想。</p><ul><li>关于 <img src="https://www.zhihu.com/equation?tex=%5Ciota" alt="\iota" eeimg="1"/> ：产生在 Lemma 4.3 的 Azuma-Hoeffding + union bound 中，我得到的 <img src="https://www.zhihu.com/equation?tex=%5Ciota+%3D+%5Clog%28%7BSAH%2Fp%7D%29" alt="\iota = \log({SAH/p})" eeimg="1"/> 不含 T，文中是 <img src="https://www.zhihu.com/equation?tex=%5Ciota+%3D+%5Clog%28%7BSAT%2Fp%7D%29" alt="\iota = \log({SAT/p})" eeimg="1"/> ，含有 T 的，并且文章后面多次出现，应该不是打印错了。</li><li>Theorem 1 证明的最后面：得到 <img src="https://www.zhihu.com/equation?tex=O%28H%5E2SA%2B%5Csqrt%7BH%5E4SAT%5Ciota%7D%29" alt="O(H^2SA+\sqrt{H^4SAT\iota})" eeimg="1"/> 之后，文章里面下面一段话完全没理解。要是令 <img src="https://www.zhihu.com/equation?tex=H%5E2SA%3D%5Csqrt%7BH%5E4SAT%5Ciota%7D" alt="H^2SA=\sqrt{H^4SAT\iota}" eeimg="1"/> 得到的结果也是 <img src="https://www.zhihu.com/equation?tex=T%3DSA%2F%5Ciota" alt="T=SA/\iota" eeimg="1"/> 啊。</li></ul><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-55b1186872977307b2ca655811d1ecd7_b.png" data-caption="" data-size="normal" data-rawwidth="1880" data-rawheight="188" class="origin_image zh-lightbox-thumb" width="1880" data-original="https://pic4.zhimg.com/v2-55b1186872977307b2ca655811d1ecd7_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1880&#39; height=&#39;188&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1880" data-rawheight="188" class="origin_image zh-lightbox-thumb lazy" width="1880" data-original="https://pic4.zhimg.com/v2-55b1186872977307b2ca655811d1ecd7_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-55b1186872977307b2ca655811d1ecd7_b.png"/></figure><ul><li>关于最后的结论：文章假定了 <img src="https://www.zhihu.com/equation?tex=R_%5Cmax%3D1" alt="R_\max=1" eeimg="1"/> ，其实最后的 regret 中至少应该有一个 <img src="https://www.zhihu.com/equation?tex=H+%5Cto+H+R_%5Cmax" alt="H \to H R_\max" eeimg="1"/> 。</li><li>文章的设定也比较奇怪：</li><ul><li>首先，使用 finite horizon + undiscounted cumulative reward，这一点也不算太奇怪，但是比较奇怪的是默认当前的步数 <img src="https://www.zhihu.com/equation?tex=h" alt="h" eeimg="1"/> 也是状态的一部分；这相当于每回合 H 步都不可能有重复的状态，并且每『层』的状态空间都是分离的。这一点对于分析有什么特别的影响呢？文章这样的设定看起来更强，因为对于不同的 h 可以有不同的 <img src="https://www.zhihu.com/equation?tex=%5Cmathbb%7BP%7D_h" alt="\mathbb{P}_h" eeimg="1"/> 。</li><li>其次，一般认为初始状态是从一个分布中采集的，但是这里认为是对手选定的。看起来文章的这种假设更强，是不是这样呢？</li></ul><li>MDP 本身的探索难问题反映在分析的哪个地方：有些 MDP 本身就探索难（某些状态不容易被访问到，比如 Kakede&amp;Langford02 中的第一个例子），如果有些状态学习中一直没有探索到，那么突然遇到时肯定『不知所措』，这时文章假定会遭受一个最大的损失 <img src="https://www.zhihu.com/equation?tex=H" alt="H" eeimg="1"/> （蓝框部分），这产生了 regret 中的常数项（与 T 无关项）。但是下一次再遇到该状态的时候，就不会有这么大的损失了。</li><li>有些时候 <img src="https://www.zhihu.com/equation?tex=%5Cmathbb%7BP%7D" alt="\mathbb{P}" eeimg="1"/> 随机性大小不定，如果除了估计均值之外还估计方差，应该可以得到更多信息。这大概是附录里面讲的 Bernstein 探索方法。再往后想，大概是 distributional RL + UCB？</li></ul></div></div><div class="ContentItem-time">发布于 2019-09-18</div><div class="Post-topicsAndReviewer"><div class="TopicList Post-Topics"><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/20039099" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习 (Reinforcement Learning)</div></div></a></span></div></div></div><div><div class="Sticky RichContent-actions is-bottom"><div class="ContentItem-actions"><span><button aria-label="赞同 34 " type="button" class="Button VoteButton VoteButton--up"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleUp VoteButton-TriangleUp" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M2 18.242c0-.326.088-.532.237-.896l7.98-13.203C10.572 3.57 11.086 3 12 3c.915 0 1.429.571 1.784 1.143l7.98 13.203c.15.364.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H3.955c-1.08 0-1.955-.517-1.955-1.9z" fill-rule="evenodd"></path></svg></span>赞同 34</button><button aria-label="反对" type="button" class="Button VoteButton VoteButton--down"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleDown" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M20.044 3H3.956C2.876 3 2 3.517 2 4.9c0 .326.087.533.236.896L10.216 19c.355.571.87 1.143 1.784 1.143s1.429-.572 1.784-1.143l7.98-13.204c.149-.363.236-.57.236-.896 0-1.386-.876-1.9-1.956-1.9z" fill-rule="evenodd"></path></svg></span></button></span><button type="button" class="Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Comment Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M10.241 19.313a.97.97 0 0 0-.77.2 7.908 7.908 0 0 1-3.772 1.482.409.409 0 0 1-.38-.637 5.825 5.825 0 0 0 1.11-2.237.605.605 0 0 0-.227-.59A7.935 7.935 0 0 1 3 11.25C3 6.7 7.03 3 12 3s9 3.7 9 8.25-4.373 9.108-10.759 8.063z" fill-rule="evenodd"></path></svg></span>4 条评论</button><div class="Popover ShareMenu"><div class="ShareMenu-toggler" id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Share Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2.931 7.89c-1.067.24-1.275 1.669-.318 2.207l5.277 2.908 8.168-4.776c.25-.127.477.198.273.39L9.05 14.66l.927 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.242c.584-.892-.212-2.029-1.234-1.796L2.93 7.89z" fill-rule="evenodd"></path></svg></span>分享</button></div></div><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Heart Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2 8.437C2 5.505 4.294 3.094 7.207 3 9.243 3 11.092 4.19 12 6c.823-1.758 2.649-3 4.651-3C19.545 3 22 5.507 22 8.432 22 16.24 13.842 21 12 21 10.158 21 2 16.24 2 8.437z" fill-rule="evenodd"></path></svg></span>喜欢</button><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Star Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5.515 19.64l.918-5.355-3.89-3.792c-.926-.902-.639-1.784.64-1.97L8.56 7.74l2.404-4.871c.572-1.16 1.5-1.16 2.072 0L15.44 7.74l5.377.782c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.219 1.274-.532 1.82-1.676 1.218L12 18.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z" fill-rule="evenodd"></path></svg></span>收藏</button><div class="Post-ActionMenuButton"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Dots Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5 14a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4z" fill-rule="evenodd"></path></svg></span></button></div></div></div></div></div></div></article><div class="Post-Sub Post-NormalSub"><div class="PostIndex-Contributions"><h3 class="BlockTitle">文章被以下专栏收录</h3><ul><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><img class="Avatar Avatar--medium Avatar--round" width="40" height="40" src="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_xs.jpg" srcSet="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_l.jpg 2x" alt="强化学习前沿"/></div></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><a class="ColumnLink ColumnItem-Title" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习前沿</div></div></a></h2><div class="ContentItem-meta">读呀读paper</div></div><div class="ContentItem-extra"><a href="/reinforcementlearning" type="button" class="Button">进入专栏</a></div></div></div></ul></div></div></div></main></div></div><script nonce="e8e5d8f4-324b-43e0-862c-c821111edac1" async="" src="https://www.googletagmanager.com/gtag/js?id=UA-149949619-1"></script><script nonce="e8e5d8f4-324b-43e0-862c-c821111edac1">function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-149949619-1");</script><script id="js-clientConfig" type="text/json">{"host":"zhihu.com","protocol":"https:","wwwHost":"www.zhihu.com","fetchRoot":{"www":"https:\u002F\u002Fwww.zhihu.com","api":"https:\u002F\u002Fapi.zhihu.com","zhuanlan":"https:\u002F\u002Fzhuanlan.zhihu.com"}}</script><script id="js-initialData" type="text/json">{"initialState":{"common":{"ask":{}},"loading":{"global":{"count":0},"local":{"env\u002FgetIpinfo\u002F":false,"article\u002Fget\u002F":false,"brand\u002FgetUrl\u002F":false}},"club":{"tags":{}},"entities":{"users":{"zhang-chu-heng":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"清华大学 交叉信息院博士在读"}],"exposedMedal":{"medalId":"1124316222665379841","medalName":"我的知乎 2019","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2592b0b52e1fac99f69b38e00252413b_r.png","miniAvatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ad363cc3088dc8de7544fd08b1c4987a_is.png","description":"参与「我的知乎 2019」即可获得"}}},"questions":{},"answers":{},"articles":{"82857779":{"trackUrl":["https:\u002F\u002Fsugar.zhihu.com\u002Fplutus_adreaper\u002Fpage_monitor_log?si=__SESSIONID__&ti=__ATOKEN__&at=view&pf=__OS__&ed=__MEMBERID__&idfa=__IDFA__&imei=__IMEI__&androidid=__ANDROIDID__&oaid=__OAID__&ci=__CREATIVEID__"],"id":82857779,"title":"【强化学习 93】UCB+Q-learning","type":"article","excerptTitle":"","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F82857779","imageUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-95e83d7d87e922ba61b18c6a26f9f0ff_b.jpg","titleImage":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-95e83d7d87e922ba61b18c6a26f9f0ff_b.jpg","excerpt":"\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-28b6d044182c1368b3294901ffedae40_200x112.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2350\" data-rawheight=\"1272\" data-watermark=\"watermark\" data-original-src=\"v2-28b6d044182c1368b3294901ffedae40\" data-watermark-src=\"v2-e6f937a6446cadb78c62bfe032d1e9df\" data-private-watermark-src=\"\" class=\"origin_image inline-img zh-lightbox-thumb\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-28b6d044182c1368b3294901ffedae40_r.png\"\u002F\u003E这篇文章把 UCB 和 Q-learning 相结合，得到两种算法 UCB-H 和 UCB-B，这里把它们统记为 UCB + Q-learning。原文传送门\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fpapers.nips.cc\u002Fpaper\u002F7735-is-q-learning-provably-efficient.pdf\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EJin, Chi, et al. &#34;Is q-learning provably efficient?.&#34; Advances in Neural Information Processing Systems. 2018.\u003C\u002Fa\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fpdf\u002F1807.03765\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EArxiv version (It…\u003C\u002Fa\u003E","created":1568775009,"updated":1568775009,"author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"清华大学 交叉信息院博士在读"}],"exposedMedal":{"medalId":"1124316222665379841","medalName":"我的知乎 2019","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2592b0b52e1fac99f69b38e00252413b_r.png","miniAvatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ad363cc3088dc8de7544fd08b1c4987a_is.png","description":"参与「我的知乎 2019」即可获得"}},"commentPermission":"all","state":"published","imageWidth":1966,"imageHeight":924,"content":"\u003Cp\u003E这篇文章把 UCB 和 Q-learning 相结合，得到两种算法 UCB-H 和 UCB-B，这里把它们统记为 UCB + Q-learning。\u003C\u002Fp\u003E\u003Ch2\u003E原文传送门\u003C\u002Fh2\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fpapers.nips.cc\u002Fpaper\u002F7735-is-q-learning-provably-efficient.pdf\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EJin, Chi, et al. &#34;Is q-learning provably efficient?.&#34; Advances in Neural Information Processing Systems. 2018.\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fpdf\u002F1807.03765\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EArxiv version (It is also a best paper in ICML 2018 workshop &#34;Exploration in RL&#34;)\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Ch2\u003E特色\u003C\u002Fh2\u003E\u003Cp\u003E前面有两讲讲了 PG theory，里面提到要得到一个有效的强化学习算法，探索是一个必不可少的环节。不同于常用的 epsilon-greedy 的探索形式，这里使用 upper confidence bound（UCB） 来做探索。UCB 是 MAB 问题中一个有效的解法，本来以为 UCB+Q-learning 应该是很早就有人做了的，但是这篇还算比较近，在 NIPS 2018 。\u003C\u002Fp\u003E\u003Cp\u003EPs，看到作者才想到去年的这个时候 Michael Jordan 来清华讲课的时候，提到过这一篇；今天大佬又来了，但是今天懒了，没去。\u003C\u002Fp\u003E\u003Ch2\u003E过程\u003C\u002Fh2\u003E\u003Ch3\u003E1. 背景\u003C\u002Fh3\u003E\u003Cp\u003E在 RL 方面，文章使用 finite horizon （每个 episode 都固定 H 步）+ cumulated reward （no discount）的设定。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-e6f937a6446cadb78c62bfe032d1e9df_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2350\" data-rawheight=\"1272\" class=\"origin_image zh-lightbox-thumb\" width=\"2350\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-e6f937a6446cadb78c62bfe032d1e9df_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2350&#39; height=&#39;1272&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2350\" data-rawheight=\"1272\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2350\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-e6f937a6446cadb78c62bfe032d1e9df_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-e6f937a6446cadb78c62bfe032d1e9df_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E上表中 T 表示 sample complexity；S 和 A 分别代表状态空间和动作空间的大小；H 表示一个回合有多少步。注意到，当 H=1 时就是一个普通的 contextual MAB 问题，因此这里可以看做是一个有 H 『层』的 contextual MAP 问题。\u003C\u002Fp\u003E\u003Cp\u003E从 regret 上来说，model-based 方法之前有 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=O%28%5Csqrt%7BT%7D%29\" alt=\"O(\\sqrt{T})\" eeimg=\"1\"\u002F\u003E 的结果，但是这类方法需要估计一个 model，这样需要一个比较大的存储空间；model-free 的方法就只需要 online 地更新，只需要存一个价值函数或者策略即可，空间上的复杂度会更低。\u003C\u002Fp\u003E\u003Cp\u003EPs，文章讲了两种算法，我暂时只看了正文里面讲的 UCB-H 方法，UCB-B 方法在附录中讲的，主要额外估计了 variance 并使用它来计算 upper confidence，从而得到更好的结果。没有仔细看，因此这里不讲了。\u003C\u002Fp\u003E\u003Ch3\u003E2. Q-learning combined with UCB\u003C\u002Fh3\u003E\u003Cp\u003E文章最核心的想法可以从如下公式看出：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a5b337a2afb82779014ddc9071464acd_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2236\" data-rawheight=\"92\" class=\"origin_image zh-lightbox-thumb\" width=\"2236\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a5b337a2afb82779014ddc9071464acd_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2236&#39; height=&#39;92&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2236\" data-rawheight=\"92\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2236\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a5b337a2afb82779014ddc9071464acd_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a5b337a2afb82779014ddc9071464acd_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其核心就是 Q-value 每次更新的 target 都会加上一个 exploration bonus \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=b_t\" alt=\"b_t\" eeimg=\"1\"\u002F\u003E ，而这里的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=t+%3D+N_h%28x%2Ca%29\" alt=\"t = N_h(x,a)\" eeimg=\"1\"\u002F\u003E ，表示该 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%28h%2Cx%2Ca%29\" alt=\"(h,x,a)\" eeimg=\"1\"\u002F\u003E 之前遇到过多少次。文章的关键就是给出了 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Calpha_t%2C+b_t\" alt=\"\\alpha_t, b_t\" eeimg=\"1\"\u002F\u003E 的具体函数关系，并且导出了这样函数关系下相应的 regret。\u003C\u002Fp\u003E\u003Cp\u003EUCB-H 算法如下：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5c973196a020acfba29d334253c53c9d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2342\" data-rawheight=\"764\" class=\"origin_image zh-lightbox-thumb\" width=\"2342\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5c973196a020acfba29d334253c53c9d_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2342&#39; height=&#39;764&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2342\" data-rawheight=\"764\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2342\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5c973196a020acfba29d334253c53c9d_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5c973196a020acfba29d334253c53c9d_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E该算法中，选择 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=b_t+%3D+c+%5Csqrt%7BH%5E3+%5Ciota+%2F+t%7D\" alt=\"b_t = c \\sqrt{H^3 \\iota \u002F t}\" eeimg=\"1\"\u002F\u003E ， \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Calpha_t+%3D+%5Cdfrac%7BH%2B1%7D%7BH%2Bt%7D\" alt=\"\\alpha_t = \\dfrac{H+1}{H+t}\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Cp\u003E该算法相应的 regret 有如下保证：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-8d935d6b0b97884cc9386339e9194e23_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2256\" data-rawheight=\"230\" class=\"origin_image zh-lightbox-thumb\" width=\"2256\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-8d935d6b0b97884cc9386339e9194e23_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2256&#39; height=&#39;230&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2256\" data-rawheight=\"230\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2256\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-8d935d6b0b97884cc9386339e9194e23_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-8d935d6b0b97884cc9386339e9194e23_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Ch3\u003E3. 证明\u003C\u002Fh3\u003E\u003Cp\u003E证明分为如下几个步骤：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E第一步：给定的是 Q-learning 的更新公式，更新公式是 bootstrap 的形式，即新的 Q 值依赖于旧的 Q 值。因此，\u003Cb\u003E\u003Ci\u003E第一步需要把这样的『递推公式』写成『通项公式』的形式\u003C\u002Fi\u003E\u003C\u002Fb\u003E。这其中需要到一个 tradeoff：如果过度依赖于最新的 Q 值，估计会更为 unbiased，但是 variance 会比较大（因为参考的样本数目较少）；如果过度依赖以前的 Q 值，就会产生更大的 bias。 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Calpha_t\" alt=\"\\alpha_t\" eeimg=\"1\"\u002F\u003E 的选取方式就是在平衡这样一个 tradeoff。\u003C\u002Fli\u003E\u003Cli\u003E第二步：虽然最后我们需要的 regret 是比较最优策略的性能和每一轮策略的性能，但是策略是依赖于所估计的 Q 函数值的，因此在\u003Cb\u003E\u003Ci\u003E第二步中需要先 bound 所估计的 Q 函数值和最优 Q 函数值的差距，即 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=Q%5Ek+-+Q%5E%2A\" alt=\"Q^k - Q^*\" eeimg=\"1\"\u002F\u003E \u003C\u002Fi\u003E\u003C\u002Fb\u003E。这一步中最为核心的想法是，如果某一个 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%28h%2Cx%2Ca%29\" alt=\"(h,x,a)\" eeimg=\"1\"\u002F\u003E 被访问的次数多（ \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=t\" alt=\"t\" eeimg=\"1\"\u002F\u003E 比较大），那么对它的估计就更准确，相应地，可以匹配一个较小的 exploration bonus \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=b_t\" alt=\"b_t\" eeimg=\"1\"\u002F\u003E ；反之，就需要一个更大的 exploration bonus 来鼓励探索。这一步依赖于前一步中写出的『通项公式』。\u003C\u002Fli\u003E\u003Cli\u003E第三步：\u003Cb\u003E\u003Ci\u003E把 regret 写出来，并且进行缩放改写，最后利用前述性质推导其上界\u003C\u002Fi\u003E\u003C\u002Fb\u003E。其中核心的想法是，regret 关心的是 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=V_1%28x_1%29\" alt=\"V_1(x_1)\" eeimg=\"1\"\u002F\u003E 的差值，然而它的差值又可以写作后一个状态价值函数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=V_2%28x_2%29\" alt=\"V_2(x_2)\" eeimg=\"1\"\u002F\u003E 的差值，以此类推，到最后（第 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=H%2B1\" alt=\"H+1\" eeimg=\"1\"\u002F\u003E 步）各个价值函数又是相同的了（即，误差为零）。因此，误差是从 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=H\" alt=\"H\" eeimg=\"1\"\u002F\u003E 步往回累加起来的。因此，需要注意误差传递的途径，然后写出最后的 regret 形式。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003E\u003Cb\u003E\u003Ci\u003E预备：更新公式\u003C\u002Fi\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9945d5d8face81b2e415a425d6f5fd3e_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1896\" data-rawheight=\"164\" class=\"origin_image zh-lightbox-thumb\" width=\"1896\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9945d5d8face81b2e415a425d6f5fd3e_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1896&#39; height=&#39;164&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1896\" data-rawheight=\"164\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1896\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9945d5d8face81b2e415a425d6f5fd3e_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9945d5d8face81b2e415a425d6f5fd3e_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-5a2e050f01fcd9175518d840a35b72f2_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1874\" data-rawheight=\"102\" class=\"origin_image zh-lightbox-thumb\" width=\"1874\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-5a2e050f01fcd9175518d840a35b72f2_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1874&#39; height=&#39;102&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1874\" data-rawheight=\"102\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1874\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-5a2e050f01fcd9175518d840a35b72f2_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-5a2e050f01fcd9175518d840a35b72f2_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中上标 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=k%5Cin%5BK%5D\" alt=\"k\\in[K]\" eeimg=\"1\"\u002F\u003E 表示是第 k 个 episode，而下标 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=h%5Cin%5BH%5D\" alt=\"h\\in[H]\" eeimg=\"1\"\u002F\u003E 表示是 episode 中的第几步。注意到，每一步的奖励在 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5B0%2C1%5D\" alt=\"[0,1]\" eeimg=\"1\"\u002F\u003E 之间，因此价值函数不超过 H，因此状态价值函数会使用 H 来截断。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E\u003Ci\u003E预备： \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Calpha_t\" alt=\"\\alpha_t\" eeimg=\"1\"\u002F\u003E 的性质\u003C\u002Fi\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E文章选择 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Calpha_t+%3D+%5Cdfrac%7BH%2B1%7D%7BH%2Bt%7D\" alt=\"\\alpha_t = \\dfrac{H+1}{H+t}\" eeimg=\"1\"\u002F\u003E ，如果定义\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c293366fa19b104b9419e54491c3c753_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1894\" data-rawheight=\"102\" class=\"origin_image zh-lightbox-thumb\" width=\"1894\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c293366fa19b104b9419e54491c3c753_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1894&#39; height=&#39;102&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1894\" data-rawheight=\"102\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1894\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c293366fa19b104b9419e54491c3c753_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c293366fa19b104b9419e54491c3c753_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E容易验证它具有如下性质。上述定义的作用后面将会看到。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1d5ad86b5044bb070d419d8ae56241fa_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1604\" data-rawheight=\"324\" class=\"origin_image zh-lightbox-thumb\" width=\"1604\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1d5ad86b5044bb070d419d8ae56241fa_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1604&#39; height=&#39;324&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1604\" data-rawheight=\"324\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1604\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1d5ad86b5044bb070d419d8ae56241fa_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1d5ad86b5044bb070d419d8ae56241fa_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cb\u003E\u003Ci\u003E第一步：价值函数的通项公式\u003C\u002Fi\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-17a3f2efeb69571fe64c0d7b44db52e0_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1902\" data-rawheight=\"146\" class=\"origin_image zh-lightbox-thumb\" width=\"1902\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-17a3f2efeb69571fe64c0d7b44db52e0_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1902&#39; height=&#39;146&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1902\" data-rawheight=\"146\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1902\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-17a3f2efeb69571fe64c0d7b44db52e0_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-17a3f2efeb69571fe64c0d7b44db52e0_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E这里我们就能观察到刚刚所定义的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Calpha_t%5Ei\" alt=\"\\alpha_t^i\" eeimg=\"1\"\u002F\u003E 的作用了，它其实是在第 t 步时各项实际的权重。前面说到 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Calpha_t\" alt=\"\\alpha_t\" eeimg=\"1\"\u002F\u003E 的设置涉及到一个 bias-variance tradeoff：如果对于一个固定的 t， \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Calpha_t%5Ei\" alt=\"\\alpha_t^i\" eeimg=\"1\"\u002F\u003E 特别倾向于最新的 target Q value（上式方括号中的式子），那么就会产生较大的 variance；对于一个固定的 t， \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Calpha_t%5Ei\" alt=\"\\alpha_t^i\" eeimg=\"1\"\u002F\u003E 比较平均地对历史上遇到的 target Q value 加权，那么会导致较大的 bias。文章采取的这种加权方案能够使得不管 t 为多少，都几乎只考虑最后的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=1%2FH\" alt=\"1\u002FH\" eeimg=\"1\"\u002F\u003E  份的样本，而最开始的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=1-1%2FH\" alt=\"1-1\u002FH\" eeimg=\"1\"\u002F\u003E 份样本会被『遗忘』。从下图可以看出这一点。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-0c23203fc97b20fa2af32fbb8f6f5318_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2012\" data-rawheight=\"588\" class=\"origin_image zh-lightbox-thumb\" width=\"2012\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-0c23203fc97b20fa2af32fbb8f6f5318_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2012&#39; height=&#39;588&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2012\" data-rawheight=\"588\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2012\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-0c23203fc97b20fa2af32fbb8f6f5318_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-0c23203fc97b20fa2af32fbb8f6f5318_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E注意到，第 h 层的价值函数依赖于第 h+1 层的价值函数，即价值函数是一层层传递过来的，因此总体上来看，所有的样本都能够得到有效地利用。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E\u003Ci\u003E第二步：估计价值函数和最优价值函数的差距\u003C\u002Fi\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E首先可以得到，如下式子\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-77e05ac0ebcdbf467aff4c3c9f4ada5a_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1892\" data-rawheight=\"292\" class=\"origin_image zh-lightbox-thumb\" width=\"1892\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-77e05ac0ebcdbf467aff4c3c9f4ada5a_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1892&#39; height=&#39;292&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1892\" data-rawheight=\"292\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1892\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-77e05ac0ebcdbf467aff4c3c9f4ada5a_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-77e05ac0ebcdbf467aff4c3c9f4ada5a_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E注意到\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-4a732d8ec207d2c565536b607fa4aa2f_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1650\" data-rawheight=\"62\" class=\"origin_image zh-lightbox-thumb\" width=\"1650\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-4a732d8ec207d2c565536b607fa4aa2f_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1650&#39; height=&#39;62&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1650\" data-rawheight=\"62\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1650\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-4a732d8ec207d2c565536b607fa4aa2f_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-4a732d8ec207d2c565536b607fa4aa2f_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6acd04aed2e11aa619cb81ce7cec80d4_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1596\" data-rawheight=\"82\" class=\"origin_image zh-lightbox-thumb\" width=\"1596\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6acd04aed2e11aa619cb81ce7cec80d4_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1596&#39; height=&#39;82&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1596\" data-rawheight=\"82\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1596\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6acd04aed2e11aa619cb81ce7cec80d4_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6acd04aed2e11aa619cb81ce7cec80d4_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E接下来，考虑到 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Chat%7B%5Cmathbb%7BP%7D%7D-%5Cmathbb%7BP%7D\" alt=\"\\hat{\\mathbb{P}}-\\mathbb{P}\" eeimg=\"1\"\u002F\u003E 其实就是 sample mean - true mean，可以使用 concentration inequality 来 bound 这一项；直观来说，就是越多的样本估计的越准确。\u003C\u002Fp\u003E\u003Cp\u003E由此，可以得到如下引理：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-c028c4b510755e07490fc7e35e495c7d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1912\" data-rawheight=\"432\" class=\"origin_image zh-lightbox-thumb\" width=\"1912\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-c028c4b510755e07490fc7e35e495c7d_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1912&#39; height=&#39;432&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1912\" data-rawheight=\"432\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1912\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-c028c4b510755e07490fc7e35e495c7d_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-c028c4b510755e07490fc7e35e495c7d_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E文章中写 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ciota+%3D+%5Clog%28SAT%2Fp%29\" alt=\"\\iota = \\log(SAT\u002Fp)\" eeimg=\"1\"\u002F\u003E ，但是我推导了半天感觉是 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ciota+%3D+%5Clog%28%7BSAH%2Fp%7D%29\" alt=\"\\iota = \\log({SAH\u002Fp})\" eeimg=\"1\"\u002F\u003E 。。。反正，最重要的就是对于每一个 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%28h%2Cx%2Ca%29\" alt=\"(h,x,a)\" eeimg=\"1\"\u002F\u003E 应用 Azuma-Hoeffding，然后再加 union bound 合起来，这样就能得到 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Chat%7B%5Cmathbb%7BP%7D%7D-%5Cmathbb%7BP%7D\" alt=\"\\hat{\\mathbb{P}}-\\mathbb{P}\" eeimg=\"1\"\u002F\u003E 项的界，接下来就需要设置 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=b_t\" alt=\"b_t\" eeimg=\"1\"\u002F\u003E 来匹配相应的界，使得所估计的 Q 值大概率是 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=Q%5E%2A\" alt=\"Q^*\" eeimg=\"1\"\u002F\u003E 的上界，但是同时也比较紧（不会比 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=Q%5E%2A\" alt=\"Q^*\" eeimg=\"1\"\u002F\u003E 大太多）。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E\u003Ci\u003E第三步：计算 regret\u003C\u002Fi\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E首先注意到：由于估计的 Q 值是 upper confidence，因此第 k 轮估计的 Q 值 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=Q_h%5Ek\" alt=\"Q_h^k\" eeimg=\"1\"\u002F\u003E 、最优 Q 值 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=Q_h%5E%2A\" alt=\"Q_h^*\" eeimg=\"1\"\u002F\u003E 和实际策略的 Q 值 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=Q_h%5E%7B%5Cpi_k%7D\" alt=\"Q_h^{\\pi_k}\" eeimg=\"1\"\u002F\u003E 的关系大致为： \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=Q_h%5Ek+%3EQ_h%5E%2A%3EQ_h%5E%7B%5Cpi_k%7D\" alt=\"Q_h^k &gt;Q_h^*&gt;Q_h^{\\pi_k}\" eeimg=\"1\"\u002F\u003E 。定义\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-36bc0c23ddccaf1edd2c2ec67535644c_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1872\" data-rawheight=\"70\" class=\"origin_image zh-lightbox-thumb\" width=\"1872\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-36bc0c23ddccaf1edd2c2ec67535644c_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1872&#39; height=&#39;70&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1872\" data-rawheight=\"70\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1872\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-36bc0c23ddccaf1edd2c2ec67535644c_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-36bc0c23ddccaf1edd2c2ec67535644c_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E因此，regret 可以被 bound 为\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-757274c333f3f736ba1e61a2093e03b7_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1906\" data-rawheight=\"106\" class=\"origin_image zh-lightbox-thumb\" width=\"1906\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-757274c333f3f736ba1e61a2093e03b7_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1906&#39; height=&#39;106&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1906\" data-rawheight=\"106\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1906\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-757274c333f3f736ba1e61a2093e03b7_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-757274c333f3f736ba1e61a2093e03b7_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E而 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta_h\" alt=\"\\delta_h\" eeimg=\"1\"\u002F\u003E 和后续的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta_%7Bh%2B1%7D\" alt=\"\\delta_{h+1}\" eeimg=\"1\"\u002F\u003E 又具有一定的联系\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ec8a0eb07fa1f4876b36b330092a1971_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1870\" data-rawheight=\"350\" class=\"origin_image zh-lightbox-thumb\" width=\"1870\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ec8a0eb07fa1f4876b36b330092a1971_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1870&#39; height=&#39;350&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1870\" data-rawheight=\"350\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1870\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ec8a0eb07fa1f4876b36b330092a1971_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ec8a0eb07fa1f4876b36b330092a1971_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E① 中的小于等于号是由于 estimated V 定义中有一个 clip 操作，同时策略就是确定性地选择 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=a_h%5Ek\" alt=\"a_h^k\" eeimg=\"1\"\u002F\u003E ，因此 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=V_h%5E%7B%5Cpi_k%7D%28s_h%5Ek%29+%3D+Q%5E%7B%5Cpi_k%7D%28s_h%5Ek%2C+%5Cpi_k%29+%3D+Q%5E%7B%5Cpi_k%7D%28s_h%5Ek%2C+a_h%5Ek%29\" alt=\"V_h^{\\pi_k}(s_h^k) = Q^{\\pi_k}(s_h^k, \\pi_k) = Q^{\\pi_k}(s_h^k, a_h^k)\" eeimg=\"1\"\u002F\u003E 。② 用到了前一步的结论，以及 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathbb%7BP%7D_h\" alt=\"\\mathbb{P}_h\" eeimg=\"1\"\u002F\u003E 算子的定义。③ 是恒等变化，需要注意到 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Chat%7B%5Cmathbb%7BP%7D%7D_h\" alt=\"\\hat{\\mathbb{P}}_h\" eeimg=\"1\"\u002F\u003E 算子的定义，其中\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e622769cca2fbb935c2e4438c8dfc1f5_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2106\" data-rawheight=\"64\" class=\"origin_image zh-lightbox-thumb\" width=\"2106\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e622769cca2fbb935c2e4438c8dfc1f5_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2106&#39; height=&#39;64&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2106\" data-rawheight=\"64\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2106\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e622769cca2fbb935c2e4438c8dfc1f5_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e622769cca2fbb935c2e4438c8dfc1f5_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E绿框部分：注意到 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=Q_h%5Ek+%3EQ_h%5E%2A%3EQ_h%5E%7B%5Cpi_k%7D\" alt=\"Q_h^k &gt;Q_h^*&gt;Q_h^{\\pi_k}\" eeimg=\"1\"\u002F\u003E ，这里其实是把 optimal V - policy V，放大成了 estimated V - policy V；但是看似矛盾的是，后面又拆成了 (estimated Q - optimal Q) + (optimal Q - policy Q)。但其实不矛盾的，一步过来的话，① 中的小于等于号是不成立的。\u003C\u002Fp\u003E\u003Cp\u003E其中第一项\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-b9515394ff728f17c2376f34b55551eb_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1920\" data-rawheight=\"178\" class=\"origin_image zh-lightbox-thumb\" width=\"1920\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-b9515394ff728f17c2376f34b55551eb_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1920&#39; height=&#39;178&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1920\" data-rawheight=\"178\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1920\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-b9515394ff728f17c2376f34b55551eb_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-b9515394ff728f17c2376f34b55551eb_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E第二项\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-8ff8ef4c70c317e0b9c543e2eb6d41cc_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1910\" data-rawheight=\"166\" class=\"origin_image zh-lightbox-thumb\" width=\"1910\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-8ff8ef4c70c317e0b9c543e2eb6d41cc_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1910&#39; height=&#39;166&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1910\" data-rawheight=\"166\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1910\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-8ff8ef4c70c317e0b9c543e2eb6d41cc_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-8ff8ef4c70c317e0b9c543e2eb6d41cc_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E根据 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta_h%5Ek+%5Cge+%5Cphi_h%5Ek+\" alt=\"\\delta_h^k \\ge \\phi_h^k \" eeimg=\"1\"\u002F\u003E ，有\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1775fc8faeb6d2a952e62c9776a179ae_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1882\" data-rawheight=\"304\" class=\"origin_image zh-lightbox-thumb\" width=\"1882\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1775fc8faeb6d2a952e62c9776a179ae_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1882&#39; height=&#39;304&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1882\" data-rawheight=\"304\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1882\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1775fc8faeb6d2a952e62c9776a179ae_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1775fc8faeb6d2a952e62c9776a179ae_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E根据递推关系，能够得到\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4f85cd72942cac212f0bd653f7883740_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1880\" data-rawheight=\"162\" class=\"origin_image zh-lightbox-thumb\" width=\"1880\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4f85cd72942cac212f0bd653f7883740_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1880&#39; height=&#39;162&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1880\" data-rawheight=\"162\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1880\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4f85cd72942cac212f0bd653f7883740_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4f85cd72942cac212f0bd653f7883740_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E最后 bound \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbeta\" alt=\"\\beta\" eeimg=\"1\"\u002F\u003E 项和 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cxi\" alt=\"\\xi\" eeimg=\"1\"\u002F\u003E 项即可：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-55da71515bfbeb21ea158ed621cfd353_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1930\" data-rawheight=\"180\" class=\"origin_image zh-lightbox-thumb\" width=\"1930\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-55da71515bfbeb21ea158ed621cfd353_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1930&#39; height=&#39;180&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1930\" data-rawheight=\"180\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1930\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-55da71515bfbeb21ea158ed621cfd353_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-55da71515bfbeb21ea158ed621cfd353_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中，① 需要注意到 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Csum_%7Bx%2Ca%7D+N_h%5Ek%28x%2Ca%29%3DK\" alt=\"\\sum_{x,a} N_h^k(x,a)=K\" eeimg=\"1\"\u002F\u003E ，因此取 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=N_h%5Ek%28x%2Ca%29%3DK%2FSA%2C+%5Cforall+h%2C+x%2C+a\" alt=\"N_h^k(x,a)=K\u002FSA, \\forall h, x, a\" eeimg=\"1\"\u002F\u003E 时能得到 upper bound。同时用积分来 bound 级数，有 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Csum_%7Bi%3D1%7D%5En+%5Cdfrac%7B1%7D%7B%5Csqrt%7Bi%7D%7D+%5Cle+1%2B%5Cint_1%5En+%5Cdfrac%7B1%7D%7B%5Csqrt%7Bx%7D%7D+dx+%3D+2%5Csqrt%7Bn%7D\" alt=\"\\sum_{i=1}^n \\dfrac{1}{\\sqrt{i}} \\le 1+\\int_1^n \\dfrac{1}{\\sqrt{x}} dx = 2\\sqrt{n}\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-7c772a8a2f770bfce0d53f5ba77854bd_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1902\" data-rawheight=\"162\" class=\"origin_image zh-lightbox-thumb\" width=\"1902\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-7c772a8a2f770bfce0d53f5ba77854bd_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1902&#39; height=&#39;162&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1902\" data-rawheight=\"162\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1902\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-7c772a8a2f770bfce0d53f5ba77854bd_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-7c772a8a2f770bfce0d53f5ba77854bd_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E注意到 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cxi\" alt=\"\\xi\" eeimg=\"1\"\u002F\u003E 是 martingale difference sequence，使用 Azuma-Hoeffding 就可以得到上式。\u003C\u002Fp\u003E\u003Cp\u003E最后得到：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-9305d4b98e37d92af3aa6e1d66ff0048_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1870\" data-rawheight=\"62\" class=\"origin_image zh-lightbox-thumb\" width=\"1870\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-9305d4b98e37d92af3aa6e1d66ff0048_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1870&#39; height=&#39;62&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1870\" data-rawheight=\"62\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1870\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-9305d4b98e37d92af3aa6e1d66ff0048_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-9305d4b98e37d92af3aa6e1d66ff0048_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Chr\u002F\u003E\u003Ch3\u003EAzuma-Hoeffding Inequality\u003C\u002Fh3\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-ab14efb569a2b055ccafd566be1a3200_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"943\" data-rawheight=\"255\" class=\"origin_image zh-lightbox-thumb\" width=\"943\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-ab14efb569a2b055ccafd566be1a3200_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;943&#39; height=&#39;255&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"943\" data-rawheight=\"255\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"943\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-ab14efb569a2b055ccafd566be1a3200_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-ab14efb569a2b055ccafd566be1a3200_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E各种 paper 里面比较喜欢写成如下形式：\u003C\u002Fp\u003E\u003Cp\u003EWith probability at least \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=1-p\" alt=\"1-p\" eeimg=\"1\"\u002F\u003E ,  \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%7CS_n%7C+%5Cle+%5Csqrt%7B2+%5Clog%28%5Cdfrac%7B2%7D%7Bp%7D%29+%5Csum_%7Bj%3D1%7D%5En+%5Csigma_j%5E2%7D\" alt=\"|S_n| \\le \\sqrt{2 \\log(\\dfrac{2}{p}) \\sum_{j=1}^n \\sigma_j^2}\" eeimg=\"1\"\u002F\u003E .\u003C\u002Fp\u003E\u003Chr\u002F\u003E\u003Ch3\u003ERegret 和 PAC Guarantee 的关系\u003C\u002Fh3\u003E\u003Cp\u003E前面说到分析 regret 和分析 PAC（或者应该也可以叫做 finite sample analysis）是等价的。这里给出具体的等价关系。\u003C\u002Fp\u003E\u003Cp\u003EPAC 分析的是需要多少样本能够找到一个 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cepsilon\" alt=\"\\epsilon\" eeimg=\"1\"\u002F\u003E -optimal 的策略，即 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=V_1%5E%2A%28x_1%29-V_1%5E%5Cpi%28x_1%29+%5Cle+%5Cepsilon\" alt=\"V_1^*(x_1)-V_1^\\pi(x_1) \\le \\epsilon\" eeimg=\"1\"\u002F\u003E ；regret 分析的结论通常可以表示为 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Csum_%7Bk%3D1%7D%5EK%5BV_1%5E%2A%28x_1%29+-+V_1%5E%7B%5Cpi_k%7D%28x_1%29%5D+%5Cle+C+%5Ccdot+T%5E%7B1-%5Calpha%7D+%3D+CHK+T%5E%7B-%5Calpha%7D\" alt=\"\\sum_{k=1}^K[V_1^*(x_1) - V_1^{\\pi_k}(x_1)] \\le C \\cdot T^{1-\\alpha} = CHK T^{-\\alpha}\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E从 regret 到 PAC：随机取一个 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cpi+%3D%5Cpi_k%2C+k%5Cin%5BK%5D\" alt=\"\\pi =\\pi_k, k\\in[K]\" eeimg=\"1\"\u002F\u003E ，大概率地有 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=V_1%5E%2A%28x_1%29+-+V%5E%5Cpi_1%28x_1%29+%5Cle+nC+H+T%5E%7B-%5Calpha%7D%2C+n+%3E1\" alt=\"V_1^*(x_1) - V^\\pi_1(x_1) \\le nC H T^{-\\alpha}, n &gt;1\" eeimg=\"1\"\u002F\u003E ，因此找到一个 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cepsilon\" alt=\"\\epsilon\" eeimg=\"1\"\u002F\u003E -optimal 的策略需要的样本大概是 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=T%3DO%5Cleft%28%5Cleft%28%5Cdfrac%7BCH%7D%7B%5Cepsilon%7D%5Cright%29%5E%7B1%2F%5Calpha%7D%5Cright%29\" alt=\"T=O\\left(\\left(\\dfrac{CH}{\\epsilon}\\right)^{1\u002F\\alpha}\\right)\" eeimg=\"1\"\u002F\u003E 。比如文章的 UCB-H、UCB-B 的 sample complexity 分别是 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctilde+O%28H%5E5SA%2F%5Cepsilon%5E2%29\" alt=\"\\tilde O(H^5SA\u002F\\epsilon^2)\" eeimg=\"1\"\u002F\u003E 和 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctilde+O%28H%5E4SA%2F%5Cepsilon%5E2%29\" alt=\"\\tilde O(H^4SA\u002F\\epsilon^2)\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fli\u003E\u003Cli\u003E从 PAC 到 regret：如果用 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=T_1%3DC+%5Cepsilon%5E%7B-%5Cbeta%7D\" alt=\"T_1=C \\epsilon^{-\\beta}\" eeimg=\"1\"\u002F\u003E 的样本找到了一个 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cepsilon\" alt=\"\\epsilon\" eeimg=\"1\"\u002F\u003E -optimal 的策略，那么可以用剩下的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=T-T_1\" alt=\"T-T_1\" eeimg=\"1\"\u002F\u003E 步继续这个策略，从而得到总 regret = \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=O%28T_1+%2B+%5Cepsilon+%28T-T_1%29%2FH%29\" alt=\"O(T_1 + \\epsilon (T-T_1)\u002FH)\" eeimg=\"1\"\u002F\u003E ，选择合适的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=T_1\" alt=\"T_1\" eeimg=\"1\"\u002F\u003E 使得 regret 最小，可以得到最小的 regret 为 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=O%28C%5E%7B1%2B%5Cbeta%7D+%28T%2FH%29%5E%7B%5Cbeta%2F1%2B%5Cbeta%7D%29\" alt=\"O(C^{1+\\beta} (T\u002FH)^{\\beta\u002F1+\\beta})\" eeimg=\"1\"\u002F\u003E 。比如，如果 sample complexity \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cpropto+1%2F%5Cepsilon%5E4\" alt=\"\\propto 1\u002F\\epsilon^4\" eeimg=\"1\"\u002F\u003E ，则 regret \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cpropto+T%5E%7B4%2F5%7D\" alt=\"\\propto T^{4\u002F5}\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Chr\u002F\u003E\u003Ch3\u003E疑问\u003C\u002Fh3\u003E\u003Cp\u003E这篇文章的推导总感觉有点问题（也可能是我自己搞错了），在这里记录一下，如果之后需要用，需要核实一下。同时有些地方也怪怪的，也记录一下，有空再想想。\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E关于 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ciota\" alt=\"\\iota\" eeimg=\"1\"\u002F\u003E ：产生在 Lemma 4.3 的 Azuma-Hoeffding + union bound 中，我得到的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ciota+%3D+%5Clog%28%7BSAH%2Fp%7D%29\" alt=\"\\iota = \\log({SAH\u002Fp})\" eeimg=\"1\"\u002F\u003E 不含 T，文中是 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ciota+%3D+%5Clog%28%7BSAT%2Fp%7D%29\" alt=\"\\iota = \\log({SAT\u002Fp})\" eeimg=\"1\"\u002F\u003E ，含有 T 的，并且文章后面多次出现，应该不是打印错了。\u003C\u002Fli\u003E\u003Cli\u003ETheorem 1 证明的最后面：得到 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=O%28H%5E2SA%2B%5Csqrt%7BH%5E4SAT%5Ciota%7D%29\" alt=\"O(H^2SA+\\sqrt{H^4SAT\\iota})\" eeimg=\"1\"\u002F\u003E 之后，文章里面下面一段话完全没理解。要是令 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=H%5E2SA%3D%5Csqrt%7BH%5E4SAT%5Ciota%7D\" alt=\"H^2SA=\\sqrt{H^4SAT\\iota}\" eeimg=\"1\"\u002F\u003E 得到的结果也是 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=T%3DSA%2F%5Ciota\" alt=\"T=SA\u002F\\iota\" eeimg=\"1\"\u002F\u003E 啊。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-55b1186872977307b2ca655811d1ecd7_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1880\" data-rawheight=\"188\" class=\"origin_image zh-lightbox-thumb\" width=\"1880\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-55b1186872977307b2ca655811d1ecd7_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1880&#39; height=&#39;188&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1880\" data-rawheight=\"188\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1880\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-55b1186872977307b2ca655811d1ecd7_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-55b1186872977307b2ca655811d1ecd7_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cul\u003E\u003Cli\u003E关于最后的结论：文章假定了 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=R_%5Cmax%3D1\" alt=\"R_\\max=1\" eeimg=\"1\"\u002F\u003E ，其实最后的 regret 中至少应该有一个 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=H+%5Cto+H+R_%5Cmax\" alt=\"H \\to H R_\\max\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fli\u003E\u003Cli\u003E文章的设定也比较奇怪：\u003C\u002Fli\u003E\u003Cul\u003E\u003Cli\u003E首先，使用 finite horizon + undiscounted cumulative reward，这一点也不算太奇怪，但是比较奇怪的是默认当前的步数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=h\" alt=\"h\" eeimg=\"1\"\u002F\u003E 也是状态的一部分；这相当于每回合 H 步都不可能有重复的状态，并且每『层』的状态空间都是分离的。这一点对于分析有什么特别的影响呢？文章这样的设定看起来更强，因为对于不同的 h 可以有不同的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathbb%7BP%7D_h\" alt=\"\\mathbb{P}_h\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fli\u003E\u003Cli\u003E其次，一般认为初始状态是从一个分布中采集的，但是这里认为是对手选定的。看起来文章的这种假设更强，是不是这样呢？\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cli\u003EMDP 本身的探索难问题反映在分析的哪个地方：有些 MDP 本身就探索难（某些状态不容易被访问到，比如 Kakede&amp;Langford02 中的第一个例子），如果有些状态学习中一直没有探索到，那么突然遇到时肯定『不知所措』，这时文章假定会遭受一个最大的损失 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=H\" alt=\"H\" eeimg=\"1\"\u002F\u003E （蓝框部分），这产生了 regret 中的常数项（与 T 无关项）。但是下一次再遇到该状态的时候，就不会有这么大的损失了。\u003C\u002Fli\u003E\u003Cli\u003E有些时候 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathbb%7BP%7D\" alt=\"\\mathbb{P}\" eeimg=\"1\"\u002F\u003E 随机性大小不定，如果除了估计均值之外还估计方差，应该可以得到更多信息。这大概是附录里面讲的 Bernstein 探索方法。再往后想，大概是 distributional RL + UCB？\u003C\u002Fli\u003E\u003C\u002Ful\u003E","adminClosedComment":false,"topics":[{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F20039099","type":"topic","id":"20039099","name":"强化学习 (Reinforcement Learning)"}],"voteupCount":34,"voting":0,"column":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"},"commentCount":4,"contributions":[{"id":21773524,"state":"accepted","type":"first_publish","column":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}}],"isTitleImageFullScreen":false,"upvotedFollowees":[],"commercialInfo":{"isCommercial":false,"plugin":{}},"suggestEdit":{"status":false,"reason":"","tip":"","url":"","title":""},"reason":"","annotationAction":[],"canTip":false,"tipjarorsCount":0,"isLabeled":false,"hasPublishingDraft":false,"isFavorited":false,"isNormal":true,"status":0,"shareText":"【强化学习 93】UCB+Q-learning - 来自知乎专栏「强化学习前沿」，作者: 张楚珩 https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F82857779 （想看更多？下载 @知乎 App：http:\u002F\u002Fweibo.com\u002Fp\u002F100404711598 ）","canComment":{"status":true,"reason":""},"mcnFpShow":-1,"isVisible":true,"isLiked":false,"likedCount":0,"visibleOnlyToAuthor":false}},"columns":{"reinforcementlearning":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}},"topics":{},"roundtables":{},"favlists":{},"comments":{},"notifications":{},"ebooks":{},"activities":{},"feeds":{},"pins":{},"promotions":{},"drafts":{},"chats":{},"posts":{},"clubs":{},"clubTags":{}},"currentUser":"","account":{"lockLevel":{},"unlockTicketStatus":false,"unlockTicket":null,"challenge":[],"errorStatus":false,"message":"","isFetching":false,"accountInfo":{},"urlToken":{"loading":false}},"settings":{"socialBind":null,"inboxMsg":null,"notification":{},"email":{},"privacyFlag":null,"blockedUsers":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"blockedFollowees":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"ignoredTopics":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"restrictedTopics":null,"laboratory":{}},"notification":{},"people":{"profileStatus":{},"activitiesByUser":{},"answersByUser":{},"answersSortByVotesByUser":{},"answersIncludedByUser":{},"votedAnswersByUser":{},"thankedAnswersByUser":{},"voteAnswersByUser":{},"thankAnswersByUser":{},"topicAnswersByUser":{},"zvideosByUser":{},"articlesByUser":{},"articlesSortByVotesByUser":{},"articlesIncludedByUser":{},"pinsByUser":{},"questionsByUser":{},"commercialQuestionsByUser":{},"favlistsByUser":{},"followingByUser":{},"followersByUser":{},"mutualsByUser":{},"followingColumnsByUser":{},"followingQuestionsByUser":{},"followingFavlistsByUser":{},"followingTopicsByUser":{},"publicationsByUser":{},"columnsByUser":{},"allFavlistsByUser":{},"brands":null,"creationsByUser":{},"creationsSortByVotesByUser":{},"creationsFeed":{}},"env":{"ab":{"config":{"experiments":[{"expId":"launch-gw_mweb_rec-1","expPrefix":"gw_mweb_rec","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-qa_hdpimg-2","expPrefix":"qa_hdpimg","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-us_foltopic_user-10","expPrefix":"us_foltopic_user","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_bullet_second-2","expPrefix":"vd_bullet_second","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_zvideo_link-10","expPrefix":"vd_zvideo_link","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false}],"params":[{"id":"web_upload","type":"String","value":"1"},{"id":"se_topicfeed","type":"String","value":"0","chainId":"_all_"},{"id":"tp_discovery_ab_1","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"top_v_album","type":"String","value":"1","chainId":"_all_"},{"id":"web_sem_ab","type":"String","value":"1"},{"id":"se_page_quality","type":"String","value":"0","chainId":"_all_"},{"id":"soc_newfeed","type":"String","value":"2","chainId":"_all_"},{"id":"li_video_section","type":"String","value":"0","chainId":"_all_"},{"id":"soc_leave_recommend","type":"String","value":"2","chainId":"_all_"},{"id":"pf_fuceng","type":"String","value":"1","chainId":"_all_"},{"id":"gue_video_replay","type":"String","value":"0"},{"id":"soc_adsort","type":"String","value":"0","chainId":"_all_"},{"id":"qap_article_like","type":"String","value":"1","chainId":"_all_"},{"id":"se_websearch","type":"String","value":"3","chainId":"_all_"},{"id":"soc_iosintimacy","type":"String","value":"2","chainId":"_all_"},{"id":"soc_zuichangfangwen","type":"String","value":"0","chainId":"_all_"},{"id":"top_test_4_liguangyi","type":"String","value":"1","chainId":"_all_"},{"id":"ug_fw_answ_aut_1","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_media_icon","type":"String","value":"1","chainId":"_all_"},{"id":"se_auto_syn","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_join","type":"String","value":"0","chainId":"_all_"},{"id":"li_ebook_read","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_rec","type":"String","value":"1","chainId":"_all_"},{"id":"tp_topic_head","type":"String","value":"0","chainId":"_all_"},{"id":"se_backsearch","type":"String","value":"0","chainId":"_all_"},{"id":"zw_sameq_sorce","type":"String","value":"999","chainId":"_all_"},{"id":"se_highlight","type":"String","value":"0","chainId":"_all_"},{"id":"web_ask","type":"String","value":"0"},{"id":"se_prf","type":"String","value":"0","chainId":"_all_"},{"id":"se_pek_test3","type":"String","value":"1","chainId":"_all_"},{"id":"web_column_auto_invite","type":"String","value":"0"},{"id":"se_searchwiki","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_qa","type":"String","value":"1","chainId":"_all_"},{"id":"top_root","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_2","type":"String","value":"1","chainId":"_all_"},{"id":"se_wannasearch","type":"String","value":"0","chainId":"_all_"},{"id":"web_unfriendly_comm","type":"String","value":"0"},{"id":"tp_sft_v2","type":"String","value":"d","chainId":"_all_"},{"id":"zw_payc_qaedit","type":"String","value":"0","chainId":"_all_"},{"id":"qap_question_author","type":"String","value":"0","chainId":"_all_"},{"id":"zr_rec_answer_cp","type":"String","value":"close","chainId":"_all_"},{"id":"zr_rel_search","type":"String","value":"base","chainId":"_all_"},{"id":"se_entity_model_14","type":"String","value":"0","chainId":"_all_"},{"id":"se_relationship","type":"String","value":"1","chainId":"_all_"},{"id":"se_sug_term","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_pic_swiper","type":"String","value":"1","chainId":"_all_"},{"id":"web_mweb_launch","type":"String","value":"0"},{"id":"tsp_vote","type":"String","value":"2","chainId":"_all_"},{"id":"ug_follow_answerer_0","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_tab_new","type":"String","value":"0-0-0","chainId":"_all_"},{"id":"zr_answer_rec_cp","type":"String","value":"open","chainId":"_all_"},{"id":"se_pek_test","type":"String","value":"1","chainId":"_all_"},{"id":"se_zu_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_adxtest","type":"String","value":"1","chainId":"_all_"},{"id":"soc_iospinweight","type":"String","value":"0","chainId":"_all_"},{"id":"ls_recommend_test","type":"String","value":"0","chainId":"_all_"},{"id":"ls_fmp4","type":"String","value":"0","chainId":"_all_"},{"id":"li_ebok_chap","type":"String","value":"0","chainId":"_all_"},{"id":"zr_video_recall","type":"String","value":"current_recall","chainId":"_all_"},{"id":"se_aa","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_pic","type":"String","value":"0.6","chainId":"_all_"},{"id":"gue_bullet_second","type":"String","value":"1"},{"id":"li_vip_verti_search","type":"String","value":"0","chainId":"_all_"},{"id":"web_question_invite","type":"String","value":"B"},{"id":"se_billboardsearch","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_header","type":"String","value":"1","chainId":"_all_"},{"id":"web_heifetz_grow_ad","type":"String","value":"1"},{"id":"gue_self_censoring","type":"String","value":"1"},{"id":"zr_slot_cold_start","type":"String","value":"aver","chainId":"_all_"},{"id":"se_hotmore","type":"String","value":"2","chainId":"_all_"},{"id":"se_college","type":"String","value":"default","chainId":"_all_"},{"id":"se_use_zitem","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_android_join","type":"String","value":"1","chainId":"_all_"},{"id":"web_n_web_msg","type":"String","value":"0"},{"id":"top_ydyq","type":"String","value":"X","chainId":"_all_"},{"id":"soc_update","type":"String","value":"1","chainId":"_all_"},{"id":"soc_zcfw_broadcast","type":"String","value":"0","chainId":"_all_"},{"id":"ug_goodcomment_0","type":"String","value":"1","chainId":"_all_"},{"id":"se_whitelist","type":"String","value":"0","chainId":"_all_"},{"id":"se_specialbutton","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_pk","type":"String","value":"1","chainId":"_all_"},{"id":"top_quality","type":"String","value":"0","chainId":"_all_"},{"id":"zr_slot_training","type":"String","value":"1","chainId":"_all_"},{"id":"se_zu_recommend","type":"String","value":"0","chainId":"_all_"},{"id":"zr_art_rec","type":"String","value":"base","chainId":"_all_"},{"id":"se_webrs","type":"String","value":"1","chainId":"_all_"},{"id":"web_answer_update","type":"String","value":"0"},{"id":"se_multianswer","type":"String","value":"2","chainId":"_all_"},{"id":"se_payconsult","type":"String","value":"0","chainId":"_all_"},{"id":"web_answerlist_ad","type":"String","value":"0"},{"id":"se_p_slideshow","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adreadline","type":"String","value":"0","chainId":"_all_"},{"id":"li_yxzl_new_style_a","type":"String","value":"1","chainId":"_all_"},{"id":"li_se_across","type":"String","value":"1","chainId":"_all_"},{"id":"se_ad_index","type":"String","value":"10","chainId":"_all_"},{"id":"li_svip_tab_search","type":"String","value":"0","chainId":"_all_"},{"id":"ug_newtag","type":"String","value":"0","chainId":"_all_"},{"id":"zr_expslotpaid","type":"String","value":"1","chainId":"_all_"},{"id":"se_ffzx_jushen1","type":"String","value":"0","chainId":"_all_"},{"id":"soc_cardheight","type":"String","value":"2","chainId":"_all_"},{"id":"top_new_feed","type":"String","value":"5","chainId":"_all_"},{"id":"pf_creator_card","type":"String","value":"1","chainId":"_all_"},{"id":"zr_search_paid","type":"String","value":"0","chainId":"_all_"},{"id":"se_cate_l3","type":"String","value":"0","chainId":"_all_"},{"id":"se_sug","type":"String","value":"1","chainId":"_all_"},{"id":"se_amovietab","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_tab","type":"String","value":"0","chainId":"_all_"},{"id":"soc_ri_merge","type":"String","value":"0","chainId":"_all_"},{"id":"gue_thanks","type":"String","value":"0"},{"id":"se_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"se_agency","type":"String","value":" 0","chainId":"_all_"},{"id":"qap_ques_invite","type":"String","value":"0","chainId":"_all_"},{"id":"gue_new_special_page","type":"String","value":"1"},{"id":"zr_search_sim","type":"String","value":"0","chainId":"_all_"},{"id":"se_aa_base","type":"String","value":"0","chainId":"_all_"},{"id":"se_preset_tech","type":"String","value":"0","chainId":"_all_"},{"id":"se_mobileweb","type":"String","value":"1","chainId":"_all_"},{"id":"tp_qa_toast","type":"String","value":"1","chainId":"_all_"},{"id":"soc_zcfw_shipinshiti","type":"String","value":"1","chainId":"_all_"},{"id":"li_education_box","type":"String","value":"0","chainId":"_all_"},{"id":"pf_adjust","type":"String","value":"0","chainId":"_all_"},{"id":"gue_card_test","type":"String","value":"1"},{"id":"web_answer_list_ad","type":"String","value":"1"},{"id":"se_hotsearch_num","type":"String","value":"0","chainId":"_all_"},{"id":"se_college_cm","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_section","type":"String","value":"0","chainId":"_all_"},{"id":"tp_qa_metacard","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_feed","type":"String","value":"1","chainId":"_all_"},{"id":"soc_special","type":"String","value":"0","chainId":"_all_"},{"id":"gue_bullet_guide","type":"String","value":"发个弹幕聊聊…"},{"id":"tp_sticky_android","type":"String","value":"2","chainId":"_all_"},{"id":"li_qa_btn_text","type":"String","value":"0","chainId":"_all_"},{"id":"se_hotsearch","type":"String","value":"0","chainId":"_all_"},{"id":"se_club_post","type":"String","value":"5","chainId":"_all_"},{"id":"web_hdpimg","type":"String","value":"1"},{"id":"zr_video_rank","type":"String","value":"new_rank","chainId":"_all_"},{"id":"se_likebutton","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_tab","type":"String","value":"0","chainId":"_all_"},{"id":"soc_bigone","type":"String","value":"0","chainId":"_all_"},{"id":"pf_foltopic_usernum","type":"String","value":"50","chainId":"_all_"},{"id":"li_ebook_gen_search","type":"String","value":"0","chainId":"_all_"},{"id":"zr_training_first","type":"String","value":"false","chainId":"_all_"},{"id":"zr_slotpaidexp","type":"String","value":"1","chainId":"_all_"},{"id":"se_rf_w","type":"String","value":"0","chainId":"_all_"},{"id":"se_new_topic","type":"String","value":"0","chainId":"_all_"},{"id":"se_hot_timebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_movietab","type":"String","value":"1","chainId":"_all_"},{"id":"soc_yxzl_zcfw","type":"String","value":"0","chainId":"_all_"},{"id":"zr_intervene","type":"String","value":"0","chainId":"_all_"},{"id":"li_hot_voted","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_android_feed","type":"String","value":"old","chainId":"_all_"},{"id":"zr_km_feed_nlp","type":"String","value":"old","chainId":"_all_"},{"id":"li_catalog_card","type":"String","value":"1","chainId":"_all_"},{"id":"se_ios_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"li_salt_hot","type":"String","value":"1","chainId":"_all_"},{"id":"se_cardrank_3","type":"String","value":"0","chainId":"_all_"},{"id":"top_universalebook","type":"String","value":"1","chainId":"_all_"},{"id":"tsp_hotlist_ui","type":"String","value":"1","chainId":"_all_"},{"id":"zr_km_answer","type":"String","value":"open_cvr","chainId":"_all_"},{"id":"se_presearch_ab","type":"String","value":"0","chainId":"_all_"},{"id":"li_answer_card","type":"String","value":"0","chainId":"_all_"},{"id":"web_sec672","type":"String","value":"0"},{"id":"zr_update_merge_size","type":"String","value":"1","chainId":"_all_"},{"id":"se_dnn_mt_v2","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_4","type":"String","value":"1","chainId":"_all_"},{"id":"se_time_threshold","type":"String","value":"0","chainId":"_all_"},{"id":"li_assessment_show","type":"String","value":"1","chainId":"_all_"},{"id":"se_sug_entrance","type":"String","value":"1","chainId":"_all_"},{"id":"gue_video_autoplay","type":"String","value":"0"},{"id":"se_webtimebox","type":"String","value":"0","chainId":"_all_"},{"id":"tp_discover_copy","type":"String","value":"0","chainId":"_all_"},{"id":"soc_bignew","type":"String","value":"1","chainId":"_all_"},{"id":"zr_article_new","type":"String","value":"close","chainId":"_all_"},{"id":"se_content0","type":"String","value":"0","chainId":"_all_"},{"id":"soc_authormore2","type":"String","value":"2","chainId":"_all_"},{"id":"web_mweb_rec_length","type":"String","value":"1"},{"id":"tp_club_discover","type":"String","value":"0","chainId":"_all_"},{"id":"tp_m_intro_re_topic","type":"String","value":"1","chainId":"_all_"},{"id":"web_audit_01","type":"String","value":"case1"},{"id":"qap_question_visitor","type":"String","value":" 0","chainId":"_all_"},{"id":"tp_topic_entry","type":"String","value":"0","chainId":"_all_"},{"id":"soc_feed_intimacy","type":"String","value":"2","chainId":"_all_"},{"id":"ug_zero_follow","type":"String","value":"0","chainId":"_all_"},{"id":"ug_follow_answerer","type":"String","value":"0","chainId":"_all_"},{"id":"gue_zhuantikapian","type":"String","value":"0"},{"id":"se_ctx_rerank","type":"String","value":"1","chainId":"_all_"},{"id":"se_colorfultab","type":"String","value":"1","chainId":"_all_"},{"id":"se_cbert_index","type":"String","value":"0","chainId":"_all_"},{"id":"soc_brdcst3","type":"String","value":"0","chainId":"_all_"},{"id":"pf_noti_entry_num","type":"String","value":"0","chainId":"_all_"},{"id":"se_webmajorob","type":"String","value":"0","chainId":"_all_"},{"id":"li_answer_label","type":"String","value":"0","chainId":"_all_"},{"id":"li_paid_answer_exp","type":"String","value":"0","chainId":"_all_"},{"id":"web_collect","type":"String","value":"0"},{"id":"se_preset_label","type":"String","value":"1","chainId":"_all_"},{"id":"se_article_icon","type":"String","value":"0","chainId":"_all_"},{"id":"se_famous","type":"String","value":"1","chainId":"_all_"},{"id":"se_subtext","type":"String","value":"0","chainId":"_all_"},{"id":"li_svip_cardshow","type":"String","value":"1","chainId":"_all_"},{"id":"ug_zero_follow_0","type":"String","value":"0","chainId":"_all_"},{"id":"se_col_boost","type":"String","value":"0","chainId":"_all_"},{"id":"gue_zvideo_link","type":"String","value":"1"},{"id":"li_sku_bottom_bar_re","type":"String","value":"0","chainId":"_all_"},{"id":"li_android_vip","type":"String","value":"0","chainId":"_all_"},{"id":"se_relation_1","type":"String","value":"0","chainId":"_all_"},{"id":"se_search_feed","type":"String","value":"N","chainId":"_all_"},{"id":"tp_header_style","type":"String","value":"1","chainId":"_all_"},{"id":"soc_zcfw_badcase","type":"String","value":"0","chainId":"_all_"},{"id":"soc_authormore","type":"String","value":"2","chainId":"_all_"},{"id":"web_creator_route","type":"String","value":"1"},{"id":"sem_up_growth","type":"String","value":"in_app","chainId":"_all_"},{"id":"top_ebook","type":"String","value":"0","chainId":"_all_"},{"id":"tsp_videobillboard","type":"String","value":"1","chainId":"_all_"},{"id":"se_cardrank_1","type":"String","value":"0","chainId":"_all_"},{"id":"zr_video_rank_nn","type":"String","value":"new_rank","chainId":"_all_"},{"id":"se_site_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"soc_userrec","type":"String","value":"0","chainId":"_all_"},{"id":"web_mini_review","type":"String","value":"0"},{"id":"se_entity_model","type":"String","value":"0","chainId":"_all_"},{"id":"se_hotsearch_2","type":"String","value":"1","chainId":"_all_"},{"id":"zr_training_boost","type":"String","value":"false","chainId":"_all_"},{"id":"li_se_edu","type":"String","value":"1","chainId":"_all_"},{"id":"se_click_club","type":"String","value":"1","chainId":"_all_"},{"id":"se_expired_ob","type":"String","value":"0","chainId":"_all_"},{"id":"soc_brdcst4","type":"String","value":"3","chainId":"_all_"},{"id":"top_hotcommerce","type":"String","value":"1","chainId":"_all_"},{"id":"li_qa_new_cover","type":"String","value":"1","chainId":"_all_"},{"id":"qap_thanks","type":"String","value":"1","chainId":"_all_"},{"id":"zr_test_aa1","type":"String","value":"0","chainId":"_all_"},{"id":"se_waterfall","type":"String","value":"0","chainId":"_all_"},{"id":"tp_qa_metacard_top","type":"String","value":"top","chainId":"_all_"},{"id":"li_purchase_test","type":"String","value":"0","chainId":"_all_"},{"id":"se_lottery","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_tab_feed","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zcfw_broadcast2","type":"String","value":"1","chainId":"_all_"},{"id":"li_answers_link","type":"String","value":"0","chainId":"_all_"},{"id":"li_pay_banner_type","type":"String","value":"6","chainId":"_all_"},{"id":"zr_ans_rec","type":"String","value":"gbrank","chainId":"_all_"},{"id":"tp_meta_card","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_style","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adpinweight","type":"String","value":"0","chainId":"_all_"},{"id":"web_ad_banner","type":"String","value":"0"},{"id":"se_new_merger","type":"String","value":"1","chainId":"_all_"},{"id":"se_topiclabel","type":"String","value":"1","chainId":"_all_"},{"id":"pf_newguide_vertical","type":"String","value":"0","chainId":"_all_"},{"id":"qap_payc_invite","type":"String","value":"0","chainId":"_all_"},{"id":"se_ltr_video","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iosreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"soc_notification","type":"String","value":"0","chainId":"_all_"},{"id":"soc_stickypush","type":"String","value":"1","chainId":"_all_"},{"id":"se_pek_test2","type":"String","value":"1","chainId":"_all_"},{"id":"se_timebox_up","type":"String","value":"0","chainId":"_all_"},{"id":"se_featured","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_qa_pic","type":"String","value":"1","chainId":"_all_"},{"id":"tp_discover","type":"String","value":"0","chainId":"_all_"},{"id":"gue_goods_card","type":"String","value":"0"},{"id":"se_related_index","type":"String","value":"3","chainId":"_all_"},{"id":"soc_iossort","type":"String","value":"0","chainId":"_all_"},{"id":"ls_videoad","type":"String","value":"2","chainId":"_all_"},{"id":"li_se_heat","type":"String","value":"1","chainId":"_all_"},{"id":"tp_score_1","type":"String","value":"a","chainId":"_all_"},{"id":"tp_sft","type":"String","value":"a","chainId":"_all_"},{"id":"soc_iosreadline","type":"String","value":"0","chainId":"_all_"},{"id":"soc_wonderuser_recom","type":"String","value":"2","chainId":"_all_"},{"id":"ug_follow_topic_1","type":"String","value":"2","chainId":"_all_"},{"id":"se_new_p","type":"String","value":"0","chainId":"_all_"}],"chains":[{"chainId":"_all_"}]},"triggers":{}},"userAgent":{"Edge":false,"Wechat":false,"Weibo":false,"QQ":false,"MQQBrowser":false,"Qzone":false,"Mobile":false,"Android":false,"iOS":false,"isAppleDevice":false,"Zhihu":false,"ZhihuHybrid":false,"isBot":false,"Tablet":false,"UC":false,"Sogou":false,"Qihoo":false,"Baidu":false,"BaiduApp":false,"Safari":false,"GoogleBot":false,"AndroidDaily":false,"iOSDaily":false,"isWebView":false,"origin":"Mozilla\u002F5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\u002F537.36 (KHTML, like Gecko) Chrome\u002F80.0.3987.100 Safari\u002F537.36"},"appViewConfig":{},"ctx":{"path":"\u002Fp\u002F82857779","query":{},"href":"http:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F82857779","host":"zhuanlan.zhihu.com"},"trafficSource":"production","edition":{"baidu":false,"sogou":false,"baiduBeijing":false,"sogouBeijing":false,"sogouInput":false},"theme":"light","enableShortcut":true,"referer":"","conf":{},"ipInfo":{"cityName":"德州","countryName":"中国","regionName":"山东","countryCode":"CN"},"logged":false},"me":{"columnContributions":[]},"label":{"recognizerLists":{}},"ecommerce":{},"comments":{"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"parent":{}},"commentsV2":{"stickers":[],"commentWithPicPermission":{},"notificationsComments":{},"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"conversationMore":{},"parent":{}},"pushNotifications":{"default":{"isFetching":false,"isDrained":false,"ids":[]},"follow":{"isFetching":false,"isDrained":false,"ids":[]},"vote_thank":{"isFetching":false,"isDrained":false,"ids":[]},"currentTab":"default","notificationsCount":{"default":0,"follow":0,"vote_thank":0}},"messages":{"data":{},"currentTab":"common","messageCount":0},"register":{"registerValidateSucceeded":null,"registerValidateErrors":{},"registerConfirmError":null,"sendDigitsError":null,"registerConfirmSucceeded":null},"login":{"loginUnregisteredError":false,"loginBindWechatError":false,"loginConfirmError":null,"sendDigitsError":null,"needSMSIdentify":false,"validateDigitsError":false,"loginConfirmSucceeded":null,"qrcodeLoginToken":"","qrcodeLoginScanStatus":0,"qrcodeLoginError":null,"qrcodeLoginReturnNewToken":false},"active":{"sendDigitsError":null,"activeConfirmSucceeded":null,"activeConfirmError":null},"switches":{},"captcha":{"captchaNeeded":false,"captchaValidated":false,"captchaBase64String":null,"captchaValidationMessage":null,"loginCaptchaExpires":false},"sms":{"supportedCountries":[]},"chat":{"chats":{},"inbox":{"recents":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"strangers":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"friends":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"search":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"config":{"newCount":0,"strangerMessageSwitch":false,"strangerMessageUnread":false,"friendCount":0}},"global":{"isChatMqttExisted":false}},"emoticons":{"emoticonGroupList":[],"emoticonGroupDetail":{}},"creator":{"currentCreatorUrlToken":null,"homeData":{"recommendQuestions":[]},"tools":{"question":{"invitationCount":{"questionFolloweeCount":0,"questionTotalCount":0},"goodatTopics":[]},"customPromotion":{"itemLists":{}},"recommend":{"recommendTimes":{}}},"explore":{"academy":{"tabs":[],"article":{}}},"rights":[],"rightsStatus":{},"levelUpperLimit":10,"account":{"growthLevel":{}},"mcn":{},"applyStatus":{}},"recommendation":{"homeRecommendations":[]},"shareTexts":{},"articles":{"voters":{}},"previewPost":{},"favlists":{"relations":{}},"columns":{"voters":{}},"reward":{"answer":{},"article":{},"question":{}},"video":{"data":{},"shareVideoDetail":{},"last":{}},"topstory":{"recommend":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"follow":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followWonderful":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"sidebar":null,"announcement":{},"hotListCategories":[],"hotList":[],"guestFeeds":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followExtra":{"isNewUser":null,"isFetched":false,"followCount":0,"followers":[]}},"readStatus":{},"column":{},"requestColumn":{"categories":[],"error":null},"articleContribution":{"contributeRequests":[],"deleteContributeIdList":[],"handledContributeIdList":[],"recommendedColumns":[],"pinnedColumns":[],"sentContributeRequestsIdList":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"reinforcementlearning"]},"columnContribution":{"contributeRequests":[],"autoInviteEnabled":false,"recommendedContributors":[],"contributionInvitation":null},"draftHistory":{"history":{},"drafts":{}},"upload":{},"articleDraft":{"titleImage":"","titleImageSize":{},"isTitleImageFullScreen":false,"canTitleImageFullScreen":false,"title":"","titleImageUploading":false,"error":"","content":"","draftLoading":false,"updating":false,"globalLoading":false,"pendingVideo":{"resource":null,"error":null},"deleteFail":{"fail":false},"recommendTopics":[],"selectedColumn":0,"articleDisclaimers":[]},"articleDrafts":{"isDrained":false,"isLoading":false,"items":[]},"columnAutocomplete":{"users":[],"friends":[]},"columnCollection":{},"mcn":{"bindInfo":{},"memberCategoryList":[],"producerList":[],"categoryList":[]}},"fetchHost":"www.zhihu.com","subAppName":"column"}</script><script src="https://static.zhihu.com/heifetz/vendor.7b36fae46082fd30a0db.js"></script><script src="https://static.zhihu.com/heifetz/column.app.76e02b16e87eec249f44.js"></script></body><script src="https://hm.baidu.com/hm.js?98beee57fd2ef70ccdd5ca52b9740c49" async=""></script><script src="https://zz.bdstatic.com/linksubmit/push.js" async=""></script></html>