<!doctype html>
<html lang="zh" data-hairline="true" data-theme="light"><head><meta charSet="utf-8"/><title data-react-helmet="true">【强化学习 75】AVF - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"/><meta name="renderer" content="webkit"/><meta name="force-rendering" content="webkit"/><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg"/><meta data-react-helmet="true" name="keywords" content="强化学习 (Reinforcement Learning)"/><meta data-react-helmet="true" name="description" content="AVF 是 adversarial value function 的缩写，这篇工作讲了一个学习 representation 的方法。原文传送门Bellemare, Marc G., et al. &amp;#34;A Geometric Perspective on Optimal Representations for Reinforcement L…"/><meta data-react-helmet="true" property="og:title" content="【强化学习 75】AVF"/><meta data-react-helmet="true" property="og:url" content="https://zhuanlan.zhihu.com/p/70150638"/><meta data-react-helmet="true" property="og:description" content="AVF 是 adversarial value function 的缩写，这篇工作讲了一个学习 representation 的方法。原文传送门Bellemare, Marc G., et al. &amp;#34;A Geometric Perspective on Optimal Representations for Reinforcement L…"/><meta data-react-helmet="true" property="og:image" content="https://pic4.zhimg.com/v2-caa1607bda55ebeef73b791b2968d20d_b.jpg"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" property="og:site_name" content="知乎专栏"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png" sizes="152x152"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-120.b3e6278d.png" sizes="120x120"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-76.7a750095.png" sizes="76x76"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-60.a4a761d4.png" sizes="60x60"/><link rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/static/favicon.ico"/><link rel="search" type="application/opensearchdescription+xml" href="https://static.zhihu.com/static/search.xml" title="知乎"/><link rel="dns-prefetch" href="//static.zhimg.com"/><link rel="dns-prefetch" href="//pic1.zhimg.com"/><link rel="dns-prefetch" href="//pic2.zhimg.com"/><link rel="dns-prefetch" href="//pic3.zhimg.com"/><link rel="dns-prefetch" href="//pic4.zhimg.com"/><style>
.u-safeAreaInset-top {
  height: constant(safe-area-inset-top) !important;
  height: env(safe-area-inset-top) !important;
  
}
.u-safeAreaInset-bottom {
  height: constant(safe-area-inset-bottom) !important;
  height: env(safe-area-inset-bottom) !important;
  
}
</style><link href="https://static.zhihu.com/heifetz/column.app.a9ced452148fee3a55c8.css" rel="stylesheet"/><script defer="" crossorigin="anonymous" src="https://unpkg.zhimg.com/@cfe/sentry-script@latest/dist/init.js" data-sentry-config="{&quot;dsn&quot;:&quot;https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224&quot;,&quot;sampleRate&quot;:0.1,&quot;release&quot;:&quot;683-127b14ad&quot;,&quot;ignoreErrorNames&quot;:[&quot;NetworkError&quot;,&quot;SecurityError&quot;],&quot;ignoreErrors&quot;:[&quot;origin message&quot;,&quot;Network request failed&quot;,&quot;Loading chunk&quot;,&quot;这个系统不支持该功能。&quot;,&quot;Can&#x27;t find variable: webkit&quot;,&quot;Can&#x27;t find variable: $&quot;,&quot;内存不足&quot;,&quot;out of memory&quot;,&quot;DOM Exception 18&quot;,&quot;The operation is insecure&quot;,&quot;[object Event]&quot;,&quot;[object FileError]&quot;,&quot;[object DOMError]&quot;,&quot;[object Object]&quot;,&quot;拒绝访问。&quot;,&quot;Maximum call stack size exceeded&quot;,&quot;UploadError&quot;,&quot;无法 fetch&quot;,&quot;draft-js&quot;,&quot;缺少 JavaScript 对象&quot;,&quot;componentWillEnter&quot;,&quot;componentWillLeave&quot;,&quot;componentWillAppear&quot;,&quot;getInlineStyleAt&quot;,&quot;getCharacterList&quot;],&quot;whitelistUrls&quot;:[&quot;static.zhihu.com&quot;]}"></script></head><body class="WhiteBg-body"><div id="root"><div class="App"><div class="LoadingBar"></div><main role="main" class="App-main"><div class="Post-content" data-zop-usertoken="{&quot;userToken&quot;:&quot;&quot;}" data-zop="{&quot;authorName&quot;:&quot;张楚珩&quot;,&quot;itemId&quot;:70150638,&quot;title&quot;:&quot;【强化学习 75】AVF&quot;,&quot;type&quot;:&quot;article&quot;}"><div class="ColumnPageHeader-Wrapper"><div><div class="Sticky ColumnPageHeader"><div class="ColumnPageHeader-content"><a href="//www.zhihu.com" aria-label="知乎"><svg viewBox="0 0 200 91" fill="#0084FF" width="64" height="30"><path d="M53.29 80.035l7.32.002 2.41 8.24 13.128-8.24h15.477v-67.98H53.29v67.978zm7.79-60.598h22.756v53.22h-8.73l-8.718 5.473-1.587-5.46-3.72-.012v-53.22zM46.818 43.162h-16.35c.545-8.467.687-16.12.687-22.955h15.987s.615-7.05-2.68-6.97H16.807c1.09-4.1 2.46-8.332 4.1-12.708 0 0-7.523 0-10.085 6.74-1.06 2.78-4.128 13.48-9.592 24.41 1.84-.2 7.927-.37 11.512-6.94.66-1.84.785-2.08 1.605-4.54h9.02c0 3.28-.374 20.9-.526 22.95H6.51c-3.67 0-4.863 7.38-4.863 7.38H22.14C20.765 66.11 13.385 79.24 0 89.62c6.403 1.828 12.784-.29 15.937-3.094 0 0 7.182-6.53 11.12-21.64L43.92 85.18s2.473-8.402-.388-12.496c-2.37-2.788-8.768-10.33-11.496-13.064l-4.57 3.627c1.363-4.368 2.183-8.61 2.46-12.71H49.19s-.027-7.38-2.372-7.38zm128.752-.502c6.51-8.013 14.054-18.302 14.054-18.302s-5.827-4.625-8.556-1.27c-1.874 2.548-11.51 15.063-11.51 15.063l6.012 4.51zm-46.903-18.462c-2.814-2.577-8.096.667-8.096.667s12.35 17.2 12.85 17.953l6.08-4.29s-8.02-11.752-10.83-14.33zM199.99 46.5c-6.18 0-40.908.292-40.953.292v-31.56c1.503 0 3.882-.124 7.14-.376 12.773-.753 21.914-1.25 27.427-1.504 0 0 3.817-8.496-.185-10.45-.96-.37-7.24 1.43-7.24 1.43s-51.63 5.153-72.61 5.64c.5 2.756 2.38 5.336 4.93 6.11 4.16 1.087 7.09.53 15.36.277 7.76-.5 13.65-.76 17.66-.76v31.19h-41.71s.88 6.97 7.97 7.14h33.73v22.16c0 4.364-3.498 6.87-7.65 6.6-4.4.034-8.15-.36-13.027-.566.623 1.24 1.977 4.496 6.035 6.824 3.087 1.502 5.054 2.053 8.13 2.053 9.237 0 14.27-5.4 14.027-14.16V53.93h38.235c3.026 0 2.72-7.432 2.72-7.432z" fill-rule="evenodd"></path></svg></a><i class="ColumnPageHeader-Line"></i><div class="ColumnPageHeader-Title"><a class="ColumnLink ColumnPageHeader-Link" href="/reinforcementlearning"><img class="Avatar Avatar--round" width="30" height="30" src="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_is.jpg" srcSet="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_im.jpg 2x" alt="强化学习前沿"/></a><div class="ColumnPageHeader-TitleName"><span class="ColumnPageHeader-TitleMeta">首发于</span><a class="ColumnLink ColumnPageHeader-TitleColumn" href="/reinforcementlearning">强化学习前沿</a></div></div><div class="ColumnPageHeader-Button"><button type="button" class="Button ColumnPageHeader-WriteButton Button--blue"><svg class="Zi Zi--EditSurround" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M18.453 7.992l-1.833-1.65.964-.978a1.223 1.223 0 0 1 1.73-.012l.005.006a1.24 1.24 0 0 1 .007 1.748l-.873.886zm-1.178 1.194l-5.578 5.66-1.935.697a.393.393 0 0 1-.504-.504l.697-1.935 5.488-5.567 1.832 1.65zM7.58 5.848l5.654.006-1.539 1.991-3.666.012A1.02 1.02 0 0 0 7 8.868v7.993c0 .558.46 1.01 1.029 1.01l7.941-.01c.568 0 1.03-.453 1.03-1.012v-4.061l2-1.442v6.002c0 1.397-1.2 2.501-2.62 2.501H7.574C6.153 19.85 5 18.717 5 17.32V8.35c0-1.397 1.16-2.502 2.58-2.502z"></path></svg>写文章</button></div></div></div></div></div><img class="TitleImage" src="https://pic4.zhimg.com/v2-caa1607bda55ebeef73b791b2968d20d_1200x500.jpg" alt="【强化学习 75】AVF"/><article class="Post-Main Post-NormalMain" tabindex="-1"><header class="Post-Header"><h1 class="Post-Title">【强化学习 75】AVF</h1><div class="Post-Author"><div class="AuthorInfo" itemProp="author" itemscope="" itemType="http://schema.org/Person"><meta itemProp="name" content="张楚珩"/><meta itemProp="image" content="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg"/><meta itemProp="url" content="https://www.zhihu.com/people/zhang-chu-heng"/><meta itemProp="zhihu:followerCount"/><span class="UserLink AuthorInfo-avatarWrapper"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/zhang-chu-heng"><img class="Avatar Avatar--round AuthorInfo-avatar" width="38" height="38" src="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_xs.jpg" srcSet="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg 2x" alt="张楚珩"/></a></div></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/zhang-chu-heng">张楚珩</a></div></div><style data-emotion-css="1cd9gw4">.css-1cd9gw4{margin-left:.3em;}</style><style data-emotion-css="1pc1mic">.css-1pc1mic{box-sizing:border-box;margin:0;min-width:0;color:#175199;display:inline-block;width:18px;height:18px;margin-left:.3em;}</style><a href="https://www.zhihu.com/question/48510028" target="_blank" class="css-1pc1mic" data-tooltip="已认证的个人" aria-label="已认证的个人"><style data-emotion-css="18biwo">.css-18biwo{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><span class="css-18biwo">​<svg viewBox="0 0 24 24" width="18" height="18"><svg viewBox="0 0 24 24" x="-3" y="-3" fill="#FFFFFF" width="30" height="30"><path d="M3.56231227,13.8535307 C2.40051305,12.768677 2.41398885,11.0669203 3.59484487,9.99979213 L3.59222085,9.99654885 C4.26730143,9.45036719 4.79446755,8.21005186 4.7184197,7.34453784 L4.72305873,7.34412719 C4.66942824,5.75539997 5.8824188,4.56066914 7.47188965,4.64242381 L7.47229112,4.6386236 C8.33515314,4.72977993 9.58467253,4.22534048 10.1426329,3.55925173 L10.1462611,3.56228565 C11.2316055,2.40008701 12.9353108,2.41394456 14.0015072,3.59634088 L14.0047263,3.59374004 C14.5498229,4.26841874 15.7896857,4.79521622 16.6545744,4.71844347 L16.6549836,4.72304294 C18.245027,4.66894057 19.4396947,5.88213996 19.3575031,7.47241135 L19.3623099,7.47292747 C19.2704388,8.3358681 19.7742711,9.58421483 20.4407199,10.1424506 L20.437686,10.1460789 C21.5997217,11.2312209 21.5860695,12.9345218 20.4042441,14.0007396 L20.4072865,14.0045125 C19.7325967,14.5495925 19.2055209,15.7896954 19.2815865,16.6561959 L19.2770449,16.6565978 C19.3315454,18.2453037 18.1173775,19.4393568 16.5274188,19.3571512 L16.5269029,19.3619539 C15.6647098,19.270083 14.415408,19.7741709 13.8573671,20.4403558 L13.8537409,20.4373235 C12.76842,21.5995708 11.0650432,21.5864553 9.99899434,20.4039226 L9.99527367,20.406923 C9.45025436,19.7323399 8.21017638,19.2051872 7.34461983,19.2812352 L7.344304,19.2776405 C5.75448683,19.3312904 4.55977145,18.1170085 4.64254978,16.527117 L4.63769921,16.5265942 C4.72957031,15.6644394 4.22547659,14.4151814 3.55928015,13.8571569 L3.56231227,13.8535307 Z"></path></svg><path d="M2.63951518,13.3895441 C3.70763333,14.2842292 4.44777637,16.1226061 4.30075305,17.5023312 L4.32211542,17.3063047 C4.17509209,18.6910561 5.17786655,19.7063729 6.5613937,19.5844846 L6.364106,19.6008202 C7.75140298,19.4789319 9.57474349,20.2554985 10.4468305,21.3349009 L10.3224262,21.1803415 C11.1982831,22.2647703 12.6257916,22.2723098 13.5167278,21.2079863 L13.3898102,21.3600325 C14.2845162,20.2919393 16.1229361,19.5518136 17.5026934,19.6988334 L17.3054057,19.6774716 C18.6914461,19.8244915 19.7067866,18.8217404 19.5836389,17.4395022 L19.6012314,17.6367853 C19.4793403,16.2482641 20.255925,14.4249662 21.3353526,13.5528995 L21.1807897,13.677301 C22.2639871,12.8014646 22.2727834,11.3739894 21.2084351,10.483074 L21.3604848,10.6099886 C20.2923667,9.71530351 19.5522236,7.87818322 19.6992469,6.49720154 L19.6778846,6.69448464 C19.8249079,5.30847665 18.8221335,4.2944164 17.4386063,4.41630468 L17.635894,4.39871256 C16.248597,4.52185742 14.4252565,3.74529084 13.5531695,2.66588842 L13.6775738,2.81919121 C12.8017169,1.73601905 11.3742084,1.72722299 10.4832722,2.79154644 L10.6101898,2.63950024 C9.71548377,3.70759343 7.87706394,4.44771919 6.49730661,4.30195588 L6.69459432,4.32206116 C5.30855394,4.17504128 4.29447,5.17904888 4.41636114,6.56128713 L4.3987686,6.36400404 C4.52065973,7.75126861 3.74407501,9.57456653 2.66464737,10.4478898 L2.81921035,10.3222318 C1.73601288,11.1993248 1.72721662,12.6255433 2.79156494,13.5164587 L2.63951518,13.3895441 Z" fill="#0084FF"></path><svg class="Zi Zi--Check" fill="#fff" x="6" y="6" viewBox="0 0 24 24" width="12" height="12"><path d="M10.229 17.516c-.318.327-.75.484-1.199.484-.453 0-.884-.16-1.202-.488l-4.335-4.47a1.77 1.77 0 0 1 .007-2.459 1.663 1.663 0 0 1 2.397.01l3.137 3.246 9.072-9.329a1.662 1.662 0 0 1 2.397 0c.663.681.663 1.786 0 2.466L10.23 17.516z" fill-rule="evenodd"></path></svg></svg></span></a></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="AuthorInfo-badgeText">清华大学 交叉信息院博士在读</div></div></div></div></div></div><div><span class="Voters"><button type="button" class="Button Button--plain">7 人<!-- -->赞同了该文章</button></span></div></header><div class="Post-RichTextContainer"><div class="RichText ztext Post-RichText"><p>AVF 是 adversarial value function 的缩写，这篇工作讲了一个学习 representation 的方法。</p><h2>原文传送门</h2><p><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1901.11530" class=" wrap external" target="_blank" rel="nofollow noreferrer">Bellemare, Marc G., et al. &#34;A Geometric Perspective on Optimal Representations for Reinforcement Learning.&#34; arXiv preprint arXiv:1901.11530 (2019).</a></p><h2>特色</h2><p>这篇工作是专栏前一篇工作（polytope）的后续，前一篇工作从几何的视角分析了策略到价值函数的映射关系，这一篇工作就利用相关的分析来对于给定 MDP 学习一个表示（representation）。相比于之前一些比较 ad hoc 的表示学习工作，这篇工作更有理论保证。具体地，这篇工作要求，对于任意的策略，学习到的表示在一个简单的线性映射下，其对于价值函数的表示误差都不会太大。</p><h2>过程</h2><h3>1. 价值函数近似</h3><p>在价值函数近似上，文章使用了一个所谓的 two-part approximation：把一个状态先映射为一个 <img src="https://www.zhihu.com/equation?tex=d" alt="d" eeimg="1"/> 维的表示 <img src="https://www.zhihu.com/equation?tex=%5Cphi+%3A+%5Cmathcal%7BX%7D+%5Cto+%5Cmathbb%7BR%7D%5Ed" alt="\phi : \mathcal{X} \to \mathbb{R}^d" eeimg="1"/> ，然后再使用一个线性映射得到相应的价值函数，</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-22aa9723389ebf4ce89a4ff3d458d074_b.png" data-caption="" data-size="normal" data-rawwidth="1414" data-rawheight="66" class="origin_image zh-lightbox-thumb" width="1414" data-original="https://pic1.zhimg.com/v2-22aa9723389ebf4ce89a4ff3d458d074_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1414&#39; height=&#39;66&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1414" data-rawheight="66" class="origin_image zh-lightbox-thumb lazy" width="1414" data-original="https://pic1.zhimg.com/v2-22aa9723389ebf4ce89a4ff3d458d074_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-22aa9723389ebf4ce89a4ff3d458d074_b.png"/></figure><p>下图展示了这个 approximation 的过程。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-0de362ce35e64f3acf516dde035f6dfe_b.jpg" data-caption="" data-size="normal" data-rawwidth="1446" data-rawheight="608" class="origin_image zh-lightbox-thumb" width="1446" data-original="https://pic3.zhimg.com/v2-0de362ce35e64f3acf516dde035f6dfe_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1446&#39; height=&#39;608&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1446" data-rawheight="608" class="origin_image zh-lightbox-thumb lazy" width="1446" data-original="https://pic3.zhimg.com/v2-0de362ce35e64f3acf516dde035f6dfe_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-0de362ce35e64f3acf516dde035f6dfe_b.jpg"/></figure><p>当 representation 给定之后，后面一层参数 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="\theta" eeimg="1"/> 的估计就只需要最小化如下这个（对于每个状态均匀加权的）误差即可</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-2951b6b51ba3f3e3052c7059fa5f1ef1_b.png" data-caption="" data-size="normal" data-rawwidth="1368" data-rawheight="126" class="origin_image zh-lightbox-thumb" width="1368" data-original="https://pic2.zhimg.com/v2-2951b6b51ba3f3e3052c7059fa5f1ef1_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1368&#39; height=&#39;126&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1368" data-rawheight="126" class="origin_image zh-lightbox-thumb lazy" width="1368" data-original="https://pic2.zhimg.com/v2-2951b6b51ba3f3e3052c7059fa5f1ef1_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-2951b6b51ba3f3e3052c7059fa5f1ef1_b.png"/></figure><p>当 representation 给定之后，如果把价值函数看做是 <img src="https://www.zhihu.com/equation?tex=n%3D%7C%5Cmathcal%7BX%7D%7C" alt="n=|\mathcal{X}|" eeimg="1"/> 维空间中的一个点，那么 <img src="https://www.zhihu.com/equation?tex=%5Chat%7BV%7D_%5Cphi" alt="\hat{V}_\phi" eeimg="1"/> 所能表示的价值函数在都在如下这个超平面中</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-2812b07ac16f836e25eaa6572820f9cc_b.png" data-caption="" data-size="normal" data-rawwidth="1508" data-rawheight="60" class="origin_image zh-lightbox-thumb" width="1508" data-original="https://pic1.zhimg.com/v2-2812b07ac16f836e25eaa6572820f9cc_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1508&#39; height=&#39;60&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1508" data-rawheight="60" class="origin_image zh-lightbox-thumb lazy" width="1508" data-original="https://pic1.zhimg.com/v2-2812b07ac16f836e25eaa6572820f9cc_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-2812b07ac16f836e25eaa6572820f9cc_b.png"/></figure><p>最小化上述误差相当于在找 <img src="https://www.zhihu.com/equation?tex=V%5E%5Cpi" alt="V^\pi" eeimg="1"/> 往这个超平面上的投影，即 <img src="https://www.zhihu.com/equation?tex=%5Chat%7BV%7D_%5Cphi%5E%5Cpi+%3D+%5CPi_%5Cphi+V%5E%5Cpi" alt="\hat{V}_\phi^\pi = \Pi_\phi V^\pi" eeimg="1"/> 。</p><p>Representation 的学习可以通过一些 auxiliary task 来得到，比如之前的工作使用 <img src="https://www.zhihu.com/equation?tex=%5Cphi%28x%29" alt="\phi(x)" eeimg="1"/> 外接神经网络去预测下一个状态。这里的学习方法也类似，只不过外接了一个线性映射去预测相应的价值函数。后面会看到，文章要求对于一族特殊的策略，希望都能找到参数 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="\theta" eeimg="1"/> 使得相应的价值函数估计接近真实的价值函数。</p><p>Representation 的学习一般可以分为两种，一种是事先学习好（pretrained），另一种是随着策略的学习同时来学习（concurrently）。这里主要讲 pretrained 的情况。</p><h3>2. 价值函数 polytope</h3><p>由于上一篇才讲了，这里就不复习 polytope 了，只说下面这个引理</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-9648ae4b641544ae460bac9d397e4c39_b.jpg" data-caption="" data-size="normal" data-rawwidth="1390" data-rawheight="252" class="origin_image zh-lightbox-thumb" width="1390" data-original="https://pic2.zhimg.com/v2-9648ae4b641544ae460bac9d397e4c39_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1390&#39; height=&#39;252&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1390" data-rawheight="252" class="origin_image zh-lightbox-thumb lazy" width="1390" data-original="https://pic2.zhimg.com/v2-9648ae4b641544ae460bac9d397e4c39_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-9648ae4b641544ae460bac9d397e4c39_b.jpg"/></figure><p>其中 extremal vertex 的定义如下</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-de66443c343d12b931cd08986f57d970_b.png" data-caption="" data-size="normal" data-rawwidth="1408" data-rawheight="148" class="origin_image zh-lightbox-thumb" width="1408" data-original="https://pic1.zhimg.com/v2-de66443c343d12b931cd08986f57d970_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1408&#39; height=&#39;148&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1408" data-rawheight="148" class="origin_image zh-lightbox-thumb lazy" width="1408" data-original="https://pic1.zhimg.com/v2-de66443c343d12b931cd08986f57d970_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-de66443c343d12b931cd08986f57d970_b.png"/></figure><p>这个比较显然，即对于一个 polytope 在某个方向上投影最远的点一定是其 convex hull 的顶点。</p><h3>3. 表示学习的目标</h3><p>希望学习到一个这样的 representation：对于任意的策略，其表示经过线性映射都能尽可能得到该策略下的价值函数。即可以写出如下优化目标</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-9694ceea1910414c51b3a0948f086d5b_b.png" data-caption="" data-size="normal" data-rawwidth="1336" data-rawheight="98" class="origin_image zh-lightbox-thumb" width="1336" data-original="https://pic4.zhimg.com/v2-9694ceea1910414c51b3a0948f086d5b_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1336&#39; height=&#39;98&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1336" data-rawheight="98" class="origin_image zh-lightbox-thumb lazy" width="1336" data-original="https://pic4.zhimg.com/v2-9694ceea1910414c51b3a0948f086d5b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-9694ceea1910414c51b3a0948f086d5b_b.png"/></figure><p>其中</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-00d73d11e8050cca617d8d6908a86200_b.png" data-caption="" data-size="normal" data-rawwidth="1482" data-rawheight="44" class="origin_image zh-lightbox-thumb" width="1482" data-original="https://pic1.zhimg.com/v2-00d73d11e8050cca617d8d6908a86200_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1482&#39; height=&#39;44&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1482" data-rawheight="44" class="origin_image zh-lightbox-thumb lazy" width="1482" data-original="https://pic1.zhimg.com/v2-00d73d11e8050cca617d8d6908a86200_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-00d73d11e8050cca617d8d6908a86200_b.png"/></figure><p>一个 <img src="https://www.zhihu.com/equation?tex=d" alt="d" eeimg="1"/> 维的 representation 能表示出来的价值函数组成一个 <img src="https://www.zhihu.com/equation?tex=d" alt="d" eeimg="1"/> 维的超平面 <img src="https://www.zhihu.com/equation?tex=H%3D%5C%7B%5CPhi%5Ctheta+%3A+%5Ctheta+%5Cin+%5Cmathbb%7BR%7D%5Ed%5C%7D" alt="H=\{\Phi\theta : \theta \in \mathbb{R}^d\}" eeimg="1"/> ，上述目标就是希望 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BV%7D" alt="\mathcal{V}" eeimg="1"/> 中的离该超平面最远的一点也不要太远。形象地说，就是希望找到一个超平面尽可能多地在 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BV%7D" alt="\mathcal{V}" eeimg="1"/> 里面。</p><p>该目标要求对于所有的策略求最大值，这显然不容易做到，但是可以证明其实只需要对于所有的 extremal policies （即 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BP%7D_v" alt="\mathcal{P}_v" eeimg="1"/> ）求最大值即可，这大大减小了搜索的空间。即，有如下定理。</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-85c878ca0638f5644ae4f0126b2d8ed5_b.jpg" data-caption="" data-size="normal" data-rawwidth="1384" data-rawheight="584" class="origin_image zh-lightbox-thumb" width="1384" data-original="https://pic2.zhimg.com/v2-85c878ca0638f5644ae4f0126b2d8ed5_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1384&#39; height=&#39;584&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1384" data-rawheight="584" class="origin_image zh-lightbox-thumb lazy" width="1384" data-original="https://pic2.zhimg.com/v2-85c878ca0638f5644ae4f0126b2d8ed5_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-85c878ca0638f5644ae4f0126b2d8ed5_b.jpg"/></figure><p>更进一步，如果一个表示是最优的，那么由它确定的 <img src="https://www.zhihu.com/equation?tex=d" alt="d" eeimg="1"/> 维超平面会对于 <img src="https://www.zhihu.com/equation?tex=d%2B1" alt="d+1" eeimg="1"/> 个 extremal policies 上价值函数的误差相同，并且这 <img src="https://www.zhihu.com/equation?tex=d%2B1" alt="d+1" eeimg="1"/> 个 extremal policies 产生的误差也等于所有 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BV%7D" alt="\mathcal{V}" eeimg="1"/> 上产生的误差。</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-253f113c894313fecb519c036ed8a10d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1414" data-rawheight="476" class="origin_image zh-lightbox-thumb" width="1414" data-original="https://pic2.zhimg.com/v2-253f113c894313fecb519c036ed8a10d_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1414&#39; height=&#39;476&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1414" data-rawheight="476" class="origin_image zh-lightbox-thumb lazy" width="1414" data-original="https://pic2.zhimg.com/v2-253f113c894313fecb519c036ed8a10d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-253f113c894313fecb519c036ed8a10d_b.jpg"/></figure><h3>4. 表示学习算法</h3><p>表示学习算法主要分为两步，即先找到 <img src="https://www.zhihu.com/equation?tex=k" alt="k" eeimg="1"/> 个特殊的策略及其对应的价值函数（adversarial value functions，AVFs），再利用 AVF 计算 representation 的损失函数，通过梯度下降的方法来训练一个神经网络编码的 representation。算法表示如下</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-a5eb6e11d43c6754fca8c06147841d23_b.jpg" data-caption="" data-size="normal" data-rawwidth="1416" data-rawheight="316" class="origin_image zh-lightbox-thumb" width="1416" data-original="https://pic4.zhimg.com/v2-a5eb6e11d43c6754fca8c06147841d23_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1416&#39; height=&#39;316&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1416" data-rawheight="316" class="origin_image zh-lightbox-thumb lazy" width="1416" data-original="https://pic4.zhimg.com/v2-a5eb6e11d43c6754fca8c06147841d23_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-a5eb6e11d43c6754fca8c06147841d23_b.jpg"/></figure><p>先讲如何得到 AVFs。前面说到给定一个方向 <img src="https://www.zhihu.com/equation?tex=%5Cdelta" alt="\delta" eeimg="1"/> ，使得 <img src="https://www.zhihu.com/equation?tex=%5Cdelta%5ET+V" alt="\delta^T V" eeimg="1"/> 最大的点是一个 extremal point，也就是我们感兴趣的一个点。因此这里随机生成一些方向，然后又策略梯度去得到这些我们感兴趣的策略，把这些策略及其对应的价值函数作为 AVF。</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-e49a90a547102f922de59a180c53bd0b_b.png" data-caption="" data-size="normal" data-rawwidth="1414" data-rawheight="160" class="origin_image zh-lightbox-thumb" width="1414" data-original="https://pic4.zhimg.com/v2-e49a90a547102f922de59a180c53bd0b_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1414&#39; height=&#39;160&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1414" data-rawheight="160" class="origin_image zh-lightbox-thumb lazy" width="1414" data-original="https://pic4.zhimg.com/v2-e49a90a547102f922de59a180c53bd0b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-e49a90a547102f922de59a180c53bd0b_b.png"/></figure><p>接下来就使用得到的 AVF 来更新 representation。Loss function 可以写为</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-b845cfca551a5ac30dc04a38b92883d9_b.png" data-caption="" data-size="normal" data-rawwidth="1550" data-rawheight="130" class="origin_image zh-lightbox-thumb" width="1550" data-original="https://pic2.zhimg.com/v2-b845cfca551a5ac30dc04a38b92883d9_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1550&#39; height=&#39;130&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1550" data-rawheight="130" class="origin_image zh-lightbox-thumb lazy" width="1550" data-original="https://pic2.zhimg.com/v2-b845cfca551a5ac30dc04a38b92883d9_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-b845cfca551a5ac30dc04a38b92883d9_b.png"/></figure><p>其中 <img src="https://www.zhihu.com/equation?tex=%7B%5Cbf+%5Cmu%7D+%3A%3D+%5Cmu_1%2C+%5Ccdots%2C+%5Cmu_k" alt="{\bf \mu} := \mu_1, \cdots, \mu_k" eeimg="1"/> 是 k 个策略，对应的价值函数为 AVFs。</p><p>由于 max 函数不方便求导（当两个策略产生的 loss 相同时梯度就会不确定性通过哪一项往回传），因此把上述的 max 改写为 softmax，即</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-279359735a91013ee12af0b7efba7e86_b.png" data-caption="" data-size="normal" data-rawwidth="1650" data-rawheight="152" class="origin_image zh-lightbox-thumb" width="1650" data-original="https://pic3.zhimg.com/v2-279359735a91013ee12af0b7efba7e86_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1650&#39; height=&#39;152&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1650" data-rawheight="152" class="origin_image zh-lightbox-thumb lazy" width="1650" data-original="https://pic3.zhimg.com/v2-279359735a91013ee12af0b7efba7e86_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-279359735a91013ee12af0b7efba7e86_b.png"/></figure><p>对该损失函数做梯度下降即可求到相应的 representation。</p><p>最大化 <img src="https://www.zhihu.com/equation?tex=%5Cdelta%5ET+V" alt="\delta^T V" eeimg="1"/> 究竟是在做什么呢？下面定理告诉我们最大化该目标相当于是在同时最大化或者最小化每个状态下的目标函数。</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-3a4ece30e2378d0d9f58a049d46b374f_b.jpg" data-caption="" data-size="normal" data-rawwidth="1536" data-rawheight="672" class="origin_image zh-lightbox-thumb" width="1536" data-original="https://pic4.zhimg.com/v2-3a4ece30e2378d0d9f58a049d46b374f_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1536&#39; height=&#39;672&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1536" data-rawheight="672" class="origin_image zh-lightbox-thumb lazy" width="1536" data-original="https://pic4.zhimg.com/v2-3a4ece30e2378d0d9f58a049d46b374f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-3a4ece30e2378d0d9f58a049d46b374f_b.jpg"/></figure><p>可以看出 <img src="https://www.zhihu.com/equation?tex=d_%5Cpi+%3D+%28I+-+%5Cgamma+P%5E%5Cpi%29%5E%7B-1%7D+%5Cdelta" alt="d_\pi = (I - \gamma P^\pi)^{-1} \delta" eeimg="1"/> ，如果 <img src="https://www.zhihu.com/equation?tex=%5Cdelta+%3D+I" alt="\delta = I" eeimg="1"/> （全 1 向量），那么 <img src="https://www.zhihu.com/equation?tex=d_%5Cpi" alt="d_\pi" eeimg="1"/> 就是前面讲到的 successor representation，这时该目标就是一个正常的强化学习目标。</p><h2>实验</h2><p>文章在一个有四个房间的格子世界上做了实验，下图画出了随机生成的一个 <img src="https://www.zhihu.com/equation?tex=%5Cdelta" alt="\delta" eeimg="1"/> 及其对应的 <img src="https://www.zhihu.com/equation?tex=d_%5Cpi" alt="d_\pi" eeimg="1"/> 和 AVF。</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-27be1e2f6a7cfa5fc7b08833b6c4df87_b.jpg" data-caption="" data-size="normal" data-rawwidth="2496" data-rawheight="716" class="origin_image zh-lightbox-thumb" width="2496" data-original="https://pic4.zhimg.com/v2-27be1e2f6a7cfa5fc7b08833b6c4df87_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2496&#39; height=&#39;716&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2496" data-rawheight="716" class="origin_image zh-lightbox-thumb lazy" width="2496" data-original="https://pic4.zhimg.com/v2-27be1e2f6a7cfa5fc7b08833b6c4df87_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-27be1e2f6a7cfa5fc7b08833b6c4df87_b.jpg"/></figure><p>经验上来说，对于某个状态 <img src="https://www.zhihu.com/equation?tex=x" alt="x" eeimg="1"/> ，如果 <img src="https://www.zhihu.com/equation?tex=%5Cdelta%28x%29%3E0" alt="\delta(x)&gt;0" eeimg="1"/> ，那么大概率地其对应的 <img src="https://www.zhihu.com/equation?tex=d_%5Cpi%28x%29+%3E+0" alt="d_\pi(x) &gt; 0" eeimg="1"/> ，当然也会有例外，比如图中红色箭头所示的状态。</p><p>文章还对比了另外两种做法形成的价值函数，一种是随机生成价值函数，另一种是随机生成策略然后求得对应的价值函数。可以看到 AVF 生成的价值函数（也可以看出相应的策略）更具有代表性。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-f08c347a617bb5695fc4c67fe73c0e5a_b.jpg" data-caption="" data-size="normal" data-rawwidth="2334" data-rawheight="868" class="origin_image zh-lightbox-thumb" width="2334" data-original="https://pic3.zhimg.com/v2-f08c347a617bb5695fc4c67fe73c0e5a_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2334&#39; height=&#39;868&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2334" data-rawheight="868" class="origin_image zh-lightbox-thumb lazy" width="2334" data-original="https://pic3.zhimg.com/v2-f08c347a617bb5695fc4c67fe73c0e5a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-f08c347a617bb5695fc4c67fe73c0e5a_b.jpg"/></figure><p>下图展示了不同数目的 AVF 学习得到 representation 每一维的图像，可以看到 <img src="https://www.zhihu.com/equation?tex=k%3D1000%3B4000" alt="k=1000;4000" eeimg="1"/> 时，学习到的 representation 每一维都基本上能够反映一些结构信息（比如在是否在某个房间里面）。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-82d6680196f32150797b6a293db7db58_b.jpg" data-caption="" data-size="normal" data-rawwidth="2078" data-rawheight="676" class="origin_image zh-lightbox-thumb" width="2078" data-original="https://pic1.zhimg.com/v2-82d6680196f32150797b6a293db7db58_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2078&#39; height=&#39;676&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2078" data-rawheight="676" class="origin_image zh-lightbox-thumb lazy" width="2078" data-original="https://pic1.zhimg.com/v2-82d6680196f32150797b6a293db7db58_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-82d6680196f32150797b6a293db7db58_b.jpg"/></figure><p>相应地，使用学到的 representation 来完成 RL 任务，需要的样本数目也会更少。</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-36b0a2c2d8f2509cfd52c16717fe730b_b.jpg" data-caption="" data-size="normal" data-rawwidth="1494" data-rawheight="946" class="origin_image zh-lightbox-thumb" width="1494" data-original="https://pic4.zhimg.com/v2-36b0a2c2d8f2509cfd52c16717fe730b_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1494&#39; height=&#39;946&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1494" data-rawheight="946" class="origin_image zh-lightbox-thumb lazy" width="1494" data-original="https://pic4.zhimg.com/v2-36b0a2c2d8f2509cfd52c16717fe730b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-36b0a2c2d8f2509cfd52c16717fe730b_b.jpg"/></figure><hr/><p>一个猜想：如果一个 MDP 有 bisimulation，那么其价值函数的 polytope 在一个低维子空间上。</p><p></p><p></p></div></div><div class="ContentItem-time">发布于 2019-06-21</div><div class="Post-topicsAndReviewer"><div class="TopicList Post-Topics"><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/20039099" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习 (Reinforcement Learning)</div></div></a></span></div></div></div><div><div class="Sticky RichContent-actions is-bottom"><div class="ContentItem-actions"><span><button aria-label="赞同 7 " type="button" class="Button VoteButton VoteButton--up"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleUp VoteButton-TriangleUp" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M2 18.242c0-.326.088-.532.237-.896l7.98-13.203C10.572 3.57 11.086 3 12 3c.915 0 1.429.571 1.784 1.143l7.98 13.203c.15.364.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H3.955c-1.08 0-1.955-.517-1.955-1.9z" fill-rule="evenodd"></path></svg></span>赞同 7</button><button aria-label="反对" type="button" class="Button VoteButton VoteButton--down"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleDown" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M20.044 3H3.956C2.876 3 2 3.517 2 4.9c0 .326.087.533.236.896L10.216 19c.355.571.87 1.143 1.784 1.143s1.429-.572 1.784-1.143l7.98-13.204c.149-.363.236-.57.236-.896 0-1.386-.876-1.9-1.956-1.9z" fill-rule="evenodd"></path></svg></span></button></span><button type="button" class="Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Comment Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M10.241 19.313a.97.97 0 0 0-.77.2 7.908 7.908 0 0 1-3.772 1.482.409.409 0 0 1-.38-.637 5.825 5.825 0 0 0 1.11-2.237.605.605 0 0 0-.227-.59A7.935 7.935 0 0 1 3 11.25C3 6.7 7.03 3 12 3s9 3.7 9 8.25-4.373 9.108-10.759 8.063z" fill-rule="evenodd"></path></svg></span>添加评论</button><div class="Popover ShareMenu"><div class="ShareMenu-toggler" id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Share Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2.931 7.89c-1.067.24-1.275 1.669-.318 2.207l5.277 2.908 8.168-4.776c.25-.127.477.198.273.39L9.05 14.66l.927 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.242c.584-.892-.212-2.029-1.234-1.796L2.93 7.89z" fill-rule="evenodd"></path></svg></span>分享</button></div></div><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Heart Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2 8.437C2 5.505 4.294 3.094 7.207 3 9.243 3 11.092 4.19 12 6c.823-1.758 2.649-3 4.651-3C19.545 3 22 5.507 22 8.432 22 16.24 13.842 21 12 21 10.158 21 2 16.24 2 8.437z" fill-rule="evenodd"></path></svg></span>喜欢</button><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Star Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5.515 19.64l.918-5.355-3.89-3.792c-.926-.902-.639-1.784.64-1.97L8.56 7.74l2.404-4.871c.572-1.16 1.5-1.16 2.072 0L15.44 7.74l5.377.782c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.219 1.274-.532 1.82-1.676 1.218L12 18.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z" fill-rule="evenodd"></path></svg></span>收藏</button><div class="Post-ActionMenuButton"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Dots Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5 14a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4z" fill-rule="evenodd"></path></svg></span></button></div></div></div></div></div></div></article><div class="Post-Sub Post-NormalSub"><div class="PostIndex-Contributions"><h3 class="BlockTitle">文章被以下专栏收录</h3><ul><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><img class="Avatar Avatar--medium Avatar--round" width="40" height="40" src="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_xs.jpg" srcSet="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_l.jpg 2x" alt="强化学习前沿"/></div></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><a class="ColumnLink ColumnItem-Title" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习前沿</div></div></a></h2><div class="ContentItem-meta">读呀读paper</div></div><div class="ContentItem-extra"><a href="/reinforcementlearning" type="button" class="Button">进入专栏</a></div></div></div></ul></div></div></div></main></div></div><script nonce="0cde26d3-9c1c-414d-bc6d-0984d4ad325e" async="" src="https://www.googletagmanager.com/gtag/js?id=UA-149949619-1"></script><script nonce="0cde26d3-9c1c-414d-bc6d-0984d4ad325e">function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-149949619-1");</script><script id="js-clientConfig" type="text/json">{"host":"zhihu.com","protocol":"https:","wwwHost":"www.zhihu.com","fetchRoot":{"www":"https:\u002F\u002Fwww.zhihu.com","api":"https:\u002F\u002Fapi.zhihu.com","zhuanlan":"https:\u002F\u002Fzhuanlan.zhihu.com"}}</script><script id="js-initialData" type="text/json">{"initialState":{"common":{"ask":{}},"loading":{"global":{"count":0},"local":{"env\u002FgetIpinfo\u002F":false,"article\u002Fget\u002F":false,"brand\u002FgetUrl\u002F":false}},"club":{"tags":{}},"entities":{"users":{"zhang-chu-heng":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"清华大学 交叉信息院博士在读"}],"exposedMedal":{"medalId":"1124316222665379841","medalName":"我的知乎 2019","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2592b0b52e1fac99f69b38e00252413b_r.png","miniAvatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ad363cc3088dc8de7544fd08b1c4987a_is.png","description":"参与「我的知乎 2019」即可获得"}}},"questions":{},"answers":{},"articles":{"70150638":{"trackUrl":["https:\u002F\u002Fsugar.zhihu.com\u002Fplutus_adreaper\u002Fpage_monitor_log?si=__SESSIONID__&ti=__ATOKEN__&at=view&pf=__OS__&ed=__MEMBERID__&idfa=__IDFA__&imei=__IMEI__&androidid=__ANDROIDID__&oaid=__OAID__&ci=__CREATIVEID__"],"id":70150638,"title":"【强化学习 75】AVF","type":"article","excerptTitle":"","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F70150638","imageUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-caa1607bda55ebeef73b791b2968d20d_b.jpg","titleImage":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-caa1607bda55ebeef73b791b2968d20d_b.jpg","excerpt":"\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c0346e3a67cda47a072db01e5f7fdbb7_200x112.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1446\" data-rawheight=\"608\" data-watermark=\"watermark\" data-original-src=\"v2-c0346e3a67cda47a072db01e5f7fdbb7\" data-watermark-src=\"v2-0de362ce35e64f3acf516dde035f6dfe\" data-private-watermark-src=\"\" class=\"origin_image inline-img zh-lightbox-thumb\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c0346e3a67cda47a072db01e5f7fdbb7_r.png\"\u002F\u003EAVF 是 adversarial value function 的缩写，这篇工作讲了一个学习 representation 的方法。原文传送门\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fpdf\u002F1901.11530\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EBellemare, Marc G., et al. &#34;A Geometric Perspective on Optimal Representations for Reinforcement Learning.&#34; arXiv preprint arXiv:1901.11530 (2…\u003C\u002Fa\u003E","created":1561132776,"updated":1561132776,"author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"清华大学 交叉信息院博士在读"}],"exposedMedal":{"medalId":"1124316222665379841","medalName":"我的知乎 2019","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2592b0b52e1fac99f69b38e00252413b_r.png","miniAvatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ad363cc3088dc8de7544fd08b1c4987a_is.png","description":"参与「我的知乎 2019」即可获得"}},"commentPermission":"all","state":"published","imageWidth":2236,"imageHeight":812,"content":"\u003Cp\u003EAVF 是 adversarial value function 的缩写，这篇工作讲了一个学习 representation 的方法。\u003C\u002Fp\u003E\u003Ch2\u003E原文传送门\u003C\u002Fh2\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fpdf\u002F1901.11530\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EBellemare, Marc G., et al. &#34;A Geometric Perspective on Optimal Representations for Reinforcement Learning.&#34; arXiv preprint arXiv:1901.11530 (2019).\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Ch2\u003E特色\u003C\u002Fh2\u003E\u003Cp\u003E这篇工作是专栏前一篇工作（polytope）的后续，前一篇工作从几何的视角分析了策略到价值函数的映射关系，这一篇工作就利用相关的分析来对于给定 MDP 学习一个表示（representation）。相比于之前一些比较 ad hoc 的表示学习工作，这篇工作更有理论保证。具体地，这篇工作要求，对于任意的策略，学习到的表示在一个简单的线性映射下，其对于价值函数的表示误差都不会太大。\u003C\u002Fp\u003E\u003Ch2\u003E过程\u003C\u002Fh2\u003E\u003Ch3\u003E1. 价值函数近似\u003C\u002Fh3\u003E\u003Cp\u003E在价值函数近似上，文章使用了一个所谓的 two-part approximation：把一个状态先映射为一个 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=d\" alt=\"d\" eeimg=\"1\"\u002F\u003E 维的表示 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cphi+%3A+%5Cmathcal%7BX%7D+%5Cto+%5Cmathbb%7BR%7D%5Ed\" alt=\"\\phi : \\mathcal{X} \\to \\mathbb{R}^d\" eeimg=\"1\"\u002F\u003E ，然后再使用一个线性映射得到相应的价值函数，\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-22aa9723389ebf4ce89a4ff3d458d074_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1414\" data-rawheight=\"66\" class=\"origin_image zh-lightbox-thumb\" width=\"1414\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-22aa9723389ebf4ce89a4ff3d458d074_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1414&#39; height=&#39;66&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1414\" data-rawheight=\"66\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1414\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-22aa9723389ebf4ce89a4ff3d458d074_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-22aa9723389ebf4ce89a4ff3d458d074_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E下图展示了这个 approximation 的过程。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0de362ce35e64f3acf516dde035f6dfe_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1446\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb\" width=\"1446\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0de362ce35e64f3acf516dde035f6dfe_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1446&#39; height=&#39;608&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1446\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1446\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0de362ce35e64f3acf516dde035f6dfe_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0de362ce35e64f3acf516dde035f6dfe_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E当 representation 给定之后，后面一层参数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"\u002F\u003E 的估计就只需要最小化如下这个（对于每个状态均匀加权的）误差即可\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-2951b6b51ba3f3e3052c7059fa5f1ef1_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1368\" data-rawheight=\"126\" class=\"origin_image zh-lightbox-thumb\" width=\"1368\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-2951b6b51ba3f3e3052c7059fa5f1ef1_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1368&#39; height=&#39;126&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1368\" data-rawheight=\"126\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1368\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-2951b6b51ba3f3e3052c7059fa5f1ef1_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-2951b6b51ba3f3e3052c7059fa5f1ef1_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E当 representation 给定之后，如果把价值函数看做是 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=n%3D%7C%5Cmathcal%7BX%7D%7C\" alt=\"n=|\\mathcal{X}|\" eeimg=\"1\"\u002F\u003E 维空间中的一个点，那么 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Chat%7BV%7D_%5Cphi\" alt=\"\\hat{V}_\\phi\" eeimg=\"1\"\u002F\u003E 所能表示的价值函数在都在如下这个超平面中\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2812b07ac16f836e25eaa6572820f9cc_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1508\" data-rawheight=\"60\" class=\"origin_image zh-lightbox-thumb\" width=\"1508\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2812b07ac16f836e25eaa6572820f9cc_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1508&#39; height=&#39;60&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1508\" data-rawheight=\"60\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1508\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2812b07ac16f836e25eaa6572820f9cc_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2812b07ac16f836e25eaa6572820f9cc_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E最小化上述误差相当于在找 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=V%5E%5Cpi\" alt=\"V^\\pi\" eeimg=\"1\"\u002F\u003E 往这个超平面上的投影，即 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Chat%7BV%7D_%5Cphi%5E%5Cpi+%3D+%5CPi_%5Cphi+V%5E%5Cpi\" alt=\"\\hat{V}_\\phi^\\pi = \\Pi_\\phi V^\\pi\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Cp\u003ERepresentation 的学习可以通过一些 auxiliary task 来得到，比如之前的工作使用 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cphi%28x%29\" alt=\"\\phi(x)\" eeimg=\"1\"\u002F\u003E 外接神经网络去预测下一个状态。这里的学习方法也类似，只不过外接了一个线性映射去预测相应的价值函数。后面会看到，文章要求对于一族特殊的策略，希望都能找到参数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"\u002F\u003E 使得相应的价值函数估计接近真实的价值函数。\u003C\u002Fp\u003E\u003Cp\u003ERepresentation 的学习一般可以分为两种，一种是事先学习好（pretrained），另一种是随着策略的学习同时来学习（concurrently）。这里主要讲 pretrained 的情况。\u003C\u002Fp\u003E\u003Ch3\u003E2. 价值函数 polytope\u003C\u002Fh3\u003E\u003Cp\u003E由于上一篇才讲了，这里就不复习 polytope 了，只说下面这个引理\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9648ae4b641544ae460bac9d397e4c39_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1390\" data-rawheight=\"252\" class=\"origin_image zh-lightbox-thumb\" width=\"1390\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9648ae4b641544ae460bac9d397e4c39_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1390&#39; height=&#39;252&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1390\" data-rawheight=\"252\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1390\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9648ae4b641544ae460bac9d397e4c39_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9648ae4b641544ae460bac9d397e4c39_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中 extremal vertex 的定义如下\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-de66443c343d12b931cd08986f57d970_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1408\" data-rawheight=\"148\" class=\"origin_image zh-lightbox-thumb\" width=\"1408\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-de66443c343d12b931cd08986f57d970_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1408&#39; height=&#39;148&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1408\" data-rawheight=\"148\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1408\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-de66443c343d12b931cd08986f57d970_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-de66443c343d12b931cd08986f57d970_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E这个比较显然，即对于一个 polytope 在某个方向上投影最远的点一定是其 convex hull 的顶点。\u003C\u002Fp\u003E\u003Ch3\u003E3. 表示学习的目标\u003C\u002Fh3\u003E\u003Cp\u003E希望学习到一个这样的 representation：对于任意的策略，其表示经过线性映射都能尽可能得到该策略下的价值函数。即可以写出如下优化目标\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9694ceea1910414c51b3a0948f086d5b_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1336\" data-rawheight=\"98\" class=\"origin_image zh-lightbox-thumb\" width=\"1336\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9694ceea1910414c51b3a0948f086d5b_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1336&#39; height=&#39;98&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1336\" data-rawheight=\"98\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1336\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9694ceea1910414c51b3a0948f086d5b_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9694ceea1910414c51b3a0948f086d5b_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-00d73d11e8050cca617d8d6908a86200_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1482\" data-rawheight=\"44\" class=\"origin_image zh-lightbox-thumb\" width=\"1482\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-00d73d11e8050cca617d8d6908a86200_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1482&#39; height=&#39;44&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1482\" data-rawheight=\"44\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1482\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-00d73d11e8050cca617d8d6908a86200_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-00d73d11e8050cca617d8d6908a86200_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E一个 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=d\" alt=\"d\" eeimg=\"1\"\u002F\u003E 维的 representation 能表示出来的价值函数组成一个 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=d\" alt=\"d\" eeimg=\"1\"\u002F\u003E 维的超平面 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=H%3D%5C%7B%5CPhi%5Ctheta+%3A+%5Ctheta+%5Cin+%5Cmathbb%7BR%7D%5Ed%5C%7D\" alt=\"H=\\{\\Phi\\theta : \\theta \\in \\mathbb{R}^d\\}\" eeimg=\"1\"\u002F\u003E ，上述目标就是希望 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathcal%7BV%7D\" alt=\"\\mathcal{V}\" eeimg=\"1\"\u002F\u003E 中的离该超平面最远的一点也不要太远。形象地说，就是希望找到一个超平面尽可能多地在 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathcal%7BV%7D\" alt=\"\\mathcal{V}\" eeimg=\"1\"\u002F\u003E 里面。\u003C\u002Fp\u003E\u003Cp\u003E该目标要求对于所有的策略求最大值，这显然不容易做到，但是可以证明其实只需要对于所有的 extremal policies （即 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathcal%7BP%7D_v\" alt=\"\\mathcal{P}_v\" eeimg=\"1\"\u002F\u003E ）求最大值即可，这大大减小了搜索的空间。即，有如下定理。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-85c878ca0638f5644ae4f0126b2d8ed5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1384\" data-rawheight=\"584\" class=\"origin_image zh-lightbox-thumb\" width=\"1384\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-85c878ca0638f5644ae4f0126b2d8ed5_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1384&#39; height=&#39;584&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1384\" data-rawheight=\"584\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1384\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-85c878ca0638f5644ae4f0126b2d8ed5_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-85c878ca0638f5644ae4f0126b2d8ed5_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E更进一步，如果一个表示是最优的，那么由它确定的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=d\" alt=\"d\" eeimg=\"1\"\u002F\u003E 维超平面会对于 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=d%2B1\" alt=\"d+1\" eeimg=\"1\"\u002F\u003E 个 extremal policies 上价值函数的误差相同，并且这 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=d%2B1\" alt=\"d+1\" eeimg=\"1\"\u002F\u003E 个 extremal policies 产生的误差也等于所有 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathcal%7BV%7D\" alt=\"\\mathcal{V}\" eeimg=\"1\"\u002F\u003E 上产生的误差。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-253f113c894313fecb519c036ed8a10d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1414\" data-rawheight=\"476\" class=\"origin_image zh-lightbox-thumb\" width=\"1414\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-253f113c894313fecb519c036ed8a10d_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1414&#39; height=&#39;476&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1414\" data-rawheight=\"476\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1414\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-253f113c894313fecb519c036ed8a10d_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-253f113c894313fecb519c036ed8a10d_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Ch3\u003E4. 表示学习算法\u003C\u002Fh3\u003E\u003Cp\u003E表示学习算法主要分为两步，即先找到 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=k\" alt=\"k\" eeimg=\"1\"\u002F\u003E 个特殊的策略及其对应的价值函数（adversarial value functions，AVFs），再利用 AVF 计算 representation 的损失函数，通过梯度下降的方法来训练一个神经网络编码的 representation。算法表示如下\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-a5eb6e11d43c6754fca8c06147841d23_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1416\" data-rawheight=\"316\" class=\"origin_image zh-lightbox-thumb\" width=\"1416\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-a5eb6e11d43c6754fca8c06147841d23_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1416&#39; height=&#39;316&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1416\" data-rawheight=\"316\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1416\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-a5eb6e11d43c6754fca8c06147841d23_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-a5eb6e11d43c6754fca8c06147841d23_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E先讲如何得到 AVFs。前面说到给定一个方向 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta\" alt=\"\\delta\" eeimg=\"1\"\u002F\u003E ，使得 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta%5ET+V\" alt=\"\\delta^T V\" eeimg=\"1\"\u002F\u003E 最大的点是一个 extremal point，也就是我们感兴趣的一个点。因此这里随机生成一些方向，然后又策略梯度去得到这些我们感兴趣的策略，把这些策略及其对应的价值函数作为 AVF。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-e49a90a547102f922de59a180c53bd0b_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1414\" data-rawheight=\"160\" class=\"origin_image zh-lightbox-thumb\" width=\"1414\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-e49a90a547102f922de59a180c53bd0b_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1414&#39; height=&#39;160&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1414\" data-rawheight=\"160\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1414\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-e49a90a547102f922de59a180c53bd0b_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-e49a90a547102f922de59a180c53bd0b_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E接下来就使用得到的 AVF 来更新 representation。Loss function 可以写为\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-b845cfca551a5ac30dc04a38b92883d9_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1550\" data-rawheight=\"130\" class=\"origin_image zh-lightbox-thumb\" width=\"1550\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-b845cfca551a5ac30dc04a38b92883d9_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1550&#39; height=&#39;130&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1550\" data-rawheight=\"130\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1550\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-b845cfca551a5ac30dc04a38b92883d9_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-b845cfca551a5ac30dc04a38b92883d9_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%7B%5Cbf+%5Cmu%7D+%3A%3D+%5Cmu_1%2C+%5Ccdots%2C+%5Cmu_k\" alt=\"{\\bf \\mu} := \\mu_1, \\cdots, \\mu_k\" eeimg=\"1\"\u002F\u003E 是 k 个策略，对应的价值函数为 AVFs。\u003C\u002Fp\u003E\u003Cp\u003E由于 max 函数不方便求导（当两个策略产生的 loss 相同时梯度就会不确定性通过哪一项往回传），因此把上述的 max 改写为 softmax，即\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-279359735a91013ee12af0b7efba7e86_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1650\" data-rawheight=\"152\" class=\"origin_image zh-lightbox-thumb\" width=\"1650\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-279359735a91013ee12af0b7efba7e86_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1650&#39; height=&#39;152&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1650\" data-rawheight=\"152\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1650\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-279359735a91013ee12af0b7efba7e86_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-279359735a91013ee12af0b7efba7e86_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E对该损失函数做梯度下降即可求到相应的 representation。\u003C\u002Fp\u003E\u003Cp\u003E最大化 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta%5ET+V\" alt=\"\\delta^T V\" eeimg=\"1\"\u002F\u003E 究竟是在做什么呢？下面定理告诉我们最大化该目标相当于是在同时最大化或者最小化每个状态下的目标函数。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-3a4ece30e2378d0d9f58a049d46b374f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1536\" data-rawheight=\"672\" class=\"origin_image zh-lightbox-thumb\" width=\"1536\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-3a4ece30e2378d0d9f58a049d46b374f_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1536&#39; height=&#39;672&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1536\" data-rawheight=\"672\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1536\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-3a4ece30e2378d0d9f58a049d46b374f_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-3a4ece30e2378d0d9f58a049d46b374f_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E可以看出 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=d_%5Cpi+%3D+%28I+-+%5Cgamma+P%5E%5Cpi%29%5E%7B-1%7D+%5Cdelta\" alt=\"d_\\pi = (I - \\gamma P^\\pi)^{-1} \\delta\" eeimg=\"1\"\u002F\u003E ，如果 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta+%3D+I\" alt=\"\\delta = I\" eeimg=\"1\"\u002F\u003E （全 1 向量），那么 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=d_%5Cpi\" alt=\"d_\\pi\" eeimg=\"1\"\u002F\u003E 就是前面讲到的 successor representation，这时该目标就是一个正常的强化学习目标。\u003C\u002Fp\u003E\u003Ch2\u003E实验\u003C\u002Fh2\u003E\u003Cp\u003E文章在一个有四个房间的格子世界上做了实验，下图画出了随机生成的一个 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta\" alt=\"\\delta\" eeimg=\"1\"\u002F\u003E 及其对应的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=d_%5Cpi\" alt=\"d_\\pi\" eeimg=\"1\"\u002F\u003E 和 AVF。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-27be1e2f6a7cfa5fc7b08833b6c4df87_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2496\" data-rawheight=\"716\" class=\"origin_image zh-lightbox-thumb\" width=\"2496\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-27be1e2f6a7cfa5fc7b08833b6c4df87_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2496&#39; height=&#39;716&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2496\" data-rawheight=\"716\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2496\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-27be1e2f6a7cfa5fc7b08833b6c4df87_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-27be1e2f6a7cfa5fc7b08833b6c4df87_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E经验上来说，对于某个状态 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=x\" alt=\"x\" eeimg=\"1\"\u002F\u003E ，如果 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta%28x%29%3E0\" alt=\"\\delta(x)&gt;0\" eeimg=\"1\"\u002F\u003E ，那么大概率地其对应的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=d_%5Cpi%28x%29+%3E+0\" alt=\"d_\\pi(x) &gt; 0\" eeimg=\"1\"\u002F\u003E ，当然也会有例外，比如图中红色箭头所示的状态。\u003C\u002Fp\u003E\u003Cp\u003E文章还对比了另外两种做法形成的价值函数，一种是随机生成价值函数，另一种是随机生成策略然后求得对应的价值函数。可以看到 AVF 生成的价值函数（也可以看出相应的策略）更具有代表性。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f08c347a617bb5695fc4c67fe73c0e5a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2334\" data-rawheight=\"868\" class=\"origin_image zh-lightbox-thumb\" width=\"2334\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f08c347a617bb5695fc4c67fe73c0e5a_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2334&#39; height=&#39;868&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2334\" data-rawheight=\"868\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2334\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f08c347a617bb5695fc4c67fe73c0e5a_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f08c347a617bb5695fc4c67fe73c0e5a_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E下图展示了不同数目的 AVF 学习得到 representation 每一维的图像，可以看到 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=k%3D1000%3B4000\" alt=\"k=1000;4000\" eeimg=\"1\"\u002F\u003E 时，学习到的 representation 每一维都基本上能够反映一些结构信息（比如在是否在某个房间里面）。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-82d6680196f32150797b6a293db7db58_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2078\" data-rawheight=\"676\" class=\"origin_image zh-lightbox-thumb\" width=\"2078\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-82d6680196f32150797b6a293db7db58_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2078&#39; height=&#39;676&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2078\" data-rawheight=\"676\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2078\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-82d6680196f32150797b6a293db7db58_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-82d6680196f32150797b6a293db7db58_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E相应地，使用学到的 representation 来完成 RL 任务，需要的样本数目也会更少。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-36b0a2c2d8f2509cfd52c16717fe730b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1494\" data-rawheight=\"946\" class=\"origin_image zh-lightbox-thumb\" width=\"1494\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-36b0a2c2d8f2509cfd52c16717fe730b_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1494&#39; height=&#39;946&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1494\" data-rawheight=\"946\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1494\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-36b0a2c2d8f2509cfd52c16717fe730b_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-36b0a2c2d8f2509cfd52c16717fe730b_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Chr\u002F\u003E\u003Cp\u003E一个猜想：如果一个 MDP 有 bisimulation，那么其价值函数的 polytope 在一个低维子空间上。\u003C\u002Fp\u003E\u003Cp\u003E\u003C\u002Fp\u003E\u003Cp\u003E\u003C\u002Fp\u003E","adminClosedComment":false,"topics":[{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F20039099","type":"topic","id":"20039099","name":"强化学习 (Reinforcement Learning)"}],"voteupCount":7,"voting":0,"column":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"},"commentCount":0,"contributions":[{"id":21123635,"state":"accepted","type":"first_publish","column":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}}],"isTitleImageFullScreen":false,"upvotedFollowees":[],"commercialInfo":{"isCommercial":false,"plugin":{}},"suggestEdit":{"status":false,"reason":"","tip":"","url":"","title":""},"reason":"","annotationAction":[],"canTip":false,"tipjarorsCount":0,"isLabeled":false,"hasPublishingDraft":false,"isFavorited":false,"isNormal":true,"status":0,"shareText":"【强化学习 75】AVF - 来自知乎专栏「强化学习前沿」，作者: 张楚珩 https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F70150638 （想看更多？下载 @知乎 App：http:\u002F\u002Fweibo.com\u002Fp\u002F100404711598 ）","canComment":{"status":true,"reason":""},"mcnFpShow":-1,"isVisible":true,"isLiked":false,"likedCount":0,"visibleOnlyToAuthor":false}},"columns":{"reinforcementlearning":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}},"topics":{},"roundtables":{},"favlists":{},"comments":{},"notifications":{},"ebooks":{},"activities":{},"feeds":{},"pins":{},"promotions":{},"drafts":{},"chats":{},"posts":{},"clubs":{},"clubTags":{}},"currentUser":"","account":{"lockLevel":{},"unlockTicketStatus":false,"unlockTicket":null,"challenge":[],"errorStatus":false,"message":"","isFetching":false,"accountInfo":{},"urlToken":{"loading":false}},"settings":{"socialBind":null,"inboxMsg":null,"notification":{},"email":{},"privacyFlag":null,"blockedUsers":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"blockedFollowees":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"ignoredTopics":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"restrictedTopics":null,"laboratory":{}},"notification":{},"people":{"profileStatus":{},"activitiesByUser":{},"answersByUser":{},"answersSortByVotesByUser":{},"answersIncludedByUser":{},"votedAnswersByUser":{},"thankedAnswersByUser":{},"voteAnswersByUser":{},"thankAnswersByUser":{},"topicAnswersByUser":{},"zvideosByUser":{},"articlesByUser":{},"articlesSortByVotesByUser":{},"articlesIncludedByUser":{},"pinsByUser":{},"questionsByUser":{},"commercialQuestionsByUser":{},"favlistsByUser":{},"followingByUser":{},"followersByUser":{},"mutualsByUser":{},"followingColumnsByUser":{},"followingQuestionsByUser":{},"followingFavlistsByUser":{},"followingTopicsByUser":{},"publicationsByUser":{},"columnsByUser":{},"allFavlistsByUser":{},"brands":null,"creationsByUser":{},"creationsSortByVotesByUser":{},"creationsFeed":{}},"env":{"ab":{"config":{"experiments":[{"expId":"launch-gw_mweb_rec-1","expPrefix":"gw_mweb_rec","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-qa_hdpimg-2","expPrefix":"qa_hdpimg","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-us_foltopic_user-10","expPrefix":"us_foltopic_user","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_bullet_second-2","expPrefix":"vd_bullet_second","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_zvideo_link-10","expPrefix":"vd_zvideo_link","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"vd_bullet_gui-4","expPrefix":"vd_bullet_gui","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false}],"params":[{"id":"tp_club_tab","type":"String","value":"0","chainId":"_all_"},{"id":"li_pay_banner_type","type":"String","value":"6","chainId":"_all_"},{"id":"web_answer_list_ad","type":"String","value":"1"},{"id":"se_ios_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"zr_search_paid","type":"String","value":"0","chainId":"_all_"},{"id":"zr_video_recall","type":"String","value":"current_recall","chainId":"_all_"},{"id":"tsp_videobillboard","type":"String","value":"1","chainId":"_all_"},{"id":"li_ebok_chap","type":"String","value":"0","chainId":"_all_"},{"id":"zw_payc_qaedit","type":"String","value":"0","chainId":"_all_"},{"id":"zw_sameq_sorce","type":"String","value":"999","chainId":"_all_"},{"id":"se_hotsearch_2","type":"String","value":"1","chainId":"_all_"},{"id":"se_whitelist","type":"String","value":"0","chainId":"_all_"},{"id":"se_ffzx_jushen1","type":"String","value":"0","chainId":"_all_"},{"id":"zr_expslotpaid","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_qa","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_join","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iossort","type":"String","value":"0","chainId":"_all_"},{"id":"li_android_vip","type":"String","value":"0","chainId":"_all_"},{"id":"li_yxzl_new_style_a","type":"String","value":"1","chainId":"_all_"},{"id":"zr_slot_cold_start","type":"String","value":"aver","chainId":"_all_"},{"id":"gue_zvideo_link","type":"String","value":"1"},{"id":"se_site_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sticky_android","type":"String","value":"2","chainId":"_all_"},{"id":"tp_qa_metacard_top","type":"String","value":"top","chainId":"_all_"},{"id":"se_time_threshold","type":"String","value":"0","chainId":"_all_"},{"id":"se_hotmore","type":"String","value":"2","chainId":"_all_"},{"id":"se_auto_syn","type":"String","value":"0","chainId":"_all_"},{"id":"ug_follow_topic_1","type":"String","value":"2","chainId":"_all_"},{"id":"web_heifetz_grow_ad","type":"String","value":"1"},{"id":"web_sem_ab","type":"String","value":"1"},{"id":"li_answer_label","type":"String","value":"0","chainId":"_all_"},{"id":"web_collect","type":"String","value":"0"},{"id":"se_hotsearch_num","type":"String","value":"0","chainId":"_all_"},{"id":"tsp_vote","type":"String","value":"2","chainId":"_all_"},{"id":"web_upload","type":"String","value":"1"},{"id":"se_dnn_mt_v2","type":"String","value":"0","chainId":"_all_"},{"id":"tp_qa_toast","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_qa_pic","type":"String","value":"1","chainId":"_all_"},{"id":"soc_bignew","type":"String","value":"1","chainId":"_all_"},{"id":"soc_update","type":"String","value":"1","chainId":"_all_"},{"id":"web_ad_banner","type":"String","value":"0"},{"id":"se_rf_w","type":"String","value":"0","chainId":"_all_"},{"id":"se_timebox_up","type":"String","value":"0","chainId":"_all_"},{"id":"tp_discovery_ab_1","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zcfw_badcase","type":"String","value":"0","chainId":"_all_"},{"id":"se_college","type":"String","value":"default","chainId":"_all_"},{"id":"se_ad_index","type":"String","value":"10","chainId":"_all_"},{"id":"li_answer_card","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_across","type":"String","value":"1","chainId":"_all_"},{"id":"web_column_auto_invite","type":"String","value":"0"},{"id":"soc_ri_merge","type":"String","value":"0","chainId":"_all_"},{"id":"li_purchase_test","type":"String","value":"0","chainId":"_all_"},{"id":"li_svip_tab_search","type":"String","value":"0","chainId":"_all_"},{"id":"gue_thanks","type":"String","value":"0"},{"id":"web_mweb_launch","type":"String","value":"0"},{"id":"pf_foltopic_usernum","type":"String","value":"50","chainId":"_all_"},{"id":"zr_training_first","type":"String","value":"false","chainId":"_all_"},{"id":"tp_club_android_join","type":"String","value":"1","chainId":"_all_"},{"id":"tp_topic_tab_new","type":"String","value":"0-0-0","chainId":"_all_"},{"id":"gue_video_replay","type":"String","value":"0"},{"id":"li_se_edu","type":"String","value":"1","chainId":"_all_"},{"id":"zr_slot_training","type":"String","value":"1","chainId":"_all_"},{"id":"zr_video_rank","type":"String","value":"new_rank","chainId":"_all_"},{"id":"li_hot_voted","type":"String","value":"0","chainId":"_all_"},{"id":"ls_videoad","type":"String","value":"2","chainId":"_all_"},{"id":"soc_cardheight","type":"String","value":"2","chainId":"_all_"},{"id":"top_v_album","type":"String","value":"1","chainId":"_all_"},{"id":"top_test_4_liguangyi","type":"String","value":"1","chainId":"_all_"},{"id":"qap_question_visitor","type":"String","value":" 0","chainId":"_all_"},{"id":"tp_discover_copy","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zcfw_broadcast","type":"String","value":"0","chainId":"_all_"},{"id":"se_page_quality","type":"String","value":"0","chainId":"_all_"},{"id":"li_svip_cardshow","type":"String","value":"1","chainId":"_all_"},{"id":"gue_self_censoring","type":"String","value":"1"},{"id":"se_cardrank_1","type":"String","value":"0","chainId":"_all_"},{"id":"se_topiclabel","type":"String","value":"1","chainId":"_all_"},{"id":"se_cbert_index","type":"String","value":"0","chainId":"_all_"},{"id":"se_use_zitem","type":"String","value":"0","chainId":"_all_"},{"id":"soc_userrec","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zcfw_broadcast2","type":"String","value":"1","chainId":"_all_"},{"id":"li_salt_hot","type":"String","value":"1","chainId":"_all_"},{"id":"web_question_invite","type":"String","value":"B"},{"id":"se_webmajorob","type":"String","value":"0","chainId":"_all_"},{"id":"top_root","type":"String","value":"0","chainId":"_all_"},{"id":"qap_thanks","type":"String","value":"1","chainId":"_all_"},{"id":"soc_iospinweight","type":"String","value":"0","chainId":"_all_"},{"id":"ug_follow_answerer","type":"String","value":"0","chainId":"_all_"},{"id":"zr_intervene","type":"String","value":"0","chainId":"_all_"},{"id":"zr_slotpaidexp","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_feed","type":"String","value":"1","chainId":"_all_"},{"id":"se_backsearch","type":"String","value":"0","chainId":"_all_"},{"id":"soc_wonderuser_recom","type":"String","value":"2","chainId":"_all_"},{"id":"soc_feed_intimacy","type":"String","value":"2","chainId":"_all_"},{"id":"ls_recommend_test","type":"String","value":"0","chainId":"_all_"},{"id":"top_ydyq","type":"String","value":"X","chainId":"_all_"},{"id":"li_assessment_show","type":"String","value":"1","chainId":"_all_"},{"id":"zr_ans_rec","type":"String","value":"gbrank","chainId":"_all_"},{"id":"tp_club_header","type":"String","value":"1","chainId":"_all_"},{"id":"soc_special","type":"String","value":"0","chainId":"_all_"},{"id":"qap_question_author","type":"String","value":"0","chainId":"_all_"},{"id":"zr_answer_rec_cp","type":"String","value":"open","chainId":"_all_"},{"id":"se_featured","type":"String","value":"1","chainId":"_all_"},{"id":"soc_stickypush","type":"String","value":"1","chainId":"_all_"},{"id":"ug_fw_answ_aut_1","type":"String","value":"0","chainId":"_all_"},{"id":"ug_newtag","type":"String","value":"0","chainId":"_all_"},{"id":"li_qa_new_cover","type":"String","value":"1","chainId":"_all_"},{"id":"se_ctx_rerank","type":"String","value":"1","chainId":"_all_"},{"id":"se_websearch","type":"String","value":"3","chainId":"_all_"},{"id":"se_movietab","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_discover","type":"String","value":"0","chainId":"_all_"},{"id":"ug_follow_answerer_0","type":"String","value":"0","chainId":"_all_"},{"id":"li_video_section","type":"String","value":"0","chainId":"_all_"},{"id":"tp_meta_card","type":"String","value":"0","chainId":"_all_"},{"id":"pf_fuceng","type":"String","value":"1","chainId":"_all_"},{"id":"se_waterfall","type":"String","value":"0","chainId":"_all_"},{"id":"gue_bullet_guide","type":"String","value":"点我，做第一个上屏的人"},{"id":"zr_art_rec","type":"String","value":"base","chainId":"_all_"},{"id":"zr_training_boost","type":"String","value":"false","chainId":"_all_"},{"id":"se_specialbutton","type":"String","value":"0","chainId":"_all_"},{"id":"se_highlight","type":"String","value":"0","chainId":"_all_"},{"id":"qap_ques_invite","type":"String","value":"0","chainId":"_all_"},{"id":"se_hotsearch","type":"String","value":"0","chainId":"_all_"},{"id":"se_preset_tech","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_section","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_android_feed","type":"String","value":"old","chainId":"_all_"},{"id":"soc_authormore","type":"String","value":"2","chainId":"_all_"},{"id":"se_famous","type":"String","value":"1","chainId":"_all_"},{"id":"soc_adsort","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zcfw_shipinshiti","type":"String","value":"1","chainId":"_all_"},{"id":"pf_adjust","type":"String","value":"0","chainId":"_all_"},{"id":"li_vip_verti_search","type":"String","value":"0","chainId":"_all_"},{"id":"web_ask","type":"String","value":"0"},{"id":"web_sec672","type":"String","value":"0"},{"id":"soc_yxzl_zcfw","type":"String","value":"0","chainId":"_all_"},{"id":"soc_authormore2","type":"String","value":"2","chainId":"_all_"},{"id":"top_ebook","type":"String","value":"0","chainId":"_all_"},{"id":"tsp_hotlist_ui","type":"String","value":"1","chainId":"_all_"},{"id":"gue_video_autoplay","type":"String","value":"0"},{"id":"zr_rec_answer_cp","type":"String","value":"close","chainId":"_all_"},{"id":"se_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_rec","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_pic_swiper","type":"String","value":"1","chainId":"_all_"},{"id":"se_amovietab","type":"String","value":"1","chainId":"_all_"},{"id":"se_multianswer","type":"String","value":"2","chainId":"_all_"},{"id":"se_lottery","type":"String","value":"0","chainId":"_all_"},{"id":"gue_goods_card","type":"String","value":"0"},{"id":"web_hdpimg","type":"String","value":"1"},{"id":"se_new_merger","type":"String","value":"1","chainId":"_all_"},{"id":"tp_sft","type":"String","value":"a","chainId":"_all_"},{"id":"soc_adreadline","type":"String","value":"0","chainId":"_all_"},{"id":"soc_newfeed","type":"String","value":"2","chainId":"_all_"},{"id":"web_mweb_rec_length","type":"String","value":"1"},{"id":"zr_km_answer","type":"String","value":"open_cvr","chainId":"_all_"},{"id":"se_zu_recommend","type":"String","value":"0","chainId":"_all_"},{"id":"se_cate_l3","type":"String","value":"0","chainId":"_all_"},{"id":"se_billboardsearch","type":"String","value":"0","chainId":"_all_"},{"id":"pf_newguide_vertical","type":"String","value":"0","chainId":"_all_"},{"id":"se_aa","type":"String","value":"0","chainId":"_all_"},{"id":"gue_zhuantikapian","type":"String","value":"0"},{"id":"se_preset_label","type":"String","value":"1","chainId":"_all_"},{"id":"se_search_feed","type":"String","value":"N","chainId":"_all_"},{"id":"se_pek_test3","type":"String","value":"1","chainId":"_all_"},{"id":"se_hot_timebox","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_entry","type":"String","value":"0","chainId":"_all_"},{"id":"ug_zero_follow","type":"String","value":"0","chainId":"_all_"},{"id":"zr_video_rank_nn","type":"String","value":"new_rank","chainId":"_all_"},{"id":"zr_test_aa1","type":"String","value":"0","chainId":"_all_"},{"id":"se_pek_test2","type":"String","value":"1","chainId":"_all_"},{"id":"qap_payc_invite","type":"String","value":"0","chainId":"_all_"},{"id":"zr_update_merge_size","type":"String","value":"1","chainId":"_all_"},{"id":"pf_noti_entry_num","type":"String","value":"0","chainId":"_all_"},{"id":"ug_zero_follow_0","type":"String","value":"0","chainId":"_all_"},{"id":"li_answers_link","type":"String","value":"0","chainId":"_all_"},{"id":"se_aa_base","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_style","type":"String","value":"0","chainId":"_all_"},{"id":"pf_creator_card","type":"String","value":"1","chainId":"_all_"},{"id":"web_unfriendly_comm","type":"String","value":"0"},{"id":"se_cardrank_2","type":"String","value":"1","chainId":"_all_"},{"id":"soc_adreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"se_searchwiki","type":"String","value":"0","chainId":"_all_"},{"id":"top_new_feed","type":"String","value":"5","chainId":"_all_"},{"id":"se_webrs","type":"String","value":"1","chainId":"_all_"},{"id":"se_mobileweb","type":"String","value":"1","chainId":"_all_"},{"id":"se_college_cm","type":"String","value":"0","chainId":"_all_"},{"id":"tp_score_1","type":"String","value":"a","chainId":"_all_"},{"id":"soc_bigone","type":"String","value":"0","chainId":"_all_"},{"id":"se_zu_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_sug_term","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_tab","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iosreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"top_universalebook","type":"String","value":"1","chainId":"_all_"},{"id":"web_answer_update","type":"String","value":"0"},{"id":"se_sug_entrance","type":"String","value":"1","chainId":"_all_"},{"id":"se_pek_test","type":"String","value":"1","chainId":"_all_"},{"id":"se_new_topic","type":"String","value":"0","chainId":"_all_"},{"id":"tp_header_style","type":"String","value":"1","chainId":"_all_"},{"id":"top_quality","type":"String","value":"0","chainId":"_all_"},{"id":"web_mini_review","type":"String","value":"0"},{"id":"li_se_media_icon","type":"String","value":"1","chainId":"_all_"},{"id":"se_expired_ob","type":"String","value":"0","chainId":"_all_"},{"id":"gue_bullet_second","type":"String","value":"1"},{"id":"qap_article_like","type":"String","value":"1","chainId":"_all_"},{"id":"se_cardrank_3","type":"String","value":"0","chainId":"_all_"},{"id":"se_presearch_ab","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sft_v2","type":"String","value":"d","chainId":"_all_"},{"id":"soc_iosreadline","type":"String","value":"0","chainId":"_all_"},{"id":"top_hotcommerce","type":"String","value":"1","chainId":"_all_"},{"id":"web_answerlist_ad","type":"String","value":"0"},{"id":"se_col_boost","type":"String","value":"0","chainId":"_all_"},{"id":"se_sug","type":"String","value":"1","chainId":"_all_"},{"id":"web_audit_01","type":"String","value":"case1"},{"id":"li_catalog_card","type":"String","value":"1","chainId":"_all_"},{"id":"gue_new_special_page","type":"String","value":"1"},{"id":"zr_article_new","type":"String","value":"close","chainId":"_all_"},{"id":"web_n_web_msg","type":"String","value":"0"},{"id":"se_wannasearch","type":"String","value":"0","chainId":"_all_"},{"id":"se_payconsult","type":"String","value":"0","chainId":"_all_"},{"id":"tp_discover","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_4","type":"String","value":"1","chainId":"_all_"},{"id":"tp_topic_head","type":"String","value":"0","chainId":"_all_"},{"id":"se_entity_model","type":"String","value":"0","chainId":"_all_"},{"id":"se_p_slideshow","type":"String","value":"0","chainId":"_all_"},{"id":"se_content0","type":"String","value":"0","chainId":"_all_"},{"id":"se_topicfeed","type":"String","value":"0","chainId":"_all_"},{"id":"se_club_post","type":"String","value":"5","chainId":"_all_"},{"id":"tp_club_pic","type":"String","value":"0.6","chainId":"_all_"},{"id":"li_ebook_gen_search","type":"String","value":"0","chainId":"_all_"},{"id":"li_qa_btn_text","type":"String","value":"0","chainId":"_all_"},{"id":"se_click_club","type":"String","value":"1","chainId":"_all_"},{"id":"ug_goodcomment_0","type":"String","value":"1","chainId":"_all_"},{"id":"se_subtext","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_pk","type":"String","value":"1","chainId":"_all_"},{"id":"soc_leave_recommend","type":"String","value":"2","chainId":"_all_"},{"id":"soc_brdcst4","type":"String","value":"3","chainId":"_all_"},{"id":"gue_card_test","type":"String","value":"1"},{"id":"se_likebutton","type":"String","value":"0","chainId":"_all_"},{"id":"se_colorfultab","type":"String","value":"1","chainId":"_all_"},{"id":"se_entity_model_14","type":"String","value":"0","chainId":"_all_"},{"id":"li_ebook_read","type":"String","value":"0","chainId":"_all_"},{"id":"li_paid_answer_exp","type":"String","value":"0","chainId":"_all_"},{"id":"zr_rel_search","type":"String","value":"base","chainId":"_all_"},{"id":"se_adxtest","type":"String","value":"1","chainId":"_all_"},{"id":"soc_notification","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zuichangfangwen","type":"String","value":"0","chainId":"_all_"},{"id":"se_webtimebox","type":"String","value":"0","chainId":"_all_"},{"id":"li_education_box","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_heat","type":"String","value":"1","chainId":"_all_"},{"id":"zr_search_sim","type":"String","value":"0","chainId":"_all_"},{"id":"soc_brdcst3","type":"String","value":"0","chainId":"_all_"},{"id":"sem_up_growth","type":"String","value":"in_app","chainId":"_all_"},{"id":"se_relation_1","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_tab_feed","type":"String","value":"0","chainId":"_all_"},{"id":"tp_qa_metacard","type":"String","value":"1","chainId":"_all_"},{"id":"li_sku_bottom_bar_re","type":"String","value":"0","chainId":"_all_"},{"id":"se_article_icon","type":"String","value":"0","chainId":"_all_"},{"id":"se_ltr_video","type":"String","value":"0","chainId":"_all_"},{"id":"ls_fmp4","type":"String","value":"0","chainId":"_all_"},{"id":"zr_km_feed_nlp","type":"String","value":"old","chainId":"_all_"},{"id":"se_prf","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adpinweight","type":"String","value":"0","chainId":"_all_"},{"id":"se_agency","type":"String","value":" 0","chainId":"_all_"},{"id":"web_creator_route","type":"String","value":"1"},{"id":"tp_m_intro_re_topic","type":"String","value":"1","chainId":"_all_"},{"id":"soc_iosintimacy","type":"String","value":"2","chainId":"_all_"},{"id":"se_new_p","type":"String","value":"0","chainId":"_all_"},{"id":"se_related_index","type":"String","value":"3","chainId":"_all_"},{"id":"se_relationship","type":"String","value":"1","chainId":"_all_"}],"chains":[{"chainId":"_all_"}]},"triggers":{}},"userAgent":{"Edge":false,"Wechat":false,"Weibo":false,"QQ":false,"MQQBrowser":false,"Qzone":false,"Mobile":false,"Android":false,"iOS":false,"isAppleDevice":false,"Zhihu":false,"ZhihuHybrid":false,"isBot":false,"Tablet":false,"UC":false,"Sogou":false,"Qihoo":false,"Baidu":false,"BaiduApp":false,"Safari":false,"GoogleBot":false,"AndroidDaily":false,"iOSDaily":false,"isWebView":false,"origin":"Mozilla\u002F5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\u002F537.36 (KHTML, like Gecko) Chrome\u002F80.0.3987.100 Safari\u002F537.36"},"appViewConfig":{},"ctx":{"path":"\u002Fp\u002F70150638","query":{},"href":"http:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F70150638","host":"zhuanlan.zhihu.com"},"trafficSource":"production","edition":{"baidu":false,"sogou":false,"baiduBeijing":false,"sogouBeijing":false,"sogouInput":false},"theme":"light","enableShortcut":true,"referer":"","conf":{},"ipInfo":{"cityName":"德州","countryName":"中国","regionName":"山东","countryCode":"CN"},"logged":false},"me":{"columnContributions":[]},"label":{"recognizerLists":{}},"ecommerce":{},"comments":{"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"parent":{}},"commentsV2":{"stickers":[],"commentWithPicPermission":{},"notificationsComments":{},"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"conversationMore":{},"parent":{}},"pushNotifications":{"default":{"isFetching":false,"isDrained":false,"ids":[]},"follow":{"isFetching":false,"isDrained":false,"ids":[]},"vote_thank":{"isFetching":false,"isDrained":false,"ids":[]},"currentTab":"default","notificationsCount":{"default":0,"follow":0,"vote_thank":0}},"messages":{"data":{},"currentTab":"common","messageCount":0},"register":{"registerValidateSucceeded":null,"registerValidateErrors":{},"registerConfirmError":null,"sendDigitsError":null,"registerConfirmSucceeded":null},"login":{"loginUnregisteredError":false,"loginBindWechatError":false,"loginConfirmError":null,"sendDigitsError":null,"needSMSIdentify":false,"validateDigitsError":false,"loginConfirmSucceeded":null,"qrcodeLoginToken":"","qrcodeLoginScanStatus":0,"qrcodeLoginError":null,"qrcodeLoginReturnNewToken":false},"active":{"sendDigitsError":null,"activeConfirmSucceeded":null,"activeConfirmError":null},"switches":{},"captcha":{"captchaNeeded":false,"captchaValidated":false,"captchaBase64String":null,"captchaValidationMessage":null,"loginCaptchaExpires":false},"sms":{"supportedCountries":[]},"chat":{"chats":{},"inbox":{"recents":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"strangers":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"friends":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"search":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"config":{"newCount":0,"strangerMessageSwitch":false,"strangerMessageUnread":false,"friendCount":0}},"global":{"isChatMqttExisted":false}},"emoticons":{"emoticonGroupList":[],"emoticonGroupDetail":{}},"creator":{"currentCreatorUrlToken":null,"homeData":{"recommendQuestions":[]},"tools":{"question":{"invitationCount":{"questionFolloweeCount":0,"questionTotalCount":0},"goodatTopics":[]},"customPromotion":{"itemLists":{}},"recommend":{"recommendTimes":{}}},"explore":{"academy":{"tabs":[],"article":{}}},"rights":[],"rightsStatus":{},"levelUpperLimit":10,"account":{"growthLevel":{}},"mcn":{},"applyStatus":{}},"recommendation":{"homeRecommendations":[]},"shareTexts":{},"articles":{"voters":{}},"previewPost":{},"favlists":{"relations":{}},"columns":{"voters":{}},"reward":{"answer":{},"article":{},"question":{}},"video":{"data":{},"shareVideoDetail":{},"last":{}},"topstory":{"recommend":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"follow":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followWonderful":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"sidebar":null,"announcement":{},"hotListCategories":[],"hotList":[],"guestFeeds":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followExtra":{"isNewUser":null,"isFetched":false,"followCount":0,"followers":[]}},"readStatus":{},"column":{},"requestColumn":{"categories":[],"error":null},"articleContribution":{"contributeRequests":[],"deleteContributeIdList":[],"handledContributeIdList":[],"recommendedColumns":[],"pinnedColumns":[],"sentContributeRequestsIdList":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"reinforcementlearning"]},"columnContribution":{"contributeRequests":[],"autoInviteEnabled":false,"recommendedContributors":[],"contributionInvitation":null},"draftHistory":{"history":{},"drafts":{}},"upload":{},"articleDraft":{"titleImage":"","titleImageSize":{},"isTitleImageFullScreen":false,"canTitleImageFullScreen":false,"title":"","titleImageUploading":false,"error":"","content":"","draftLoading":false,"updating":false,"globalLoading":false,"pendingVideo":{"resource":null,"error":null},"deleteFail":{"fail":false},"recommendTopics":[],"selectedColumn":0,"articleDisclaimers":[]},"articleDrafts":{"isDrained":false,"isLoading":false,"items":[]},"columnAutocomplete":{"users":[],"friends":[]},"columnCollection":{},"mcn":{"bindInfo":{},"memberCategoryList":[],"producerList":[],"categoryList":[]}},"fetchHost":"www.zhihu.com","subAppName":"column"}</script><script src="https://static.zhihu.com/heifetz/vendor.7b36fae46082fd30a0db.js"></script><script src="https://static.zhihu.com/heifetz/column.app.76e02b16e87eec249f44.js"></script></body><script src="https://hm.baidu.com/hm.js?98beee57fd2ef70ccdd5ca52b9740c49" async=""></script><script src="https://zz.bdstatic.com/linksubmit/push.js" async=""></script></html>