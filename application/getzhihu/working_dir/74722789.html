<!doctype html>
<html lang="zh" data-hairline="true" data-theme="light"><head><meta charSet="utf-8"/><title data-react-helmet="true">【算法】Prediction2 - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"/><meta name="renderer" content="webkit"/><meta name="force-rendering" content="webkit"/><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg"/><meta data-react-helmet="true" name="keywords" content="强化学习 (Reinforcement Learning),博弈论"/><meta data-react-helmet="true" name="description" content="这一篇讲第二章：Prediction with Expert Advice。原文传送门Cesa-Bianchi, Nicolo, and Gabor Lugosi.Prediction, learning, and games. Cambridge university press, 2006. 由于是图书，就不放链接了，直接 goog…"/><meta data-react-helmet="true" property="og:title" content="【算法】Prediction2"/><meta data-react-helmet="true" property="og:url" content="https://zhuanlan.zhihu.com/p/74722789"/><meta data-react-helmet="true" property="og:description" content="这一篇讲第二章：Prediction with Expert Advice。原文传送门Cesa-Bianchi, Nicolo, and Gabor Lugosi.Prediction, learning, and games. Cambridge university press, 2006. 由于是图书，就不放链接了，直接 goog…"/><meta data-react-helmet="true" property="og:image" content="https://pic3.zhimg.com/v2-d17eddb36dc4f026969547138793ea34_b.jpg"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" property="og:site_name" content="知乎专栏"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png" sizes="152x152"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-120.b3e6278d.png" sizes="120x120"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-76.7a750095.png" sizes="76x76"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-60.a4a761d4.png" sizes="60x60"/><link rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/static/favicon.ico"/><link rel="search" type="application/opensearchdescription+xml" href="https://static.zhihu.com/static/search.xml" title="知乎"/><link rel="dns-prefetch" href="//static.zhimg.com"/><link rel="dns-prefetch" href="//pic1.zhimg.com"/><link rel="dns-prefetch" href="//pic2.zhimg.com"/><link rel="dns-prefetch" href="//pic3.zhimg.com"/><link rel="dns-prefetch" href="//pic4.zhimg.com"/><style>
.u-safeAreaInset-top {
  height: constant(safe-area-inset-top) !important;
  height: env(safe-area-inset-top) !important;
  
}
.u-safeAreaInset-bottom {
  height: constant(safe-area-inset-bottom) !important;
  height: env(safe-area-inset-bottom) !important;
  
}
</style><link href="https://static.zhihu.com/heifetz/column.app.a9ced452148fee3a55c8.css" rel="stylesheet"/><script defer="" crossorigin="anonymous" src="https://unpkg.zhimg.com/@cfe/sentry-script@latest/dist/init.js" data-sentry-config="{&quot;dsn&quot;:&quot;https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224&quot;,&quot;sampleRate&quot;:0.1,&quot;release&quot;:&quot;683-127b14ad&quot;,&quot;ignoreErrorNames&quot;:[&quot;NetworkError&quot;,&quot;SecurityError&quot;],&quot;ignoreErrors&quot;:[&quot;origin message&quot;,&quot;Network request failed&quot;,&quot;Loading chunk&quot;,&quot;这个系统不支持该功能。&quot;,&quot;Can&#x27;t find variable: webkit&quot;,&quot;Can&#x27;t find variable: $&quot;,&quot;内存不足&quot;,&quot;out of memory&quot;,&quot;DOM Exception 18&quot;,&quot;The operation is insecure&quot;,&quot;[object Event]&quot;,&quot;[object FileError]&quot;,&quot;[object DOMError]&quot;,&quot;[object Object]&quot;,&quot;拒绝访问。&quot;,&quot;Maximum call stack size exceeded&quot;,&quot;UploadError&quot;,&quot;无法 fetch&quot;,&quot;draft-js&quot;,&quot;缺少 JavaScript 对象&quot;,&quot;componentWillEnter&quot;,&quot;componentWillLeave&quot;,&quot;componentWillAppear&quot;,&quot;getInlineStyleAt&quot;,&quot;getCharacterList&quot;],&quot;whitelistUrls&quot;:[&quot;static.zhihu.com&quot;]}"></script></head><body class="WhiteBg-body"><div id="root"><div class="App"><div class="LoadingBar"></div><main role="main" class="App-main"><div class="Post-content" data-zop-usertoken="{&quot;userToken&quot;:&quot;&quot;}" data-zop="{&quot;authorName&quot;:&quot;张楚珩&quot;,&quot;itemId&quot;:74722789,&quot;title&quot;:&quot;【算法】Prediction2&quot;,&quot;type&quot;:&quot;article&quot;}"><div class="ColumnPageHeader-Wrapper"><div><div class="Sticky ColumnPageHeader"><div class="ColumnPageHeader-content"><a href="//www.zhihu.com" aria-label="知乎"><svg viewBox="0 0 200 91" fill="#0084FF" width="64" height="30"><path d="M53.29 80.035l7.32.002 2.41 8.24 13.128-8.24h15.477v-67.98H53.29v67.978zm7.79-60.598h22.756v53.22h-8.73l-8.718 5.473-1.587-5.46-3.72-.012v-53.22zM46.818 43.162h-16.35c.545-8.467.687-16.12.687-22.955h15.987s.615-7.05-2.68-6.97H16.807c1.09-4.1 2.46-8.332 4.1-12.708 0 0-7.523 0-10.085 6.74-1.06 2.78-4.128 13.48-9.592 24.41 1.84-.2 7.927-.37 11.512-6.94.66-1.84.785-2.08 1.605-4.54h9.02c0 3.28-.374 20.9-.526 22.95H6.51c-3.67 0-4.863 7.38-4.863 7.38H22.14C20.765 66.11 13.385 79.24 0 89.62c6.403 1.828 12.784-.29 15.937-3.094 0 0 7.182-6.53 11.12-21.64L43.92 85.18s2.473-8.402-.388-12.496c-2.37-2.788-8.768-10.33-11.496-13.064l-4.57 3.627c1.363-4.368 2.183-8.61 2.46-12.71H49.19s-.027-7.38-2.372-7.38zm128.752-.502c6.51-8.013 14.054-18.302 14.054-18.302s-5.827-4.625-8.556-1.27c-1.874 2.548-11.51 15.063-11.51 15.063l6.012 4.51zm-46.903-18.462c-2.814-2.577-8.096.667-8.096.667s12.35 17.2 12.85 17.953l6.08-4.29s-8.02-11.752-10.83-14.33zM199.99 46.5c-6.18 0-40.908.292-40.953.292v-31.56c1.503 0 3.882-.124 7.14-.376 12.773-.753 21.914-1.25 27.427-1.504 0 0 3.817-8.496-.185-10.45-.96-.37-7.24 1.43-7.24 1.43s-51.63 5.153-72.61 5.64c.5 2.756 2.38 5.336 4.93 6.11 4.16 1.087 7.09.53 15.36.277 7.76-.5 13.65-.76 17.66-.76v31.19h-41.71s.88 6.97 7.97 7.14h33.73v22.16c0 4.364-3.498 6.87-7.65 6.6-4.4.034-8.15-.36-13.027-.566.623 1.24 1.977 4.496 6.035 6.824 3.087 1.502 5.054 2.053 8.13 2.053 9.237 0 14.27-5.4 14.027-14.16V53.93h38.235c3.026 0 2.72-7.432 2.72-7.432z" fill-rule="evenodd"></path></svg></a><i class="ColumnPageHeader-Line"></i><div class="ColumnPageHeader-Title"><a class="ColumnLink ColumnPageHeader-Link" href="/reinforcementlearning"><img class="Avatar Avatar--round" width="30" height="30" src="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_is.jpg" srcSet="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_im.jpg 2x" alt="强化学习前沿"/></a><div class="ColumnPageHeader-TitleName"><span class="ColumnPageHeader-TitleMeta">首发于</span><a class="ColumnLink ColumnPageHeader-TitleColumn" href="/reinforcementlearning">强化学习前沿</a></div></div><div class="ColumnPageHeader-Button"><button type="button" class="Button ColumnPageHeader-WriteButton Button--blue"><svg class="Zi Zi--EditSurround" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M18.453 7.992l-1.833-1.65.964-.978a1.223 1.223 0 0 1 1.73-.012l.005.006a1.24 1.24 0 0 1 .007 1.748l-.873.886zm-1.178 1.194l-5.578 5.66-1.935.697a.393.393 0 0 1-.504-.504l.697-1.935 5.488-5.567 1.832 1.65zM7.58 5.848l5.654.006-1.539 1.991-3.666.012A1.02 1.02 0 0 0 7 8.868v7.993c0 .558.46 1.01 1.029 1.01l7.941-.01c.568 0 1.03-.453 1.03-1.012v-4.061l2-1.442v6.002c0 1.397-1.2 2.501-2.62 2.501H7.574C6.153 19.85 5 18.717 5 17.32V8.35c0-1.397 1.16-2.502 2.58-2.502z"></path></svg>写文章</button></div></div></div></div></div><img class="TitleImage" src="https://pic3.zhimg.com/v2-d17eddb36dc4f026969547138793ea34_1200x500.jpg" alt="【算法】Prediction2"/><article class="Post-Main Post-NormalMain" tabindex="-1"><header class="Post-Header"><h1 class="Post-Title">【算法】Prediction2</h1><div class="Post-Author"><div class="AuthorInfo" itemProp="author" itemscope="" itemType="http://schema.org/Person"><meta itemProp="name" content="张楚珩"/><meta itemProp="image" content="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg"/><meta itemProp="url" content="https://www.zhihu.com/people/zhang-chu-heng"/><meta itemProp="zhihu:followerCount"/><span class="UserLink AuthorInfo-avatarWrapper"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/zhang-chu-heng"><img class="Avatar Avatar--round AuthorInfo-avatar" width="38" height="38" src="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_xs.jpg" srcSet="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg 2x" alt="张楚珩"/></a></div></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/zhang-chu-heng">张楚珩</a></div></div><style data-emotion-css="1cd9gw4">.css-1cd9gw4{margin-left:.3em;}</style><style data-emotion-css="1pc1mic">.css-1pc1mic{box-sizing:border-box;margin:0;min-width:0;color:#175199;display:inline-block;width:18px;height:18px;margin-left:.3em;}</style><a href="https://www.zhihu.com/question/48510028" target="_blank" class="css-1pc1mic" data-tooltip="已认证的个人" aria-label="已认证的个人"><style data-emotion-css="18biwo">.css-18biwo{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><span class="css-18biwo">​<svg viewBox="0 0 24 24" width="18" height="18"><svg viewBox="0 0 24 24" x="-3" y="-3" fill="#FFFFFF" width="30" height="30"><path d="M3.56231227,13.8535307 C2.40051305,12.768677 2.41398885,11.0669203 3.59484487,9.99979213 L3.59222085,9.99654885 C4.26730143,9.45036719 4.79446755,8.21005186 4.7184197,7.34453784 L4.72305873,7.34412719 C4.66942824,5.75539997 5.8824188,4.56066914 7.47188965,4.64242381 L7.47229112,4.6386236 C8.33515314,4.72977993 9.58467253,4.22534048 10.1426329,3.55925173 L10.1462611,3.56228565 C11.2316055,2.40008701 12.9353108,2.41394456 14.0015072,3.59634088 L14.0047263,3.59374004 C14.5498229,4.26841874 15.7896857,4.79521622 16.6545744,4.71844347 L16.6549836,4.72304294 C18.245027,4.66894057 19.4396947,5.88213996 19.3575031,7.47241135 L19.3623099,7.47292747 C19.2704388,8.3358681 19.7742711,9.58421483 20.4407199,10.1424506 L20.437686,10.1460789 C21.5997217,11.2312209 21.5860695,12.9345218 20.4042441,14.0007396 L20.4072865,14.0045125 C19.7325967,14.5495925 19.2055209,15.7896954 19.2815865,16.6561959 L19.2770449,16.6565978 C19.3315454,18.2453037 18.1173775,19.4393568 16.5274188,19.3571512 L16.5269029,19.3619539 C15.6647098,19.270083 14.415408,19.7741709 13.8573671,20.4403558 L13.8537409,20.4373235 C12.76842,21.5995708 11.0650432,21.5864553 9.99899434,20.4039226 L9.99527367,20.406923 C9.45025436,19.7323399 8.21017638,19.2051872 7.34461983,19.2812352 L7.344304,19.2776405 C5.75448683,19.3312904 4.55977145,18.1170085 4.64254978,16.527117 L4.63769921,16.5265942 C4.72957031,15.6644394 4.22547659,14.4151814 3.55928015,13.8571569 L3.56231227,13.8535307 Z"></path></svg><path d="M2.63951518,13.3895441 C3.70763333,14.2842292 4.44777637,16.1226061 4.30075305,17.5023312 L4.32211542,17.3063047 C4.17509209,18.6910561 5.17786655,19.7063729 6.5613937,19.5844846 L6.364106,19.6008202 C7.75140298,19.4789319 9.57474349,20.2554985 10.4468305,21.3349009 L10.3224262,21.1803415 C11.1982831,22.2647703 12.6257916,22.2723098 13.5167278,21.2079863 L13.3898102,21.3600325 C14.2845162,20.2919393 16.1229361,19.5518136 17.5026934,19.6988334 L17.3054057,19.6774716 C18.6914461,19.8244915 19.7067866,18.8217404 19.5836389,17.4395022 L19.6012314,17.6367853 C19.4793403,16.2482641 20.255925,14.4249662 21.3353526,13.5528995 L21.1807897,13.677301 C22.2639871,12.8014646 22.2727834,11.3739894 21.2084351,10.483074 L21.3604848,10.6099886 C20.2923667,9.71530351 19.5522236,7.87818322 19.6992469,6.49720154 L19.6778846,6.69448464 C19.8249079,5.30847665 18.8221335,4.2944164 17.4386063,4.41630468 L17.635894,4.39871256 C16.248597,4.52185742 14.4252565,3.74529084 13.5531695,2.66588842 L13.6775738,2.81919121 C12.8017169,1.73601905 11.3742084,1.72722299 10.4832722,2.79154644 L10.6101898,2.63950024 C9.71548377,3.70759343 7.87706394,4.44771919 6.49730661,4.30195588 L6.69459432,4.32206116 C5.30855394,4.17504128 4.29447,5.17904888 4.41636114,6.56128713 L4.3987686,6.36400404 C4.52065973,7.75126861 3.74407501,9.57456653 2.66464737,10.4478898 L2.81921035,10.3222318 C1.73601288,11.1993248 1.72721662,12.6255433 2.79156494,13.5164587 L2.63951518,13.3895441 Z" fill="#0084FF"></path><svg class="Zi Zi--Check" fill="#fff" x="6" y="6" viewBox="0 0 24 24" width="12" height="12"><path d="M10.229 17.516c-.318.327-.75.484-1.199.484-.453 0-.884-.16-1.202-.488l-4.335-4.47a1.77 1.77 0 0 1 .007-2.459 1.663 1.663 0 0 1 2.397.01l3.137 3.246 9.072-9.329a1.662 1.662 0 0 1 2.397 0c.663.681.663 1.786 0 2.466L10.23 17.516z" fill-rule="evenodd"></path></svg></svg></span></a></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="AuthorInfo-badgeText">清华大学 交叉信息院博士在读</div></div></div></div></div></div><div><span class="Voters"><button type="button" class="Button Button--plain">6 人<!-- -->赞同了该文章</button></span></div></header><div class="Post-RichTextContainer"><div class="RichText ztext Post-RichText"><p>这一篇讲第二章：Prediction with Expert Advice。</p><h2>原文传送门</h2><p>Cesa-Bianchi, Nicolo, and Gabor Lugosi.<i>Prediction, learning, and games</i>. Cambridge university press, 2006. </p><p>由于是图书，就不放链接了，直接 google 就能搜得到 PDF。</p><h2>特色</h2><p>针对前一讲提到的 expert problem 的设定，针对一些略微不同的问题设定，给出了相应的策略并且证明了不同策略下的 regret bound。这些策略都是『综合考虑不同专家给出的意见』，数学上来说，即采用 weighted average 的方式作出预测。</p><h2>过程</h2><h3>1. 问题设定</h3><p>和上一讲的设定一样，只不过这里更形式化一点。定义 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BY%7D" alt="\mathcal{Y}" eeimg="1"/> 为 outcome space， <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BD%7D" alt="\mathcal{D}" eeimg="1"/> 为 decision space， <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BE%7D" alt="\mathcal{E}" eeimg="1"/> 为专家的集合。每一轮 <img src="https://www.zhihu.com/equation?tex=t" alt="t" eeimg="1"/> 按照如下顺序进行：</p><ul><li>1）专家给出建议 <img src="https://www.zhihu.com/equation?tex=f_%7BE%2C+t%7D+%5Cin%5Cmathcal%7BD%7D%2C+E+%5Cin+%5Cmathcal%7BE%7D" alt="f_{E, t} \in\mathcal{D}, E \in \mathcal{E}" eeimg="1"/> ；</li><li>2）玩家（forecaster）根据专家的建议做出预测 <img src="https://www.zhihu.com/equation?tex=%5Chat%7Bp%7D_t%5Cin+%5Cmathcal%7BD%7D" alt="\hat{p}_t\in \mathcal{D}" eeimg="1"/> ；</li><li>3）环境给出结果 <img src="https://www.zhihu.com/equation?tex=y_t+%5Cin+%5Cmathcal%7BY%7D" alt="y_t \in \mathcal{Y}" eeimg="1"/> ；</li><li>4）玩家遭受损失， <img src="https://www.zhihu.com/equation?tex=l%28%5Chat%7Bp%7D_t%2C+y_t%29" alt="l(\hat{p}_t, y_t)" eeimg="1"/> ，其中损失函数 <img src="https://www.zhihu.com/equation?tex=l%3A+%5Cmathcal%7BD%5Ctimes+Y%7D+%5Cto+%5Cmathbb%7BR%7D" alt="l: \mathcal{D\times Y} \to \mathbb{R}" eeimg="1"/> 。</li></ul><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-558f2173ea8cc56916b46e935068e4da_b.jpg" data-caption="" data-size="normal" data-rawwidth="2358" data-rawheight="1038" class="origin_image zh-lightbox-thumb" width="2358" data-original="https://pic3.zhimg.com/v2-558f2173ea8cc56916b46e935068e4da_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2358&#39; height=&#39;1038&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2358" data-rawheight="1038" class="origin_image zh-lightbox-thumb lazy" width="2358" data-original="https://pic3.zhimg.com/v2-558f2173ea8cc56916b46e935068e4da_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-558f2173ea8cc56916b46e935068e4da_b.jpg"/></figure><p>目标是最小化 regret，即</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-bc70d5aa91a0260535069c99065a47ba_b.png" data-caption="" data-size="normal" data-rawwidth="2326" data-rawheight="220" class="origin_image zh-lightbox-thumb" width="2326" data-original="https://pic3.zhimg.com/v2-bc70d5aa91a0260535069c99065a47ba_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2326&#39; height=&#39;220&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2326" data-rawheight="220" class="origin_image zh-lightbox-thumb lazy" width="2326" data-original="https://pic3.zhimg.com/v2-bc70d5aa91a0260535069c99065a47ba_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-bc70d5aa91a0260535069c99065a47ba_b.png"/></figure><p>注意到，它的比较基准是全部 follow 同一个专家 <img src="https://www.zhihu.com/equation?tex=E" alt="E" eeimg="1"/> 。这本书都考虑有限个专家，因此每个专家可以记做 <img src="https://www.zhihu.com/equation?tex=E%5Cin%5Cmathcal%7BE%7D+%5Cto+i%5Cin%5BN%5D" alt="E\in\mathcal{E} \to i\in[N]" eeimg="1"/> 。</p><p>期望设计的策略能够使得 regret 的增长速度比玩的轮数 <img src="https://www.zhihu.com/equation?tex=n" alt="n" eeimg="1"/> 要慢得多，即</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-5ebbd7d313e0b206ae57d5655d25ba51_b.png" data-caption="" data-size="normal" data-rawwidth="2264" data-rawheight="170" class="origin_image zh-lightbox-thumb" width="2264" data-original="https://pic2.zhimg.com/v2-5ebbd7d313e0b206ae57d5655d25ba51_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2264&#39; height=&#39;170&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2264" data-rawheight="170" class="origin_image zh-lightbox-thumb lazy" width="2264" data-original="https://pic2.zhimg.com/v2-5ebbd7d313e0b206ae57d5655d25ba51_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-5ebbd7d313e0b206ae57d5655d25ba51_b.png"/></figure><h3>2. Weighted average prediction</h3><p>一个最简单的想法还是对于每个专家维护一个权重，然后决定的时候使用加权平均来做预测。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-e2175e7302508e107e186011608c96ec_b.png" data-caption="" data-size="normal" data-rawwidth="2342" data-rawheight="236" class="origin_image zh-lightbox-thumb" width="2342" data-original="https://pic1.zhimg.com/v2-e2175e7302508e107e186011608c96ec_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2342&#39; height=&#39;236&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2342" data-rawheight="236" class="origin_image zh-lightbox-thumb lazy" width="2342" data-original="https://pic1.zhimg.com/v2-e2175e7302508e107e186011608c96ec_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-e2175e7302508e107e186011608c96ec_b.png"/></figure><p>玩家能获取的信息主要是玩家历史上产生的损失和各个专家在历史上产生的损失，一个比较自然的选择是让各个专家的权重取决于历史上玩家相对于该专家的 regret <img src="https://www.zhihu.com/equation?tex=R_%7Bi%2Ct-1%7D%3D%5Chat%7BL%7D_%7Bt-1%7D+-+L_%7Bi%2C+t-1%7D" alt="R_{i,t-1}=\hat{L}_{t-1} - L_{i, t-1}" eeimg="1"/> 。（当然，也可以只取决于各个专家在历史上产生的损失，而不取决于玩家在历史上的损失；毕竟一个专家的靠谱程度应该和玩家之前有没有听从其建议无关，后面会有这样的方案，不过这里暂且假定取决于各个 regret。） </p><p><b><i>下面定义一类的权重函数，它给出了专家历史上 regret 到各个专家对应权重之间的关系；接下来将会看到它和 regret bound 之间的联系。</i></b></p><p>令 instantaneous regret vector <img src="https://www.zhihu.com/equation?tex=%7B%5Cbf+r%7D_t+%3D+%28r_%7B1%2C+t%7D%2C+%5Ccdots%2C+r_%7BN%2Ct%7D%29+%5Cin+%5Cmathbb%7BR%7D%5EN" alt="{\bf r}_t = (r_{1, t}, \cdots, r_{N,t}) \in \mathbb{R}^N" eeimg="1"/> ，使得 <img src="https://www.zhihu.com/equation?tex=%7B%5Cbf+R%7D_t%3D%5Csum_%7Bt%3D1%7D%5En+%7B%5Cbf+r%7D_t" alt="{\bf R}_t=\sum_{t=1}^n {\bf r}_t" eeimg="1"/> 的各个分量为玩家相对于各个专家截止当前时刻的 regret。定义</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-93773d9df1d22db3028c461ea992970a_b.jpg" data-caption="" data-size="normal" data-rawwidth="2346" data-rawheight="484" class="origin_image zh-lightbox-thumb" width="2346" data-original="https://pic3.zhimg.com/v2-93773d9df1d22db3028c461ea992970a_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2346&#39; height=&#39;484&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2346" data-rawheight="484" class="origin_image zh-lightbox-thumb lazy" width="2346" data-original="https://pic3.zhimg.com/v2-93773d9df1d22db3028c461ea992970a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-93773d9df1d22db3028c461ea992970a_b.jpg"/></figure><p>可以看出势能函数是相对于 regret 的增函数，因此我们希望多轮之后势能函数尽可能小。</p><p>让玩家每次按照如下公式做出预测</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-e641bd0e8f51814bb9f16af814add0b4_b.png" data-caption="" data-size="normal" data-rawwidth="2414" data-rawheight="326" class="origin_image zh-lightbox-thumb" width="2414" data-original="https://pic1.zhimg.com/v2-e641bd0e8f51814bb9f16af814add0b4_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2414&#39; height=&#39;326&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2414" data-rawheight="326" class="origin_image zh-lightbox-thumb lazy" width="2414" data-original="https://pic1.zhimg.com/v2-e641bd0e8f51814bb9f16af814add0b4_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-e641bd0e8f51814bb9f16af814add0b4_b.png"/></figure><p>如果损失函数是 convex 的，可以发现（利用 Jensen 不等式），每一轮按照权重加权平均的 instantaneous regret 都是小于等于零的，即 Blackwell condition：</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-2f7efd9d79a0bb4a76d7e1dde3e68918_b.png" data-caption="" data-size="normal" data-rawwidth="2332" data-rawheight="150" class="origin_image zh-lightbox-thumb" width="2332" data-original="https://pic1.zhimg.com/v2-2f7efd9d79a0bb4a76d7e1dde3e68918_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2332&#39; height=&#39;150&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2332" data-rawheight="150" class="origin_image zh-lightbox-thumb lazy" width="2332" data-original="https://pic1.zhimg.com/v2-2f7efd9d79a0bb4a76d7e1dde3e68918_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-2f7efd9d79a0bb4a76d7e1dde3e68918_b.png"/></figure><p>下图比较形象地说明了满足 Blackwell condition 下的更新情形。</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-118a509a1e39d0a702b9b3832d24ccc5_b.jpg" data-caption="" data-size="normal" data-rawwidth="2388" data-rawheight="1564" class="origin_image zh-lightbox-thumb" width="2388" data-original="https://pic2.zhimg.com/v2-118a509a1e39d0a702b9b3832d24ccc5_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2388&#39; height=&#39;1564&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2388" data-rawheight="1564" class="origin_image zh-lightbox-thumb lazy" width="2388" data-original="https://pic2.zhimg.com/v2-118a509a1e39d0a702b9b3832d24ccc5_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-118a509a1e39d0a702b9b3832d24ccc5_b.jpg"/></figure><p>这样的更新方式保证了 regret 的变化方向 <img src="https://www.zhihu.com/equation?tex=%7B%5Cbf+r%7D_t+%3D+%7B%5Cbf+R%7D_t+-+%7B%5Cbf+R%7D_%7Bt-1%7D++" alt="{\bf r}_t = {\bf R}_t - {\bf R}_{t-1}  " eeimg="1"/> 和势能的梯度上升方向 <img src="https://www.zhihu.com/equation?tex=%5Cnabla%5CPhi%28%7B%5Cbf+R%7D_%7Bt-1%7D%29" alt="\nabla\Phi({\bf R}_{t-1})" eeimg="1"/> （也就是说各个专家的权重）夹角为钝角，这样虽然有可能 <img src="https://www.zhihu.com/equation?tex=%7B%5Cbf+R%7D_t+" alt="{\bf R}_t " eeimg="1"/> 的势能还是比 <img src="https://www.zhihu.com/equation?tex=%7B%5Cbf+R%7D_%7Bt-1%7D+" alt="{\bf R}_{t-1} " eeimg="1"/> 大，但是不至于上升地太快。由于 regret 变化的<b><i>方向</i></b>是朝着势能变小的方向的，如果只看一阶近似， <img src="https://www.zhihu.com/equation?tex=%7B%5Cbf+R%7D_t+" alt="{\bf R}_t " eeimg="1"/> 的势能应该比 <img src="https://www.zhihu.com/equation?tex=%7B%5Cbf+R%7D_%7Bt-1%7D+" alt="{\bf R}_{t-1} " eeimg="1"/> 更低。由此自然想到，如果我们 bound 更高阶的近似，就能够得到势能的上界。</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-c92c370ecc921f4bae24134fddea38c3_b.jpg" data-caption="" data-size="normal" data-rawwidth="2342" data-rawheight="474" class="origin_image zh-lightbox-thumb" width="2342" data-original="https://pic4.zhimg.com/v2-c92c370ecc921f4bae24134fddea38c3_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2342&#39; height=&#39;474&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2342" data-rawheight="474" class="origin_image zh-lightbox-thumb lazy" width="2342" data-original="https://pic4.zhimg.com/v2-c92c370ecc921f4bae24134fddea38c3_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-c92c370ecc921f4bae24134fddea38c3_b.jpg"/></figure><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-7f7786d3fa77c14b3ff70f56d5741064_b.png" data-caption="" data-size="normal" data-rawwidth="2304" data-rawheight="350" class="origin_image zh-lightbox-thumb" width="2304" data-original="https://pic1.zhimg.com/v2-7f7786d3fa77c14b3ff70f56d5741064_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2304&#39; height=&#39;350&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2304" data-rawheight="350" class="origin_image zh-lightbox-thumb lazy" width="2304" data-original="https://pic1.zhimg.com/v2-7f7786d3fa77c14b3ff70f56d5741064_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-7f7786d3fa77c14b3ff70f56d5741064_b.png"/></figure><p>证明方法也比较简单，就是泰勒展开之后 bound 二阶导。</p><p>以上定理的意义在于 bound 了势能函数相当于就 bound 了这种策略下的 regret，注意到</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-784b0aecedc60dd20a627f2b8066cd02_b.png" data-caption="" data-size="normal" data-rawwidth="2392" data-rawheight="238" class="origin_image zh-lightbox-thumb" width="2392" data-original="https://pic3.zhimg.com/v2-784b0aecedc60dd20a627f2b8066cd02_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2392&#39; height=&#39;238&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2392" data-rawheight="238" class="origin_image zh-lightbox-thumb lazy" width="2392" data-original="https://pic3.zhimg.com/v2-784b0aecedc60dd20a627f2b8066cd02_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-784b0aecedc60dd20a627f2b8066cd02_b.png"/></figure><p>（最大的 regret 比 regret 的和要小，前一讲里面的证明也用到这个原理）</p><p>有</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-71f7375e6ce4362db450c9b605e6fa71_b.png" data-caption="" data-size="normal" data-rawwidth="2370" data-rawheight="158" class="origin_image zh-lightbox-thumb" width="2370" data-original="https://pic2.zhimg.com/v2-71f7375e6ce4362db450c9b605e6fa71_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2370&#39; height=&#39;158&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2370" data-rawheight="158" class="origin_image zh-lightbox-thumb lazy" width="2370" data-original="https://pic2.zhimg.com/v2-71f7375e6ce4362db450c9b605e6fa71_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-71f7375e6ce4362db450c9b605e6fa71_b.png"/></figure><p><b><i>和前一讲里面问题设定的区别</i></b></p><p>前一讲中 decision space 和 outcome space 都是 binary 的，是离散的，不是 convex set，用 majority vote。 这里的 decision space 是一个 convex set，这样保证对于各个专家加权平均之后得到的结果还在 decision space 中，因此使用加权平均。很多情况下可以认为 decision space = outcome space。</p><h3>3. Polynomially weighted average forecaster</h3><p>前面定义了一种势能，多项式加权平均是满足前述定义势能函数的一个特殊的例子。多项式势能定义如下：</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-0b4340ee8327fc4444796a65d0df244e_b.png" data-caption="" data-size="normal" data-rawwidth="2298" data-rawheight="256" class="origin_image zh-lightbox-thumb" width="2298" data-original="https://pic3.zhimg.com/v2-0b4340ee8327fc4444796a65d0df244e_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2298&#39; height=&#39;256&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2298" data-rawheight="256" class="origin_image zh-lightbox-thumb lazy" width="2298" data-original="https://pic3.zhimg.com/v2-0b4340ee8327fc4444796a65d0df244e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-0b4340ee8327fc4444796a65d0df244e_b.png"/></figure><p>即，前面势能的定义中 <img src="https://www.zhihu.com/equation?tex=%5Cpsi%28%5Ccdot%29%3D%28%5Ccdot%29%5E%7B2%2Fp%7D%2C+%5Cphi%28%5Ccdot%29+%3D+%28%5Ccdot%29_%2B%5Ep" alt="\psi(\cdot)=(\cdot)^{2/p}, \phi(\cdot) = (\cdot)_+^p" eeimg="1"/> 。这样每个 expert 对应的权重为</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-80cfd047331aa1a7d097bfad4ba778f8_b.png" data-caption="" data-size="normal" data-rawwidth="2338" data-rawheight="194" class="origin_image zh-lightbox-thumb" width="2338" data-original="https://pic1.zhimg.com/v2-80cfd047331aa1a7d097bfad4ba778f8_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2338&#39; height=&#39;194&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2338" data-rawheight="194" class="origin_image zh-lightbox-thumb lazy" width="2338" data-original="https://pic1.zhimg.com/v2-80cfd047331aa1a7d097bfad4ba778f8_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-80cfd047331aa1a7d097bfad4ba778f8_b.png"/></figure><p>玩家每次的预测数值为</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-9b00dfc2f61a10dea7cb24ce227ced95_b.jpg" data-caption="" data-size="normal" data-rawwidth="2358" data-rawheight="512" class="origin_image zh-lightbox-thumb" width="2358" data-original="https://pic2.zhimg.com/v2-9b00dfc2f61a10dea7cb24ce227ced95_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2358&#39; height=&#39;512&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2358" data-rawheight="512" class="origin_image zh-lightbox-thumb lazy" width="2358" data-original="https://pic2.zhimg.com/v2-9b00dfc2f61a10dea7cb24ce227ced95_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-9b00dfc2f61a10dea7cb24ce227ced95_b.jpg"/></figure><p>注意到势能定义里面的 <img src="https://www.zhihu.com/equation?tex=%5Cpsi%28%5Ccdot%29" alt="\psi(\cdot)" eeimg="1"/> 其实不影响玩家给出的预测数值，它的设定只是为了分析方便。因此，设定 <img src="https://www.zhihu.com/equation?tex=%5CPhi_p%28%7B%5Cbf+u%7D%29%3D%7C%7C%7B%5Cbf+u%7D_%2B%7C%7C_p" alt="\Phi_p({\bf u})=||{\bf u}_+||_p" eeimg="1"/> 也是一样的。</p><p>可以套用前面的结论，可以得到这种策略下的 regret bound：</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-6ab67816d5baa76cdabe417ee8d5d8ef_b.png" data-caption="" data-size="normal" data-rawwidth="2338" data-rawheight="212" class="origin_image zh-lightbox-thumb" width="2338" data-original="https://pic4.zhimg.com/v2-6ab67816d5baa76cdabe417ee8d5d8ef_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2338&#39; height=&#39;212&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2338" data-rawheight="212" class="origin_image zh-lightbox-thumb lazy" width="2338" data-original="https://pic4.zhimg.com/v2-6ab67816d5baa76cdabe417ee8d5d8ef_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-6ab67816d5baa76cdabe417ee8d5d8ef_b.png"/></figure><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-cb62061ec56235e082e2cd58447b7158_b.png" data-caption="" data-size="normal" data-rawwidth="2364" data-rawheight="268" class="origin_image zh-lightbox-thumb" width="2364" data-original="https://pic1.zhimg.com/v2-cb62061ec56235e082e2cd58447b7158_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2364&#39; height=&#39;268&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2364" data-rawheight="268" class="origin_image zh-lightbox-thumb lazy" width="2364" data-original="https://pic1.zhimg.com/v2-cb62061ec56235e082e2cd58447b7158_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-cb62061ec56235e082e2cd58447b7158_b.png"/></figure><p>令 <img src="https://www.zhihu.com/equation?tex=p+%3D+2%5Cln+N" alt="p = 2\ln N" eeimg="1"/> ，可以得到一个最优的 bound：</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-209dcc20a28849166252867746a9b35b_b.png" data-caption="" data-size="normal" data-rawwidth="2342" data-rawheight="140" class="origin_image zh-lightbox-thumb" width="2342" data-original="https://pic4.zhimg.com/v2-209dcc20a28849166252867746a9b35b_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2342&#39; height=&#39;140&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2342" data-rawheight="140" class="origin_image zh-lightbox-thumb lazy" width="2342" data-original="https://pic4.zhimg.com/v2-209dcc20a28849166252867746a9b35b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-209dcc20a28849166252867746a9b35b_b.png"/></figure><h3>4. Exponentially weighted average forecaster</h3><p>前面的介绍的多项式势能产生的策略不仅仅依赖于各个专家历史上产生的损失，还取决于玩家在历史上产生的损失。但是各个专家的权重其实可以不依赖于玩家产生的损失。当我们使用如下的这种指数势能函数的时候，玩家产生的权重部分就可以被抵消掉，因而形成一个和玩家历史无关的 forecaster。</p><p>定义指数势能为：</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-f4ebde1e90ebe6ba6868bc8faf41768a_b.png" data-caption="" data-size="normal" data-rawwidth="2352" data-rawheight="222" class="origin_image zh-lightbox-thumb" width="2352" data-original="https://pic3.zhimg.com/v2-f4ebde1e90ebe6ba6868bc8faf41768a_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2352&#39; height=&#39;222&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2352" data-rawheight="222" class="origin_image zh-lightbox-thumb lazy" width="2352" data-original="https://pic3.zhimg.com/v2-f4ebde1e90ebe6ba6868bc8faf41768a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-f4ebde1e90ebe6ba6868bc8faf41768a_b.png"/></figure><p>各个专家的权重为：</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-22c083f7056faa16db7c94fecdb278e0_b.png" data-caption="" data-size="normal" data-rawwidth="2324" data-rawheight="234" class="origin_image zh-lightbox-thumb" width="2324" data-original="https://pic1.zhimg.com/v2-22c083f7056faa16db7c94fecdb278e0_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2324&#39; height=&#39;234&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2324" data-rawheight="234" class="origin_image zh-lightbox-thumb lazy" width="2324" data-original="https://pic1.zhimg.com/v2-22c083f7056faa16db7c94fecdb278e0_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-22c083f7056faa16db7c94fecdb278e0_b.png"/></figure><p>或者写作：</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-09c462c8b78535ff70e5e99e762b111e_b.png" data-caption="" data-size="normal" data-rawwidth="2294" data-rawheight="224" class="origin_image zh-lightbox-thumb" width="2294" data-original="https://pic3.zhimg.com/v2-09c462c8b78535ff70e5e99e762b111e_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2294&#39; height=&#39;224&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2294" data-rawheight="224" class="origin_image zh-lightbox-thumb lazy" width="2294" data-original="https://pic3.zhimg.com/v2-09c462c8b78535ff70e5e99e762b111e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-09c462c8b78535ff70e5e99e762b111e_b.png"/></figure><p>相应的 forecaster 为，观察到玩家的历史损失被上下约掉了：</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-d953b1927a0f56ed946940a47f45e010_b.png" data-caption="" data-size="normal" data-rawwidth="2298" data-rawheight="250" class="origin_image zh-lightbox-thumb" width="2298" data-original="https://pic1.zhimg.com/v2-d953b1927a0f56ed946940a47f45e010_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2298&#39; height=&#39;250&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2298" data-rawheight="250" class="origin_image zh-lightbox-thumb lazy" width="2298" data-original="https://pic1.zhimg.com/v2-d953b1927a0f56ed946940a47f45e010_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-d953b1927a0f56ed946940a47f45e010_b.png"/></figure><p>相应地，还是套用前面的结论，可以得到这种 forecaster 对应的 regret bound：</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-8338bda996c0248db0f242f7f235a3be_b.jpg" data-caption="" data-size="normal" data-rawwidth="2384" data-rawheight="478" class="origin_image zh-lightbox-thumb" width="2384" data-original="https://pic3.zhimg.com/v2-8338bda996c0248db0f242f7f235a3be_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2384&#39; height=&#39;478&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2384" data-rawheight="478" class="origin_image zh-lightbox-thumb lazy" width="2384" data-original="https://pic3.zhimg.com/v2-8338bda996c0248db0f242f7f235a3be_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-8338bda996c0248db0f242f7f235a3be_b.jpg"/></figure><p>选择 <img src="https://www.zhihu.com/equation?tex=%5Ceta+%3D+%5Csqrt%7B2+%5Cln+N%2Fn%7D" alt="\eta = \sqrt{2 \ln N/n}" eeimg="1"/> ，可以得到最好情况下的 regret bound 为 <img src="https://www.zhihu.com/equation?tex=%5Csqrt%7B2+n+%5Cln+N%7D" alt="\sqrt{2 n \ln N}" eeimg="1"/> 。</p><p>如果针对这种该方法进行分析（而不是直接套用前面的结论），可以得到一个更好的 bound。隐约记得这个 bound 导师的课讲过。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-b8b6e74484557defbfee3e4a023c9546_b.jpg" data-caption="" data-size="normal" data-rawwidth="2332" data-rawheight="604" class="origin_image zh-lightbox-thumb" width="2332" data-original="https://pic3.zhimg.com/v2-b8b6e74484557defbfee3e4a023c9546_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2332&#39; height=&#39;604&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2332" data-rawheight="604" class="origin_image zh-lightbox-thumb lazy" width="2332" data-original="https://pic3.zhimg.com/v2-b8b6e74484557defbfee3e4a023c9546_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-b8b6e74484557defbfee3e4a023c9546_b.jpg"/></figure><p>可以看到，它比前一个 bound 改善了一个常数 2。这种策略比多项式势能对应的策略更好一些（常数 <img src="https://www.zhihu.com/equation?tex=2+%5Csqrt%7Be%7D" alt="2 \sqrt{e}" eeimg="1"/> 倍）。</p><h3>5. Uniform over time</h3><p>注意到上述策略里面的超参数 <img src="https://www.zhihu.com/equation?tex=%5Ceta+%3D+%5Csqrt%7B8+%5Cln+N+%2Fn%7D" alt="\eta = \sqrt{8 \ln N /n}" eeimg="1"/> 中含有总共玩的轮数，亦即要求先知道总共玩多少轮。但很多时候我们希望不提前告诉玩的总轮数，并且不管玩多少轮，都有相应的 regret bound（即，这里讲的 uniform over time）。</p><p>一个简单的办法是使用 doubling trick，把时间划分为若干段，每一段的长度都是前一段的两倍，每一段使用和这一段长度对应的 <img src="https://www.zhihu.com/equation?tex=%5Ceta" alt="\eta" eeimg="1"/> ，这样仍然可以套用前面的结论得到相应的 regret bound。该 regret bound 在条件假设上有所放松，因此得到的 bound 略差一些（差了常数倍 <img src="https://www.zhihu.com/equation?tex=%5Cdfrac%7B%5Csqrt%7B2%7D%7D%7B%5Csqrt%7B2%7D+-+1%7D+%5Capprox+3.41" alt="\dfrac{\sqrt{2}}{\sqrt{2} - 1} \approx 3.41" eeimg="1"/> ）。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-37538ae7411bbd91137f54a5b3decd68_b.jpg" data-caption="" data-size="normal" data-rawwidth="1540" data-rawheight="474" class="origin_image zh-lightbox-thumb" width="1540" data-original="https://pic1.zhimg.com/v2-37538ae7411bbd91137f54a5b3decd68_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1540&#39; height=&#39;474&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1540" data-rawheight="474" class="origin_image zh-lightbox-thumb lazy" width="1540" data-original="https://pic1.zhimg.com/v2-37538ae7411bbd91137f54a5b3decd68_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-37538ae7411bbd91137f54a5b3decd68_b.jpg"/></figure><p>观察到 doubling trick 里面相当于把 <img src="https://www.zhihu.com/equation?tex=%5Ceta" alt="\eta" eeimg="1"/> 中的总轮数换成了差不多为当前经历的时间步，另外一个看起来更优雅的方法是直接把参数中的总轮数换成当前的时间步，即 <img src="https://www.zhihu.com/equation?tex=%5Ceta%28t%29+%3D+%5Csqrt%7B8+%5Cln+N+%2Ft%7D" alt="\eta(t) = \sqrt{8 \ln N /t}" eeimg="1"/> 。这样能够得到一个更好的 bound：</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-570108e87f001ed814f53cb397f340d8_b.jpg" data-caption="" data-size="normal" data-rawwidth="1504" data-rawheight="330" class="origin_image zh-lightbox-thumb" width="1504" data-original="https://pic1.zhimg.com/v2-570108e87f001ed814f53cb397f340d8_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1504&#39; height=&#39;330&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1504" data-rawheight="330" class="origin_image zh-lightbox-thumb lazy" width="1504" data-original="https://pic1.zhimg.com/v2-570108e87f001ed814f53cb397f340d8_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-570108e87f001ed814f53cb397f340d8_b.jpg"/></figure><h3>6. An improvement for small losses</h3><p>回忆前面的一个例子，如果告知存在一个不犯错误的专家，那么我们可以采取更为激进的策略（如果任何一个专家犯错，都直接把它剔除），同时能够获得一个更好 bound。这个regret bound 与玩家玩的轮数 <img src="https://www.zhihu.com/equation?tex=n" alt="n" eeimg="1"/> 无关，即不论玩多少轮，犯错次数都不超过某个数。</p><p>这个例子告诉我们，如果预知存在一个犯错较少的专家，那么能够采取一个更激进的策略，使得 regret bound 更紧。下面的定理告诉我们，假设已知有一个专家遭受的损失为 <img src="https://www.zhihu.com/equation?tex=L_n%5E%2A+%3D+%5Cmin_%7Bi%5Cin%5BN%5D%7DL_%7Bi%2Cn%7D" alt="L_n^* = \min_{i\in[N]}L_{i,n}" eeimg="1"/> ，那么玩家所受损失有如下上界：</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-d4c2fe8aa1d6cf14adf7ed9e3925dc96_b.jpg" data-caption="" data-size="normal" data-rawwidth="1502" data-rawheight="298" class="origin_image zh-lightbox-thumb" width="1502" data-original="https://pic3.zhimg.com/v2-d4c2fe8aa1d6cf14adf7ed9e3925dc96_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1502&#39; height=&#39;298&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1502" data-rawheight="298" class="origin_image zh-lightbox-thumb lazy" width="1502" data-original="https://pic3.zhimg.com/v2-d4c2fe8aa1d6cf14adf7ed9e3925dc96_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-d4c2fe8aa1d6cf14adf7ed9e3925dc96_b.jpg"/></figure><p>通过选择一个合适的 <img src="https://www.zhihu.com/equation?tex=%5Ceta" alt="\eta" eeimg="1"/> 能够得到一个最优的上界：</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-04c6c93eb125c36ed9881163d42dd474_b.png" data-caption="" data-size="normal" data-rawwidth="1520" data-rawheight="252" class="origin_image zh-lightbox-thumb" width="1520" data-original="https://pic1.zhimg.com/v2-04c6c93eb125c36ed9881163d42dd474_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1520&#39; height=&#39;252&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1520" data-rawheight="252" class="origin_image zh-lightbox-thumb lazy" width="1520" data-original="https://pic1.zhimg.com/v2-04c6c93eb125c36ed9881163d42dd474_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-04c6c93eb125c36ed9881163d42dd474_b.png"/></figure><p>注意到，当 <img src="https://www.zhihu.com/equation?tex=L%5E%2A_n+%3D+o%28%5Csqrt%7Bn%7D%29" alt="L^*_n = o(\sqrt{n})" eeimg="1"/> 的时候，这个 bound 比之前的结果更好（Theorem 2.2），否则会更差。</p><h3>7. Forecasters using the gradient of the losses</h3><p>前面讲的 polynomially weighted average forecaster 和 exponentially weighted average forecaster 都是基于对于势能的导数的分析而得到的策略（Theorem 2.1）。这里讲另外一种 forecaster，它适用于损失函数可导并且 decision space 是有限维度的 convex linear space 的情形。</p><p>该 forecaster 可以被写作：</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-18fb7edb8ddc41d122d48a73b0ad3b68_b.png" data-caption="" data-size="normal" data-rawwidth="1528" data-rawheight="164" class="origin_image zh-lightbox-thumb" width="1528" data-original="https://pic1.zhimg.com/v2-18fb7edb8ddc41d122d48a73b0ad3b68_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1528&#39; height=&#39;164&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1528" data-rawheight="164" class="origin_image zh-lightbox-thumb lazy" width="1528" data-original="https://pic1.zhimg.com/v2-18fb7edb8ddc41d122d48a73b0ad3b68_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-18fb7edb8ddc41d122d48a73b0ad3b68_b.png"/></figure><p>直观地来说，如果在历史上，某个专家给出的建议 <img src="https://www.zhihu.com/equation?tex=f_%7Bi%2Cs%7D" alt="f_{i,s}" eeimg="1"/> 能够进一步帮助玩家（在历史上的那个时刻）减小损失，就给该专家分配更多的权重。类似地，如果损失函数的导数 <img src="https://www.zhihu.com/equation?tex=%7C%7C%5Cnabla+l%7C%7C+%5Cle+1" alt="||\nabla l|| \le 1" eeimg="1"/> ，这样的 forecaster 也存在和 exponentially weighted average forecaster 类似的 regret bound：</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-4d290f15f98a1ed244044b32ab44991c_b.jpg" data-caption="" data-size="normal" data-rawwidth="1536" data-rawheight="362" class="origin_image zh-lightbox-thumb" width="1536" data-original="https://pic1.zhimg.com/v2-4d290f15f98a1ed244044b32ab44991c_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1536&#39; height=&#39;362&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1536" data-rawheight="362" class="origin_image zh-lightbox-thumb lazy" width="1536" data-original="https://pic1.zhimg.com/v2-4d290f15f98a1ed244044b32ab44991c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-4d290f15f98a1ed244044b32ab44991c_b.jpg"/></figure><h3>8. Scaled losses and signed games</h3><p>前面假设了 loss 的范围在 <img src="https://www.zhihu.com/equation?tex=+%5B0%2C1%5D" alt=" [0,1]" eeimg="1"/> 之间，假如 loss 的范围在 <img src="https://www.zhihu.com/equation?tex=%5B0%2CM%5D" alt="[0,M]" eeimg="1"/> 之间，相应的 regret bound 会怎样呢？</p><p>对于之前的一个损失函数 <img src="https://www.zhihu.com/equation?tex=l" alt="l" eeimg="1"/> ，考虑一个刚好被 scale <img src="https://www.zhihu.com/equation?tex=M" alt="M" eeimg="1"/> 倍的新损失函数，这样玩家受到的损失也会 scale <img src="https://www.zhihu.com/equation?tex=M" alt="M" eeimg="1"/> 倍 ，但是 outcome 序列可以刚好选择为使得 <img src="https://www.zhihu.com/equation?tex=L_n%5E%2A" alt="L_n^*" eeimg="1"/> 不变。观察到 <img src="https://www.zhihu.com/equation?tex=%5Chat%7BL%7D_n+%5Cle+%5Cdfrac%7B%5Ceta+L_n%5E%2A+%2B+%5Cln+N%7D%7B1-e%5E%7B-%5Ceta%7D%7D" alt="\hat{L}_n \le \dfrac{\eta L_n^* + \ln N}{1-e^{-\eta}}" eeimg="1"/> ，即前一部分不会被 scale，但是后面的一部分被 scale，则有 <img src="https://www.zhihu.com/equation?tex=%5Chat%7BL%7D_n+%5Cle+%5Cdfrac%7B%5Ceta+L_n%5E%2A+%2B+M+%5Cln+N%7D%7B1-e%5E%7B-%5Ceta%7D%7D" alt="\hat{L}_n \le \dfrac{\eta L_n^* + M \ln N}{1-e^{-\eta}}" eeimg="1"/> ，相应地有</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-5e0970af97488d940e3ab6f5e4cefd95_b.png" data-caption="" data-size="normal" data-rawwidth="1504" data-rawheight="80" class="origin_image zh-lightbox-thumb" width="1504" data-original="https://pic2.zhimg.com/v2-5e0970af97488d940e3ab6f5e4cefd95_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1504&#39; height=&#39;80&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1504" data-rawheight="80" class="origin_image zh-lightbox-thumb lazy" width="1504" data-original="https://pic2.zhimg.com/v2-5e0970af97488d940e3ab6f5e4cefd95_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-5e0970af97488d940e3ab6f5e4cefd95_b.png"/></figure><p>（这只是一个口头的分析，不严谨，详细的证明需要把 <img src="https://www.zhihu.com/equation?tex=l%2FM%5Cto+l" alt="l/M\to l" eeimg="1"/> 带入到原本的证明中）</p><p>如果 loss 的范围在 <img src="https://www.zhihu.com/equation?tex=%5B-M%2C0%5D" alt="[-M,0]" eeimg="1"/> 之间，类似地有：</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-f15ed0e77c4d100ab51a677ebc1580fb_b.png" data-caption="" data-size="normal" data-rawwidth="1512" data-rawheight="86" class="origin_image zh-lightbox-thumb" width="1512" data-original="https://pic4.zhimg.com/v2-f15ed0e77c4d100ab51a677ebc1580fb_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1512&#39; height=&#39;86&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1512" data-rawheight="86" class="origin_image zh-lightbox-thumb lazy" width="1512" data-original="https://pic4.zhimg.com/v2-f15ed0e77c4d100ab51a677ebc1580fb_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-f15ed0e77c4d100ab51a677ebc1580fb_b.png"/></figure><p>其中 <img src="https://www.zhihu.com/equation?tex=G+%3D+-L%2C+G%5E%2A+%3D+-L%5E%2A" alt="G = -L, G^* = -L^*" eeimg="1"/> 。</p><p>当 loss 的范围在 <img src="https://www.zhihu.com/equation?tex=%5B-M%2CM%5D" alt="[-M,M]" eeimg="1"/> 时，也可以用 scale 的方法分析，得到</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-53fd3f6f50cd682ce176006ea0b3b61b_b.png" data-caption="" data-size="normal" data-rawwidth="1480" data-rawheight="82" class="origin_image zh-lightbox-thumb" width="1480" data-original="https://pic4.zhimg.com/v2-53fd3f6f50cd682ce176006ea0b3b61b_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1480&#39; height=&#39;82&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1480" data-rawheight="82" class="origin_image zh-lightbox-thumb lazy" width="1480" data-original="https://pic4.zhimg.com/v2-53fd3f6f50cd682ce176006ea0b3b61b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-53fd3f6f50cd682ce176006ea0b3b61b_b.png"/></figure><p>可以大致认为 <img src="https://www.zhihu.com/equation?tex=H+%3D+-L%2C+H%5E%2A+%3D+-L%5E%2A" alt="H = -L, H^* = -L^*" eeimg="1"/> 。比较糟糕的是，这里多了一个和玩的轮数有关的项 <img src="https://www.zhihu.com/equation?tex=%5Csqrt%7Bn%7D" alt="\sqrt{n}" eeimg="1"/> 。不过可以使用其他的策略（multilinear forecaster，具体定义参考书），使得</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-4846736e50348b59c2a4ef05ebcf3018_b.png" data-caption="" data-size="normal" data-rawwidth="1526" data-rawheight="72" class="origin_image zh-lightbox-thumb" width="1526" data-original="https://pic1.zhimg.com/v2-4846736e50348b59c2a4ef05ebcf3018_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1526&#39; height=&#39;72&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1526" data-rawheight="72" class="origin_image zh-lightbox-thumb lazy" width="1526" data-original="https://pic1.zhimg.com/v2-4846736e50348b59c2a4ef05ebcf3018_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-4846736e50348b59c2a4ef05ebcf3018_b.png"/></figure><p>其中</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-b6e60d71fe481f82caefe118fea220cb_b.png" data-caption="" data-size="normal" data-rawwidth="1544" data-rawheight="112" class="origin_image zh-lightbox-thumb" width="1544" data-original="https://pic4.zhimg.com/v2-b6e60d71fe481f82caefe118fea220cb_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1544&#39; height=&#39;112&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1544" data-rawheight="112" class="origin_image zh-lightbox-thumb lazy" width="1544" data-original="https://pic4.zhimg.com/v2-b6e60d71fe481f82caefe118fea220cb_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-b6e60d71fe481f82caefe118fea220cb_b.png"/></figure><h3>9. Simulatable experts and minimax regret</h3><p>假定专家给出的建议只依赖于历史上的 outcome sequence，即 <img src="https://www.zhihu.com/equation?tex=f_%7BE%2Ct%7D%3A%5Cmathcal%7BY%7D%5E%7Bt-1%7D+%5Cto+%5Cmathcal%7BD%7D" alt="f_{E,t}:\mathcal{Y}^{t-1} \to \mathcal{D}" eeimg="1"/> ，并且每个专家的在未来的预测结果（通过给定假想的未来的 outcome sequence）都能通过模拟得到。这个额外的可以被利用的条件称作 simulatable experts。这个额外的条件能够为策略带来更多的信息，从而形成更好的 regret bound。</p><p>另外一种特殊情况是 static experts，即 <img src="https://www.zhihu.com/equation?tex=f_%7BE%2Ct%7D" alt="f_{E,t}" eeimg="1"/> 是一个 constant function，即其数值可以和时间 <img src="https://www.zhihu.com/equation?tex=t" alt="t" eeimg="1"/> 有关，但是和历史上的 outcome 无关。</p><p>这件事情第一眼看上去有点微妙，不太好理解，看了一下书后面第八章的例子，大概是这么个情况。首先，regret 的目标是最小化相对于每个专家的损失差距，因此，如果各个专家之间意见产生的损失差距不大，那么我们选择他们意见的加权平均产生的 loss 跟最好的专家之间差距肯定不会太大。其次，如果专家的建议可以被模拟，那么我们可以按照 <img src="https://www.zhihu.com/equation?tex=n%2Cn-1%2C%5Ccdots%2C+t" alt="n,n-1,\cdots, t" eeimg="1"/> 的顺序，把各种 outcome 产生的 regret 都倒推回来，并且尽量减小最坏 outcome sequence 产生的 regret。这个做法类似于强化学习里面的 planning，只不过强化学习里面是优化期望，这里是优化最坏情形。</p><p>注意到在这本书的分析里面着重强调的是 bound 最坏情况，即找一个策略，使得在环境给出最坏的 outcome sequence 以及专家给出最坏的建议的时候，还能保证相应的 regret 上界。这个问题可以被显式地写为如下目标：</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-fdb7316891a6757fa252b1bb5587e346_b.jpg" data-caption="" data-size="normal" data-rawwidth="1506" data-rawheight="280" class="origin_image zh-lightbox-thumb" width="1506" data-original="https://pic3.zhimg.com/v2-fdb7316891a6757fa252b1bb5587e346_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1506&#39; height=&#39;280&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1506" data-rawheight="280" class="origin_image zh-lightbox-thumb lazy" width="1506" data-original="https://pic3.zhimg.com/v2-fdb7316891a6757fa252b1bb5587e346_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-fdb7316891a6757fa252b1bb5587e346_b.jpg"/></figure><p>注意到蓝色框里面三个一组，说明了『策略』和『专家、环境』之间的对抗关系。</p><p>如果是 static expert（不过不能预知它们的序列，不然它就是 simulatable 的了），令这些 expert 的建议来自一个函数族 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BF%7D" alt="\mathcal{F}" eeimg="1"/> ，该问题可以被表述为：</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-c2114da5254450bde9f60f7f2781c8a1_b.png" data-caption="" data-size="normal" data-rawwidth="1502" data-rawheight="152" class="origin_image zh-lightbox-thumb" width="1502" data-original="https://pic2.zhimg.com/v2-c2114da5254450bde9f60f7f2781c8a1_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1502&#39; height=&#39;152&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1502" data-rawheight="152" class="origin_image zh-lightbox-thumb lazy" width="1502" data-original="https://pic2.zhimg.com/v2-c2114da5254450bde9f60f7f2781c8a1_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-c2114da5254450bde9f60f7f2781c8a1_b.png"/></figure><p>关于它，前面我们得到一个最好的 regret bound： <img src="https://www.zhihu.com/equation?tex=V_n%5E%7B%28N%29%7D+%5Cle+%5Csqrt%7B%28n%2F2%29%5Cln+N%7D" alt="V_n^{(N)} \le \sqrt{(n/2)\ln N}" eeimg="1"/> 。</p><p>如果 expert 是可以 simulatable 的，并且相应的函数族为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BF%7D" alt="\mathcal{F}" eeimg="1"/> ，那么它就不再成为一个『对抗』的因素了（不用分析关于它的最坏情形了），相应的 regret 就依赖于这个函数族，即：</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-09c2735d294537fb65e98e4e6f786719_b.png" data-caption="" data-size="normal" data-rawwidth="1532" data-rawheight="138" class="origin_image zh-lightbox-thumb" width="1532" data-original="https://pic2.zhimg.com/v2-09c2735d294537fb65e98e4e6f786719_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1532&#39; height=&#39;138&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1532" data-rawheight="138" class="origin_image zh-lightbox-thumb lazy" width="1532" data-original="https://pic2.zhimg.com/v2-09c2735d294537fb65e98e4e6f786719_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-09c2735d294537fb65e98e4e6f786719_b.png"/></figure><p>当 <img src="https://www.zhihu.com/equation?tex=%7C%5Cmathcal%7BF%7D%7C%3Dn" alt="|\mathcal{F}|=n" eeimg="1"/> 时，有 <img src="https://www.zhihu.com/equation?tex=V_n%28%5Cmathcal%7BF%7D%29+%5Cle+V_n%5E%7B%28N%29%7D" alt="V_n(\mathcal{F}) \le V_n^{(N)}" eeimg="1"/> （来自第八章）。其原因是专家 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BF%7D" alt="\mathcal{F}" eeimg="1"/> 可以被模拟之后，它就可以被策略所利用，从而得到更好的 regret bound。</p><h2>总结</h2><p>对于最为基础的 expert problem 问题，这一章先提出了基于势能的 weighted average 方案，并且由此推出了 polynomially weighted average 和 exponentially weighted average。接着提出了另外一种（不基于势能）的把 loss 的梯度作为权重的 weighted average 方案。文章出了：1）超参数不含有总轮数 <img src="https://www.zhihu.com/equation?tex=n" alt="n" eeimg="1"/> 的修正方案；2）得知最优专家遭受较小损失 <img src="https://www.zhihu.com/equation?tex=L_n%5E%2A" alt="L_n^*" eeimg="1"/> 时的改进方案；3）每一局的损失函数不再是 <img src="https://www.zhihu.com/equation?tex=%5B0%2C1%5D" alt="[0,1]" eeimg="1"/> 之间而是任意区间内的 bound。最后，文章做了 simulatable expert 和 discounted regret 的推广，其中后者不太感兴趣，没写出来。</p><h2>思考</h2><p>目前看到 expert problem 相比于 RL 问题，有两个比较重要的区别：</p><ul><li>Expert problem 假定 loss function 已知，这样即使你没有采取某个专家的建议，它的 loss 也会被知道；RL 里面只能知道采取某个行动（某个专家的建议）之后的收益，而未采取的行动对应的收益不知道。考虑到这一点，前面讲的 POLITEX 就需要使用价值函数的估计，来近似地得到未采取行动的收益/损失。</li><li>Expert problem 的目标是与给定的 expert 作比较，因此策略的选择只考虑 expert 的建议们的『平均值』，即内部，而不要考虑这些建议『外部』的区域，即使可能这些 expert 都很差。隐约感觉 expert problem 不太有『探索』的问题，主要是如何『利用』的问题。而 RL 有探索的问题。如果像 POLITEX 一样用 expert problem 去套 RL 问题，一般就假设 expert 包含了所有可能的 action。</li></ul><p>（最后这一条我感觉我没说清楚。。因为我还没想清楚。。）</p><p></p></div></div><div class="ContentItem-time">发布于 2019-07-23</div><div class="Post-topicsAndReviewer"><div class="TopicList Post-Topics"><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/20039099" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习 (Reinforcement Learning)</div></div></a></span></div><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/19567962" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">博弈论</div></div></a></span></div></div></div><div><div class="Sticky RichContent-actions is-bottom"><div class="ContentItem-actions"><span><button aria-label="赞同 6 " type="button" class="Button VoteButton VoteButton--up"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleUp VoteButton-TriangleUp" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M2 18.242c0-.326.088-.532.237-.896l7.98-13.203C10.572 3.57 11.086 3 12 3c.915 0 1.429.571 1.784 1.143l7.98 13.203c.15.364.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H3.955c-1.08 0-1.955-.517-1.955-1.9z" fill-rule="evenodd"></path></svg></span>赞同 6</button><button aria-label="反对" type="button" class="Button VoteButton VoteButton--down"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleDown" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M20.044 3H3.956C2.876 3 2 3.517 2 4.9c0 .326.087.533.236.896L10.216 19c.355.571.87 1.143 1.784 1.143s1.429-.572 1.784-1.143l7.98-13.204c.149-.363.236-.57.236-.896 0-1.386-.876-1.9-1.956-1.9z" fill-rule="evenodd"></path></svg></span></button></span><button type="button" class="Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Comment Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M10.241 19.313a.97.97 0 0 0-.77.2 7.908 7.908 0 0 1-3.772 1.482.409.409 0 0 1-.38-.637 5.825 5.825 0 0 0 1.11-2.237.605.605 0 0 0-.227-.59A7.935 7.935 0 0 1 3 11.25C3 6.7 7.03 3 12 3s9 3.7 9 8.25-4.373 9.108-10.759 8.063z" fill-rule="evenodd"></path></svg></span>2 条评论</button><div class="Popover ShareMenu"><div class="ShareMenu-toggler" id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Share Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2.931 7.89c-1.067.24-1.275 1.669-.318 2.207l5.277 2.908 8.168-4.776c.25-.127.477.198.273.39L9.05 14.66l.927 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.242c.584-.892-.212-2.029-1.234-1.796L2.93 7.89z" fill-rule="evenodd"></path></svg></span>分享</button></div></div><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Heart Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2 8.437C2 5.505 4.294 3.094 7.207 3 9.243 3 11.092 4.19 12 6c.823-1.758 2.649-3 4.651-3C19.545 3 22 5.507 22 8.432 22 16.24 13.842 21 12 21 10.158 21 2 16.24 2 8.437z" fill-rule="evenodd"></path></svg></span>喜欢</button><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Star Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5.515 19.64l.918-5.355-3.89-3.792c-.926-.902-.639-1.784.64-1.97L8.56 7.74l2.404-4.871c.572-1.16 1.5-1.16 2.072 0L15.44 7.74l5.377.782c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.219 1.274-.532 1.82-1.676 1.218L12 18.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z" fill-rule="evenodd"></path></svg></span>收藏</button><div class="Post-ActionMenuButton"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Dots Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5 14a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4z" fill-rule="evenodd"></path></svg></span></button></div></div></div></div></div></div></article><div class="Post-Sub Post-NormalSub"><div class="PostIndex-Contributions"><h3 class="BlockTitle">文章被以下专栏收录</h3><ul><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><img class="Avatar Avatar--medium Avatar--round" width="40" height="40" src="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_xs.jpg" srcSet="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_l.jpg 2x" alt="强化学习前沿"/></div></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><a class="ColumnLink ColumnItem-Title" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习前沿</div></div></a></h2><div class="ContentItem-meta">读呀读paper</div></div><div class="ContentItem-extra"><a href="/reinforcementlearning" type="button" class="Button">进入专栏</a></div></div></div></ul></div></div></div></main></div></div><script nonce="8d7b230c-0bea-4493-b8f9-74710b3d59f6" async="" src="https://www.googletagmanager.com/gtag/js?id=UA-149949619-1"></script><script nonce="8d7b230c-0bea-4493-b8f9-74710b3d59f6">function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-149949619-1");</script><script id="js-clientConfig" type="text/json">{"host":"zhihu.com","protocol":"https:","wwwHost":"www.zhihu.com","fetchRoot":{"www":"https:\u002F\u002Fwww.zhihu.com","api":"https:\u002F\u002Fapi.zhihu.com","zhuanlan":"https:\u002F\u002Fzhuanlan.zhihu.com"}}</script><script id="js-initialData" type="text/json">{"initialState":{"common":{"ask":{}},"loading":{"global":{"count":0},"local":{"env\u002FgetIpinfo\u002F":false,"article\u002Fget\u002F":false,"brand\u002FgetUrl\u002F":false}},"club":{"tags":{}},"entities":{"users":{"zhang-chu-heng":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"清华大学 交叉信息院博士在读"}],"exposedMedal":{"medalId":"1124316222665379841","medalName":"我的知乎 2019","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2592b0b52e1fac99f69b38e00252413b_r.png","miniAvatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ad363cc3088dc8de7544fd08b1c4987a_is.png","description":"参与「我的知乎 2019」即可获得"}}},"questions":{},"answers":{},"articles":{"74722789":{"trackUrl":["https:\u002F\u002Fsugar.zhihu.com\u002Fplutus_adreaper\u002Fpage_monitor_log?si=__SESSIONID__&ti=__ATOKEN__&at=view&pf=__OS__&ed=__MEMBERID__&idfa=__IDFA__&imei=__IMEI__&androidid=__ANDROIDID__&oaid=__OAID__&ci=__CREATIVEID__"],"id":74722789,"title":"【算法】Prediction2","type":"article","excerptTitle":"","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F74722789","imageUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-d17eddb36dc4f026969547138793ea34_b.jpg","titleImage":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-d17eddb36dc4f026969547138793ea34_b.jpg","excerpt":"\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-5e12fc68d36f8227c3971962c3ab8f7f_200x112.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2358\" data-rawheight=\"1038\" data-watermark=\"watermark\" data-original-src=\"v2-5e12fc68d36f8227c3971962c3ab8f7f\" data-watermark-src=\"v2-558f2173ea8cc56916b46e935068e4da\" data-private-watermark-src=\"\" class=\"origin_image inline-img zh-lightbox-thumb\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-5e12fc68d36f8227c3971962c3ab8f7f_r.png\"\u002F\u003E这一篇讲第二章：Prediction with Expert Advice。原文传送门Cesa-Bianchi, Nicolo, and Gabor Lugosi.\u003Ci\u003EPrediction, learning, and games\u003C\u002Fi\u003E. Cambridge university press, 2006. 由于是图书，就不放链接了，直接 google 就能搜得到 PDF。特色针对前一讲提到的 …","created":1563852604,"updated":1563852604,"author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"清华大学 交叉信息院博士在读"}],"exposedMedal":{"medalId":"1124316222665379841","medalName":"我的知乎 2019","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2592b0b52e1fac99f69b38e00252413b_r.png","miniAvatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ad363cc3088dc8de7544fd08b1c4987a_is.png","description":"参与「我的知乎 2019」即可获得"}},"commentPermission":"all","state":"published","imageWidth":677,"imageHeight":151,"content":"\u003Cp\u003E这一篇讲第二章：Prediction with Expert Advice。\u003C\u002Fp\u003E\u003Ch2\u003E原文传送门\u003C\u002Fh2\u003E\u003Cp\u003ECesa-Bianchi, Nicolo, and Gabor Lugosi.\u003Ci\u003EPrediction, learning, and games\u003C\u002Fi\u003E. Cambridge university press, 2006. \u003C\u002Fp\u003E\u003Cp\u003E由于是图书，就不放链接了，直接 google 就能搜得到 PDF。\u003C\u002Fp\u003E\u003Ch2\u003E特色\u003C\u002Fh2\u003E\u003Cp\u003E针对前一讲提到的 expert problem 的设定，针对一些略微不同的问题设定，给出了相应的策略并且证明了不同策略下的 regret bound。这些策略都是『综合考虑不同专家给出的意见』，数学上来说，即采用 weighted average 的方式作出预测。\u003C\u002Fp\u003E\u003Ch2\u003E过程\u003C\u002Fh2\u003E\u003Ch3\u003E1. 问题设定\u003C\u002Fh3\u003E\u003Cp\u003E和上一讲的设定一样，只不过这里更形式化一点。定义 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathcal%7BY%7D\" alt=\"\\mathcal{Y}\" eeimg=\"1\"\u002F\u003E 为 outcome space， \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathcal%7BD%7D\" alt=\"\\mathcal{D}\" eeimg=\"1\"\u002F\u003E 为 decision space， \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathcal%7BE%7D\" alt=\"\\mathcal{E}\" eeimg=\"1\"\u002F\u003E 为专家的集合。每一轮 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=t\" alt=\"t\" eeimg=\"1\"\u002F\u003E 按照如下顺序进行：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E1）专家给出建议 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=f_%7BE%2C+t%7D+%5Cin%5Cmathcal%7BD%7D%2C+E+%5Cin+%5Cmathcal%7BE%7D\" alt=\"f_{E, t} \\in\\mathcal{D}, E \\in \\mathcal{E}\" eeimg=\"1\"\u002F\u003E ；\u003C\u002Fli\u003E\u003Cli\u003E2）玩家（forecaster）根据专家的建议做出预测 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Chat%7Bp%7D_t%5Cin+%5Cmathcal%7BD%7D\" alt=\"\\hat{p}_t\\in \\mathcal{D}\" eeimg=\"1\"\u002F\u003E ；\u003C\u002Fli\u003E\u003Cli\u003E3）环境给出结果 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=y_t+%5Cin+%5Cmathcal%7BY%7D\" alt=\"y_t \\in \\mathcal{Y}\" eeimg=\"1\"\u002F\u003E ；\u003C\u002Fli\u003E\u003Cli\u003E4）玩家遭受损失， \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=l%28%5Chat%7Bp%7D_t%2C+y_t%29\" alt=\"l(\\hat{p}_t, y_t)\" eeimg=\"1\"\u002F\u003E ，其中损失函数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=l%3A+%5Cmathcal%7BD%5Ctimes+Y%7D+%5Cto+%5Cmathbb%7BR%7D\" alt=\"l: \\mathcal{D\\times Y} \\to \\mathbb{R}\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-558f2173ea8cc56916b46e935068e4da_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2358\" data-rawheight=\"1038\" class=\"origin_image zh-lightbox-thumb\" width=\"2358\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-558f2173ea8cc56916b46e935068e4da_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2358&#39; height=&#39;1038&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2358\" data-rawheight=\"1038\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2358\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-558f2173ea8cc56916b46e935068e4da_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-558f2173ea8cc56916b46e935068e4da_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E目标是最小化 regret，即\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-bc70d5aa91a0260535069c99065a47ba_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2326\" data-rawheight=\"220\" class=\"origin_image zh-lightbox-thumb\" width=\"2326\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-bc70d5aa91a0260535069c99065a47ba_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2326&#39; height=&#39;220&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2326\" data-rawheight=\"220\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2326\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-bc70d5aa91a0260535069c99065a47ba_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-bc70d5aa91a0260535069c99065a47ba_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E注意到，它的比较基准是全部 follow 同一个专家 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=E\" alt=\"E\" eeimg=\"1\"\u002F\u003E 。这本书都考虑有限个专家，因此每个专家可以记做 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=E%5Cin%5Cmathcal%7BE%7D+%5Cto+i%5Cin%5BN%5D\" alt=\"E\\in\\mathcal{E} \\to i\\in[N]\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Cp\u003E期望设计的策略能够使得 regret 的增长速度比玩的轮数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=n\" alt=\"n\" eeimg=\"1\"\u002F\u003E 要慢得多，即\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5ebbd7d313e0b206ae57d5655d25ba51_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2264\" data-rawheight=\"170\" class=\"origin_image zh-lightbox-thumb\" width=\"2264\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5ebbd7d313e0b206ae57d5655d25ba51_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2264&#39; height=&#39;170&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2264\" data-rawheight=\"170\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2264\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5ebbd7d313e0b206ae57d5655d25ba51_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5ebbd7d313e0b206ae57d5655d25ba51_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Ch3\u003E2. Weighted average prediction\u003C\u002Fh3\u003E\u003Cp\u003E一个最简单的想法还是对于每个专家维护一个权重，然后决定的时候使用加权平均来做预测。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-e2175e7302508e107e186011608c96ec_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2342\" data-rawheight=\"236\" class=\"origin_image zh-lightbox-thumb\" width=\"2342\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-e2175e7302508e107e186011608c96ec_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2342&#39; height=&#39;236&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2342\" data-rawheight=\"236\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2342\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-e2175e7302508e107e186011608c96ec_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-e2175e7302508e107e186011608c96ec_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E玩家能获取的信息主要是玩家历史上产生的损失和各个专家在历史上产生的损失，一个比较自然的选择是让各个专家的权重取决于历史上玩家相对于该专家的 regret \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=R_%7Bi%2Ct-1%7D%3D%5Chat%7BL%7D_%7Bt-1%7D+-+L_%7Bi%2C+t-1%7D\" alt=\"R_{i,t-1}=\\hat{L}_{t-1} - L_{i, t-1}\" eeimg=\"1\"\u002F\u003E 。（当然，也可以只取决于各个专家在历史上产生的损失，而不取决于玩家在历史上的损失；毕竟一个专家的靠谱程度应该和玩家之前有没有听从其建议无关，后面会有这样的方案，不过这里暂且假定取决于各个 regret。） \u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E\u003Ci\u003E下面定义一类的权重函数，它给出了专家历史上 regret 到各个专家对应权重之间的关系；接下来将会看到它和 regret bound 之间的联系。\u003C\u002Fi\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E令 instantaneous regret vector \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%7B%5Cbf+r%7D_t+%3D+%28r_%7B1%2C+t%7D%2C+%5Ccdots%2C+r_%7BN%2Ct%7D%29+%5Cin+%5Cmathbb%7BR%7D%5EN\" alt=\"{\\bf r}_t = (r_{1, t}, \\cdots, r_{N,t}) \\in \\mathbb{R}^N\" eeimg=\"1\"\u002F\u003E ，使得 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%7B%5Cbf+R%7D_t%3D%5Csum_%7Bt%3D1%7D%5En+%7B%5Cbf+r%7D_t\" alt=\"{\\bf R}_t=\\sum_{t=1}^n {\\bf r}_t\" eeimg=\"1\"\u002F\u003E 的各个分量为玩家相对于各个专家截止当前时刻的 regret。定义\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-93773d9df1d22db3028c461ea992970a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2346\" data-rawheight=\"484\" class=\"origin_image zh-lightbox-thumb\" width=\"2346\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-93773d9df1d22db3028c461ea992970a_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2346&#39; height=&#39;484&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2346\" data-rawheight=\"484\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2346\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-93773d9df1d22db3028c461ea992970a_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-93773d9df1d22db3028c461ea992970a_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E可以看出势能函数是相对于 regret 的增函数，因此我们希望多轮之后势能函数尽可能小。\u003C\u002Fp\u003E\u003Cp\u003E让玩家每次按照如下公式做出预测\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-e641bd0e8f51814bb9f16af814add0b4_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2414\" data-rawheight=\"326\" class=\"origin_image zh-lightbox-thumb\" width=\"2414\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-e641bd0e8f51814bb9f16af814add0b4_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2414&#39; height=&#39;326&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2414\" data-rawheight=\"326\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2414\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-e641bd0e8f51814bb9f16af814add0b4_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-e641bd0e8f51814bb9f16af814add0b4_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E如果损失函数是 convex 的，可以发现（利用 Jensen 不等式），每一轮按照权重加权平均的 instantaneous regret 都是小于等于零的，即 Blackwell condition：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2f7efd9d79a0bb4a76d7e1dde3e68918_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2332\" data-rawheight=\"150\" class=\"origin_image zh-lightbox-thumb\" width=\"2332\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2f7efd9d79a0bb4a76d7e1dde3e68918_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2332&#39; height=&#39;150&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2332\" data-rawheight=\"150\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2332\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2f7efd9d79a0bb4a76d7e1dde3e68918_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2f7efd9d79a0bb4a76d7e1dde3e68918_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E下图比较形象地说明了满足 Blackwell condition 下的更新情形。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-118a509a1e39d0a702b9b3832d24ccc5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2388\" data-rawheight=\"1564\" class=\"origin_image zh-lightbox-thumb\" width=\"2388\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-118a509a1e39d0a702b9b3832d24ccc5_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2388&#39; height=&#39;1564&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2388\" data-rawheight=\"1564\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2388\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-118a509a1e39d0a702b9b3832d24ccc5_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-118a509a1e39d0a702b9b3832d24ccc5_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E这样的更新方式保证了 regret 的变化方向 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%7B%5Cbf+r%7D_t+%3D+%7B%5Cbf+R%7D_t+-+%7B%5Cbf+R%7D_%7Bt-1%7D++\" alt=\"{\\bf r}_t = {\\bf R}_t - {\\bf R}_{t-1}  \" eeimg=\"1\"\u002F\u003E 和势能的梯度上升方向 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cnabla%5CPhi%28%7B%5Cbf+R%7D_%7Bt-1%7D%29\" alt=\"\\nabla\\Phi({\\bf R}_{t-1})\" eeimg=\"1\"\u002F\u003E （也就是说各个专家的权重）夹角为钝角，这样虽然有可能 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%7B%5Cbf+R%7D_t+\" alt=\"{\\bf R}_t \" eeimg=\"1\"\u002F\u003E 的势能还是比 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%7B%5Cbf+R%7D_%7Bt-1%7D+\" alt=\"{\\bf R}_{t-1} \" eeimg=\"1\"\u002F\u003E 大，但是不至于上升地太快。由于 regret 变化的\u003Cb\u003E\u003Ci\u003E方向\u003C\u002Fi\u003E\u003C\u002Fb\u003E是朝着势能变小的方向的，如果只看一阶近似， \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%7B%5Cbf+R%7D_t+\" alt=\"{\\bf R}_t \" eeimg=\"1\"\u002F\u003E 的势能应该比 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%7B%5Cbf+R%7D_%7Bt-1%7D+\" alt=\"{\\bf R}_{t-1} \" eeimg=\"1\"\u002F\u003E 更低。由此自然想到，如果我们 bound 更高阶的近似，就能够得到势能的上界。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c92c370ecc921f4bae24134fddea38c3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2342\" data-rawheight=\"474\" class=\"origin_image zh-lightbox-thumb\" width=\"2342\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c92c370ecc921f4bae24134fddea38c3_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2342&#39; height=&#39;474&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2342\" data-rawheight=\"474\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2342\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c92c370ecc921f4bae24134fddea38c3_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c92c370ecc921f4bae24134fddea38c3_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-7f7786d3fa77c14b3ff70f56d5741064_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2304\" data-rawheight=\"350\" class=\"origin_image zh-lightbox-thumb\" width=\"2304\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-7f7786d3fa77c14b3ff70f56d5741064_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2304&#39; height=&#39;350&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2304\" data-rawheight=\"350\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2304\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-7f7786d3fa77c14b3ff70f56d5741064_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-7f7786d3fa77c14b3ff70f56d5741064_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E证明方法也比较简单，就是泰勒展开之后 bound 二阶导。\u003C\u002Fp\u003E\u003Cp\u003E以上定理的意义在于 bound 了势能函数相当于就 bound 了这种策略下的 regret，注意到\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-784b0aecedc60dd20a627f2b8066cd02_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2392\" data-rawheight=\"238\" class=\"origin_image zh-lightbox-thumb\" width=\"2392\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-784b0aecedc60dd20a627f2b8066cd02_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2392&#39; height=&#39;238&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2392\" data-rawheight=\"238\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2392\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-784b0aecedc60dd20a627f2b8066cd02_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-784b0aecedc60dd20a627f2b8066cd02_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E（最大的 regret 比 regret 的和要小，前一讲里面的证明也用到这个原理）\u003C\u002Fp\u003E\u003Cp\u003E有\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-71f7375e6ce4362db450c9b605e6fa71_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2370\" data-rawheight=\"158\" class=\"origin_image zh-lightbox-thumb\" width=\"2370\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-71f7375e6ce4362db450c9b605e6fa71_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2370&#39; height=&#39;158&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2370\" data-rawheight=\"158\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2370\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-71f7375e6ce4362db450c9b605e6fa71_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-71f7375e6ce4362db450c9b605e6fa71_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cb\u003E\u003Ci\u003E和前一讲里面问题设定的区别\u003C\u002Fi\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E前一讲中 decision space 和 outcome space 都是 binary 的，是离散的，不是 convex set，用 majority vote。 这里的 decision space 是一个 convex set，这样保证对于各个专家加权平均之后得到的结果还在 decision space 中，因此使用加权平均。很多情况下可以认为 decision space = outcome space。\u003C\u002Fp\u003E\u003Ch3\u003E3. Polynomially weighted average forecaster\u003C\u002Fh3\u003E\u003Cp\u003E前面定义了一种势能，多项式加权平均是满足前述定义势能函数的一个特殊的例子。多项式势能定义如下：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0b4340ee8327fc4444796a65d0df244e_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2298\" data-rawheight=\"256\" class=\"origin_image zh-lightbox-thumb\" width=\"2298\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0b4340ee8327fc4444796a65d0df244e_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2298&#39; height=&#39;256&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2298\" data-rawheight=\"256\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2298\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0b4340ee8327fc4444796a65d0df244e_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0b4340ee8327fc4444796a65d0df244e_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E即，前面势能的定义中 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cpsi%28%5Ccdot%29%3D%28%5Ccdot%29%5E%7B2%2Fp%7D%2C+%5Cphi%28%5Ccdot%29+%3D+%28%5Ccdot%29_%2B%5Ep\" alt=\"\\psi(\\cdot)=(\\cdot)^{2\u002Fp}, \\phi(\\cdot) = (\\cdot)_+^p\" eeimg=\"1\"\u002F\u003E 。这样每个 expert 对应的权重为\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-80cfd047331aa1a7d097bfad4ba778f8_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2338\" data-rawheight=\"194\" class=\"origin_image zh-lightbox-thumb\" width=\"2338\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-80cfd047331aa1a7d097bfad4ba778f8_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2338&#39; height=&#39;194&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2338\" data-rawheight=\"194\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2338\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-80cfd047331aa1a7d097bfad4ba778f8_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-80cfd047331aa1a7d097bfad4ba778f8_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E玩家每次的预测数值为\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9b00dfc2f61a10dea7cb24ce227ced95_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2358\" data-rawheight=\"512\" class=\"origin_image zh-lightbox-thumb\" width=\"2358\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9b00dfc2f61a10dea7cb24ce227ced95_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2358&#39; height=&#39;512&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2358\" data-rawheight=\"512\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2358\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9b00dfc2f61a10dea7cb24ce227ced95_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9b00dfc2f61a10dea7cb24ce227ced95_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E注意到势能定义里面的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cpsi%28%5Ccdot%29\" alt=\"\\psi(\\cdot)\" eeimg=\"1\"\u002F\u003E 其实不影响玩家给出的预测数值，它的设定只是为了分析方便。因此，设定 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5CPhi_p%28%7B%5Cbf+u%7D%29%3D%7C%7C%7B%5Cbf+u%7D_%2B%7C%7C_p\" alt=\"\\Phi_p({\\bf u})=||{\\bf u}_+||_p\" eeimg=\"1\"\u002F\u003E 也是一样的。\u003C\u002Fp\u003E\u003Cp\u003E可以套用前面的结论，可以得到这种策略下的 regret bound：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-6ab67816d5baa76cdabe417ee8d5d8ef_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2338\" data-rawheight=\"212\" class=\"origin_image zh-lightbox-thumb\" width=\"2338\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-6ab67816d5baa76cdabe417ee8d5d8ef_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2338&#39; height=&#39;212&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2338\" data-rawheight=\"212\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2338\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-6ab67816d5baa76cdabe417ee8d5d8ef_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-6ab67816d5baa76cdabe417ee8d5d8ef_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-cb62061ec56235e082e2cd58447b7158_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2364\" data-rawheight=\"268\" class=\"origin_image zh-lightbox-thumb\" width=\"2364\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-cb62061ec56235e082e2cd58447b7158_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2364&#39; height=&#39;268&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2364\" data-rawheight=\"268\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2364\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-cb62061ec56235e082e2cd58447b7158_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-cb62061ec56235e082e2cd58447b7158_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E令 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=p+%3D+2%5Cln+N\" alt=\"p = 2\\ln N\" eeimg=\"1\"\u002F\u003E ，可以得到一个最优的 bound：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-209dcc20a28849166252867746a9b35b_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2342\" data-rawheight=\"140\" class=\"origin_image zh-lightbox-thumb\" width=\"2342\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-209dcc20a28849166252867746a9b35b_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2342&#39; height=&#39;140&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2342\" data-rawheight=\"140\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2342\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-209dcc20a28849166252867746a9b35b_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-209dcc20a28849166252867746a9b35b_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Ch3\u003E4. Exponentially weighted average forecaster\u003C\u002Fh3\u003E\u003Cp\u003E前面的介绍的多项式势能产生的策略不仅仅依赖于各个专家历史上产生的损失，还取决于玩家在历史上产生的损失。但是各个专家的权重其实可以不依赖于玩家产生的损失。当我们使用如下的这种指数势能函数的时候，玩家产生的权重部分就可以被抵消掉，因而形成一个和玩家历史无关的 forecaster。\u003C\u002Fp\u003E\u003Cp\u003E定义指数势能为：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f4ebde1e90ebe6ba6868bc8faf41768a_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2352\" data-rawheight=\"222\" class=\"origin_image zh-lightbox-thumb\" width=\"2352\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f4ebde1e90ebe6ba6868bc8faf41768a_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2352&#39; height=&#39;222&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2352\" data-rawheight=\"222\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2352\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f4ebde1e90ebe6ba6868bc8faf41768a_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f4ebde1e90ebe6ba6868bc8faf41768a_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E各个专家的权重为：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-22c083f7056faa16db7c94fecdb278e0_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2324\" data-rawheight=\"234\" class=\"origin_image zh-lightbox-thumb\" width=\"2324\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-22c083f7056faa16db7c94fecdb278e0_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2324&#39; height=&#39;234&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2324\" data-rawheight=\"234\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2324\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-22c083f7056faa16db7c94fecdb278e0_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-22c083f7056faa16db7c94fecdb278e0_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E或者写作：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-09c462c8b78535ff70e5e99e762b111e_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2294\" data-rawheight=\"224\" class=\"origin_image zh-lightbox-thumb\" width=\"2294\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-09c462c8b78535ff70e5e99e762b111e_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2294&#39; height=&#39;224&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2294\" data-rawheight=\"224\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2294\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-09c462c8b78535ff70e5e99e762b111e_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-09c462c8b78535ff70e5e99e762b111e_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E相应的 forecaster 为，观察到玩家的历史损失被上下约掉了：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-d953b1927a0f56ed946940a47f45e010_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2298\" data-rawheight=\"250\" class=\"origin_image zh-lightbox-thumb\" width=\"2298\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-d953b1927a0f56ed946940a47f45e010_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2298&#39; height=&#39;250&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2298\" data-rawheight=\"250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2298\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-d953b1927a0f56ed946940a47f45e010_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-d953b1927a0f56ed946940a47f45e010_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E相应地，还是套用前面的结论，可以得到这种 forecaster 对应的 regret bound：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-8338bda996c0248db0f242f7f235a3be_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2384\" data-rawheight=\"478\" class=\"origin_image zh-lightbox-thumb\" width=\"2384\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-8338bda996c0248db0f242f7f235a3be_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2384&#39; height=&#39;478&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2384\" data-rawheight=\"478\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2384\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-8338bda996c0248db0f242f7f235a3be_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-8338bda996c0248db0f242f7f235a3be_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E选择 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ceta+%3D+%5Csqrt%7B2+%5Cln+N%2Fn%7D\" alt=\"\\eta = \\sqrt{2 \\ln N\u002Fn}\" eeimg=\"1\"\u002F\u003E ，可以得到最好情况下的 regret bound 为 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Csqrt%7B2+n+%5Cln+N%7D\" alt=\"\\sqrt{2 n \\ln N}\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Cp\u003E如果针对这种该方法进行分析（而不是直接套用前面的结论），可以得到一个更好的 bound。隐约记得这个 bound 导师的课讲过。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-b8b6e74484557defbfee3e4a023c9546_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2332\" data-rawheight=\"604\" class=\"origin_image zh-lightbox-thumb\" width=\"2332\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-b8b6e74484557defbfee3e4a023c9546_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2332&#39; height=&#39;604&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2332\" data-rawheight=\"604\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2332\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-b8b6e74484557defbfee3e4a023c9546_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-b8b6e74484557defbfee3e4a023c9546_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E可以看到，它比前一个 bound 改善了一个常数 2。这种策略比多项式势能对应的策略更好一些（常数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=2+%5Csqrt%7Be%7D\" alt=\"2 \\sqrt{e}\" eeimg=\"1\"\u002F\u003E 倍）。\u003C\u002Fp\u003E\u003Ch3\u003E5. Uniform over time\u003C\u002Fh3\u003E\u003Cp\u003E注意到上述策略里面的超参数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ceta+%3D+%5Csqrt%7B8+%5Cln+N+%2Fn%7D\" alt=\"\\eta = \\sqrt{8 \\ln N \u002Fn}\" eeimg=\"1\"\u002F\u003E 中含有总共玩的轮数，亦即要求先知道总共玩多少轮。但很多时候我们希望不提前告诉玩的总轮数，并且不管玩多少轮，都有相应的 regret bound（即，这里讲的 uniform over time）。\u003C\u002Fp\u003E\u003Cp\u003E一个简单的办法是使用 doubling trick，把时间划分为若干段，每一段的长度都是前一段的两倍，每一段使用和这一段长度对应的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ceta\" alt=\"\\eta\" eeimg=\"1\"\u002F\u003E ，这样仍然可以套用前面的结论得到相应的 regret bound。该 regret bound 在条件假设上有所放松，因此得到的 bound 略差一些（差了常数倍 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdfrac%7B%5Csqrt%7B2%7D%7D%7B%5Csqrt%7B2%7D+-+1%7D+%5Capprox+3.41\" alt=\"\\dfrac{\\sqrt{2}}{\\sqrt{2} - 1} \\approx 3.41\" eeimg=\"1\"\u002F\u003E ）。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-37538ae7411bbd91137f54a5b3decd68_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1540\" data-rawheight=\"474\" class=\"origin_image zh-lightbox-thumb\" width=\"1540\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-37538ae7411bbd91137f54a5b3decd68_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1540&#39; height=&#39;474&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1540\" data-rawheight=\"474\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1540\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-37538ae7411bbd91137f54a5b3decd68_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-37538ae7411bbd91137f54a5b3decd68_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E观察到 doubling trick 里面相当于把 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ceta\" alt=\"\\eta\" eeimg=\"1\"\u002F\u003E 中的总轮数换成了差不多为当前经历的时间步，另外一个看起来更优雅的方法是直接把参数中的总轮数换成当前的时间步，即 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ceta%28t%29+%3D+%5Csqrt%7B8+%5Cln+N+%2Ft%7D\" alt=\"\\eta(t) = \\sqrt{8 \\ln N \u002Ft}\" eeimg=\"1\"\u002F\u003E 。这样能够得到一个更好的 bound：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-570108e87f001ed814f53cb397f340d8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1504\" data-rawheight=\"330\" class=\"origin_image zh-lightbox-thumb\" width=\"1504\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-570108e87f001ed814f53cb397f340d8_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1504&#39; height=&#39;330&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1504\" data-rawheight=\"330\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1504\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-570108e87f001ed814f53cb397f340d8_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-570108e87f001ed814f53cb397f340d8_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Ch3\u003E6. An improvement for small losses\u003C\u002Fh3\u003E\u003Cp\u003E回忆前面的一个例子，如果告知存在一个不犯错误的专家，那么我们可以采取更为激进的策略（如果任何一个专家犯错，都直接把它剔除），同时能够获得一个更好 bound。这个regret bound 与玩家玩的轮数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=n\" alt=\"n\" eeimg=\"1\"\u002F\u003E 无关，即不论玩多少轮，犯错次数都不超过某个数。\u003C\u002Fp\u003E\u003Cp\u003E这个例子告诉我们，如果预知存在一个犯错较少的专家，那么能够采取一个更激进的策略，使得 regret bound 更紧。下面的定理告诉我们，假设已知有一个专家遭受的损失为 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=L_n%5E%2A+%3D+%5Cmin_%7Bi%5Cin%5BN%5D%7DL_%7Bi%2Cn%7D\" alt=\"L_n^* = \\min_{i\\in[N]}L_{i,n}\" eeimg=\"1\"\u002F\u003E ，那么玩家所受损失有如下上界：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-d4c2fe8aa1d6cf14adf7ed9e3925dc96_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1502\" data-rawheight=\"298\" class=\"origin_image zh-lightbox-thumb\" width=\"1502\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-d4c2fe8aa1d6cf14adf7ed9e3925dc96_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1502&#39; height=&#39;298&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1502\" data-rawheight=\"298\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1502\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-d4c2fe8aa1d6cf14adf7ed9e3925dc96_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-d4c2fe8aa1d6cf14adf7ed9e3925dc96_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E通过选择一个合适的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ceta\" alt=\"\\eta\" eeimg=\"1\"\u002F\u003E 能够得到一个最优的上界：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-04c6c93eb125c36ed9881163d42dd474_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1520\" data-rawheight=\"252\" class=\"origin_image zh-lightbox-thumb\" width=\"1520\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-04c6c93eb125c36ed9881163d42dd474_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1520&#39; height=&#39;252&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1520\" data-rawheight=\"252\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1520\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-04c6c93eb125c36ed9881163d42dd474_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-04c6c93eb125c36ed9881163d42dd474_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E注意到，当 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=L%5E%2A_n+%3D+o%28%5Csqrt%7Bn%7D%29\" alt=\"L^*_n = o(\\sqrt{n})\" eeimg=\"1\"\u002F\u003E 的时候，这个 bound 比之前的结果更好（Theorem 2.2），否则会更差。\u003C\u002Fp\u003E\u003Ch3\u003E7. Forecasters using the gradient of the losses\u003C\u002Fh3\u003E\u003Cp\u003E前面讲的 polynomially weighted average forecaster 和 exponentially weighted average forecaster 都是基于对于势能的导数的分析而得到的策略（Theorem 2.1）。这里讲另外一种 forecaster，它适用于损失函数可导并且 decision space 是有限维度的 convex linear space 的情形。\u003C\u002Fp\u003E\u003Cp\u003E该 forecaster 可以被写作：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-18fb7edb8ddc41d122d48a73b0ad3b68_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1528\" data-rawheight=\"164\" class=\"origin_image zh-lightbox-thumb\" width=\"1528\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-18fb7edb8ddc41d122d48a73b0ad3b68_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1528&#39; height=&#39;164&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1528\" data-rawheight=\"164\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1528\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-18fb7edb8ddc41d122d48a73b0ad3b68_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-18fb7edb8ddc41d122d48a73b0ad3b68_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E直观地来说，如果在历史上，某个专家给出的建议 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=f_%7Bi%2Cs%7D\" alt=\"f_{i,s}\" eeimg=\"1\"\u002F\u003E 能够进一步帮助玩家（在历史上的那个时刻）减小损失，就给该专家分配更多的权重。类似地，如果损失函数的导数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%7C%7C%5Cnabla+l%7C%7C+%5Cle+1\" alt=\"||\\nabla l|| \\le 1\" eeimg=\"1\"\u002F\u003E ，这样的 forecaster 也存在和 exponentially weighted average forecaster 类似的 regret bound：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4d290f15f98a1ed244044b32ab44991c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1536\" data-rawheight=\"362\" class=\"origin_image zh-lightbox-thumb\" width=\"1536\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4d290f15f98a1ed244044b32ab44991c_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1536&#39; height=&#39;362&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1536\" data-rawheight=\"362\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1536\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4d290f15f98a1ed244044b32ab44991c_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4d290f15f98a1ed244044b32ab44991c_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Ch3\u003E8. Scaled losses and signed games\u003C\u002Fh3\u003E\u003Cp\u003E前面假设了 loss 的范围在 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=+%5B0%2C1%5D\" alt=\" [0,1]\" eeimg=\"1\"\u002F\u003E 之间，假如 loss 的范围在 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5B0%2CM%5D\" alt=\"[0,M]\" eeimg=\"1\"\u002F\u003E 之间，相应的 regret bound 会怎样呢？\u003C\u002Fp\u003E\u003Cp\u003E对于之前的一个损失函数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=l\" alt=\"l\" eeimg=\"1\"\u002F\u003E ，考虑一个刚好被 scale \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=M\" alt=\"M\" eeimg=\"1\"\u002F\u003E 倍的新损失函数，这样玩家受到的损失也会 scale \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=M\" alt=\"M\" eeimg=\"1\"\u002F\u003E 倍 ，但是 outcome 序列可以刚好选择为使得 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=L_n%5E%2A\" alt=\"L_n^*\" eeimg=\"1\"\u002F\u003E 不变。观察到 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Chat%7BL%7D_n+%5Cle+%5Cdfrac%7B%5Ceta+L_n%5E%2A+%2B+%5Cln+N%7D%7B1-e%5E%7B-%5Ceta%7D%7D\" alt=\"\\hat{L}_n \\le \\dfrac{\\eta L_n^* + \\ln N}{1-e^{-\\eta}}\" eeimg=\"1\"\u002F\u003E ，即前一部分不会被 scale，但是后面的一部分被 scale，则有 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Chat%7BL%7D_n+%5Cle+%5Cdfrac%7B%5Ceta+L_n%5E%2A+%2B+M+%5Cln+N%7D%7B1-e%5E%7B-%5Ceta%7D%7D\" alt=\"\\hat{L}_n \\le \\dfrac{\\eta L_n^* + M \\ln N}{1-e^{-\\eta}}\" eeimg=\"1\"\u002F\u003E ，相应地有\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5e0970af97488d940e3ab6f5e4cefd95_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1504\" data-rawheight=\"80\" class=\"origin_image zh-lightbox-thumb\" width=\"1504\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5e0970af97488d940e3ab6f5e4cefd95_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1504&#39; height=&#39;80&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1504\" data-rawheight=\"80\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1504\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5e0970af97488d940e3ab6f5e4cefd95_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5e0970af97488d940e3ab6f5e4cefd95_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E（这只是一个口头的分析，不严谨，详细的证明需要把 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=l%2FM%5Cto+l\" alt=\"l\u002FM\\to l\" eeimg=\"1\"\u002F\u003E 带入到原本的证明中）\u003C\u002Fp\u003E\u003Cp\u003E如果 loss 的范围在 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5B-M%2C0%5D\" alt=\"[-M,0]\" eeimg=\"1\"\u002F\u003E 之间，类似地有：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f15ed0e77c4d100ab51a677ebc1580fb_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1512\" data-rawheight=\"86\" class=\"origin_image zh-lightbox-thumb\" width=\"1512\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f15ed0e77c4d100ab51a677ebc1580fb_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1512&#39; height=&#39;86&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1512\" data-rawheight=\"86\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1512\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f15ed0e77c4d100ab51a677ebc1580fb_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f15ed0e77c4d100ab51a677ebc1580fb_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=G+%3D+-L%2C+G%5E%2A+%3D+-L%5E%2A\" alt=\"G = -L, G^* = -L^*\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Cp\u003E当 loss 的范围在 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5B-M%2CM%5D\" alt=\"[-M,M]\" eeimg=\"1\"\u002F\u003E 时，也可以用 scale 的方法分析，得到\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-53fd3f6f50cd682ce176006ea0b3b61b_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1480\" data-rawheight=\"82\" class=\"origin_image zh-lightbox-thumb\" width=\"1480\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-53fd3f6f50cd682ce176006ea0b3b61b_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1480&#39; height=&#39;82&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1480\" data-rawheight=\"82\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1480\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-53fd3f6f50cd682ce176006ea0b3b61b_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-53fd3f6f50cd682ce176006ea0b3b61b_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E可以大致认为 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=H+%3D+-L%2C+H%5E%2A+%3D+-L%5E%2A\" alt=\"H = -L, H^* = -L^*\" eeimg=\"1\"\u002F\u003E 。比较糟糕的是，这里多了一个和玩的轮数有关的项 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Csqrt%7Bn%7D\" alt=\"\\sqrt{n}\" eeimg=\"1\"\u002F\u003E 。不过可以使用其他的策略（multilinear forecaster，具体定义参考书），使得\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4846736e50348b59c2a4ef05ebcf3018_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1526\" data-rawheight=\"72\" class=\"origin_image zh-lightbox-thumb\" width=\"1526\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4846736e50348b59c2a4ef05ebcf3018_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1526&#39; height=&#39;72&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1526\" data-rawheight=\"72\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1526\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4846736e50348b59c2a4ef05ebcf3018_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4846736e50348b59c2a4ef05ebcf3018_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-b6e60d71fe481f82caefe118fea220cb_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1544\" data-rawheight=\"112\" class=\"origin_image zh-lightbox-thumb\" width=\"1544\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-b6e60d71fe481f82caefe118fea220cb_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1544&#39; height=&#39;112&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1544\" data-rawheight=\"112\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1544\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-b6e60d71fe481f82caefe118fea220cb_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-b6e60d71fe481f82caefe118fea220cb_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Ch3\u003E9. Simulatable experts and minimax regret\u003C\u002Fh3\u003E\u003Cp\u003E假定专家给出的建议只依赖于历史上的 outcome sequence，即 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=f_%7BE%2Ct%7D%3A%5Cmathcal%7BY%7D%5E%7Bt-1%7D+%5Cto+%5Cmathcal%7BD%7D\" alt=\"f_{E,t}:\\mathcal{Y}^{t-1} \\to \\mathcal{D}\" eeimg=\"1\"\u002F\u003E ，并且每个专家的在未来的预测结果（通过给定假想的未来的 outcome sequence）都能通过模拟得到。这个额外的可以被利用的条件称作 simulatable experts。这个额外的条件能够为策略带来更多的信息，从而形成更好的 regret bound。\u003C\u002Fp\u003E\u003Cp\u003E另外一种特殊情况是 static experts，即 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=f_%7BE%2Ct%7D\" alt=\"f_{E,t}\" eeimg=\"1\"\u002F\u003E 是一个 constant function，即其数值可以和时间 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=t\" alt=\"t\" eeimg=\"1\"\u002F\u003E 有关，但是和历史上的 outcome 无关。\u003C\u002Fp\u003E\u003Cp\u003E这件事情第一眼看上去有点微妙，不太好理解，看了一下书后面第八章的例子，大概是这么个情况。首先，regret 的目标是最小化相对于每个专家的损失差距，因此，如果各个专家之间意见产生的损失差距不大，那么我们选择他们意见的加权平均产生的 loss 跟最好的专家之间差距肯定不会太大。其次，如果专家的建议可以被模拟，那么我们可以按照 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=n%2Cn-1%2C%5Ccdots%2C+t\" alt=\"n,n-1,\\cdots, t\" eeimg=\"1\"\u002F\u003E 的顺序，把各种 outcome 产生的 regret 都倒推回来，并且尽量减小最坏 outcome sequence 产生的 regret。这个做法类似于强化学习里面的 planning，只不过强化学习里面是优化期望，这里是优化最坏情形。\u003C\u002Fp\u003E\u003Cp\u003E注意到在这本书的分析里面着重强调的是 bound 最坏情况，即找一个策略，使得在环境给出最坏的 outcome sequence 以及专家给出最坏的建议的时候，还能保证相应的 regret 上界。这个问题可以被显式地写为如下目标：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-fdb7316891a6757fa252b1bb5587e346_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1506\" data-rawheight=\"280\" class=\"origin_image zh-lightbox-thumb\" width=\"1506\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-fdb7316891a6757fa252b1bb5587e346_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1506&#39; height=&#39;280&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1506\" data-rawheight=\"280\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1506\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-fdb7316891a6757fa252b1bb5587e346_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-fdb7316891a6757fa252b1bb5587e346_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E注意到蓝色框里面三个一组，说明了『策略』和『专家、环境』之间的对抗关系。\u003C\u002Fp\u003E\u003Cp\u003E如果是 static expert（不过不能预知它们的序列，不然它就是 simulatable 的了），令这些 expert 的建议来自一个函数族 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathcal%7BF%7D\" alt=\"\\mathcal{F}\" eeimg=\"1\"\u002F\u003E ，该问题可以被表述为：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-c2114da5254450bde9f60f7f2781c8a1_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1502\" data-rawheight=\"152\" class=\"origin_image zh-lightbox-thumb\" width=\"1502\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-c2114da5254450bde9f60f7f2781c8a1_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1502&#39; height=&#39;152&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1502\" data-rawheight=\"152\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1502\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-c2114da5254450bde9f60f7f2781c8a1_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-c2114da5254450bde9f60f7f2781c8a1_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E关于它，前面我们得到一个最好的 regret bound： \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=V_n%5E%7B%28N%29%7D+%5Cle+%5Csqrt%7B%28n%2F2%29%5Cln+N%7D\" alt=\"V_n^{(N)} \\le \\sqrt{(n\u002F2)\\ln N}\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Cp\u003E如果 expert 是可以 simulatable 的，并且相应的函数族为 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathcal%7BF%7D\" alt=\"\\mathcal{F}\" eeimg=\"1\"\u002F\u003E ，那么它就不再成为一个『对抗』的因素了（不用分析关于它的最坏情形了），相应的 regret 就依赖于这个函数族，即：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-09c2735d294537fb65e98e4e6f786719_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1532\" data-rawheight=\"138\" class=\"origin_image zh-lightbox-thumb\" width=\"1532\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-09c2735d294537fb65e98e4e6f786719_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1532&#39; height=&#39;138&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1532\" data-rawheight=\"138\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1532\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-09c2735d294537fb65e98e4e6f786719_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-09c2735d294537fb65e98e4e6f786719_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E当 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%7C%5Cmathcal%7BF%7D%7C%3Dn\" alt=\"|\\mathcal{F}|=n\" eeimg=\"1\"\u002F\u003E 时，有 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=V_n%28%5Cmathcal%7BF%7D%29+%5Cle+V_n%5E%7B%28N%29%7D\" alt=\"V_n(\\mathcal{F}) \\le V_n^{(N)}\" eeimg=\"1\"\u002F\u003E （来自第八章）。其原因是专家 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathcal%7BF%7D\" alt=\"\\mathcal{F}\" eeimg=\"1\"\u002F\u003E 可以被模拟之后，它就可以被策略所利用，从而得到更好的 regret bound。\u003C\u002Fp\u003E\u003Ch2\u003E总结\u003C\u002Fh2\u003E\u003Cp\u003E对于最为基础的 expert problem 问题，这一章先提出了基于势能的 weighted average 方案，并且由此推出了 polynomially weighted average 和 exponentially weighted average。接着提出了另外一种（不基于势能）的把 loss 的梯度作为权重的 weighted average 方案。文章出了：1）超参数不含有总轮数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=n\" alt=\"n\" eeimg=\"1\"\u002F\u003E 的修正方案；2）得知最优专家遭受较小损失 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=L_n%5E%2A\" alt=\"L_n^*\" eeimg=\"1\"\u002F\u003E 时的改进方案；3）每一局的损失函数不再是 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5B0%2C1%5D\" alt=\"[0,1]\" eeimg=\"1\"\u002F\u003E 之间而是任意区间内的 bound。最后，文章做了 simulatable expert 和 discounted regret 的推广，其中后者不太感兴趣，没写出来。\u003C\u002Fp\u003E\u003Ch2\u003E思考\u003C\u002Fh2\u003E\u003Cp\u003E目前看到 expert problem 相比于 RL 问题，有两个比较重要的区别：\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003EExpert problem 假定 loss function 已知，这样即使你没有采取某个专家的建议，它的 loss 也会被知道；RL 里面只能知道采取某个行动（某个专家的建议）之后的收益，而未采取的行动对应的收益不知道。考虑到这一点，前面讲的 POLITEX 就需要使用价值函数的估计，来近似地得到未采取行动的收益\u002F损失。\u003C\u002Fli\u003E\u003Cli\u003EExpert problem 的目标是与给定的 expert 作比较，因此策略的选择只考虑 expert 的建议们的『平均值』，即内部，而不要考虑这些建议『外部』的区域，即使可能这些 expert 都很差。隐约感觉 expert problem 不太有『探索』的问题，主要是如何『利用』的问题。而 RL 有探索的问题。如果像 POLITEX 一样用 expert problem 去套 RL 问题，一般就假设 expert 包含了所有可能的 action。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003E（最后这一条我感觉我没说清楚。。因为我还没想清楚。。）\u003C\u002Fp\u003E\u003Cp\u003E\u003C\u002Fp\u003E","adminClosedComment":false,"topics":[{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F20039099","type":"topic","id":"20039099","name":"强化学习 (Reinforcement Learning)"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F19567962","type":"topic","id":"19567962","name":"博弈论"}],"voteupCount":6,"voting":0,"column":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"},"commentCount":2,"contributions":[{"id":21337413,"state":"accepted","type":"first_publish","column":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}}],"isTitleImageFullScreen":false,"upvotedFollowees":[],"commercialInfo":{"isCommercial":false,"plugin":{}},"suggestEdit":{"status":false,"reason":"","tip":"","url":"","title":""},"reason":"","annotationAction":[],"canTip":false,"tipjarorsCount":0,"isLabeled":false,"hasPublishingDraft":false,"isFavorited":false,"isNormal":true,"status":0,"shareText":"【算法】Prediction2 - 来自知乎专栏「强化学习前沿」，作者: 张楚珩 https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F74722789 （想看更多？下载 @知乎 App：http:\u002F\u002Fweibo.com\u002Fp\u002F100404711598 ）","canComment":{"status":true,"reason":""},"mcnFpShow":-1,"isVisible":true,"isLiked":false,"likedCount":0,"visibleOnlyToAuthor":false}},"columns":{"reinforcementlearning":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}},"topics":{},"roundtables":{},"favlists":{},"comments":{},"notifications":{},"ebooks":{},"activities":{},"feeds":{},"pins":{},"promotions":{},"drafts":{},"chats":{},"posts":{},"clubs":{},"clubTags":{}},"currentUser":"","account":{"lockLevel":{},"unlockTicketStatus":false,"unlockTicket":null,"challenge":[],"errorStatus":false,"message":"","isFetching":false,"accountInfo":{},"urlToken":{"loading":false}},"settings":{"socialBind":null,"inboxMsg":null,"notification":{},"email":{},"privacyFlag":null,"blockedUsers":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"blockedFollowees":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"ignoredTopics":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"restrictedTopics":null,"laboratory":{}},"notification":{},"people":{"profileStatus":{},"activitiesByUser":{},"answersByUser":{},"answersSortByVotesByUser":{},"answersIncludedByUser":{},"votedAnswersByUser":{},"thankedAnswersByUser":{},"voteAnswersByUser":{},"thankAnswersByUser":{},"topicAnswersByUser":{},"zvideosByUser":{},"articlesByUser":{},"articlesSortByVotesByUser":{},"articlesIncludedByUser":{},"pinsByUser":{},"questionsByUser":{},"commercialQuestionsByUser":{},"favlistsByUser":{},"followingByUser":{},"followersByUser":{},"mutualsByUser":{},"followingColumnsByUser":{},"followingQuestionsByUser":{},"followingFavlistsByUser":{},"followingTopicsByUser":{},"publicationsByUser":{},"columnsByUser":{},"allFavlistsByUser":{},"brands":null,"creationsByUser":{},"creationsSortByVotesByUser":{},"creationsFeed":{}},"env":{"ab":{"config":{"experiments":[{"expId":"launch-gw_mweb_rec-1","expPrefix":"gw_mweb_rec","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-qa_hdpimg-2","expPrefix":"qa_hdpimg","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-us_foltopic_user-10","expPrefix":"us_foltopic_user","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_bullet_second-2","expPrefix":"vd_bullet_second","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_zvideo_link-10","expPrefix":"vd_zvideo_link","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false}],"params":[{"id":"se_webmajorob","type":"String","value":"0","chainId":"_all_"},{"id":"se_new_p","type":"String","value":"0","chainId":"_all_"},{"id":"se_timebox_up","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_qa_pic","type":"String","value":"1","chainId":"_all_"},{"id":"web_heifetz_grow_ad","type":"String","value":"1"},{"id":"li_se_media_icon","type":"String","value":"1","chainId":"_all_"},{"id":"web_column_auto_invite","type":"String","value":"0"},{"id":"zr_slot_cold_start","type":"String","value":"aver","chainId":"_all_"},{"id":"ug_goodcomment_0","type":"String","value":"1","chainId":"_all_"},{"id":"tp_score_1","type":"String","value":"a","chainId":"_all_"},{"id":"li_education_box","type":"String","value":"0","chainId":"_all_"},{"id":"zr_answer_rec_cp","type":"String","value":"open","chainId":"_all_"},{"id":"se_aa","type":"String","value":"0","chainId":"_all_"},{"id":"se_zu_recommend","type":"String","value":"0","chainId":"_all_"},{"id":"zr_training_first","type":"String","value":"false","chainId":"_all_"},{"id":"se_hotmore","type":"String","value":"2","chainId":"_all_"},{"id":"se_sug_term","type":"String","value":"0","chainId":"_all_"},{"id":"ls_videoad","type":"String","value":"2","chainId":"_all_"},{"id":"tp_club_discover","type":"String","value":"0","chainId":"_all_"},{"id":"li_qa_new_cover","type":"String","value":"1","chainId":"_all_"},{"id":"li_vip_verti_search","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_edu","type":"String","value":"1","chainId":"_all_"},{"id":"se_col_boost","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_pic","type":"String","value":"0.6","chainId":"_all_"},{"id":"soc_iossort","type":"String","value":"0","chainId":"_all_"},{"id":"top_ydyq","type":"String","value":"X","chainId":"_all_"},{"id":"web_answer_update","type":"String","value":"0"},{"id":"zr_ans_rec","type":"String","value":"gbrank","chainId":"_all_"},{"id":"se_sug","type":"String","value":"1","chainId":"_all_"},{"id":"li_answer_card","type":"String","value":"0","chainId":"_all_"},{"id":"qap_question_visitor","type":"String","value":" 0","chainId":"_all_"},{"id":"se_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"se_wannasearch","type":"String","value":"0","chainId":"_all_"},{"id":"zr_km_answer","type":"String","value":"open_cvr","chainId":"_all_"},{"id":"se_topiclabel","type":"String","value":"1","chainId":"_all_"},{"id":"se_college_cm","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_3","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_tab_feed","type":"String","value":"0","chainId":"_all_"},{"id":"top_new_feed","type":"String","value":"5","chainId":"_all_"},{"id":"li_ebook_read","type":"String","value":"0","chainId":"_all_"},{"id":"li_paid_answer_exp","type":"String","value":"0","chainId":"_all_"},{"id":"se_site_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_movietab","type":"String","value":"1","chainId":"_all_"},{"id":"soc_iosreadline","type":"String","value":"0","chainId":"_all_"},{"id":"tsp_vote","type":"String","value":"2","chainId":"_all_"},{"id":"li_answers_link","type":"String","value":"0","chainId":"_all_"},{"id":"zr_training_boost","type":"String","value":"false","chainId":"_all_"},{"id":"se_likebutton","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_tab","type":"String","value":"0","chainId":"_all_"},{"id":"se_club_post","type":"String","value":"5","chainId":"_all_"},{"id":"se_content0","type":"String","value":"0","chainId":"_all_"},{"id":"tp_qa_metacard","type":"String","value":"1","chainId":"_all_"},{"id":"ug_zero_follow_0","type":"String","value":"0","chainId":"_all_"},{"id":"se_hot_timebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_payconsult","type":"String","value":"0","chainId":"_all_"},{"id":"soc_notification","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zcfw_shipinshiti","type":"String","value":"1","chainId":"_all_"},{"id":"top_ebook","type":"String","value":"0","chainId":"_all_"},{"id":"li_video_section","type":"String","value":"0","chainId":"_all_"},{"id":"web_audit_01","type":"String","value":"case1"},{"id":"se_entity_model","type":"String","value":"0","chainId":"_all_"},{"id":"se_pek_test3","type":"String","value":"1","chainId":"_all_"},{"id":"tp_discover_copy","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iospinweight","type":"String","value":"0","chainId":"_all_"},{"id":"gue_card_test","type":"String","value":"1"},{"id":"zr_test_aa1","type":"String","value":"0","chainId":"_all_"},{"id":"se_amovietab","type":"String","value":"1","chainId":"_all_"},{"id":"se_featured","type":"String","value":"1","chainId":"_all_"},{"id":"li_qa_btn_text","type":"String","value":"0","chainId":"_all_"},{"id":"web_unfriendly_comm","type":"String","value":"0"},{"id":"se_whitelist","type":"String","value":"0","chainId":"_all_"},{"id":"se_dnn_mt_v2","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zcfw_badcase","type":"String","value":"0","chainId":"_all_"},{"id":"ug_follow_topic_1","type":"String","value":"2","chainId":"_all_"},{"id":"se_ios_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"se_college","type":"String","value":"default","chainId":"_all_"},{"id":"se_zu_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iosintimacy","type":"String","value":"2","chainId":"_all_"},{"id":"zw_payc_qaedit","type":"String","value":"0","chainId":"_all_"},{"id":"web_n_web_msg","type":"String","value":"0"},{"id":"tp_discover","type":"String","value":"0","chainId":"_all_"},{"id":"tsp_hotlist_ui","type":"String","value":"1","chainId":"_all_"},{"id":"se_ctx_rerank","type":"String","value":"1","chainId":"_all_"},{"id":"se_new_merger","type":"String","value":"1","chainId":"_all_"},{"id":"se_ffzx_jushen1","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_pk","type":"String","value":"1","chainId":"_all_"},{"id":"ug_follow_answerer_0","type":"String","value":"0","chainId":"_all_"},{"id":"ls_recommend_test","type":"String","value":"0","chainId":"_all_"},{"id":"se_cate_l3","type":"String","value":"0","chainId":"_all_"},{"id":"se_cbert_index","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_pic_swiper","type":"String","value":"1","chainId":"_all_"},{"id":"tp_sft_v2","type":"String","value":"d","chainId":"_all_"},{"id":"li_se_heat","type":"String","value":"1","chainId":"_all_"},{"id":"li_sku_bottom_bar_re","type":"String","value":"0","chainId":"_all_"},{"id":"se_webrs","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_qa","type":"String","value":"1","chainId":"_all_"},{"id":"li_ebook_gen_search","type":"String","value":"0","chainId":"_all_"},{"id":"web_upload","type":"String","value":"1"},{"id":"se_backsearch","type":"String","value":"0","chainId":"_all_"},{"id":"pf_noti_entry_num","type":"String","value":"0","chainId":"_all_"},{"id":"zr_slotpaidexp","type":"String","value":"1","chainId":"_all_"},{"id":"se_famous","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_feed","type":"String","value":"1","chainId":"_all_"},{"id":"soc_yxzl_zcfw","type":"String","value":"0","chainId":"_all_"},{"id":"se_hotsearch_num","type":"String","value":"0","chainId":"_all_"},{"id":"se_article_icon","type":"String","value":"0","chainId":"_all_"},{"id":"tp_m_intro_re_topic","type":"String","value":"1","chainId":"_all_"},{"id":"soc_adsort","type":"String","value":"0","chainId":"_all_"},{"id":"zr_rec_answer_cp","type":"String","value":"close","chainId":"_all_"},{"id":"se_ltr_video","type":"String","value":"0","chainId":"_all_"},{"id":"tp_meta_card","type":"String","value":"0","chainId":"_all_"},{"id":"soc_authormore2","type":"String","value":"2","chainId":"_all_"},{"id":"se_mobileweb","type":"String","value":"1","chainId":"_all_"},{"id":"soc_update","type":"String","value":"1","chainId":"_all_"},{"id":"gue_bullet_guide","type":"String","value":"发个弹幕聊聊…"},{"id":"li_catalog_card","type":"String","value":"1","chainId":"_all_"},{"id":"li_ebok_chap","type":"String","value":"0","chainId":"_all_"},{"id":"zr_slot_training","type":"String","value":"1","chainId":"_all_"},{"id":"se_p_slideshow","type":"String","value":"0","chainId":"_all_"},{"id":"li_pay_banner_type","type":"String","value":"6","chainId":"_all_"},{"id":"web_ask","type":"String","value":"0"},{"id":"web_collect","type":"String","value":"0"},{"id":"se_specialbutton","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_head","type":"String","value":"0","chainId":"_all_"},{"id":"soc_bigone","type":"String","value":"0","chainId":"_all_"},{"id":"gue_zhuantikapian","type":"String","value":"0"},{"id":"zr_art_rec","type":"String","value":"base","chainId":"_all_"},{"id":"zr_rel_search","type":"String","value":"base","chainId":"_all_"},{"id":"se_pek_test","type":"String","value":"1","chainId":"_all_"},{"id":"qap_thanks","type":"String","value":"1","chainId":"_all_"},{"id":"zr_video_rank_nn","type":"String","value":"new_rank","chainId":"_all_"},{"id":"se_use_zitem","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adpinweight","type":"String","value":"0","chainId":"_all_"},{"id":"web_hdpimg","type":"String","value":"1"},{"id":"se_rf_w","type":"String","value":"0","chainId":"_all_"},{"id":"se_ad_index","type":"String","value":"10","chainId":"_all_"},{"id":"se_lottery","type":"String","value":"0","chainId":"_all_"},{"id":"soc_ri_merge","type":"String","value":"0","chainId":"_all_"},{"id":"top_test_4_liguangyi","type":"String","value":"1","chainId":"_all_"},{"id":"pf_newguide_vertical","type":"String","value":"0","chainId":"_all_"},{"id":"zr_update_merge_size","type":"String","value":"1","chainId":"_all_"},{"id":"zr_video_recall","type":"String","value":"current_recall","chainId":"_all_"},{"id":"se_aa_base","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_tab","type":"String","value":"0","chainId":"_all_"},{"id":"web_creator_route","type":"String","value":"1"},{"id":"se_cardrank_2","type":"String","value":"1","chainId":"_all_"},{"id":"se_preset_tech","type":"String","value":"0","chainId":"_all_"},{"id":"se_waterfall","type":"String","value":"0","chainId":"_all_"},{"id":"se_websearch","type":"String","value":"3","chainId":"_all_"},{"id":"pf_adjust","type":"String","value":"0","chainId":"_all_"},{"id":"pf_fuceng","type":"String","value":"1","chainId":"_all_"},{"id":"web_mini_review","type":"String","value":"0"},{"id":"zr_km_feed_nlp","type":"String","value":"old","chainId":"_all_"},{"id":"zr_intervene","type":"String","value":"0","chainId":"_all_"},{"id":"se_related_index","type":"String","value":"3","chainId":"_all_"},{"id":"tp_topic_style","type":"String","value":"0","chainId":"_all_"},{"id":"top_universalebook","type":"String","value":"1","chainId":"_all_"},{"id":"li_yxzl_new_style_a","type":"String","value":"1","chainId":"_all_"},{"id":"web_question_invite","type":"String","value":"B"},{"id":"zr_search_sim","type":"String","value":"0","chainId":"_all_"},{"id":"se_webtimebox","type":"String","value":"0","chainId":"_all_"},{"id":"zr_search_paid","type":"String","value":"0","chainId":"_all_"},{"id":"se_auto_syn","type":"String","value":"0","chainId":"_all_"},{"id":"se_subtext","type":"String","value":"0","chainId":"_all_"},{"id":"soc_bignew","type":"String","value":"1","chainId":"_all_"},{"id":"sem_up_growth","type":"String","value":"in_app","chainId":"_all_"},{"id":"li_android_vip","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_across","type":"String","value":"1","chainId":"_all_"},{"id":"web_answer_list_ad","type":"String","value":"1"},{"id":"soc_brdcst4","type":"String","value":"3","chainId":"_all_"},{"id":"top_quality","type":"String","value":"0","chainId":"_all_"},{"id":"se_preset_label","type":"String","value":"1","chainId":"_all_"},{"id":"se_sug_entrance","type":"String","value":"1","chainId":"_all_"},{"id":"tp_discovery_ab_1","type":"String","value":"0","chainId":"_all_"},{"id":"gue_video_replay","type":"String","value":"0"},{"id":"tp_sft","type":"String","value":"a","chainId":"_all_"},{"id":"soc_adreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"pf_creator_card","type":"String","value":"1","chainId":"_all_"},{"id":"gue_video_autoplay","type":"String","value":"0"},{"id":"gue_thanks","type":"String","value":"0"},{"id":"se_highlight","type":"String","value":"0","chainId":"_all_"},{"id":"soc_brdcst3","type":"String","value":"0","chainId":"_all_"},{"id":"li_answer_label","type":"String","value":"0","chainId":"_all_"},{"id":"qap_question_author","type":"String","value":"0","chainId":"_all_"},{"id":"se_click_club","type":"String","value":"1","chainId":"_all_"},{"id":"se_page_quality","type":"String","value":"0","chainId":"_all_"},{"id":"top_v_album","type":"String","value":"1","chainId":"_all_"},{"id":"web_ad_banner","type":"String","value":"0"},{"id":"li_assessment_show","type":"String","value":"1","chainId":"_all_"},{"id":"se_relationship","type":"String","value":"1","chainId":"_all_"},{"id":"soc_authormore","type":"String","value":"2","chainId":"_all_"},{"id":"tp_qa_toast","type":"String","value":"1","chainId":"_all_"},{"id":"tp_sticky_android","type":"String","value":"2","chainId":"_all_"},{"id":"soc_zcfw_broadcast","type":"String","value":"0","chainId":"_all_"},{"id":"ug_follow_answerer","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iosreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"gue_bullet_second","type":"String","value":"1"},{"id":"se_hotsearch_2","type":"String","value":"1","chainId":"_all_"},{"id":"tp_topic_rec","type":"String","value":"1","chainId":"_all_"},{"id":"qap_ques_invite","type":"String","value":"0","chainId":"_all_"},{"id":"se_multianswer","type":"String","value":"2","chainId":"_all_"},{"id":"tp_club_android_feed","type":"String","value":"old","chainId":"_all_"},{"id":"tp_club_android_join","type":"String","value":"1","chainId":"_all_"},{"id":"se_new_topic","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adreadline","type":"String","value":"0","chainId":"_all_"},{"id":"qap_article_like","type":"String","value":"1","chainId":"_all_"},{"id":"se_searchwiki","type":"String","value":"0","chainId":"_all_"},{"id":"se_presearch_ab","type":"String","value":"0","chainId":"_all_"},{"id":"web_answerlist_ad","type":"String","value":"0"},{"id":"tp_qa_metacard_top","type":"String","value":"top","chainId":"_all_"},{"id":"top_root","type":"String","value":"0","chainId":"_all_"},{"id":"top_hotcommerce","type":"String","value":"1","chainId":"_all_"},{"id":"gue_new_special_page","type":"String","value":"1"},{"id":"se_pek_test2","type":"String","value":"1","chainId":"_all_"},{"id":"soc_zuichangfangwen","type":"String","value":"0","chainId":"_all_"},{"id":"soc_special","type":"String","value":"0","chainId":"_all_"},{"id":"ug_zero_follow","type":"String","value":"0","chainId":"_all_"},{"id":"se_hotsearch","type":"String","value":"0","chainId":"_all_"},{"id":"soc_newfeed","type":"String","value":"2","chainId":"_all_"},{"id":"soc_stickypush","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_join","type":"String","value":"0","chainId":"_all_"},{"id":"gue_zvideo_link","type":"String","value":"1"},{"id":"web_mweb_launch","type":"String","value":"0"},{"id":"se_entity_model_14","type":"String","value":"0","chainId":"_all_"},{"id":"se_topicfeed","type":"String","value":"0","chainId":"_all_"},{"id":"se_search_feed","type":"String","value":"N","chainId":"_all_"},{"id":"se_prf","type":"String","value":"0","chainId":"_all_"},{"id":"se_relation_1","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_entry","type":"String","value":"0","chainId":"_all_"},{"id":"ls_fmp4","type":"String","value":"0","chainId":"_all_"},{"id":"zr_expslotpaid","type":"String","value":"1","chainId":"_all_"},{"id":"se_agency","type":"String","value":" 0","chainId":"_all_"},{"id":"tp_header_style","type":"String","value":"1","chainId":"_all_"},{"id":"soc_zcfw_broadcast2","type":"String","value":"1","chainId":"_all_"},{"id":"tp_topic_tab_new","type":"String","value":"0-0-0","chainId":"_all_"},{"id":"li_svip_tab_search","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_1","type":"String","value":"0","chainId":"_all_"},{"id":"se_colorfultab","type":"String","value":"1","chainId":"_all_"},{"id":"se_cardrank_4","type":"String","value":"1","chainId":"_all_"},{"id":"li_svip_cardshow","type":"String","value":"1","chainId":"_all_"},{"id":"zr_video_rank","type":"String","value":"new_rank","chainId":"_all_"},{"id":"pf_foltopic_usernum","type":"String","value":"50","chainId":"_all_"},{"id":"soc_feed_intimacy","type":"String","value":"2","chainId":"_all_"},{"id":"tsp_videobillboard","type":"String","value":"1","chainId":"_all_"},{"id":"li_purchase_test","type":"String","value":"0","chainId":"_all_"},{"id":"li_salt_hot","type":"String","value":"1","chainId":"_all_"},{"id":"gue_goods_card","type":"String","value":"0"},{"id":"soc_userrec","type":"String","value":"0","chainId":"_all_"},{"id":"se_adxtest","type":"String","value":"1","chainId":"_all_"},{"id":"soc_wonderuser_recom","type":"String","value":"2","chainId":"_all_"},{"id":"ug_fw_answ_aut_1","type":"String","value":"0","chainId":"_all_"},{"id":"qap_payc_invite","type":"String","value":"0","chainId":"_all_"},{"id":"zw_sameq_sorce","type":"String","value":"999","chainId":"_all_"},{"id":"se_expired_ob","type":"String","value":"0","chainId":"_all_"},{"id":"se_time_threshold","type":"String","value":"0","chainId":"_all_"},{"id":"zr_article_new","type":"String","value":"close","chainId":"_all_"},{"id":"tp_club_header","type":"String","value":"1","chainId":"_all_"},{"id":"soc_cardheight","type":"String","value":"2","chainId":"_all_"},{"id":"ug_newtag","type":"String","value":"0","chainId":"_all_"},{"id":"web_mweb_rec_length","type":"String","value":"1"},{"id":"web_sem_ab","type":"String","value":"1"},{"id":"li_se_section","type":"String","value":"0","chainId":"_all_"},{"id":"web_sec672","type":"String","value":"0"},{"id":"li_hot_voted","type":"String","value":"0","chainId":"_all_"},{"id":"gue_self_censoring","type":"String","value":"1"},{"id":"se_billboardsearch","type":"String","value":"0","chainId":"_all_"},{"id":"soc_leave_recommend","type":"String","value":"2","chainId":"_all_"}],"chains":[{"chainId":"_all_"}]},"triggers":{}},"userAgent":{"Edge":false,"Wechat":false,"Weibo":false,"QQ":false,"MQQBrowser":false,"Qzone":false,"Mobile":false,"Android":false,"iOS":false,"isAppleDevice":false,"Zhihu":false,"ZhihuHybrid":false,"isBot":false,"Tablet":false,"UC":false,"Sogou":false,"Qihoo":false,"Baidu":false,"BaiduApp":false,"Safari":false,"GoogleBot":false,"AndroidDaily":false,"iOSDaily":false,"isWebView":false,"origin":"Mozilla\u002F5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\u002F537.36 (KHTML, like Gecko) Chrome\u002F80.0.3987.100 Safari\u002F537.36"},"appViewConfig":{},"ctx":{"path":"\u002Fp\u002F74722789","query":{},"href":"http:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F74722789","host":"zhuanlan.zhihu.com"},"trafficSource":"production","edition":{"baidu":false,"sogou":false,"baiduBeijing":false,"sogouBeijing":false,"sogouInput":false},"theme":"light","enableShortcut":true,"referer":"","conf":{},"ipInfo":{"cityName":"德州","countryName":"中国","regionName":"山东","countryCode":"CN"},"logged":false},"me":{"columnContributions":[]},"label":{"recognizerLists":{}},"ecommerce":{},"comments":{"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"parent":{}},"commentsV2":{"stickers":[],"commentWithPicPermission":{},"notificationsComments":{},"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"conversationMore":{},"parent":{}},"pushNotifications":{"default":{"isFetching":false,"isDrained":false,"ids":[]},"follow":{"isFetching":false,"isDrained":false,"ids":[]},"vote_thank":{"isFetching":false,"isDrained":false,"ids":[]},"currentTab":"default","notificationsCount":{"default":0,"follow":0,"vote_thank":0}},"messages":{"data":{},"currentTab":"common","messageCount":0},"register":{"registerValidateSucceeded":null,"registerValidateErrors":{},"registerConfirmError":null,"sendDigitsError":null,"registerConfirmSucceeded":null},"login":{"loginUnregisteredError":false,"loginBindWechatError":false,"loginConfirmError":null,"sendDigitsError":null,"needSMSIdentify":false,"validateDigitsError":false,"loginConfirmSucceeded":null,"qrcodeLoginToken":"","qrcodeLoginScanStatus":0,"qrcodeLoginError":null,"qrcodeLoginReturnNewToken":false},"active":{"sendDigitsError":null,"activeConfirmSucceeded":null,"activeConfirmError":null},"switches":{},"captcha":{"captchaNeeded":false,"captchaValidated":false,"captchaBase64String":null,"captchaValidationMessage":null,"loginCaptchaExpires":false},"sms":{"supportedCountries":[]},"chat":{"chats":{},"inbox":{"recents":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"strangers":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"friends":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"search":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"config":{"newCount":0,"strangerMessageSwitch":false,"strangerMessageUnread":false,"friendCount":0}},"global":{"isChatMqttExisted":false}},"emoticons":{"emoticonGroupList":[],"emoticonGroupDetail":{}},"creator":{"currentCreatorUrlToken":null,"homeData":{"recommendQuestions":[]},"tools":{"question":{"invitationCount":{"questionFolloweeCount":0,"questionTotalCount":0},"goodatTopics":[]},"customPromotion":{"itemLists":{}},"recommend":{"recommendTimes":{}}},"explore":{"academy":{"tabs":[],"article":{}}},"rights":[],"rightsStatus":{},"levelUpperLimit":10,"account":{"growthLevel":{}},"mcn":{},"applyStatus":{}},"recommendation":{"homeRecommendations":[]},"shareTexts":{},"articles":{"voters":{}},"previewPost":{},"favlists":{"relations":{}},"columns":{"voters":{}},"reward":{"answer":{},"article":{},"question":{}},"video":{"data":{},"shareVideoDetail":{},"last":{}},"topstory":{"recommend":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"follow":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followWonderful":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"sidebar":null,"announcement":{},"hotListCategories":[],"hotList":[],"guestFeeds":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followExtra":{"isNewUser":null,"isFetched":false,"followCount":0,"followers":[]}},"readStatus":{},"column":{},"requestColumn":{"categories":[],"error":null},"articleContribution":{"contributeRequests":[],"deleteContributeIdList":[],"handledContributeIdList":[],"recommendedColumns":[],"pinnedColumns":[],"sentContributeRequestsIdList":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"reinforcementlearning"]},"columnContribution":{"contributeRequests":[],"autoInviteEnabled":false,"recommendedContributors":[],"contributionInvitation":null},"draftHistory":{"history":{},"drafts":{}},"upload":{},"articleDraft":{"titleImage":"","titleImageSize":{},"isTitleImageFullScreen":false,"canTitleImageFullScreen":false,"title":"","titleImageUploading":false,"error":"","content":"","draftLoading":false,"updating":false,"globalLoading":false,"pendingVideo":{"resource":null,"error":null},"deleteFail":{"fail":false},"recommendTopics":[],"selectedColumn":0,"articleDisclaimers":[]},"articleDrafts":{"isDrained":false,"isLoading":false,"items":[]},"columnAutocomplete":{"users":[],"friends":[]},"columnCollection":{},"mcn":{"bindInfo":{},"memberCategoryList":[],"producerList":[],"categoryList":[]}},"fetchHost":"www.zhihu.com","subAppName":"column"}</script><script src="https://static.zhihu.com/heifetz/vendor.7b36fae46082fd30a0db.js"></script><script src="https://static.zhihu.com/heifetz/column.app.76e02b16e87eec249f44.js"></script></body><script src="https://hm.baidu.com/hm.js?98beee57fd2ef70ccdd5ca52b9740c49" async=""></script><script src="https://zz.bdstatic.com/linksubmit/push.js" async=""></script></html>