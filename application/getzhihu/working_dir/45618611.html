<!doctype html>
<html lang="zh" data-hairline="true" data-theme="light"><head><meta charSet="utf-8"/><title data-react-helmet="true">【强化学习算法 13】iLQG - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"/><meta name="renderer" content="webkit"/><meta name="force-rendering" content="webkit"/><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg"/><meta data-react-helmet="true" name="keywords" content="算法,机器学习,强化学习 (Reinforcement Learning)"/><meta data-react-helmet="true" name="description" content="i打头但并不是苹果家的产品哈，其全称是 Iterative Linear Quadratic Gaussian。原文传送门：Todorov, Emanuel, and Weiwei Li. &amp;#34;A generalized iterative LQG method for locally-optimal feedback control o…"/><meta data-react-helmet="true" property="og:title" content="【强化学习算法 13】iLQG"/><meta data-react-helmet="true" property="og:url" content="https://zhuanlan.zhihu.com/p/45618611"/><meta data-react-helmet="true" property="og:description" content="i打头但并不是苹果家的产品哈，其全称是 Iterative Linear Quadratic Gaussian。原文传送门：Todorov, Emanuel, and Weiwei Li. &amp;#34;A generalized iterative LQG method for locally-optimal feedback control o…"/><meta data-react-helmet="true" property="og:image" content="https://pic2.zhimg.com/v2-b528ccd79db60c8738ad54ca1f09ad77_b.jpg"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" property="og:site_name" content="知乎专栏"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png" sizes="152x152"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-120.b3e6278d.png" sizes="120x120"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-76.7a750095.png" sizes="76x76"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-60.a4a761d4.png" sizes="60x60"/><link rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/static/favicon.ico"/><link rel="search" type="application/opensearchdescription+xml" href="https://static.zhihu.com/static/search.xml" title="知乎"/><link rel="dns-prefetch" href="//static.zhimg.com"/><link rel="dns-prefetch" href="//pic1.zhimg.com"/><link rel="dns-prefetch" href="//pic2.zhimg.com"/><link rel="dns-prefetch" href="//pic3.zhimg.com"/><link rel="dns-prefetch" href="//pic4.zhimg.com"/><style>
.u-safeAreaInset-top {
  height: constant(safe-area-inset-top) !important;
  height: env(safe-area-inset-top) !important;
  
}
.u-safeAreaInset-bottom {
  height: constant(safe-area-inset-bottom) !important;
  height: env(safe-area-inset-bottom) !important;
  
}
</style><link href="https://static.zhihu.com/heifetz/column.app.a9ced452148fee3a55c8.css" rel="stylesheet"/><script defer="" crossorigin="anonymous" src="https://unpkg.zhimg.com/@cfe/sentry-script@latest/dist/init.js" data-sentry-config="{&quot;dsn&quot;:&quot;https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224&quot;,&quot;sampleRate&quot;:0.1,&quot;release&quot;:&quot;683-127b14ad&quot;,&quot;ignoreErrorNames&quot;:[&quot;NetworkError&quot;,&quot;SecurityError&quot;],&quot;ignoreErrors&quot;:[&quot;origin message&quot;,&quot;Network request failed&quot;,&quot;Loading chunk&quot;,&quot;这个系统不支持该功能。&quot;,&quot;Can&#x27;t find variable: webkit&quot;,&quot;Can&#x27;t find variable: $&quot;,&quot;内存不足&quot;,&quot;out of memory&quot;,&quot;DOM Exception 18&quot;,&quot;The operation is insecure&quot;,&quot;[object Event]&quot;,&quot;[object FileError]&quot;,&quot;[object DOMError]&quot;,&quot;[object Object]&quot;,&quot;拒绝访问。&quot;,&quot;Maximum call stack size exceeded&quot;,&quot;UploadError&quot;,&quot;无法 fetch&quot;,&quot;draft-js&quot;,&quot;缺少 JavaScript 对象&quot;,&quot;componentWillEnter&quot;,&quot;componentWillLeave&quot;,&quot;componentWillAppear&quot;,&quot;getInlineStyleAt&quot;,&quot;getCharacterList&quot;],&quot;whitelistUrls&quot;:[&quot;static.zhihu.com&quot;]}"></script></head><body class="WhiteBg-body"><div id="root"><div class="App"><div class="LoadingBar"></div><main role="main" class="App-main"><div class="Post-content" data-zop-usertoken="{&quot;userToken&quot;:&quot;&quot;}" data-zop="{&quot;authorName&quot;:&quot;张楚珩&quot;,&quot;itemId&quot;:45618611,&quot;title&quot;:&quot;【强化学习算法 13】iLQG&quot;,&quot;type&quot;:&quot;article&quot;}"><div class="ColumnPageHeader-Wrapper"><div><div class="Sticky ColumnPageHeader"><div class="ColumnPageHeader-content"><a href="//www.zhihu.com" aria-label="知乎"><svg viewBox="0 0 200 91" fill="#0084FF" width="64" height="30"><path d="M53.29 80.035l7.32.002 2.41 8.24 13.128-8.24h15.477v-67.98H53.29v67.978zm7.79-60.598h22.756v53.22h-8.73l-8.718 5.473-1.587-5.46-3.72-.012v-53.22zM46.818 43.162h-16.35c.545-8.467.687-16.12.687-22.955h15.987s.615-7.05-2.68-6.97H16.807c1.09-4.1 2.46-8.332 4.1-12.708 0 0-7.523 0-10.085 6.74-1.06 2.78-4.128 13.48-9.592 24.41 1.84-.2 7.927-.37 11.512-6.94.66-1.84.785-2.08 1.605-4.54h9.02c0 3.28-.374 20.9-.526 22.95H6.51c-3.67 0-4.863 7.38-4.863 7.38H22.14C20.765 66.11 13.385 79.24 0 89.62c6.403 1.828 12.784-.29 15.937-3.094 0 0 7.182-6.53 11.12-21.64L43.92 85.18s2.473-8.402-.388-12.496c-2.37-2.788-8.768-10.33-11.496-13.064l-4.57 3.627c1.363-4.368 2.183-8.61 2.46-12.71H49.19s-.027-7.38-2.372-7.38zm128.752-.502c6.51-8.013 14.054-18.302 14.054-18.302s-5.827-4.625-8.556-1.27c-1.874 2.548-11.51 15.063-11.51 15.063l6.012 4.51zm-46.903-18.462c-2.814-2.577-8.096.667-8.096.667s12.35 17.2 12.85 17.953l6.08-4.29s-8.02-11.752-10.83-14.33zM199.99 46.5c-6.18 0-40.908.292-40.953.292v-31.56c1.503 0 3.882-.124 7.14-.376 12.773-.753 21.914-1.25 27.427-1.504 0 0 3.817-8.496-.185-10.45-.96-.37-7.24 1.43-7.24 1.43s-51.63 5.153-72.61 5.64c.5 2.756 2.38 5.336 4.93 6.11 4.16 1.087 7.09.53 15.36.277 7.76-.5 13.65-.76 17.66-.76v31.19h-41.71s.88 6.97 7.97 7.14h33.73v22.16c0 4.364-3.498 6.87-7.65 6.6-4.4.034-8.15-.36-13.027-.566.623 1.24 1.977 4.496 6.035 6.824 3.087 1.502 5.054 2.053 8.13 2.053 9.237 0 14.27-5.4 14.027-14.16V53.93h38.235c3.026 0 2.72-7.432 2.72-7.432z" fill-rule="evenodd"></path></svg></a><i class="ColumnPageHeader-Line"></i><div class="ColumnPageHeader-Title"><a class="ColumnLink ColumnPageHeader-Link" href="/reinforcementlearning"><img class="Avatar Avatar--round" width="30" height="30" src="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_is.jpg" srcSet="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_im.jpg 2x" alt="强化学习前沿"/></a><div class="ColumnPageHeader-TitleName"><span class="ColumnPageHeader-TitleMeta">首发于</span><a class="ColumnLink ColumnPageHeader-TitleColumn" href="/reinforcementlearning">强化学习前沿</a></div></div><div class="ColumnPageHeader-Button"><button type="button" class="Button ColumnPageHeader-WriteButton Button--blue"><svg class="Zi Zi--EditSurround" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M18.453 7.992l-1.833-1.65.964-.978a1.223 1.223 0 0 1 1.73-.012l.005.006a1.24 1.24 0 0 1 .007 1.748l-.873.886zm-1.178 1.194l-5.578 5.66-1.935.697a.393.393 0 0 1-.504-.504l.697-1.935 5.488-5.567 1.832 1.65zM7.58 5.848l5.654.006-1.539 1.991-3.666.012A1.02 1.02 0 0 0 7 8.868v7.993c0 .558.46 1.01 1.029 1.01l7.941-.01c.568 0 1.03-.453 1.03-1.012v-4.061l2-1.442v6.002c0 1.397-1.2 2.501-2.62 2.501H7.574C6.153 19.85 5 18.717 5 17.32V8.35c0-1.397 1.16-2.502 2.58-2.502z"></path></svg>写文章</button></div></div></div></div></div><img class="TitleImage" src="https://pic2.zhimg.com/v2-b528ccd79db60c8738ad54ca1f09ad77_1200x500.jpg" alt="【强化学习算法 13】iLQG"/><article class="Post-Main Post-NormalMain" tabindex="-1"><header class="Post-Header"><h1 class="Post-Title">【强化学习算法 13】iLQG</h1><div class="Post-Author"><div class="AuthorInfo" itemProp="author" itemscope="" itemType="http://schema.org/Person"><meta itemProp="name" content="张楚珩"/><meta itemProp="image" content="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg"/><meta itemProp="url" content="https://www.zhihu.com/people/zhang-chu-heng"/><meta itemProp="zhihu:followerCount"/><span class="UserLink AuthorInfo-avatarWrapper"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/zhang-chu-heng"><img class="Avatar Avatar--round AuthorInfo-avatar" width="38" height="38" src="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_xs.jpg" srcSet="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg 2x" alt="张楚珩"/></a></div></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/zhang-chu-heng">张楚珩</a></div></div><style data-emotion-css="1cd9gw4">.css-1cd9gw4{margin-left:.3em;}</style><style data-emotion-css="1pc1mic">.css-1pc1mic{box-sizing:border-box;margin:0;min-width:0;color:#175199;display:inline-block;width:18px;height:18px;margin-left:.3em;}</style><a href="https://www.zhihu.com/question/48510028" target="_blank" class="css-1pc1mic" data-tooltip="已认证的个人" aria-label="已认证的个人"><style data-emotion-css="18biwo">.css-18biwo{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><span class="css-18biwo">​<svg viewBox="0 0 24 24" width="18" height="18"><svg viewBox="0 0 24 24" x="-3" y="-3" fill="#FFFFFF" width="30" height="30"><path d="M3.56231227,13.8535307 C2.40051305,12.768677 2.41398885,11.0669203 3.59484487,9.99979213 L3.59222085,9.99654885 C4.26730143,9.45036719 4.79446755,8.21005186 4.7184197,7.34453784 L4.72305873,7.34412719 C4.66942824,5.75539997 5.8824188,4.56066914 7.47188965,4.64242381 L7.47229112,4.6386236 C8.33515314,4.72977993 9.58467253,4.22534048 10.1426329,3.55925173 L10.1462611,3.56228565 C11.2316055,2.40008701 12.9353108,2.41394456 14.0015072,3.59634088 L14.0047263,3.59374004 C14.5498229,4.26841874 15.7896857,4.79521622 16.6545744,4.71844347 L16.6549836,4.72304294 C18.245027,4.66894057 19.4396947,5.88213996 19.3575031,7.47241135 L19.3623099,7.47292747 C19.2704388,8.3358681 19.7742711,9.58421483 20.4407199,10.1424506 L20.437686,10.1460789 C21.5997217,11.2312209 21.5860695,12.9345218 20.4042441,14.0007396 L20.4072865,14.0045125 C19.7325967,14.5495925 19.2055209,15.7896954 19.2815865,16.6561959 L19.2770449,16.6565978 C19.3315454,18.2453037 18.1173775,19.4393568 16.5274188,19.3571512 L16.5269029,19.3619539 C15.6647098,19.270083 14.415408,19.7741709 13.8573671,20.4403558 L13.8537409,20.4373235 C12.76842,21.5995708 11.0650432,21.5864553 9.99899434,20.4039226 L9.99527367,20.406923 C9.45025436,19.7323399 8.21017638,19.2051872 7.34461983,19.2812352 L7.344304,19.2776405 C5.75448683,19.3312904 4.55977145,18.1170085 4.64254978,16.527117 L4.63769921,16.5265942 C4.72957031,15.6644394 4.22547659,14.4151814 3.55928015,13.8571569 L3.56231227,13.8535307 Z"></path></svg><path d="M2.63951518,13.3895441 C3.70763333,14.2842292 4.44777637,16.1226061 4.30075305,17.5023312 L4.32211542,17.3063047 C4.17509209,18.6910561 5.17786655,19.7063729 6.5613937,19.5844846 L6.364106,19.6008202 C7.75140298,19.4789319 9.57474349,20.2554985 10.4468305,21.3349009 L10.3224262,21.1803415 C11.1982831,22.2647703 12.6257916,22.2723098 13.5167278,21.2079863 L13.3898102,21.3600325 C14.2845162,20.2919393 16.1229361,19.5518136 17.5026934,19.6988334 L17.3054057,19.6774716 C18.6914461,19.8244915 19.7067866,18.8217404 19.5836389,17.4395022 L19.6012314,17.6367853 C19.4793403,16.2482641 20.255925,14.4249662 21.3353526,13.5528995 L21.1807897,13.677301 C22.2639871,12.8014646 22.2727834,11.3739894 21.2084351,10.483074 L21.3604848,10.6099886 C20.2923667,9.71530351 19.5522236,7.87818322 19.6992469,6.49720154 L19.6778846,6.69448464 C19.8249079,5.30847665 18.8221335,4.2944164 17.4386063,4.41630468 L17.635894,4.39871256 C16.248597,4.52185742 14.4252565,3.74529084 13.5531695,2.66588842 L13.6775738,2.81919121 C12.8017169,1.73601905 11.3742084,1.72722299 10.4832722,2.79154644 L10.6101898,2.63950024 C9.71548377,3.70759343 7.87706394,4.44771919 6.49730661,4.30195588 L6.69459432,4.32206116 C5.30855394,4.17504128 4.29447,5.17904888 4.41636114,6.56128713 L4.3987686,6.36400404 C4.52065973,7.75126861 3.74407501,9.57456653 2.66464737,10.4478898 L2.81921035,10.3222318 C1.73601288,11.1993248 1.72721662,12.6255433 2.79156494,13.5164587 L2.63951518,13.3895441 Z" fill="#0084FF"></path><svg class="Zi Zi--Check" fill="#fff" x="6" y="6" viewBox="0 0 24 24" width="12" height="12"><path d="M10.229 17.516c-.318.327-.75.484-1.199.484-.453 0-.884-.16-1.202-.488l-4.335-4.47a1.77 1.77 0 0 1 .007-2.459 1.663 1.663 0 0 1 2.397.01l3.137 3.246 9.072-9.329a1.662 1.662 0 0 1 2.397 0c.663.681.663 1.786 0 2.466L10.23 17.516z" fill-rule="evenodd"></path></svg></svg></span></a></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="AuthorInfo-badgeText">清华大学 交叉信息院博士在读</div></div></div></div></div></div><div><span class="Voters"><button type="button" class="Button Button--plain">19 人<!-- -->赞同了该文章</button></span></div></header><div class="Post-RichTextContainer"><div class="RichText ztext Post-RichText"><p>i打头但并不是苹果家的产品哈，其全称是 Iterative Linear Quadratic Gaussian。</p><h2><b>原文传送门：</b></h2><p><a href="https://link.zhihu.com/?target=http%3A//maeresearch.ucsd.edu/groups/skelton/publications/weiwei_ilqg_CDC43.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Todorov, Emanuel, and Weiwei Li. &#34;A generalized iterative LQG method for locally-optimal feedback control of constrained nonlinear stochastic systems.&#34; American Control Conference, 2005. Proceedings of the 2005. IEEE, 2005.</a> </p><h2><b>特色：</b></h2><p>确切的说这里要讲的不是一个强化学习算法，而是一个最优控制问题。其区别在于强化学习中不直接知道系统的dynamics，而最优控制的问题可以知道系统的dynamics。但是由于控制理论是强化理论的重要基础，相比于更为玄学的强化学习，它的理论分析更细致，了解一些控制论对于理解强化学习很有帮助。</p><p>这篇工作把一个非线性最优控制问题，在每次迭代中都在局部归化为控制理论里面研究很成熟的Linear Quadratic Gaussian（LQG）问题，然后迭代地去求解更好的控制序列，直到收敛。这篇工作里面的结果以现在的标准来看并不惊艳，但是展示的很仔细，对于强化学习过程中理解什么是价值函数、轨迹等都很有帮助。</p><h2><b>分类：</b></h2><p>不是强化学习算法、continuous state space、continuous action space、不仅仅是model-based而且需要知道model dynamics</p><h2><b>背景：</b></h2><p><b>LQG的最优控制</b>是控制理论里面一个非常经典的问题，考虑一个线性时变系统，其动力学特性</p><p><img src="https://www.zhihu.com/equation?tex=x%28k%2B1%29+%3D+F%28k%29+x%28k%29+%2B+G%28k%29+u%28k%29+%5Cquad+k%5Cin%5BN-1%5D" alt="x(k+1) = F(k) x(k) + G(k) u(k) \quad k\in[N-1]" eeimg="1"/> </p><p>控制目标是找到一个控制序列 <img src="https://www.zhihu.com/equation?tex=u%28k%29" alt="u(k)" eeimg="1"/> 最小化如下二次型性能指标函数</p><p><img src="https://www.zhihu.com/equation?tex=J+%3D+x%5ET%28N%29+Q_0+x%28N%29+%2B+%5Csum_%7Bk%3Dk_0%7D%5E%7BN-1%7D+%5Bx%5ET%28k%29+Q_1%28k%29x%28k%29+%2B+u%5ET%28k%29+Q_2%28k%29+u%28k%29%5D" alt="J = x^T(N) Q_0 x(N) + \sum_{k=k_0}^{N-1} [x^T(k) Q_1(k)x(k) + u^T(k) Q_2(k) u(k)]" eeimg="1"/> </p><p>其中要求 <img src="https://www.zhihu.com/equation?tex=Q_0%2C+Q_1" alt="Q_0, Q_1" eeimg="1"/> 非负定， <img src="https://www.zhihu.com/equation?tex=Q_2" alt="Q_2" eeimg="1"/> 正定。</p><p>该问题的解决方式就是使用动态规划求解，依次写出 <img src="https://www.zhihu.com/equation?tex=J_N%2C+J_%7BN-1%7D%2C+%5Ccdots" alt="J_N, J_{N-1}, \cdots" eeimg="1"/> ，把 <img src="https://www.zhihu.com/equation?tex=J%28N-1%29" alt="J(N-1)" eeimg="1"/> 用 <img src="https://www.zhihu.com/equation?tex=J%28N%29" alt="J(N)" eeimg="1"/> 表示，然后对于控制量求导，然后依次得到最优的控制序列 <img src="https://www.zhihu.com/equation?tex=u%28N-1%29%2C+u%28N-2%29%2C+%5Ccdots" alt="u(N-1), u(N-2), \cdots" eeimg="1"/> 。得到最优控制（Riccati方程）</p><p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bcases%7D+u%28k%29+%3D+-L%28k%29+x%28k%29+%5C%5C+L%28k%29+%3D+%5BQ_2%28k%29+%2B+G%5ET%28k%29+S%28k%2B1%29+G%28k%29%5D%5E%7B-1%7D%5BG%5ET%28k%29+S%28k%2B1%29+F%28k%29%5D+%5C%5C+S%28k%29+%3D+%5BF%28k%29+-+G%28k%29L%28k%29%5D%5ET+S%28k%2B1%29+%5BF%28k%29+-+G%28k%29L%28k%29%5D+%2B+Q_1%28k%29+%2B+L%5ET%28k%29+Q_2%28k%29+L%28k%29+%5C%5C+S%28N%29+%3D+Q_0+%5Cend%7Bcases%7D" alt="\begin{cases} u(k) = -L(k) x(k) \\ L(k) = [Q_2(k) + G^T(k) S(k+1) G(k)]^{-1}[G^T(k) S(k+1) F(k)] \\ S(k) = [F(k) - G(k)L(k)]^T S(k+1) [F(k) - G(k)L(k)] + Q_1(k) + L^T(k) Q_2(k) L(k) \\ S(N) = Q_0 \end{cases}" eeimg="1"/> </p><p>相应的最优性能指标函数为 <img src="https://www.zhihu.com/equation?tex=J_%7B%5Cmin%7D+%3D+x%5ET%28k_0%29S%28k_0%29x%28k_0%29" alt="J_{\min} = x^T(k_0)S(k_0)x(k_0)" eeimg="1"/>。</p><p>若考虑一个定常系统，即 <img src="https://www.zhihu.com/equation?tex=F%2C+G%2C+Q_1%2C+Q_2" alt="F, G, Q_1, Q_2" eeimg="1"/> 与时间无关，在求解该方程的时候可以发现 <img src="https://www.zhihu.com/equation?tex=S%28k%29" alt="S(k)" eeimg="1"/> 在远离 <img src="https://www.zhihu.com/equation?tex=k%3DN" alt="k=N" eeimg="1"/> 的地方几乎为一个稳定的常数，并且当 <img src="https://www.zhihu.com/equation?tex=N" alt="N" eeimg="1"/> 很大的时候，不论 <img src="https://www.zhihu.com/equation?tex=S%28N%29+%3D+Q_0" alt="S(N) = Q_0" eeimg="1"/> 取值如何该常数值都不变，因此有定常的控制规律</p><p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bcases%7D+u%28k%29+%3D+-L+x%28k%29+%5C%5C+L+%3D+%5BQ_2+%2B+G%5ET+S+G%5D%5E%7B-1%7D%5BG%5ET+S+F%5D+%5C%5C+S+%3D+%5BF+-+GL%5D%5ET+S+%5BF+-+GL%5D+%2B+Q_1+%2B+L%5ET+Q_2+L++%5Cend%7Bcases%7D" alt="\begin{cases} u(k) = -L x(k) \\ L = [Q_2 + G^T S G]^{-1}[G^T S F] \\ S = [F - GL]^T S [F - GL] + Q_1 + L^T Q_2 L  \end{cases}" eeimg="1"/> </p><h2><b>过程：</b></h2><p>iLQG的<b>主要思路</b>就是先任意找一个控制序列 <img src="https://www.zhihu.com/equation?tex=+%5Cleft%5C%7B+%5Cbar%7Bu%7D%28k%29+%5Cright%5C%7D" alt=" \left\{ \bar{u}(k) \right\}" eeimg="1"/> ，然后按照这个控制做一次rollout，得到轨迹 <img src="https://www.zhihu.com/equation?tex=%5C%7B+%5Cbar%7Bx%7D%28k%29+%5C%7D" alt="\{ \bar{x}(k) \}" eeimg="1"/> 。在这个轨迹附近，将系统的动力学特性线性化、将损失函数二次化，并考虑如何在 <img src="https://www.zhihu.com/equation?tex=%5Cleft%5C%7B+%5Cbar%7Bu%7D%28k%29+%5Cright%5C%7D" alt="\left\{ \bar{u}(k) \right\}" eeimg="1"/> 和 <img src="https://www.zhihu.com/equation?tex=%5C%7B+%5Cbar%7Bx%7D+%28k%29+%5C%7D" alt="\{ \bar{x} (k) \}" eeimg="1"/> 附近找到扰动 <img src="https://www.zhihu.com/equation?tex=%5Cdelta+u+%3D+u-%5Cbar%7Bu%7D" alt="\delta u = u-\bar{u}" eeimg="1"/>和<img src="https://www.zhihu.com/equation?tex=%5Cdelta+x+%3D+x+-+%5Cbar%7Bx%7D" alt="\delta x = x - \bar{x}" eeimg="1"/> 使得新的控制比之前的更好。迭代地做更新直到收敛即得到最优控制序列。</p><p>下面来具体地说各个步骤。</p><p>首先可以将系统的动力学特性线性化并且将损失函数二次化，有</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-7f5465abac7883d3298b3132d00a33db_b.jpg" data-caption="" data-size="normal" data-rawwidth="545" data-rawheight="182" class="origin_image zh-lightbox-thumb" width="545" data-original="https://pic4.zhimg.com/v2-7f5465abac7883d3298b3132d00a33db_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;545&#39; height=&#39;182&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="545" data-rawheight="182" class="origin_image zh-lightbox-thumb lazy" width="545" data-original="https://pic4.zhimg.com/v2-7f5465abac7883d3298b3132d00a33db_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-7f5465abac7883d3298b3132d00a33db_b.jpg"/></figure><p>其中 <img src="https://www.zhihu.com/equation?tex=A_k" alt="A_k" eeimg="1"/> 和 <img src="https://www.zhihu.com/equation?tex=B_k" alt="B_k" eeimg="1"/> 可以由已知的动力学规律在轨迹 <img src="https://www.zhihu.com/equation?tex=%5C%7B+%5Cbar%7Bx%7D%28k%29+%5C%7D" alt="\{ \bar{x}(k) \}" eeimg="1"/> 附近求导得到，各种Q和R都可以对于损失函数在现有轨迹附近求导得到， <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BC%7D_k" alt="\mathcal{C}_k" eeimg="1"/> 是由上述列向量拼成的，反映的是控制引起的噪声。即，认为各种A、B、C、Q、R已知。</p><p>假设有state value function写成如下形式</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-68545a67a9450607aaf0e9e9f4a4d97d_b.jpg" data-caption="" data-size="normal" data-rawwidth="602" data-rawheight="58" class="origin_image zh-lightbox-thumb" width="602" data-original="https://pic2.zhimg.com/v2-68545a67a9450607aaf0e9e9f4a4d97d_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;602&#39; height=&#39;58&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="602" data-rawheight="58" class="origin_image zh-lightbox-thumb lazy" width="602" data-original="https://pic2.zhimg.com/v2-68545a67a9450607aaf0e9e9f4a4d97d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-68545a67a9450607aaf0e9e9f4a4d97d_b.jpg"/></figure><p>应用Bellman方程</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-c7a91cd07ec40542c329887cf7e92fb4_b.jpg" data-caption="" data-size="normal" data-rawwidth="630" data-rawheight="37" class="origin_image zh-lightbox-thumb" width="630" data-original="https://pic1.zhimg.com/v2-c7a91cd07ec40542c329887cf7e92fb4_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;630&#39; height=&#39;37&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="630" data-rawheight="37" class="origin_image zh-lightbox-thumb lazy" width="630" data-original="https://pic1.zhimg.com/v2-c7a91cd07ec40542c329887cf7e92fb4_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-c7a91cd07ec40542c329887cf7e92fb4_b.jpg"/></figure><p>可以求得到</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-c9027d450e93f09844bfa8f5d86cb47e_b.jpg" data-caption="" data-size="normal" data-rawwidth="617" data-rawheight="152" class="origin_image zh-lightbox-thumb" width="617" data-original="https://pic3.zhimg.com/v2-c9027d450e93f09844bfa8f5d86cb47e_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;617&#39; height=&#39;152&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="617" data-rawheight="152" class="origin_image zh-lightbox-thumb lazy" width="617" data-original="https://pic3.zhimg.com/v2-c9027d450e93f09844bfa8f5d86cb47e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-c9027d450e93f09844bfa8f5d86cb47e_b.jpg"/></figure><p>假设具有形如 <img src="https://www.zhihu.com/equation?tex=%5Cdelta+u+%3D+%5Cpi_k%28%5Cdelta+x%29+%3D+I_k+%2B+L_k+%5Cdelta+x" alt="\delta u = \pi_k(\delta x) = I_k + L_k \delta x" eeimg="1"/> 的闭环控制形式，可以得到最优控制（具体讨论见附注）</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-ef296584481672158986d03641249e47_b.jpg" data-caption="" data-size="normal" data-rawwidth="604" data-rawheight="28" class="origin_image zh-lightbox-thumb" width="604" data-original="https://pic4.zhimg.com/v2-ef296584481672158986d03641249e47_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;604&#39; height=&#39;28&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="604" data-rawheight="28" class="origin_image zh-lightbox-thumb lazy" width="604" data-original="https://pic4.zhimg.com/v2-ef296584481672158986d03641249e47_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-ef296584481672158986d03641249e47_b.jpg"/></figure><p>并且可以求得到state value function</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-f9bd66f1e1067827e7216c547f55a594_b.jpg" data-caption="" data-size="normal" data-rawwidth="904" data-rawheight="268" class="origin_image zh-lightbox-thumb" width="904" data-original="https://pic1.zhimg.com/v2-f9bd66f1e1067827e7216c547f55a594_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;904&#39; height=&#39;268&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="904" data-rawheight="268" class="origin_image zh-lightbox-thumb lazy" width="904" data-original="https://pic1.zhimg.com/v2-f9bd66f1e1067827e7216c547f55a594_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-f9bd66f1e1067827e7216c547f55a594_b.jpg"/></figure><p>进行比对可以得到</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-7789c3adf845ec1e1c8ba6ffd6e51189_b.jpg" data-caption="" data-size="normal" data-rawwidth="625" data-rawheight="110" class="origin_image zh-lightbox-thumb" width="625" data-original="https://pic2.zhimg.com/v2-7789c3adf845ec1e1c8ba6ffd6e51189_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;625&#39; height=&#39;110&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="625" data-rawheight="110" class="origin_image zh-lightbox-thumb lazy" width="625" data-original="https://pic2.zhimg.com/v2-7789c3adf845ec1e1c8ba6ffd6e51189_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-7789c3adf845ec1e1c8ba6ffd6e51189_b.jpg"/></figure><p>其中</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-0432579f272457600878bb0943a60042_b.jpg" data-caption="" data-size="normal" data-rawwidth="594" data-rawheight="110" class="origin_image zh-lightbox-thumb" width="594" data-original="https://pic3.zhimg.com/v2-0432579f272457600878bb0943a60042_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;594&#39; height=&#39;110&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="594" data-rawheight="110" class="origin_image zh-lightbox-thumb lazy" width="594" data-original="https://pic3.zhimg.com/v2-0432579f272457600878bb0943a60042_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-0432579f272457600878bb0943a60042_b.jpg"/></figure><p>相应算法的每一次迭代都在轨迹 <img src="https://www.zhihu.com/equation?tex=%5Cleft%5C%7B+%5Cbar%7Bx%7D%28k%29%2C+%5Cbar%7Bu%7D%28k%29+%5Cright%5C%7D" alt="\left\{ \bar{x}(k), \bar{u}(k) \right\}" eeimg="1"/> 附近先找到控制序列 <img src="https://www.zhihu.com/equation?tex=u+%3D+%5Cbar%7Bu%7D+%2B+%5Cdelta+u" alt="u = \bar{u} + \delta u" eeimg="1"/> ，然后根据动力学规律找到新的轨迹 <img src="https://www.zhihu.com/equation?tex=x+%3D+%5Cbar%7Bx%7D+%2B+%5Cdelta+x" alt="x = \bar{x} + \delta x" eeimg="1"/> ，反复迭代直到收敛。</p><h2><b>算法：</b></h2><p>找到一条初始的轨迹 <img src="https://www.zhihu.com/equation?tex=%5Cleft%5C%7B+%5Cbar%7Bx%7D%28k%29%2C+%5Cbar%7Bu%7D%28k%29+%5Cright%5C%7D" alt="\left\{ \bar{x}(k), \bar{u}(k) \right\}" eeimg="1"/> ，然后反复进行如下迭代：</p><ol><li>做动态规划找到更好的控制序列：按照 <img src="https://www.zhihu.com/equation?tex=k%3DK%2C+K-1%2C+%5Ccdots%2C+1" alt="k=K, K-1, \cdots, 1" eeimg="1"/> 的顺序迭代，计算新的控制规律参数<img src="https://www.zhihu.com/equation?tex=%5Cdelta+u_k+%3D+I_k+%2B+L_k+%5Cdelta+x_k" alt="\delta u_k = I_k + L_k \delta x_k" eeimg="1"/> 和 <img src="https://www.zhihu.com/equation?tex=v_k%28%5Cdelta+x%29+%3D+s_k+%2B+s_k%5ET+%5Cdelta+x+%2B+%5Cdfrac%7B1%7D%7B2%7D+%5Cdelta+x%5ET+S_k+%5Cdelta+x" alt="v_k(\delta x) = s_k + s_k^T \delta x + \dfrac{1}{2} \delta x^T S_k \delta x" eeimg="1"/> ；</li><li>更新新的轨迹：按照 <img src="https://www.zhihu.com/equation?tex=k%3D1%2C+2%2C+%5Ccdots%2C+K" alt="k=1, 2, \cdots, K" eeimg="1"/> 的顺序迭代，根据上步计算到的控制规律和 <img src="https://www.zhihu.com/equation?tex=%5Cdelta+x_%7Bk%2B1%7D+%3D+A_k+%5Cdelta+x_k+%2B+B_k+%5Cdelta+u_k" alt="\delta x_{k+1} = A_k \delta x_k + B_k \delta u_k" eeimg="1"/> 计算新的轨迹；</li></ol><p>另外还有一些有意思的点和比较繁琐的讨论放在附录中供参考。</p><hr/><p><b>iLQG 与强化学习里面的 Policy Gradient 方法有什么区别和联系？</b></p><p>首先，这里的设定是已知环境的 dynamics，但是一般强化学习的设定是不知道环境的 dynamics。在知道环境 dynamics 的情况下，如果有了控制的扰动 <img src="https://www.zhihu.com/equation?tex=%5Cdelta+u" alt="\delta u" eeimg="1"/> 之后，就能直接算出状态空间的扰动 <img src="https://www.zhihu.com/equation?tex=%5Cdelta+x" alt="\delta x" eeimg="1"/> 了，因此这里的算法每一次迭代都会直接通过计算状态空间的扰动得到新的状态空间轨迹。而在强化学习的设定下，一般会用新的控制序列重新做 rollout 得到新的状态空间轨迹。</p><p>其次，两者对于控制的扰动 <img src="https://www.zhihu.com/equation?tex=%5Cdelta+u" alt="\delta u" eeimg="1"/> 的计算方式不同。state value function <img src="https://www.zhihu.com/equation?tex=v_%5Cpi%28%5Cdelta+x%2C+%5Cdelta+u%29" alt="v_\pi(\delta x, \delta u)" eeimg="1"/> 中关于控制扰动的项提出来可以写作 <img src="https://www.zhihu.com/equation?tex=+a%28%5Cdelta+u%29+%3D+%5Cdelta+u%5ET+%28g+%2B+G+%5Cdelta+x%29+%2B+%5Cdfrac%7B1%7D%7B2%7D+%5Cdelta+u+%5ET+H+%5Cdelta+u" alt=" a(\delta u) = \delta u^T (g + G \delta x) + \dfrac{1}{2} \delta u ^T H \delta u" eeimg="1"/> 。做如下近似1）<b>认为控制的扰动是开环的</b>，即和 <img src="https://www.zhihu.com/equation?tex=%5Cdelta+x" alt="\delta x" eeimg="1"/> 无关；2）<b>认为扰动是微小的</b>，即可以忽略二阶项 <img src="https://www.zhihu.com/equation?tex=%5Cdfrac%7B1%7D%7B2%7D+%5Cdelta+u+%5ET+H+%5Cdelta+u" alt="\dfrac{1}{2} \delta u ^T H \delta u" eeimg="1"/> ，并且对于一个小的 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon" alt="\epsilon" eeimg="1"/> ，有<img src="https://www.zhihu.com/equation?tex=%5Cdelta+u_k+%3DI_k+%3D+-+%5Cepsilon+g_k" alt="\delta u_k =I_k = - \epsilon g_k" eeimg="1"/> ；3）观察到 <img src="https://www.zhihu.com/equation?tex=g_k+%3D+%5Cbm%7Br_k%7D+%2B+B_k%5ET+%5Cbm%7Bs_%7Bk%2B1%7D%7D+%3D+%5Cdfrac%7B%5Cpartial+J%7D%7B%5Cpartial+u_k%7D+%2B+%5Cdfrac%7B%5Cpartial+f%7D%7B%5Cpartial+u_k%7D+%28%5Cdfrac%7B%5Cpartial+J%7D%7B%5Cpartial+x_%7Bk%2B1%7D%7D+%2B+%28I%2B%5Cdfrac%7B%5Cpartial+f%7D%7B%5Cpartial+x_k%7D+%29%5ET+%5Cbm%7Bs%7D_%7Bk%2B2%7D+%2B+G%5ET+I_%7Bk%2B1%7D%29" alt="g_k = \bm{r_k} + B_k^T \bm{s_{k+1}} = \dfrac{\partial J}{\partial u_k} + \dfrac{\partial f}{\partial u_k} (\dfrac{\partial J}{\partial x_{k+1}} + (I+\dfrac{\partial f}{\partial x_k} )^T \bm{s}_{k+2} + G^T I_{k+1})" eeimg="1"/> ，如果<b>假定每一步 k 上的扰动都不影响前后的状态空间轨迹</b>，那么上式后一项就没有了。通过上述三个假设，可以自然得到 policy gradient 的公式 <img src="https://www.zhihu.com/equation?tex=%5Cdelta+u_k+%3D+-%5Cepsilon+%5Cdfrac%7B%5Cpartial+J%7D%7B%5Cpartial+u_k%7D" alt="\delta u_k = -\epsilon \dfrac{\partial J}{\partial u_k}" eeimg="1"/> 。</p><p>通过上面的计算我们可以发现，梯度下降方法可以看做是做了以上近似之后 iLQG 的特殊情况。</p><hr/><p><b>上述公式里面的 <img src="https://www.zhihu.com/equation?tex=+H" alt=" H" eeimg="1"/> 是否能够保证正定？如果不正定应该怎么办？</b></p><p>一个物理上可行的系统，求出来的 <img src="https://www.zhihu.com/equation?tex=H" alt="H" eeimg="1"/> 肯定是正定的，原因如下。注意到 <img src="https://www.zhihu.com/equation?tex=+a%28%5Cdelta+u%29+%3D+%5Cdelta+u%5ET+%28g+%2B+G+%5Cdelta+x%29+%2B+%5Cdfrac%7B1%7D%7B2%7D+%5Cdelta+u+%5ET+H+%5Cdelta+u" alt=" a(\delta u) = \delta u^T (g + G \delta x) + \dfrac{1}{2} \delta u ^T H \delta u" eeimg="1"/> ，如果 H 有负特征值，那么存在控制扰动使得目标函数无限小。但是实际的数值计算中肯定存在负数或者接近零的特征值，那么我们考虑找一个正定的 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BH%7D" alt="\mathcal{H}" eeimg="1"/> 作为它的替代。</p><ol><li>一个方案是使用 Levenberg-Marquardt trick，即 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BH%7D+%3D+H+%2B+%28%5Cepsilon+-+%5Clambda_%5Cmin%29+I" alt="\mathcal{H} = H + (\epsilon - \lambda_\min) I" eeimg="1"/> 。可以理解为把原矩阵的特征值都加上一个数值使得其为正定。由于 <img src="https://www.zhihu.com/equation?tex=update+%5Cpropto+%5Cmathcal%7BH%7D%5E%7B-1%7D+%28%5Ccdot%29" alt="update \propto \mathcal{H}^{-1} (\cdot)" eeimg="1"/> ，每个特征值都变大相对于更新来说就更保守。</li><li>另一个方案是先做特征值分解 <img src="https://www.zhihu.com/equation?tex=H+%3D+V+D+V%5ET" alt="H = V D V^T" eeimg="1"/> ，将 D 矩阵中特征值小于零的元素都设置为 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon" alt="\epsilon" eeimg="1"/> ，然后形成新的替代矩阵。注意到这样做并不会增加更多的运算量，因为本身我们就要对矩阵求逆，这样逆可以直接算出来 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BH%7D%5E%7B-1%7D+%3D+V+%5Cmathcal%7BD%7D%5E%7B-1%7D+V%5ET" alt="\mathcal{H}^{-1} = V \mathcal{D}^{-1} V^T" eeimg="1"/> 。</li></ol><hr/><p><b>如果对于action space 有 constraint，即有约束 <img src="https://www.zhihu.com/equation?tex=u%28t%29+%5Cin+%5Cmathcal%7BU%7D" alt="u(t) \in \mathcal{U}" eeimg="1"/> ，应该怎么办？</b></p><p>首先每次迭代中原本的控制肯定是满足约束的，考虑 <img src="https://www.zhihu.com/equation?tex=%5Cdelta+u+%3D+I_k+%2B+L_k+%5Cdelta+x" alt="\delta u = I_k + L_k \delta x" eeimg="1"/> 。首先不管 <img src="https://www.zhihu.com/equation?tex=%5Cdelta+x" alt="\delta x" eeimg="1"/> 是多少，开环控制部分我们希望没有超过约束边界；如果 <img src="https://www.zhihu.com/equation?tex=I_k" alt="I_k" eeimg="1"/> 部分穿过了约束边界，那么可以把它收缩成 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon+I_k" alt="\epsilon I_k" eeimg="1"/> ， <img src="https://www.zhihu.com/equation?tex=0%5Cle%5Cepsilon%5Cle+1" alt="0\le\epsilon\le 1" eeimg="1"/> 可以通过 backtrack 得到。而第二部分如果穿过了约束边界，我们可以直接把这一项设置为零。当约束是对于控制的每一位独立约束的时候，可以不这么保守，即只把超过的那一位设置为零。</p><p class="ztext-empty-paragraph"><br/></p><p>ps. 如果遇到公式显示有问题，再次刷新，有一定几率该公式能正常显示，同时也有一定几率使得其他公式显示不出来，请多刷几次= =</p></div></div><div class="ContentItem-time">编辑于 2018-10-01</div><div class="Post-topicsAndReviewer"><div class="TopicList Post-Topics"><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/19553510" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">算法</div></div></a></span></div><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/19559450" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">机器学习</div></div></a></span></div><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/20039099" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习 (Reinforcement Learning)</div></div></a></span></div></div></div><div><div class="Sticky RichContent-actions is-bottom"><div class="ContentItem-actions"><span><button aria-label="赞同 19 " type="button" class="Button VoteButton VoteButton--up"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleUp VoteButton-TriangleUp" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M2 18.242c0-.326.088-.532.237-.896l7.98-13.203C10.572 3.57 11.086 3 12 3c.915 0 1.429.571 1.784 1.143l7.98 13.203c.15.364.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H3.955c-1.08 0-1.955-.517-1.955-1.9z" fill-rule="evenodd"></path></svg></span>赞同 19</button><button aria-label="反对" type="button" class="Button VoteButton VoteButton--down"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleDown" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M20.044 3H3.956C2.876 3 2 3.517 2 4.9c0 .326.087.533.236.896L10.216 19c.355.571.87 1.143 1.784 1.143s1.429-.572 1.784-1.143l7.98-13.204c.149-.363.236-.57.236-.896 0-1.386-.876-1.9-1.956-1.9z" fill-rule="evenodd"></path></svg></span></button></span><button type="button" class="Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Comment Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M10.241 19.313a.97.97 0 0 0-.77.2 7.908 7.908 0 0 1-3.772 1.482.409.409 0 0 1-.38-.637 5.825 5.825 0 0 0 1.11-2.237.605.605 0 0 0-.227-.59A7.935 7.935 0 0 1 3 11.25C3 6.7 7.03 3 12 3s9 3.7 9 8.25-4.373 9.108-10.759 8.063z" fill-rule="evenodd"></path></svg></span>添加评论</button><div class="Popover ShareMenu"><div class="ShareMenu-toggler" id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Share Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2.931 7.89c-1.067.24-1.275 1.669-.318 2.207l5.277 2.908 8.168-4.776c.25-.127.477.198.273.39L9.05 14.66l.927 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.242c.584-.892-.212-2.029-1.234-1.796L2.93 7.89z" fill-rule="evenodd"></path></svg></span>分享</button></div></div><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Heart Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2 8.437C2 5.505 4.294 3.094 7.207 3 9.243 3 11.092 4.19 12 6c.823-1.758 2.649-3 4.651-3C19.545 3 22 5.507 22 8.432 22 16.24 13.842 21 12 21 10.158 21 2 16.24 2 8.437z" fill-rule="evenodd"></path></svg></span>喜欢</button><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Star Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5.515 19.64l.918-5.355-3.89-3.792c-.926-.902-.639-1.784.64-1.97L8.56 7.74l2.404-4.871c.572-1.16 1.5-1.16 2.072 0L15.44 7.74l5.377.782c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.219 1.274-.532 1.82-1.676 1.218L12 18.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z" fill-rule="evenodd"></path></svg></span>收藏</button><div class="Post-ActionMenuButton"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Dots Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5 14a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4z" fill-rule="evenodd"></path></svg></span></button></div></div></div></div></div></div></article><div class="Post-Sub Post-NormalSub"><div class="PostIndex-Contributions"><h3 class="BlockTitle">文章被以下专栏收录</h3><ul><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><img class="Avatar Avatar--medium Avatar--round" width="40" height="40" src="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_xs.jpg" srcSet="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_l.jpg 2x" alt="强化学习前沿"/></div></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><a class="ColumnLink ColumnItem-Title" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习前沿</div></div></a></h2><div class="ContentItem-meta">读呀读paper</div></div><div class="ContentItem-extra"><a href="/reinforcementlearning" type="button" class="Button">进入专栏</a></div></div></div></ul></div></div></div></main></div></div><script nonce="0849094e-e629-4e57-b47e-687eb2473f5e" async="" src="https://www.googletagmanager.com/gtag/js?id=UA-149949619-1"></script><script nonce="0849094e-e629-4e57-b47e-687eb2473f5e">function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-149949619-1");</script><script id="js-clientConfig" type="text/json">{"host":"zhihu.com","protocol":"https:","wwwHost":"www.zhihu.com","fetchRoot":{"www":"https:\u002F\u002Fwww.zhihu.com","api":"https:\u002F\u002Fapi.zhihu.com","zhuanlan":"https:\u002F\u002Fzhuanlan.zhihu.com"}}</script><script id="js-initialData" type="text/json">{"initialState":{"common":{"ask":{}},"loading":{"global":{"count":0},"local":{"env\u002FgetIpinfo\u002F":false,"article\u002Fget\u002F":false,"brand\u002FgetUrl\u002F":false}},"club":{"tags":{}},"entities":{"users":{"zhang-chu-heng":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"清华大学 交叉信息院博士在读"}],"exposedMedal":{"medalId":"1124316222665379841","medalName":"我的知乎 2019","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2592b0b52e1fac99f69b38e00252413b_r.png","miniAvatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ad363cc3088dc8de7544fd08b1c4987a_is.png","description":"参与「我的知乎 2019」即可获得"}}},"questions":{},"answers":{},"articles":{"45618611":{"trackUrl":["https:\u002F\u002Fsugar.zhihu.com\u002Fplutus_adreaper\u002Fpage_monitor_log?si=__SESSIONID__&ti=__ATOKEN__&at=view&pf=__OS__&ed=__MEMBERID__&idfa=__IDFA__&imei=__IMEI__&androidid=__ANDROIDID__&oaid=__OAID__&ci=__CREATIVEID__"],"id":45618611,"title":"【强化学习算法 13】iLQG","type":"article","excerptTitle":"","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F45618611","imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-b528ccd79db60c8738ad54ca1f09ad77_b.jpg","titleImage":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-b528ccd79db60c8738ad54ca1f09ad77_b.jpg","excerpt":"\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-3b0c86a8fb4764f1416b8edea0aa927e_200x112.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"545\" data-rawheight=\"182\" data-watermark=\"watermark\" data-original-src=\"v2-3b0c86a8fb4764f1416b8edea0aa927e\" data-watermark-src=\"v2-7f5465abac7883d3298b3132d00a33db\" data-private-watermark-src=\"\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-3b0c86a8fb4764f1416b8edea0aa927e_r.jpg\" class=\"origin_image inline-img zh-lightbox-thumb\"\u002F\u003Ei打头但并不是苹果家的产品哈，其全称是 Iterative Linear Quadratic Gaussian。\u003Cb\u003E原文传送门：\u003C\u002Fb\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=http%3A\u002F\u002Fmaeresearch.ucsd.edu\u002Fgroups\u002Fskelton\u002Fpublications\u002Fweiwei_ilqg_CDC43.pdf\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003ETodorov, Emanuel, and Weiwei Li. &#34;A generalized iterative LQG method for locally-optimal feedback control of constrained nonlinear stochastic systems.&#34;…\u003C\u002Fa\u003E","created":1538199247,"updated":1538377195,"author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"清华大学 交叉信息院博士在读"}],"exposedMedal":{"medalId":"1124316222665379841","medalName":"我的知乎 2019","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2592b0b52e1fac99f69b38e00252413b_r.png","miniAvatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ad363cc3088dc8de7544fd08b1c4987a_is.png","description":"参与「我的知乎 2019」即可获得"}},"commentPermission":"all","state":"published","imageWidth":1636,"imageHeight":448,"content":"\u003Cp\u003Ei打头但并不是苹果家的产品哈，其全称是 Iterative Linear Quadratic Gaussian。\u003C\u002Fp\u003E\u003Ch2\u003E\u003Cb\u003E原文传送门：\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=http%3A\u002F\u002Fmaeresearch.ucsd.edu\u002Fgroups\u002Fskelton\u002Fpublications\u002Fweiwei_ilqg_CDC43.pdf\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003ETodorov, Emanuel, and Weiwei Li. &#34;A generalized iterative LQG method for locally-optimal feedback control of constrained nonlinear stochastic systems.&#34; American Control Conference, 2005. Proceedings of the 2005. IEEE, 2005.\u003C\u002Fa\u003E \u003C\u002Fp\u003E\u003Ch2\u003E\u003Cb\u003E特色：\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E确切的说这里要讲的不是一个强化学习算法，而是一个最优控制问题。其区别在于强化学习中不直接知道系统的dynamics，而最优控制的问题可以知道系统的dynamics。但是由于控制理论是强化理论的重要基础，相比于更为玄学的强化学习，它的理论分析更细致，了解一些控制论对于理解强化学习很有帮助。\u003C\u002Fp\u003E\u003Cp\u003E这篇工作把一个非线性最优控制问题，在每次迭代中都在局部归化为控制理论里面研究很成熟的Linear Quadratic Gaussian（LQG）问题，然后迭代地去求解更好的控制序列，直到收敛。这篇工作里面的结果以现在的标准来看并不惊艳，但是展示的很仔细，对于强化学习过程中理解什么是价值函数、轨迹等都很有帮助。\u003C\u002Fp\u003E\u003Ch2\u003E\u003Cb\u003E分类：\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E不是强化学习算法、continuous state space、continuous action space、不仅仅是model-based而且需要知道model dynamics\u003C\u002Fp\u003E\u003Ch2\u003E\u003Cb\u003E背景：\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E\u003Cb\u003ELQG的最优控制\u003C\u002Fb\u003E是控制理论里面一个非常经典的问题，考虑一个线性时变系统，其动力学特性\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=x%28k%2B1%29+%3D+F%28k%29+x%28k%29+%2B+G%28k%29+u%28k%29+%5Cquad+k%5Cin%5BN-1%5D\" alt=\"x(k+1) = F(k) x(k) + G(k) u(k) \\quad k\\in[N-1]\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E控制目标是找到一个控制序列 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=u%28k%29\" alt=\"u(k)\" eeimg=\"1\"\u002F\u003E 最小化如下二次型性能指标函数\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=J+%3D+x%5ET%28N%29+Q_0+x%28N%29+%2B+%5Csum_%7Bk%3Dk_0%7D%5E%7BN-1%7D+%5Bx%5ET%28k%29+Q_1%28k%29x%28k%29+%2B+u%5ET%28k%29+Q_2%28k%29+u%28k%29%5D\" alt=\"J = x^T(N) Q_0 x(N) + \\sum_{k=k_0}^{N-1} [x^T(k) Q_1(k)x(k) + u^T(k) Q_2(k) u(k)]\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E其中要求 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=Q_0%2C+Q_1\" alt=\"Q_0, Q_1\" eeimg=\"1\"\u002F\u003E 非负定， \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=Q_2\" alt=\"Q_2\" eeimg=\"1\"\u002F\u003E 正定。\u003C\u002Fp\u003E\u003Cp\u003E该问题的解决方式就是使用动态规划求解，依次写出 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=J_N%2C+J_%7BN-1%7D%2C+%5Ccdots\" alt=\"J_N, J_{N-1}, \\cdots\" eeimg=\"1\"\u002F\u003E ，把 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=J%28N-1%29\" alt=\"J(N-1)\" eeimg=\"1\"\u002F\u003E 用 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=J%28N%29\" alt=\"J(N)\" eeimg=\"1\"\u002F\u003E 表示，然后对于控制量求导，然后依次得到最优的控制序列 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=u%28N-1%29%2C+u%28N-2%29%2C+%5Ccdots\" alt=\"u(N-1), u(N-2), \\cdots\" eeimg=\"1\"\u002F\u003E 。得到最优控制（Riccati方程）\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbegin%7Bcases%7D+u%28k%29+%3D+-L%28k%29+x%28k%29+%5C%5C+L%28k%29+%3D+%5BQ_2%28k%29+%2B+G%5ET%28k%29+S%28k%2B1%29+G%28k%29%5D%5E%7B-1%7D%5BG%5ET%28k%29+S%28k%2B1%29+F%28k%29%5D+%5C%5C+S%28k%29+%3D+%5BF%28k%29+-+G%28k%29L%28k%29%5D%5ET+S%28k%2B1%29+%5BF%28k%29+-+G%28k%29L%28k%29%5D+%2B+Q_1%28k%29+%2B+L%5ET%28k%29+Q_2%28k%29+L%28k%29+%5C%5C+S%28N%29+%3D+Q_0+%5Cend%7Bcases%7D\" alt=\"\\begin{cases} u(k) = -L(k) x(k) \\\\ L(k) = [Q_2(k) + G^T(k) S(k+1) G(k)]^{-1}[G^T(k) S(k+1) F(k)] \\\\ S(k) = [F(k) - G(k)L(k)]^T S(k+1) [F(k) - G(k)L(k)] + Q_1(k) + L^T(k) Q_2(k) L(k) \\\\ S(N) = Q_0 \\end{cases}\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E相应的最优性能指标函数为 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=J_%7B%5Cmin%7D+%3D+x%5ET%28k_0%29S%28k_0%29x%28k_0%29\" alt=\"J_{\\min} = x^T(k_0)S(k_0)x(k_0)\" eeimg=\"1\"\u002F\u003E。\u003C\u002Fp\u003E\u003Cp\u003E若考虑一个定常系统，即 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=F%2C+G%2C+Q_1%2C+Q_2\" alt=\"F, G, Q_1, Q_2\" eeimg=\"1\"\u002F\u003E 与时间无关，在求解该方程的时候可以发现 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=S%28k%29\" alt=\"S(k)\" eeimg=\"1\"\u002F\u003E 在远离 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=k%3DN\" alt=\"k=N\" eeimg=\"1\"\u002F\u003E 的地方几乎为一个稳定的常数，并且当 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=N\" alt=\"N\" eeimg=\"1\"\u002F\u003E 很大的时候，不论 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=S%28N%29+%3D+Q_0\" alt=\"S(N) = Q_0\" eeimg=\"1\"\u002F\u003E 取值如何该常数值都不变，因此有定常的控制规律\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbegin%7Bcases%7D+u%28k%29+%3D+-L+x%28k%29+%5C%5C+L+%3D+%5BQ_2+%2B+G%5ET+S+G%5D%5E%7B-1%7D%5BG%5ET+S+F%5D+%5C%5C+S+%3D+%5BF+-+GL%5D%5ET+S+%5BF+-+GL%5D+%2B+Q_1+%2B+L%5ET+Q_2+L++%5Cend%7Bcases%7D\" alt=\"\\begin{cases} u(k) = -L x(k) \\\\ L = [Q_2 + G^T S G]^{-1}[G^T S F] \\\\ S = [F - GL]^T S [F - GL] + Q_1 + L^T Q_2 L  \\end{cases}\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Ch2\u003E\u003Cb\u003E过程：\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003EiLQG的\u003Cb\u003E主要思路\u003C\u002Fb\u003E就是先任意找一个控制序列 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=+%5Cleft%5C%7B+%5Cbar%7Bu%7D%28k%29+%5Cright%5C%7D\" alt=\" \\left\\{ \\bar{u}(k) \\right\\}\" eeimg=\"1\"\u002F\u003E ，然后按照这个控制做一次rollout，得到轨迹 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5C%7B+%5Cbar%7Bx%7D%28k%29+%5C%7D\" alt=\"\\{ \\bar{x}(k) \\}\" eeimg=\"1\"\u002F\u003E 。在这个轨迹附近，将系统的动力学特性线性化、将损失函数二次化，并考虑如何在 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cleft%5C%7B+%5Cbar%7Bu%7D%28k%29+%5Cright%5C%7D\" alt=\"\\left\\{ \\bar{u}(k) \\right\\}\" eeimg=\"1\"\u002F\u003E 和 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5C%7B+%5Cbar%7Bx%7D+%28k%29+%5C%7D\" alt=\"\\{ \\bar{x} (k) \\}\" eeimg=\"1\"\u002F\u003E 附近找到扰动 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta+u+%3D+u-%5Cbar%7Bu%7D\" alt=\"\\delta u = u-\\bar{u}\" eeimg=\"1\"\u002F\u003E和\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta+x+%3D+x+-+%5Cbar%7Bx%7D\" alt=\"\\delta x = x - \\bar{x}\" eeimg=\"1\"\u002F\u003E 使得新的控制比之前的更好。迭代地做更新直到收敛即得到最优控制序列。\u003C\u002Fp\u003E\u003Cp\u003E下面来具体地说各个步骤。\u003C\u002Fp\u003E\u003Cp\u003E首先可以将系统的动力学特性线性化并且将损失函数二次化，有\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-7f5465abac7883d3298b3132d00a33db_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"545\" data-rawheight=\"182\" class=\"origin_image zh-lightbox-thumb\" width=\"545\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-7f5465abac7883d3298b3132d00a33db_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;545&#39; height=&#39;182&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"545\" data-rawheight=\"182\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"545\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-7f5465abac7883d3298b3132d00a33db_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-7f5465abac7883d3298b3132d00a33db_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=A_k\" alt=\"A_k\" eeimg=\"1\"\u002F\u003E 和 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=B_k\" alt=\"B_k\" eeimg=\"1\"\u002F\u003E 可以由已知的动力学规律在轨迹 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5C%7B+%5Cbar%7Bx%7D%28k%29+%5C%7D\" alt=\"\\{ \\bar{x}(k) \\}\" eeimg=\"1\"\u002F\u003E 附近求导得到，各种Q和R都可以对于损失函数在现有轨迹附近求导得到， \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathcal%7BC%7D_k\" alt=\"\\mathcal{C}_k\" eeimg=\"1\"\u002F\u003E 是由上述列向量拼成的，反映的是控制引起的噪声。即，认为各种A、B、C、Q、R已知。\u003C\u002Fp\u003E\u003Cp\u003E假设有state value function写成如下形式\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-68545a67a9450607aaf0e9e9f4a4d97d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"602\" data-rawheight=\"58\" class=\"origin_image zh-lightbox-thumb\" width=\"602\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-68545a67a9450607aaf0e9e9f4a4d97d_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;602&#39; height=&#39;58&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"602\" data-rawheight=\"58\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"602\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-68545a67a9450607aaf0e9e9f4a4d97d_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-68545a67a9450607aaf0e9e9f4a4d97d_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E应用Bellman方程\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-c7a91cd07ec40542c329887cf7e92fb4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"630\" data-rawheight=\"37\" class=\"origin_image zh-lightbox-thumb\" width=\"630\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-c7a91cd07ec40542c329887cf7e92fb4_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;630&#39; height=&#39;37&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"630\" data-rawheight=\"37\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"630\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-c7a91cd07ec40542c329887cf7e92fb4_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-c7a91cd07ec40542c329887cf7e92fb4_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E可以求得到\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c9027d450e93f09844bfa8f5d86cb47e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"617\" data-rawheight=\"152\" class=\"origin_image zh-lightbox-thumb\" width=\"617\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c9027d450e93f09844bfa8f5d86cb47e_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;617&#39; height=&#39;152&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"617\" data-rawheight=\"152\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"617\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c9027d450e93f09844bfa8f5d86cb47e_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c9027d450e93f09844bfa8f5d86cb47e_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E假设具有形如 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta+u+%3D+%5Cpi_k%28%5Cdelta+x%29+%3D+I_k+%2B+L_k+%5Cdelta+x\" alt=\"\\delta u = \\pi_k(\\delta x) = I_k + L_k \\delta x\" eeimg=\"1\"\u002F\u003E 的闭环控制形式，可以得到最优控制（具体讨论见附注）\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-ef296584481672158986d03641249e47_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"604\" data-rawheight=\"28\" class=\"origin_image zh-lightbox-thumb\" width=\"604\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-ef296584481672158986d03641249e47_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;604&#39; height=&#39;28&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"604\" data-rawheight=\"28\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"604\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-ef296584481672158986d03641249e47_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-ef296584481672158986d03641249e47_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E并且可以求得到state value function\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-f9bd66f1e1067827e7216c547f55a594_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"904\" data-rawheight=\"268\" class=\"origin_image zh-lightbox-thumb\" width=\"904\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-f9bd66f1e1067827e7216c547f55a594_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;904&#39; height=&#39;268&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"904\" data-rawheight=\"268\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"904\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-f9bd66f1e1067827e7216c547f55a594_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-f9bd66f1e1067827e7216c547f55a594_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E进行比对可以得到\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-7789c3adf845ec1e1c8ba6ffd6e51189_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"625\" data-rawheight=\"110\" class=\"origin_image zh-lightbox-thumb\" width=\"625\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-7789c3adf845ec1e1c8ba6ffd6e51189_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;625&#39; height=&#39;110&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"625\" data-rawheight=\"110\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"625\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-7789c3adf845ec1e1c8ba6ffd6e51189_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-7789c3adf845ec1e1c8ba6ffd6e51189_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0432579f272457600878bb0943a60042_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"594\" data-rawheight=\"110\" class=\"origin_image zh-lightbox-thumb\" width=\"594\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0432579f272457600878bb0943a60042_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;594&#39; height=&#39;110&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"594\" data-rawheight=\"110\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"594\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0432579f272457600878bb0943a60042_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0432579f272457600878bb0943a60042_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E相应算法的每一次迭代都在轨迹 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cleft%5C%7B+%5Cbar%7Bx%7D%28k%29%2C+%5Cbar%7Bu%7D%28k%29+%5Cright%5C%7D\" alt=\"\\left\\{ \\bar{x}(k), \\bar{u}(k) \\right\\}\" eeimg=\"1\"\u002F\u003E 附近先找到控制序列 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=u+%3D+%5Cbar%7Bu%7D+%2B+%5Cdelta+u\" alt=\"u = \\bar{u} + \\delta u\" eeimg=\"1\"\u002F\u003E ，然后根据动力学规律找到新的轨迹 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=x+%3D+%5Cbar%7Bx%7D+%2B+%5Cdelta+x\" alt=\"x = \\bar{x} + \\delta x\" eeimg=\"1\"\u002F\u003E ，反复迭代直到收敛。\u003C\u002Fp\u003E\u003Ch2\u003E\u003Cb\u003E算法：\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E找到一条初始的轨迹 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cleft%5C%7B+%5Cbar%7Bx%7D%28k%29%2C+%5Cbar%7Bu%7D%28k%29+%5Cright%5C%7D\" alt=\"\\left\\{ \\bar{x}(k), \\bar{u}(k) \\right\\}\" eeimg=\"1\"\u002F\u003E ，然后反复进行如下迭代：\u003C\u002Fp\u003E\u003Col\u003E\u003Cli\u003E做动态规划找到更好的控制序列：按照 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=k%3DK%2C+K-1%2C+%5Ccdots%2C+1\" alt=\"k=K, K-1, \\cdots, 1\" eeimg=\"1\"\u002F\u003E 的顺序迭代，计算新的控制规律参数\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta+u_k+%3D+I_k+%2B+L_k+%5Cdelta+x_k\" alt=\"\\delta u_k = I_k + L_k \\delta x_k\" eeimg=\"1\"\u002F\u003E 和 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=v_k%28%5Cdelta+x%29+%3D+s_k+%2B+s_k%5ET+%5Cdelta+x+%2B+%5Cdfrac%7B1%7D%7B2%7D+%5Cdelta+x%5ET+S_k+%5Cdelta+x\" alt=\"v_k(\\delta x) = s_k + s_k^T \\delta x + \\dfrac{1}{2} \\delta x^T S_k \\delta x\" eeimg=\"1\"\u002F\u003E ；\u003C\u002Fli\u003E\u003Cli\u003E更新新的轨迹：按照 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=k%3D1%2C+2%2C+%5Ccdots%2C+K\" alt=\"k=1, 2, \\cdots, K\" eeimg=\"1\"\u002F\u003E 的顺序迭代，根据上步计算到的控制规律和 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta+x_%7Bk%2B1%7D+%3D+A_k+%5Cdelta+x_k+%2B+B_k+%5Cdelta+u_k\" alt=\"\\delta x_{k+1} = A_k \\delta x_k + B_k \\delta u_k\" eeimg=\"1\"\u002F\u003E 计算新的轨迹；\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Cp\u003E另外还有一些有意思的点和比较繁琐的讨论放在附录中供参考。\u003C\u002Fp\u003E\u003Chr\u002F\u003E\u003Cp\u003E\u003Cb\u003EiLQG 与强化学习里面的 Policy Gradient 方法有什么区别和联系？\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E首先，这里的设定是已知环境的 dynamics，但是一般强化学习的设定是不知道环境的 dynamics。在知道环境 dynamics 的情况下，如果有了控制的扰动 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta+u\" alt=\"\\delta u\" eeimg=\"1\"\u002F\u003E 之后，就能直接算出状态空间的扰动 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta+x\" alt=\"\\delta x\" eeimg=\"1\"\u002F\u003E 了，因此这里的算法每一次迭代都会直接通过计算状态空间的扰动得到新的状态空间轨迹。而在强化学习的设定下，一般会用新的控制序列重新做 rollout 得到新的状态空间轨迹。\u003C\u002Fp\u003E\u003Cp\u003E其次，两者对于控制的扰动 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta+u\" alt=\"\\delta u\" eeimg=\"1\"\u002F\u003E 的计算方式不同。state value function \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=v_%5Cpi%28%5Cdelta+x%2C+%5Cdelta+u%29\" alt=\"v_\\pi(\\delta x, \\delta u)\" eeimg=\"1\"\u002F\u003E 中关于控制扰动的项提出来可以写作 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=+a%28%5Cdelta+u%29+%3D+%5Cdelta+u%5ET+%28g+%2B+G+%5Cdelta+x%29+%2B+%5Cdfrac%7B1%7D%7B2%7D+%5Cdelta+u+%5ET+H+%5Cdelta+u\" alt=\" a(\\delta u) = \\delta u^T (g + G \\delta x) + \\dfrac{1}{2} \\delta u ^T H \\delta u\" eeimg=\"1\"\u002F\u003E 。做如下近似1）\u003Cb\u003E认为控制的扰动是开环的\u003C\u002Fb\u003E，即和 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta+x\" alt=\"\\delta x\" eeimg=\"1\"\u002F\u003E 无关；2）\u003Cb\u003E认为扰动是微小的\u003C\u002Fb\u003E，即可以忽略二阶项 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdfrac%7B1%7D%7B2%7D+%5Cdelta+u+%5ET+H+%5Cdelta+u\" alt=\"\\dfrac{1}{2} \\delta u ^T H \\delta u\" eeimg=\"1\"\u002F\u003E ，并且对于一个小的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cepsilon\" alt=\"\\epsilon\" eeimg=\"1\"\u002F\u003E ，有\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta+u_k+%3DI_k+%3D+-+%5Cepsilon+g_k\" alt=\"\\delta u_k =I_k = - \\epsilon g_k\" eeimg=\"1\"\u002F\u003E ；3）观察到 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=g_k+%3D+%5Cbm%7Br_k%7D+%2B+B_k%5ET+%5Cbm%7Bs_%7Bk%2B1%7D%7D+%3D+%5Cdfrac%7B%5Cpartial+J%7D%7B%5Cpartial+u_k%7D+%2B+%5Cdfrac%7B%5Cpartial+f%7D%7B%5Cpartial+u_k%7D+%28%5Cdfrac%7B%5Cpartial+J%7D%7B%5Cpartial+x_%7Bk%2B1%7D%7D+%2B+%28I%2B%5Cdfrac%7B%5Cpartial+f%7D%7B%5Cpartial+x_k%7D+%29%5ET+%5Cbm%7Bs%7D_%7Bk%2B2%7D+%2B+G%5ET+I_%7Bk%2B1%7D%29\" alt=\"g_k = \\bm{r_k} + B_k^T \\bm{s_{k+1}} = \\dfrac{\\partial J}{\\partial u_k} + \\dfrac{\\partial f}{\\partial u_k} (\\dfrac{\\partial J}{\\partial x_{k+1}} + (I+\\dfrac{\\partial f}{\\partial x_k} )^T \\bm{s}_{k+2} + G^T I_{k+1})\" eeimg=\"1\"\u002F\u003E ，如果\u003Cb\u003E假定每一步 k 上的扰动都不影响前后的状态空间轨迹\u003C\u002Fb\u003E，那么上式后一项就没有了。通过上述三个假设，可以自然得到 policy gradient 的公式 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta+u_k+%3D+-%5Cepsilon+%5Cdfrac%7B%5Cpartial+J%7D%7B%5Cpartial+u_k%7D\" alt=\"\\delta u_k = -\\epsilon \\dfrac{\\partial J}{\\partial u_k}\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Cp\u003E通过上面的计算我们可以发现，梯度下降方法可以看做是做了以上近似之后 iLQG 的特殊情况。\u003C\u002Fp\u003E\u003Chr\u002F\u003E\u003Cp\u003E\u003Cb\u003E上述公式里面的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=+H\" alt=\" H\" eeimg=\"1\"\u002F\u003E 是否能够保证正定？如果不正定应该怎么办？\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E一个物理上可行的系统，求出来的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=H\" alt=\"H\" eeimg=\"1\"\u002F\u003E 肯定是正定的，原因如下。注意到 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=+a%28%5Cdelta+u%29+%3D+%5Cdelta+u%5ET+%28g+%2B+G+%5Cdelta+x%29+%2B+%5Cdfrac%7B1%7D%7B2%7D+%5Cdelta+u+%5ET+H+%5Cdelta+u\" alt=\" a(\\delta u) = \\delta u^T (g + G \\delta x) + \\dfrac{1}{2} \\delta u ^T H \\delta u\" eeimg=\"1\"\u002F\u003E ，如果 H 有负特征值，那么存在控制扰动使得目标函数无限小。但是实际的数值计算中肯定存在负数或者接近零的特征值，那么我们考虑找一个正定的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathcal%7BH%7D\" alt=\"\\mathcal{H}\" eeimg=\"1\"\u002F\u003E 作为它的替代。\u003C\u002Fp\u003E\u003Col\u003E\u003Cli\u003E一个方案是使用 Levenberg-Marquardt trick，即 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathcal%7BH%7D+%3D+H+%2B+%28%5Cepsilon+-+%5Clambda_%5Cmin%29+I\" alt=\"\\mathcal{H} = H + (\\epsilon - \\lambda_\\min) I\" eeimg=\"1\"\u002F\u003E 。可以理解为把原矩阵的特征值都加上一个数值使得其为正定。由于 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=update+%5Cpropto+%5Cmathcal%7BH%7D%5E%7B-1%7D+%28%5Ccdot%29\" alt=\"update \\propto \\mathcal{H}^{-1} (\\cdot)\" eeimg=\"1\"\u002F\u003E ，每个特征值都变大相对于更新来说就更保守。\u003C\u002Fli\u003E\u003Cli\u003E另一个方案是先做特征值分解 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=H+%3D+V+D+V%5ET\" alt=\"H = V D V^T\" eeimg=\"1\"\u002F\u003E ，将 D 矩阵中特征值小于零的元素都设置为 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cepsilon\" alt=\"\\epsilon\" eeimg=\"1\"\u002F\u003E ，然后形成新的替代矩阵。注意到这样做并不会增加更多的运算量，因为本身我们就要对矩阵求逆，这样逆可以直接算出来 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathcal%7BH%7D%5E%7B-1%7D+%3D+V+%5Cmathcal%7BD%7D%5E%7B-1%7D+V%5ET\" alt=\"\\mathcal{H}^{-1} = V \\mathcal{D}^{-1} V^T\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Chr\u002F\u003E\u003Cp\u003E\u003Cb\u003E如果对于action space 有 constraint，即有约束 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=u%28t%29+%5Cin+%5Cmathcal%7BU%7D\" alt=\"u(t) \\in \\mathcal{U}\" eeimg=\"1\"\u002F\u003E ，应该怎么办？\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E首先每次迭代中原本的控制肯定是满足约束的，考虑 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta+u+%3D+I_k+%2B+L_k+%5Cdelta+x\" alt=\"\\delta u = I_k + L_k \\delta x\" eeimg=\"1\"\u002F\u003E 。首先不管 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta+x\" alt=\"\\delta x\" eeimg=\"1\"\u002F\u003E 是多少，开环控制部分我们希望没有超过约束边界；如果 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=I_k\" alt=\"I_k\" eeimg=\"1\"\u002F\u003E 部分穿过了约束边界，那么可以把它收缩成 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cepsilon+I_k\" alt=\"\\epsilon I_k\" eeimg=\"1\"\u002F\u003E ， \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=0%5Cle%5Cepsilon%5Cle+1\" alt=\"0\\le\\epsilon\\le 1\" eeimg=\"1\"\u002F\u003E 可以通过 backtrack 得到。而第二部分如果穿过了约束边界，我们可以直接把这一项设置为零。当约束是对于控制的每一位独立约束的时候，可以不这么保守，即只把超过的那一位设置为零。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003Eps. 如果遇到公式显示有问题，再次刷新，有一定几率该公式能正常显示，同时也有一定几率使得其他公式显示不出来，请多刷几次= =\u003C\u002Fp\u003E","adminClosedComment":false,"topics":[{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F19553510","type":"topic","id":"19553510","name":"算法"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F19559450","type":"topic","id":"19559450","name":"机器学习"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F20039099","type":"topic","id":"20039099","name":"强化学习 (Reinforcement Learning)"}],"voteupCount":19,"voting":0,"column":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"},"commentCount":0,"contributions":[{"id":2197923,"state":"accepted","type":"first_publish","column":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}}],"isTitleImageFullScreen":false,"upvotedFollowees":[],"commercialInfo":{"isCommercial":false,"plugin":{}},"suggestEdit":{"status":false,"reason":"","tip":"","url":"","title":""},"reason":"","annotationAction":[],"canTip":false,"tipjarorsCount":0,"isLabeled":false,"hasPublishingDraft":false,"isFavorited":false,"isNormal":true,"status":0,"shareText":"【强化学习算法 13】iLQG - 来自知乎专栏「强化学习前沿」，作者: 张楚珩 https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F45618611 （想看更多？下载 @知乎 App：http:\u002F\u002Fweibo.com\u002Fp\u002F100404711598 ）","canComment":{"status":true,"reason":""},"mcnFpShow":-1,"isVisible":true,"isLiked":false,"likedCount":0,"visibleOnlyToAuthor":false}},"columns":{"reinforcementlearning":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}},"topics":{},"roundtables":{},"favlists":{},"comments":{},"notifications":{},"ebooks":{},"activities":{},"feeds":{},"pins":{},"promotions":{},"drafts":{},"chats":{},"posts":{},"clubs":{},"clubTags":{}},"currentUser":"","account":{"lockLevel":{},"unlockTicketStatus":false,"unlockTicket":null,"challenge":[],"errorStatus":false,"message":"","isFetching":false,"accountInfo":{},"urlToken":{"loading":false}},"settings":{"socialBind":null,"inboxMsg":null,"notification":{},"email":{},"privacyFlag":null,"blockedUsers":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"blockedFollowees":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"ignoredTopics":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"restrictedTopics":null,"laboratory":{}},"notification":{},"people":{"profileStatus":{},"activitiesByUser":{},"answersByUser":{},"answersSortByVotesByUser":{},"answersIncludedByUser":{},"votedAnswersByUser":{},"thankedAnswersByUser":{},"voteAnswersByUser":{},"thankAnswersByUser":{},"topicAnswersByUser":{},"zvideosByUser":{},"articlesByUser":{},"articlesSortByVotesByUser":{},"articlesIncludedByUser":{},"pinsByUser":{},"questionsByUser":{},"commercialQuestionsByUser":{},"favlistsByUser":{},"followingByUser":{},"followersByUser":{},"mutualsByUser":{},"followingColumnsByUser":{},"followingQuestionsByUser":{},"followingFavlistsByUser":{},"followingTopicsByUser":{},"publicationsByUser":{},"columnsByUser":{},"allFavlistsByUser":{},"brands":null,"creationsByUser":{},"creationsSortByVotesByUser":{},"creationsFeed":{}},"env":{"ab":{"config":{"experiments":[{"expId":"launch-gw_mweb_rec-1","expPrefix":"gw_mweb_rec","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-qa_hdpimg-2","expPrefix":"qa_hdpimg","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-us_foltopic_user-10","expPrefix":"us_foltopic_user","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_bullet_second-2","expPrefix":"vd_bullet_second","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_zvideo_link-10","expPrefix":"vd_zvideo_link","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"se_topicfeed-1","expPrefix":"se_topicfeed","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false}],"params":[{"id":"se_subtext","type":"String","value":"0","chainId":"_all_"},{"id":"gue_self_censoring","type":"String","value":"1"},{"id":"se_websearch","type":"String","value":"3","chainId":"_all_"},{"id":"tp_club_pk","type":"String","value":"1","chainId":"_all_"},{"id":"soc_zcfw_shipinshiti","type":"String","value":"1","chainId":"_all_"},{"id":"ug_zero_follow","type":"String","value":"0","chainId":"_all_"},{"id":"zr_km_feed_nlp","type":"String","value":"old","chainId":"_all_"},{"id":"tp_club_pic","type":"String","value":"0.6","chainId":"_all_"},{"id":"se_prf","type":"String","value":"0","chainId":"_all_"},{"id":"gue_bullet_guide","type":"String","value":"发个弹幕聊聊…"},{"id":"tp_topic_rec","type":"String","value":"1","chainId":"_all_"},{"id":"gue_zvideo_link","type":"String","value":"1"},{"id":"web_heifetz_grow_ad","type":"String","value":"1"},{"id":"se_content0","type":"String","value":"0","chainId":"_all_"},{"id":"soc_special","type":"String","value":"0","chainId":"_all_"},{"id":"li_sku_bottom_bar_re","type":"String","value":"0","chainId":"_all_"},{"id":"se_ffzx_jushen1","type":"String","value":"0","chainId":"_all_"},{"id":"se_club_post","type":"String","value":"5","chainId":"_all_"},{"id":"se_cardrank_3","type":"String","value":"0","chainId":"_all_"},{"id":"tp_qa_toast","type":"String","value":"1","chainId":"_all_"},{"id":"tp_qa_metacard","type":"String","value":"1","chainId":"_all_"},{"id":"ug_goodcomment_0","type":"String","value":"1","chainId":"_all_"},{"id":"li_se_across","type":"String","value":"1","chainId":"_all_"},{"id":"qap_question_visitor","type":"String","value":" 0","chainId":"_all_"},{"id":"soc_newfeed","type":"String","value":"2","chainId":"_all_"},{"id":"tp_club_feed","type":"String","value":"1","chainId":"_all_"},{"id":"soc_iossort","type":"String","value":"0","chainId":"_all_"},{"id":"gue_card_test","type":"String","value":"1"},{"id":"tp_topic_entry","type":"String","value":"0","chainId":"_all_"},{"id":"web_audit_01","type":"String","value":"case1"},{"id":"top_quality","type":"String","value":"0","chainId":"_all_"},{"id":"top_universalebook","type":"String","value":"1","chainId":"_all_"},{"id":"sem_up_growth","type":"String","value":"in_app","chainId":"_all_"},{"id":"li_hot_voted","type":"String","value":"0","chainId":"_all_"},{"id":"li_video_section","type":"String","value":"0","chainId":"_all_"},{"id":"web_ask","type":"String","value":"0"},{"id":"se_expired_ob","type":"String","value":"0","chainId":"_all_"},{"id":"se_time_threshold","type":"String","value":"0","chainId":"_all_"},{"id":"tp_m_intro_re_topic","type":"String","value":"1","chainId":"_all_"},{"id":"top_hotcommerce","type":"String","value":"1","chainId":"_all_"},{"id":"li_salt_hot","type":"String","value":"1","chainId":"_all_"},{"id":"li_se_media_icon","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_android_join","type":"String","value":"1","chainId":"_all_"},{"id":"se_aa_base","type":"String","value":"0","chainId":"_all_"},{"id":"soc_notification","type":"String","value":"0","chainId":"_all_"},{"id":"web_sec672","type":"String","value":"0"},{"id":"se_hotsearch_num","type":"String","value":"0","chainId":"_all_"},{"id":"qap_payc_invite","type":"String","value":"0","chainId":"_all_"},{"id":"se_specialbutton","type":"String","value":"0","chainId":"_all_"},{"id":"se_multianswer","type":"String","value":"2","chainId":"_all_"},{"id":"soc_zcfw_badcase","type":"String","value":"0","chainId":"_all_"},{"id":"soc_authormore2","type":"String","value":"2","chainId":"_all_"},{"id":"soc_ri_merge","type":"String","value":"0","chainId":"_all_"},{"id":"li_purchase_test","type":"String","value":"0","chainId":"_all_"},{"id":"li_yxzl_new_style_a","type":"String","value":"1","chainId":"_all_"},{"id":"pf_fuceng","type":"String","value":"1","chainId":"_all_"},{"id":"ls_videoad","type":"String","value":"2","chainId":"_all_"},{"id":"tp_topic_head","type":"String","value":"0","chainId":"_all_"},{"id":"top_ebook","type":"String","value":"0","chainId":"_all_"},{"id":"se_colorfultab","type":"String","value":"1","chainId":"_all_"},{"id":"tp_sft_v2","type":"String","value":"d","chainId":"_all_"},{"id":"soc_authormore","type":"String","value":"2","chainId":"_all_"},{"id":"pf_newguide_vertical","type":"String","value":"0","chainId":"_all_"},{"id":"gue_bullet_second","type":"String","value":"1"},{"id":"se_ad_index","type":"String","value":"10","chainId":"_all_"},{"id":"soc_cardheight","type":"String","value":"2","chainId":"_all_"},{"id":"se_entity_model_14","type":"String","value":"0","chainId":"_all_"},{"id":"se_preset_tech","type":"String","value":"0","chainId":"_all_"},{"id":"se_sug","type":"String","value":"1","chainId":"_all_"},{"id":"top_new_feed","type":"String","value":"5","chainId":"_all_"},{"id":"web_creator_route","type":"String","value":"1"},{"id":"pf_foltopic_usernum","type":"String","value":"50","chainId":"_all_"},{"id":"li_android_vip","type":"String","value":"0","chainId":"_all_"},{"id":"zr_search_sim","type":"String","value":"0","chainId":"_all_"},{"id":"zr_rel_search","type":"String","value":"base","chainId":"_all_"},{"id":"zr_video_rank_nn","type":"String","value":"new_rank","chainId":"_all_"},{"id":"tp_qa_metacard_top","type":"String","value":"top","chainId":"_all_"},{"id":"soc_stickypush","type":"String","value":"1","chainId":"_all_"},{"id":"ug_follow_topic_1","type":"String","value":"2","chainId":"_all_"},{"id":"li_qa_new_cover","type":"String","value":"1","chainId":"_all_"},{"id":"li_answer_card","type":"String","value":"0","chainId":"_all_"},{"id":"se_college","type":"String","value":"default","chainId":"_all_"},{"id":"se_backsearch","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zcfw_broadcast","type":"String","value":"0","chainId":"_all_"},{"id":"ug_follow_answerer_0","type":"String","value":"0","chainId":"_all_"},{"id":"ug_newtag","type":"String","value":"0","chainId":"_all_"},{"id":"li_education_box","type":"String","value":"0","chainId":"_all_"},{"id":"zr_update_merge_size","type":"String","value":"1","chainId":"_all_"},{"id":"se_article_icon","type":"String","value":"0","chainId":"_all_"},{"id":"se_zu_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_use_zitem","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sticky_android","type":"String","value":"2","chainId":"_all_"},{"id":"li_svip_cardshow","type":"String","value":"1","chainId":"_all_"},{"id":"qap_question_author","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adsort","type":"String","value":"0","chainId":"_all_"},{"id":"se_topicfeed","type":"String","value":"0","chainId":"_all_"},{"id":"se_highlight","type":"String","value":"0","chainId":"_all_"},{"id":"tp_header_style","type":"String","value":"1","chainId":"_all_"},{"id":"soc_userrec","type":"String","value":"0","chainId":"_all_"},{"id":"top_root","type":"String","value":"0","chainId":"_all_"},{"id":"web_answer_list_ad","type":"String","value":"1"},{"id":"se_cbert_index","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_4","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_qa_pic","type":"String","value":"1","chainId":"_all_"},{"id":"soc_iosintimacy","type":"String","value":"2","chainId":"_all_"},{"id":"ug_fw_answ_aut_1","type":"String","value":"0","chainId":"_all_"},{"id":"zr_ans_rec","type":"String","value":"gbrank","chainId":"_all_"},{"id":"se_webtimebox","type":"String","value":"0","chainId":"_all_"},{"id":"zr_article_new","type":"String","value":"close","chainId":"_all_"},{"id":"tp_discovery_ab_1","type":"String","value":"0","chainId":"_all_"},{"id":"ug_zero_follow_0","type":"String","value":"0","chainId":"_all_"},{"id":"li_ebook_read","type":"String","value":"0","chainId":"_all_"},{"id":"zw_payc_qaedit","type":"String","value":"0","chainId":"_all_"},{"id":"top_test_4_liguangyi","type":"String","value":"1","chainId":"_all_"},{"id":"gue_zhuantikapian","type":"String","value":"0"},{"id":"se_hot_timebox","type":"String","value":"0","chainId":"_all_"},{"id":"zr_intervene","type":"String","value":"0","chainId":"_all_"},{"id":"se_page_quality","type":"String","value":"0","chainId":"_all_"},{"id":"se_searchwiki","type":"String","value":"0","chainId":"_all_"},{"id":"li_paid_answer_exp","type":"String","value":"0","chainId":"_all_"},{"id":"web_unfriendly_comm","type":"String","value":"0"},{"id":"se_pek_test3","type":"String","value":"1","chainId":"_all_"},{"id":"ls_recommend_test","type":"String","value":"0","chainId":"_all_"},{"id":"qap_thanks","type":"String","value":"1","chainId":"_all_"},{"id":"se_pek_test2","type":"String","value":"1","chainId":"_all_"},{"id":"se_entity_model","type":"String","value":"0","chainId":"_all_"},{"id":"se_relationship","type":"String","value":"1","chainId":"_all_"},{"id":"tp_topic_style","type":"String","value":"0","chainId":"_all_"},{"id":"li_pay_banner_type","type":"String","value":"6","chainId":"_all_"},{"id":"web_column_auto_invite","type":"String","value":"0"},{"id":"se_cardrank_1","type":"String","value":"0","chainId":"_all_"},{"id":"soc_bignew","type":"String","value":"1","chainId":"_all_"},{"id":"li_catalog_card","type":"String","value":"1","chainId":"_all_"},{"id":"li_answer_label","type":"String","value":"0","chainId":"_all_"},{"id":"se_hotsearch","type":"String","value":"0","chainId":"_all_"},{"id":"se_aa","type":"String","value":"0","chainId":"_all_"},{"id":"se_wannasearch","type":"String","value":"0","chainId":"_all_"},{"id":"se_mobileweb","type":"String","value":"1","chainId":"_all_"},{"id":"gue_goods_card","type":"String","value":"0"},{"id":"zr_slotpaidexp","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_qa","type":"String","value":"1","chainId":"_all_"},{"id":"se_hotsearch_2","type":"String","value":"1","chainId":"_all_"},{"id":"se_sug_term","type":"String","value":"0","chainId":"_all_"},{"id":"se_new_topic","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sft","type":"String","value":"a","chainId":"_all_"},{"id":"li_assessment_show","type":"String","value":"1","chainId":"_all_"},{"id":"zr_slot_cold_start","type":"String","value":"aver","chainId":"_all_"},{"id":"se_search_feed","type":"String","value":"N","chainId":"_all_"},{"id":"se_cate_l3","type":"String","value":"0","chainId":"_all_"},{"id":"se_amovietab","type":"String","value":"1","chainId":"_all_"},{"id":"tp_topic_tab","type":"String","value":"0","chainId":"_all_"},{"id":"soc_brdcst4","type":"String","value":"3","chainId":"_all_"},{"id":"web_ad_banner","type":"String","value":"0"},{"id":"se_timebox_up","type":"String","value":"0","chainId":"_all_"},{"id":"se_ios_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"web_mini_review","type":"String","value":"0"},{"id":"web_answer_update","type":"String","value":"0"},{"id":"soc_leave_recommend","type":"String","value":"2","chainId":"_all_"},{"id":"tsp_videobillboard","type":"String","value":"1","chainId":"_all_"},{"id":"se_col_boost","type":"String","value":"0","chainId":"_all_"},{"id":"se_movietab","type":"String","value":"1","chainId":"_all_"},{"id":"li_se_heat","type":"String","value":"1","chainId":"_all_"},{"id":"web_hdpimg","type":"String","value":"1"},{"id":"se_webrs","type":"String","value":"1","chainId":"_all_"},{"id":"se_zu_recommend","type":"String","value":"0","chainId":"_all_"},{"id":"tp_discover_copy","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iosreadline","type":"String","value":"0","chainId":"_all_"},{"id":"gue_video_autoplay","type":"String","value":"0"},{"id":"li_vip_verti_search","type":"String","value":"0","chainId":"_all_"},{"id":"web_upload","type":"String","value":"1"},{"id":"se_waterfall","type":"String","value":"0","chainId":"_all_"},{"id":"se_famous","type":"String","value":"1","chainId":"_all_"},{"id":"zr_video_recall","type":"String","value":"current_recall","chainId":"_all_"},{"id":"se_site_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_preset_label","type":"String","value":"1","chainId":"_all_"},{"id":"soc_wonderuser_recom","type":"String","value":"2","chainId":"_all_"},{"id":"se_likebutton","type":"String","value":"0","chainId":"_all_"},{"id":"se_relation_1","type":"String","value":"0","chainId":"_all_"},{"id":"se_adxtest","type":"String","value":"1","chainId":"_all_"},{"id":"tp_topic_tab_new","type":"String","value":"0-0-0","chainId":"_all_"},{"id":"soc_adreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iospinweight","type":"String","value":"0","chainId":"_all_"},{"id":"top_ydyq","type":"String","value":"X","chainId":"_all_"},{"id":"zr_training_first","type":"String","value":"false","chainId":"_all_"},{"id":"gue_new_special_page","type":"String","value":"1"},{"id":"se_related_index","type":"String","value":"3","chainId":"_all_"},{"id":"tp_club_android_feed","type":"String","value":"old","chainId":"_all_"},{"id":"soc_adpinweight","type":"String","value":"0","chainId":"_all_"},{"id":"soc_brdcst3","type":"String","value":"0","chainId":"_all_"},{"id":"web_mweb_rec_length","type":"String","value":"1"},{"id":"li_ebok_chap","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zcfw_broadcast2","type":"String","value":"1","chainId":"_all_"},{"id":"pf_creator_card","type":"String","value":"1","chainId":"_all_"},{"id":"se_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"se_ltr_video","type":"String","value":"0","chainId":"_all_"},{"id":"zr_test_aa1","type":"String","value":"0","chainId":"_all_"},{"id":"tp_discover","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adreadline","type":"String","value":"0","chainId":"_all_"},{"id":"web_n_web_msg","type":"String","value":"0"},{"id":"gue_video_replay","type":"String","value":"0"},{"id":"se_dnn_mt_v2","type":"String","value":"0","chainId":"_all_"},{"id":"se_featured","type":"String","value":"1","chainId":"_all_"},{"id":"se_ctx_rerank","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_pic_swiper","type":"String","value":"1","chainId":"_all_"},{"id":"tp_meta_card","type":"String","value":"0","chainId":"_all_"},{"id":"zw_sameq_sorce","type":"String","value":"999","chainId":"_all_"},{"id":"se_topiclabel","type":"String","value":"1","chainId":"_all_"},{"id":"qap_article_like","type":"String","value":"1","chainId":"_all_"},{"id":"se_webmajorob","type":"String","value":"0","chainId":"_all_"},{"id":"se_college_cm","type":"String","value":"0","chainId":"_all_"},{"id":"se_presearch_ab","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_tab","type":"String","value":"0","chainId":"_all_"},{"id":"soc_bigone","type":"String","value":"0","chainId":"_all_"},{"id":"li_ebook_gen_search","type":"String","value":"0","chainId":"_all_"},{"id":"li_qa_btn_text","type":"String","value":"0","chainId":"_all_"},{"id":"se_sug_entrance","type":"String","value":"1","chainId":"_all_"},{"id":"se_auto_syn","type":"String","value":"0","chainId":"_all_"},{"id":"soc_yxzl_zcfw","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_edu","type":"String","value":"1","chainId":"_all_"},{"id":"web_collect","type":"String","value":"0"},{"id":"zr_expslotpaid","type":"String","value":"1","chainId":"_all_"},{"id":"tp_score_1","type":"String","value":"a","chainId":"_all_"},{"id":"zr_rec_answer_cp","type":"String","value":"close","chainId":"_all_"},{"id":"se_click_club","type":"String","value":"1","chainId":"_all_"},{"id":"se_cardrank_2","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_tab_feed","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zuichangfangwen","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_section","type":"String","value":"0","chainId":"_all_"},{"id":"zr_km_answer","type":"String","value":"open_cvr","chainId":"_all_"},{"id":"tp_club_discover","type":"String","value":"0","chainId":"_all_"},{"id":"se_new_p","type":"String","value":"0","chainId":"_all_"},{"id":"se_agency","type":"String","value":" 0","chainId":"_all_"},{"id":"tp_club_header","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_join","type":"String","value":"0","chainId":"_all_"},{"id":"soc_update","type":"String","value":"1","chainId":"_all_"},{"id":"tsp_vote","type":"String","value":"2","chainId":"_all_"},{"id":"pf_noti_entry_num","type":"String","value":"0","chainId":"_all_"},{"id":"zr_answer_rec_cp","type":"String","value":"open","chainId":"_all_"},{"id":"zr_search_paid","type":"String","value":"0","chainId":"_all_"},{"id":"zr_slot_training","type":"String","value":"1","chainId":"_all_"},{"id":"gue_thanks","type":"String","value":"0"},{"id":"web_answerlist_ad","type":"String","value":"0"},{"id":"soc_feed_intimacy","type":"String","value":"2","chainId":"_all_"},{"id":"pf_adjust","type":"String","value":"0","chainId":"_all_"},{"id":"zr_art_rec","type":"String","value":"base","chainId":"_all_"},{"id":"se_rf_w","type":"String","value":"0","chainId":"_all_"},{"id":"zr_video_rank","type":"String","value":"new_rank","chainId":"_all_"},{"id":"se_billboardsearch","type":"String","value":"0","chainId":"_all_"},{"id":"li_answers_link","type":"String","value":"0","chainId":"_all_"},{"id":"qap_ques_invite","type":"String","value":"0","chainId":"_all_"},{"id":"se_p_slideshow","type":"String","value":"0","chainId":"_all_"},{"id":"se_lottery","type":"String","value":"0","chainId":"_all_"},{"id":"top_v_album","type":"String","value":"1","chainId":"_all_"},{"id":"web_sem_ab","type":"String","value":"1"},{"id":"se_hotmore","type":"String","value":"2","chainId":"_all_"},{"id":"zr_training_boost","type":"String","value":"false","chainId":"_all_"},{"id":"se_new_merger","type":"String","value":"1","chainId":"_all_"},{"id":"se_payconsult","type":"String","value":"0","chainId":"_all_"},{"id":"li_svip_tab_search","type":"String","value":"0","chainId":"_all_"},{"id":"web_question_invite","type":"String","value":"B"},{"id":"soc_iosreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"tsp_hotlist_ui","type":"String","value":"1","chainId":"_all_"},{"id":"ls_fmp4","type":"String","value":"0","chainId":"_all_"},{"id":"web_mweb_launch","type":"String","value":"0"},{"id":"se_pek_test","type":"String","value":"1","chainId":"_all_"},{"id":"se_whitelist","type":"String","value":"0","chainId":"_all_"},{"id":"ug_follow_answerer","type":"String","value":"0","chainId":"_all_"}],"chains":[{"chainId":"_all_"}]},"triggers":{}},"userAgent":{"Edge":false,"Wechat":false,"Weibo":false,"QQ":false,"MQQBrowser":false,"Qzone":false,"Mobile":false,"Android":false,"iOS":false,"isAppleDevice":false,"Zhihu":false,"ZhihuHybrid":false,"isBot":false,"Tablet":false,"UC":false,"Sogou":false,"Qihoo":false,"Baidu":false,"BaiduApp":false,"Safari":false,"GoogleBot":false,"AndroidDaily":false,"iOSDaily":false,"isWebView":false,"origin":"Mozilla\u002F5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\u002F537.36 (KHTML, like Gecko) Chrome\u002F80.0.3987.100 Safari\u002F537.36"},"appViewConfig":{},"ctx":{"path":"\u002Fp\u002F45618611","query":{},"href":"http:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F45618611","host":"zhuanlan.zhihu.com"},"trafficSource":"production","edition":{"baidu":false,"sogou":false,"baiduBeijing":false,"sogouBeijing":false,"sogouInput":false},"theme":"light","enableShortcut":true,"referer":"","conf":{},"ipInfo":{"cityName":"德州","countryName":"中国","regionName":"山东","countryCode":"CN"},"logged":false},"me":{"columnContributions":[]},"label":{"recognizerLists":{}},"ecommerce":{},"comments":{"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"parent":{}},"commentsV2":{"stickers":[],"commentWithPicPermission":{},"notificationsComments":{},"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"conversationMore":{},"parent":{}},"pushNotifications":{"default":{"isFetching":false,"isDrained":false,"ids":[]},"follow":{"isFetching":false,"isDrained":false,"ids":[]},"vote_thank":{"isFetching":false,"isDrained":false,"ids":[]},"currentTab":"default","notificationsCount":{"default":0,"follow":0,"vote_thank":0}},"messages":{"data":{},"currentTab":"common","messageCount":0},"register":{"registerValidateSucceeded":null,"registerValidateErrors":{},"registerConfirmError":null,"sendDigitsError":null,"registerConfirmSucceeded":null},"login":{"loginUnregisteredError":false,"loginBindWechatError":false,"loginConfirmError":null,"sendDigitsError":null,"needSMSIdentify":false,"validateDigitsError":false,"loginConfirmSucceeded":null,"qrcodeLoginToken":"","qrcodeLoginScanStatus":0,"qrcodeLoginError":null,"qrcodeLoginReturnNewToken":false},"active":{"sendDigitsError":null,"activeConfirmSucceeded":null,"activeConfirmError":null},"switches":{},"captcha":{"captchaNeeded":false,"captchaValidated":false,"captchaBase64String":null,"captchaValidationMessage":null,"loginCaptchaExpires":false},"sms":{"supportedCountries":[]},"chat":{"chats":{},"inbox":{"recents":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"strangers":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"friends":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"search":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"config":{"newCount":0,"strangerMessageSwitch":false,"strangerMessageUnread":false,"friendCount":0}},"global":{"isChatMqttExisted":false}},"emoticons":{"emoticonGroupList":[],"emoticonGroupDetail":{}},"creator":{"currentCreatorUrlToken":null,"homeData":{"recommendQuestions":[]},"tools":{"question":{"invitationCount":{"questionFolloweeCount":0,"questionTotalCount":0},"goodatTopics":[]},"customPromotion":{"itemLists":{}},"recommend":{"recommendTimes":{}}},"explore":{"academy":{"tabs":[],"article":{}}},"rights":[],"rightsStatus":{},"levelUpperLimit":10,"account":{"growthLevel":{}},"mcn":{},"applyStatus":{}},"recommendation":{"homeRecommendations":[]},"shareTexts":{},"articles":{"voters":{}},"previewPost":{},"favlists":{"relations":{}},"columns":{"voters":{}},"reward":{"answer":{},"article":{},"question":{}},"video":{"data":{},"shareVideoDetail":{},"last":{}},"topstory":{"recommend":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"follow":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followWonderful":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"sidebar":null,"announcement":{},"hotListCategories":[],"hotList":[],"guestFeeds":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followExtra":{"isNewUser":null,"isFetched":false,"followCount":0,"followers":[]}},"readStatus":{},"column":{},"requestColumn":{"categories":[],"error":null},"articleContribution":{"contributeRequests":[],"deleteContributeIdList":[],"handledContributeIdList":[],"recommendedColumns":[],"pinnedColumns":[],"sentContributeRequestsIdList":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"reinforcementlearning"]},"columnContribution":{"contributeRequests":[],"autoInviteEnabled":false,"recommendedContributors":[],"contributionInvitation":null},"draftHistory":{"history":{},"drafts":{}},"upload":{},"articleDraft":{"titleImage":"","titleImageSize":{},"isTitleImageFullScreen":false,"canTitleImageFullScreen":false,"title":"","titleImageUploading":false,"error":"","content":"","draftLoading":false,"updating":false,"globalLoading":false,"pendingVideo":{"resource":null,"error":null},"deleteFail":{"fail":false},"recommendTopics":[],"selectedColumn":0,"articleDisclaimers":[]},"articleDrafts":{"isDrained":false,"isLoading":false,"items":[]},"columnAutocomplete":{"users":[],"friends":[]},"columnCollection":{},"mcn":{"bindInfo":{},"memberCategoryList":[],"producerList":[],"categoryList":[]}},"fetchHost":"www.zhihu.com","subAppName":"column"}</script><script src="https://static.zhihu.com/heifetz/vendor.7b36fae46082fd30a0db.js"></script><script src="https://static.zhihu.com/heifetz/column.app.76e02b16e87eec249f44.js"></script></body><script src="https://hm.baidu.com/hm.js?98beee57fd2ef70ccdd5ca52b9740c49" async=""></script><script src="https://zz.bdstatic.com/linksubmit/push.js" async=""></script></html>