<!doctype html>
<html lang="zh" data-hairline="true" data-theme="light"><head><meta charSet="utf-8"/><title data-react-helmet="true">【强化学习 41】Go-Explore - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"/><meta name="renderer" content="webkit"/><meta name="force-rendering" content="webkit"/><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg"/><meta data-react-helmet="true" name="keywords" content="强化学习 (Reinforcement Learning)"/><meta data-react-helmet="true" name="description" content="Go-Explore是uber团队开发的算法，直观的意思是走到最好的状态（Go），然后从这个状态开始探索（Explore）。原文传送门Ecoffet, Adrien, et al. &amp;#34;Go-Explore: a New Approach for Hard-Exploration Problems.&amp;…"/><meta data-react-helmet="true" property="og:title" content="【强化学习 41】Go-Explore"/><meta data-react-helmet="true" property="og:url" content="https://zhuanlan.zhihu.com/p/58053501"/><meta data-react-helmet="true" property="og:description" content="Go-Explore是uber团队开发的算法，直观的意思是走到最好的状态（Go），然后从这个状态开始探索（Explore）。原文传送门Ecoffet, Adrien, et al. &amp;#34;Go-Explore: a New Approach for Hard-Exploration Problems.&amp;…"/><meta data-react-helmet="true" property="og:image" content="https://pic1.zhimg.com/v2-11210974f862247312ff89351b4edac2_b.jpg"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" property="og:site_name" content="知乎专栏"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png" sizes="152x152"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-120.b3e6278d.png" sizes="120x120"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-76.7a750095.png" sizes="76x76"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-60.a4a761d4.png" sizes="60x60"/><link rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/static/favicon.ico"/><link rel="search" type="application/opensearchdescription+xml" href="https://static.zhihu.com/static/search.xml" title="知乎"/><link rel="dns-prefetch" href="//static.zhimg.com"/><link rel="dns-prefetch" href="//pic1.zhimg.com"/><link rel="dns-prefetch" href="//pic2.zhimg.com"/><link rel="dns-prefetch" href="//pic3.zhimg.com"/><link rel="dns-prefetch" href="//pic4.zhimg.com"/><style>
.u-safeAreaInset-top {
  height: constant(safe-area-inset-top) !important;
  height: env(safe-area-inset-top) !important;
  
}
.u-safeAreaInset-bottom {
  height: constant(safe-area-inset-bottom) !important;
  height: env(safe-area-inset-bottom) !important;
  
}
</style><link href="https://static.zhihu.com/heifetz/column.app.a9ced452148fee3a55c8.css" rel="stylesheet"/><script defer="" crossorigin="anonymous" src="https://unpkg.zhimg.com/@cfe/sentry-script@latest/dist/init.js" data-sentry-config="{&quot;dsn&quot;:&quot;https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224&quot;,&quot;sampleRate&quot;:0.1,&quot;release&quot;:&quot;683-127b14ad&quot;,&quot;ignoreErrorNames&quot;:[&quot;NetworkError&quot;,&quot;SecurityError&quot;],&quot;ignoreErrors&quot;:[&quot;origin message&quot;,&quot;Network request failed&quot;,&quot;Loading chunk&quot;,&quot;这个系统不支持该功能。&quot;,&quot;Can&#x27;t find variable: webkit&quot;,&quot;Can&#x27;t find variable: $&quot;,&quot;内存不足&quot;,&quot;out of memory&quot;,&quot;DOM Exception 18&quot;,&quot;The operation is insecure&quot;,&quot;[object Event]&quot;,&quot;[object FileError]&quot;,&quot;[object DOMError]&quot;,&quot;[object Object]&quot;,&quot;拒绝访问。&quot;,&quot;Maximum call stack size exceeded&quot;,&quot;UploadError&quot;,&quot;无法 fetch&quot;,&quot;draft-js&quot;,&quot;缺少 JavaScript 对象&quot;,&quot;componentWillEnter&quot;,&quot;componentWillLeave&quot;,&quot;componentWillAppear&quot;,&quot;getInlineStyleAt&quot;,&quot;getCharacterList&quot;],&quot;whitelistUrls&quot;:[&quot;static.zhihu.com&quot;]}"></script></head><body class="WhiteBg-body"><div id="root"><div class="App"><div class="LoadingBar"></div><main role="main" class="App-main"><div class="Post-content" data-zop-usertoken="{&quot;userToken&quot;:&quot;&quot;}" data-zop="{&quot;authorName&quot;:&quot;张楚珩&quot;,&quot;itemId&quot;:58053501,&quot;title&quot;:&quot;【强化学习 41】Go-Explore&quot;,&quot;type&quot;:&quot;article&quot;}"><div class="ColumnPageHeader-Wrapper"><div><div class="Sticky ColumnPageHeader"><div class="ColumnPageHeader-content"><a href="//www.zhihu.com" aria-label="知乎"><svg viewBox="0 0 200 91" fill="#0084FF" width="64" height="30"><path d="M53.29 80.035l7.32.002 2.41 8.24 13.128-8.24h15.477v-67.98H53.29v67.978zm7.79-60.598h22.756v53.22h-8.73l-8.718 5.473-1.587-5.46-3.72-.012v-53.22zM46.818 43.162h-16.35c.545-8.467.687-16.12.687-22.955h15.987s.615-7.05-2.68-6.97H16.807c1.09-4.1 2.46-8.332 4.1-12.708 0 0-7.523 0-10.085 6.74-1.06 2.78-4.128 13.48-9.592 24.41 1.84-.2 7.927-.37 11.512-6.94.66-1.84.785-2.08 1.605-4.54h9.02c0 3.28-.374 20.9-.526 22.95H6.51c-3.67 0-4.863 7.38-4.863 7.38H22.14C20.765 66.11 13.385 79.24 0 89.62c6.403 1.828 12.784-.29 15.937-3.094 0 0 7.182-6.53 11.12-21.64L43.92 85.18s2.473-8.402-.388-12.496c-2.37-2.788-8.768-10.33-11.496-13.064l-4.57 3.627c1.363-4.368 2.183-8.61 2.46-12.71H49.19s-.027-7.38-2.372-7.38zm128.752-.502c6.51-8.013 14.054-18.302 14.054-18.302s-5.827-4.625-8.556-1.27c-1.874 2.548-11.51 15.063-11.51 15.063l6.012 4.51zm-46.903-18.462c-2.814-2.577-8.096.667-8.096.667s12.35 17.2 12.85 17.953l6.08-4.29s-8.02-11.752-10.83-14.33zM199.99 46.5c-6.18 0-40.908.292-40.953.292v-31.56c1.503 0 3.882-.124 7.14-.376 12.773-.753 21.914-1.25 27.427-1.504 0 0 3.817-8.496-.185-10.45-.96-.37-7.24 1.43-7.24 1.43s-51.63 5.153-72.61 5.64c.5 2.756 2.38 5.336 4.93 6.11 4.16 1.087 7.09.53 15.36.277 7.76-.5 13.65-.76 17.66-.76v31.19h-41.71s.88 6.97 7.97 7.14h33.73v22.16c0 4.364-3.498 6.87-7.65 6.6-4.4.034-8.15-.36-13.027-.566.623 1.24 1.977 4.496 6.035 6.824 3.087 1.502 5.054 2.053 8.13 2.053 9.237 0 14.27-5.4 14.027-14.16V53.93h38.235c3.026 0 2.72-7.432 2.72-7.432z" fill-rule="evenodd"></path></svg></a><i class="ColumnPageHeader-Line"></i><div class="ColumnPageHeader-Title"><a class="ColumnLink ColumnPageHeader-Link" href="/reinforcementlearning"><img class="Avatar Avatar--round" width="30" height="30" src="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_is.jpg" srcSet="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_im.jpg 2x" alt="强化学习前沿"/></a><div class="ColumnPageHeader-TitleName"><span class="ColumnPageHeader-TitleMeta">首发于</span><a class="ColumnLink ColumnPageHeader-TitleColumn" href="/reinforcementlearning">强化学习前沿</a></div></div><div class="ColumnPageHeader-Button"><button type="button" class="Button ColumnPageHeader-WriteButton Button--blue"><svg class="Zi Zi--EditSurround" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M18.453 7.992l-1.833-1.65.964-.978a1.223 1.223 0 0 1 1.73-.012l.005.006a1.24 1.24 0 0 1 .007 1.748l-.873.886zm-1.178 1.194l-5.578 5.66-1.935.697a.393.393 0 0 1-.504-.504l.697-1.935 5.488-5.567 1.832 1.65zM7.58 5.848l5.654.006-1.539 1.991-3.666.012A1.02 1.02 0 0 0 7 8.868v7.993c0 .558.46 1.01 1.029 1.01l7.941-.01c.568 0 1.03-.453 1.03-1.012v-4.061l2-1.442v6.002c0 1.397-1.2 2.501-2.62 2.501H7.574C6.153 19.85 5 18.717 5 17.32V8.35c0-1.397 1.16-2.502 2.58-2.502z"></path></svg>写文章</button></div></div></div></div></div><img class="TitleImage" src="https://pic1.zhimg.com/v2-11210974f862247312ff89351b4edac2_1200x500.jpg" alt="【强化学习 41】Go-Explore"/><article class="Post-Main Post-NormalMain" tabindex="-1"><header class="Post-Header"><h1 class="Post-Title">【强化学习 41】Go-Explore</h1><div class="Post-Author"><div class="AuthorInfo" itemProp="author" itemscope="" itemType="http://schema.org/Person"><meta itemProp="name" content="张楚珩"/><meta itemProp="image" content="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg"/><meta itemProp="url" content="https://www.zhihu.com/people/zhang-chu-heng"/><meta itemProp="zhihu:followerCount"/><span class="UserLink AuthorInfo-avatarWrapper"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/zhang-chu-heng"><img class="Avatar Avatar--round AuthorInfo-avatar" width="38" height="38" src="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_xs.jpg" srcSet="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg 2x" alt="张楚珩"/></a></div></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/zhang-chu-heng">张楚珩</a></div></div><style data-emotion-css="1cd9gw4">.css-1cd9gw4{margin-left:.3em;}</style><style data-emotion-css="1pc1mic">.css-1pc1mic{box-sizing:border-box;margin:0;min-width:0;color:#175199;display:inline-block;width:18px;height:18px;margin-left:.3em;}</style><a href="https://www.zhihu.com/question/48510028" target="_blank" class="css-1pc1mic" data-tooltip="已认证的个人" aria-label="已认证的个人"><style data-emotion-css="18biwo">.css-18biwo{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><span class="css-18biwo">​<svg viewBox="0 0 24 24" width="18" height="18"><svg viewBox="0 0 24 24" x="-3" y="-3" fill="#FFFFFF" width="30" height="30"><path d="M3.56231227,13.8535307 C2.40051305,12.768677 2.41398885,11.0669203 3.59484487,9.99979213 L3.59222085,9.99654885 C4.26730143,9.45036719 4.79446755,8.21005186 4.7184197,7.34453784 L4.72305873,7.34412719 C4.66942824,5.75539997 5.8824188,4.56066914 7.47188965,4.64242381 L7.47229112,4.6386236 C8.33515314,4.72977993 9.58467253,4.22534048 10.1426329,3.55925173 L10.1462611,3.56228565 C11.2316055,2.40008701 12.9353108,2.41394456 14.0015072,3.59634088 L14.0047263,3.59374004 C14.5498229,4.26841874 15.7896857,4.79521622 16.6545744,4.71844347 L16.6549836,4.72304294 C18.245027,4.66894057 19.4396947,5.88213996 19.3575031,7.47241135 L19.3623099,7.47292747 C19.2704388,8.3358681 19.7742711,9.58421483 20.4407199,10.1424506 L20.437686,10.1460789 C21.5997217,11.2312209 21.5860695,12.9345218 20.4042441,14.0007396 L20.4072865,14.0045125 C19.7325967,14.5495925 19.2055209,15.7896954 19.2815865,16.6561959 L19.2770449,16.6565978 C19.3315454,18.2453037 18.1173775,19.4393568 16.5274188,19.3571512 L16.5269029,19.3619539 C15.6647098,19.270083 14.415408,19.7741709 13.8573671,20.4403558 L13.8537409,20.4373235 C12.76842,21.5995708 11.0650432,21.5864553 9.99899434,20.4039226 L9.99527367,20.406923 C9.45025436,19.7323399 8.21017638,19.2051872 7.34461983,19.2812352 L7.344304,19.2776405 C5.75448683,19.3312904 4.55977145,18.1170085 4.64254978,16.527117 L4.63769921,16.5265942 C4.72957031,15.6644394 4.22547659,14.4151814 3.55928015,13.8571569 L3.56231227,13.8535307 Z"></path></svg><path d="M2.63951518,13.3895441 C3.70763333,14.2842292 4.44777637,16.1226061 4.30075305,17.5023312 L4.32211542,17.3063047 C4.17509209,18.6910561 5.17786655,19.7063729 6.5613937,19.5844846 L6.364106,19.6008202 C7.75140298,19.4789319 9.57474349,20.2554985 10.4468305,21.3349009 L10.3224262,21.1803415 C11.1982831,22.2647703 12.6257916,22.2723098 13.5167278,21.2079863 L13.3898102,21.3600325 C14.2845162,20.2919393 16.1229361,19.5518136 17.5026934,19.6988334 L17.3054057,19.6774716 C18.6914461,19.8244915 19.7067866,18.8217404 19.5836389,17.4395022 L19.6012314,17.6367853 C19.4793403,16.2482641 20.255925,14.4249662 21.3353526,13.5528995 L21.1807897,13.677301 C22.2639871,12.8014646 22.2727834,11.3739894 21.2084351,10.483074 L21.3604848,10.6099886 C20.2923667,9.71530351 19.5522236,7.87818322 19.6992469,6.49720154 L19.6778846,6.69448464 C19.8249079,5.30847665 18.8221335,4.2944164 17.4386063,4.41630468 L17.635894,4.39871256 C16.248597,4.52185742 14.4252565,3.74529084 13.5531695,2.66588842 L13.6775738,2.81919121 C12.8017169,1.73601905 11.3742084,1.72722299 10.4832722,2.79154644 L10.6101898,2.63950024 C9.71548377,3.70759343 7.87706394,4.44771919 6.49730661,4.30195588 L6.69459432,4.32206116 C5.30855394,4.17504128 4.29447,5.17904888 4.41636114,6.56128713 L4.3987686,6.36400404 C4.52065973,7.75126861 3.74407501,9.57456653 2.66464737,10.4478898 L2.81921035,10.3222318 C1.73601288,11.1993248 1.72721662,12.6255433 2.79156494,13.5164587 L2.63951518,13.3895441 Z" fill="#0084FF"></path><svg class="Zi Zi--Check" fill="#fff" x="6" y="6" viewBox="0 0 24 24" width="12" height="12"><path d="M10.229 17.516c-.318.327-.75.484-1.199.484-.453 0-.884-.16-1.202-.488l-4.335-4.47a1.77 1.77 0 0 1 .007-2.459 1.663 1.663 0 0 1 2.397.01l3.137 3.246 9.072-9.329a1.662 1.662 0 0 1 2.397 0c.663.681.663 1.786 0 2.466L10.23 17.516z" fill-rule="evenodd"></path></svg></svg></span></a></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="AuthorInfo-badgeText">清华大学 交叉信息院博士在读</div></div></div></div></div></div><div><span class="Voters"><button type="button" class="Button Button--plain">16 人<!-- -->赞同了该文章</button></span></div></header><div class="Post-RichTextContainer"><div class="RichText ztext Post-RichText"><p>Go-Explore是uber团队开发的算法，直观的意思是走到最好的状态（Go），然后从这个状态开始探索（Explore）。</p><h2><b>原文传送门</b></h2><p><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1901.10995" class=" wrap external" target="_blank" rel="nofollow noreferrer">Ecoffet, Adrien, et al. &#34;Go-Explore: a New Approach for Hard-Exploration Problems.&#34; arXiv preprint arXiv:1901.10995 (2019).</a></p><h2><b>特色</b></h2><p>Go-Explore旨在解决探索困难（hard-exploration）的问题，这类问题通常奖励稀疏（sparse）并且会有误导性的奖励（deceptive）。这篇文章通过一系列算法设计，使得它在 Montezuma&#39;s Revenge 和 Pitfall 游戏上的表现相比于之前的算法有了质的飞跃。</p><h2><b>过程</b></h2><p><b>1. 任务困难之处</b></p><p>文章中讲到的探索困难的问题主要包括两个难点。</p><ul><li>第一个难点在于其任务给的奖励很稀疏，即需要作出特定的一连串动作才可能得到一个非零的奖励，对于每一步都随机探索的很多算法来说，很可能在整个探索过程中都遇不到一个非零的奖励。比如在 Montezuma&#39;s Revenge 里面需要走很多步去获取钥匙或者进入新的房间才会有一个奖励。</li><li>第二个难点在于任务给的奖励具有误导性。比如在 Pitfall 这个游戏里面不仅奖励很稀疏，而且很多小动作会导致负奖励，这会使得智能体在学习到如何获取奖励之前，反而由于这些负奖励而原地不动、停止探索。</li></ul><p>在此之前的算法为了更加有效地探索，通常使用使用 intrinsic motivation （IM）或者 intrinsic reward（IR）技术，除了尽量获取更多的奖励之外，也尽可能激励智能体去探索没有遇到过的状态空间。这方面的算法可以参考本专栏的其他文章（比如 RND、VIME、ICM 等）。</p><p>但是 IM 类方法具有 detachment 和 derailment 的缺点。前者指的是，算法虽然鼓励智能体去探索未知的状态空间，但是当前状态到被探索状态空间的边界之间隔着很多被探索过的状态，算法并不能激励智能体越过这些 IR 很小的状态走到边界上再去探索。因此，当前状态到未被探索过的状态之间是“分离”的，这限制了有效的探索。那么自然有一个想法就是让智能体先走到已被探索过的状态的边界上，然后再去探索新的状态，但是现有的算法会在走到边界的半路上“边走边探索”，最后偏离的轨迹，无法到达边界，这就是 derailment 所描述的问题。</p><p><b>2. 算法大致流程</b></p><p>如下图所示，算法分为两个部分。其中第一部分（Phase 1）的最终目的是通过在环境中探索生成一系列高奖励的轨迹；第二部分（Phase 2）使用第一部分生成的轨迹做 imitation learning 并获得最终的策略。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-5d98fa033d78ac3a9323afbad1e3535e_b.jpg" data-caption="" data-size="normal" data-rawwidth="1924" data-rawheight="456" class="origin_image zh-lightbox-thumb" width="1924" data-original="https://pic3.zhimg.com/v2-5d98fa033d78ac3a9323afbad1e3535e_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1924&#39; height=&#39;456&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1924" data-rawheight="456" class="origin_image zh-lightbox-thumb lazy" width="1924" data-original="https://pic3.zhimg.com/v2-5d98fa033d78ac3a9323afbad1e3535e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-5d98fa033d78ac3a9323afbad1e3535e_b.jpg"/></figure><p>第一部分限定在确定性（deterministic）并且可以重启（resettable）的环境中进行，这样的好处是记录下行动序列就可以确定性地到达之前到达的状态上。第一部分的主要思想是维护一个存档（archive），保存着从起始状态到达各个已经探索到状态的路径。每一轮都选择一个已经达到过的状态，然后利用存档中的信息走到这个状态上，接着从这个状态出发做探索，如果探索到了新的状态或者有用的路径，就记录下来加入存档中。注意到这个部分纯粹是做探索并且记录状态和行动序列，这里面并没有使用神经网络。（该部分具体细节见后）</p><p>第二部分使用第一部分生成的轨迹做训练。这不仅仅是因为第一部分其实压根没有学习到概括性的策略，而且也是因为第一部分实在确定性的环境中探索的，其策略没法适应真实的随机性环境。文中使用了一种 learning from demostration 的方法 Backward Algorithm。大致上来说，拿到一条高奖励的轨迹之后，先把智能体放在离轨迹末端较近的位置，让智能体能够学习到如何从这个离目标很近状态走到目标，然后再逐步把智能体放在轨迹上离目标更远一些的地方。通过这种方式智能体就能逐步学习到如何从初始位置走到目标位置。其学习的算法还是使用的通用的强化学习算法，比如 PPO 等。这个过程也可以看做是一个课程学习（curriculum learning），使用第一部分生成的反向轨迹来作为由易到难设定的课程。</p><p><b>3. 算法细节</b></p><p>【状态的表示】</p><p>文章中算法的输入是游戏视频，这是一个高维度的状态表示，如果把每个不同的高维度状态表示都放到存档里面显然是不可能的，因为不同的状态太多了。文章通过转化为灰度图像和下采样的方法把这些高维度的状态都转化为了状态单元（cell），如下图所示。算法第一部分的所说的各种状态都是针对这个状态单元（cell）而言的。</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-458c7ebd65b489d5171b3611787453c3_b.jpg" data-caption="" data-size="normal" data-rawwidth="1940" data-rawheight="710" class="origin_image zh-lightbox-thumb" width="1940" data-original="https://pic4.zhimg.com/v2-458c7ebd65b489d5171b3611787453c3_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1940&#39; height=&#39;710&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1940" data-rawheight="710" class="origin_image zh-lightbox-thumb lazy" width="1940" data-original="https://pic4.zhimg.com/v2-458c7ebd65b489d5171b3611787453c3_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-458c7ebd65b489d5171b3611787453c3_b.jpg"/></figure><p>同时文章还测试了加上与任务特定知识有关的信息（domain knowledge）。他们在上面提取的状态的基础上还使用编写的程序从图中提取一些与游戏相关的信息作为状态特征，比如智能体的x, y坐标，当前房间的位置，当前处于的关卡数等。</p><p>【从存档中选择要前往的状态】</p><p>显然我们更希望找出那些离未探索区域更近的状态，因为从这些状态出发能够更容易找到未探索过的状态。文章中使用了一些启发式的评价指标，并且以更大的概率选择那些具有更高得分的状态。文章中使用的评价指标主要包括三类：1）该状态是否更少被访问过，并且之前对它的访问都有较好的结果；2）该状态附近是否有更多未被探索过的状态；3）该状态是否处于更高的关卡中。</p><p>【从初始状态出发前往探索的起点】</p><p>从存档中选择了要前往的状态之后，就需要开始行动前往这个状态。由于在算法的第一部分中环境都是确定性并且可以重启的，因此这一部分就变得很容易了，只需要把存档中的行动序列读出来然后按照原来的行动序列行动就可以到达指定的状态了。</p><p>注意到为了更加充分地利用存档中储存的信息，轨迹中途经的各个状态也会被记录下来，如果要前往这些状态也可以复用前半部分的轨迹。</p><p>【从这个状态出发探索】</p><p>这个探索的过程相对来说比较直接，就是做 <img src="https://www.zhihu.com/equation?tex=k%3D100" alt="k=100" eeimg="1"/> 步的随机行动采样，并且有95%的概率重复上一步的动作，然后看看能够到达什么状态。</p><p>【更新存档】</p><p>存档会记录以下信息不仅会记录到达某状态的轨迹，而且还会记录下所获得的奖励和轨迹长度。</p><p>当遇到以下两种情况之一的时候会更新存档。一种是遇到了之前没有遇到过的状态；另一种遇到了已经存在于存档中的状态，但是其走到该状态的路径更优。这里说的更优指的是获得了更多的奖励或者获得了相同的奖励但是轨迹长度更短。这样原本的状态对应的轨迹就会被更新成新的轨迹。</p><p>假如，之前从 A 到 B 的轨迹被更新了，同时存档中还存在一条从 A 经 B 到 C 的轨迹，后面这条轨迹不会被更新，因为这里讲的状态 B 是很多可能的状态集合起来的状态单元，前面一条轨迹中的 B 可能和后者中的 B 不一样。</p><p><b>4. 算法核心思想</b></p><p>文章总结了 Go-Explore 算法成功的三大核心思想，文章称这三大核心思想是该算法成功的关键。</p><ul><li>记录下之前访问过的状态；</li><li>优先考虑返回更有可能探索到新状态的状态，返回的过程中采用确定性环境，这样一定能够返回到特定的状态；</li><li>现在确定性的环境中探索出可能比较脆弱的高奖励轨迹，然后再利用该轨迹学习到鲁棒的策略。</li></ul><h2><b>实验结果</b></h2><p>这里只放 Montezuma&#39;s Revenge 上的结果，Pitfall 上的结果类似。不使用 domain knowledge 的结果就超越了人类专家的水平。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-1e0ccb42bab1c4d60b779fbcade38832_b.jpg" data-size="normal" data-rawwidth="1908" data-rawheight="890" class="origin_image zh-lightbox-thumb" width="1908" data-original="https://pic3.zhimg.com/v2-1e0ccb42bab1c4d60b779fbcade38832_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1908&#39; height=&#39;890&#39;&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="1908" data-rawheight="890" class="origin_image zh-lightbox-thumb lazy" width="1908" data-original="https://pic3.zhimg.com/v2-1e0ccb42bab1c4d60b779fbcade38832_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-1e0ccb42bab1c4d60b779fbcade38832_b.jpg"/><figcaption>不使用 domain knowledge就在 Montezuma&amp;#39;s Revenge 游戏上超过人类专家的水平</figcaption></figure><p>下图展示了 Go-Explore 算法和其他算法得分的比较，可以看到该算法相比于其他算法也有了很大的提升。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-10a1e159ee0843fdb430de5b74f08306_b.jpg" data-caption="" data-size="normal" data-rawwidth="2026" data-rawheight="1298" class="origin_image zh-lightbox-thumb" width="2026" data-original="https://pic3.zhimg.com/v2-10a1e159ee0843fdb430de5b74f08306_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2026&#39; height=&#39;1298&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2026" data-rawheight="1298" class="origin_image zh-lightbox-thumb lazy" width="2026" data-original="https://pic3.zhimg.com/v2-10a1e159ee0843fdb430de5b74f08306_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-10a1e159ee0843fdb430de5b74f08306_b.jpg"/></figure><p>使用了专家知识之后，效果又提升了一大截，通过这个也说明如果能够使用更强的 representation 将给算法效果带来更大的提升。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-5917947c25a18318c32db8ebbe20af7c_b.jpg" data-caption="" data-size="normal" data-rawwidth="1968" data-rawheight="960" class="origin_image zh-lightbox-thumb" width="1968" data-original="https://pic1.zhimg.com/v2-5917947c25a18318c32db8ebbe20af7c_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1968&#39; height=&#39;960&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1968" data-rawheight="960" class="origin_image zh-lightbox-thumb lazy" width="1968" data-original="https://pic1.zhimg.com/v2-5917947c25a18318c32db8ebbe20af7c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-5917947c25a18318c32db8ebbe20af7c_b.jpg"/></figure><hr/><p><b>评述</b></p><p>该工作在实验效果上取得了巨大的成就，不过目前看来有以下的不足之处。</p><ul><li>算法的第一部分把高维度的状态都做了离散化，这是为了确切地区分某两个状态是相同的还是不同的，并且把不同的状态都存在存档里面。这样的做法不方便 scale up，可能会限制该算法解决更困难的问题。另外，文章中把游戏图像下采样的方法虽然说是没有用到游戏的 domain knowledge，但是这其实还是利用了一个先验，即这个游戏都是“格子”类的游戏，通过下采样刚好反映了各个格子上的状态。这样的方法能不能用于更为困难的游戏值得商榷。</li><li>算法及其依赖于确定性的训练环境，当无法获取一个确定性的训练环境的时候算法将失效（这一点文章也提到了）。当然作者也说了，这种情况下可以再学一个 goal-conditioned policy，让智能体返回特定的状态，不过感觉这么操作就有点复杂了。下一步可能需要研究如何简化这个过程，并且保证相当的返回特定状态的概率。</li><li>同时，个人感觉，当环境极其复杂的时候，单一确定性环境中训练得到的轨迹们可能无法有效表征对应随机环境的特征，这种情况下第二部分算法能否通过这些轨迹有效地学习值得进一步实验观察。</li><li>本文的思路可能更适合文章实验的这两款以探索为目的的游戏，对其他游戏不一定能试用。毕竟文章中也提到了，Go-Explore 解决的是 hard-exploration。目前还有一类比较困难的游戏，比如即时战略类游戏，其难点可能在于 temporal abstract。</li></ul><p>不过不管怎样，文章中提出的思路非常有价值，即需要直接走到最前沿的某个状态，然后再探索，它确实能有效解决目前强化学习探索上的痛点。这个思路也很符合人类平时探索的思维模式。</p></div></div><div class="ContentItem-time">发布于 2019-03-02</div><div class="Post-topicsAndReviewer"><div class="TopicList Post-Topics"><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/20039099" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习 (Reinforcement Learning)</div></div></a></span></div></div></div><div><div class="Sticky RichContent-actions is-bottom"><div class="ContentItem-actions"><span><button aria-label="赞同 16 " type="button" class="Button VoteButton VoteButton--up"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleUp VoteButton-TriangleUp" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M2 18.242c0-.326.088-.532.237-.896l7.98-13.203C10.572 3.57 11.086 3 12 3c.915 0 1.429.571 1.784 1.143l7.98 13.203c.15.364.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H3.955c-1.08 0-1.955-.517-1.955-1.9z" fill-rule="evenodd"></path></svg></span>赞同 16</button><button aria-label="反对" type="button" class="Button VoteButton VoteButton--down"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleDown" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M20.044 3H3.956C2.876 3 2 3.517 2 4.9c0 .326.087.533.236.896L10.216 19c.355.571.87 1.143 1.784 1.143s1.429-.572 1.784-1.143l7.98-13.204c.149-.363.236-.57.236-.896 0-1.386-.876-1.9-1.956-1.9z" fill-rule="evenodd"></path></svg></span></button></span><button type="button" class="Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Comment Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M10.241 19.313a.97.97 0 0 0-.77.2 7.908 7.908 0 0 1-3.772 1.482.409.409 0 0 1-.38-.637 5.825 5.825 0 0 0 1.11-2.237.605.605 0 0 0-.227-.59A7.935 7.935 0 0 1 3 11.25C3 6.7 7.03 3 12 3s9 3.7 9 8.25-4.373 9.108-10.759 8.063z" fill-rule="evenodd"></path></svg></span>2 条评论</button><div class="Popover ShareMenu"><div class="ShareMenu-toggler" id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Share Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2.931 7.89c-1.067.24-1.275 1.669-.318 2.207l5.277 2.908 8.168-4.776c.25-.127.477.198.273.39L9.05 14.66l.927 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.242c.584-.892-.212-2.029-1.234-1.796L2.93 7.89z" fill-rule="evenodd"></path></svg></span>分享</button></div></div><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Heart Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2 8.437C2 5.505 4.294 3.094 7.207 3 9.243 3 11.092 4.19 12 6c.823-1.758 2.649-3 4.651-3C19.545 3 22 5.507 22 8.432 22 16.24 13.842 21 12 21 10.158 21 2 16.24 2 8.437z" fill-rule="evenodd"></path></svg></span>喜欢</button><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Star Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5.515 19.64l.918-5.355-3.89-3.792c-.926-.902-.639-1.784.64-1.97L8.56 7.74l2.404-4.871c.572-1.16 1.5-1.16 2.072 0L15.44 7.74l5.377.782c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.219 1.274-.532 1.82-1.676 1.218L12 18.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z" fill-rule="evenodd"></path></svg></span>收藏</button><div class="Post-ActionMenuButton"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Dots Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5 14a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4z" fill-rule="evenodd"></path></svg></span></button></div></div></div></div></div></div></article><div class="Post-Sub Post-NormalSub"><div class="PostIndex-Contributions"><h3 class="BlockTitle">文章被以下专栏收录</h3><ul><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><img class="Avatar Avatar--medium Avatar--round" width="40" height="40" src="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_xs.jpg" srcSet="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_l.jpg 2x" alt="强化学习前沿"/></div></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><a class="ColumnLink ColumnItem-Title" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习前沿</div></div></a></h2><div class="ContentItem-meta">读呀读paper</div></div><div class="ContentItem-extra"><a href="/reinforcementlearning" type="button" class="Button">进入专栏</a></div></div></div></ul></div></div></div></main></div></div><script nonce="4420b338-e20e-42a7-acdd-3d9f5114c240" async="" src="https://www.googletagmanager.com/gtag/js?id=UA-149949619-1"></script><script nonce="4420b338-e20e-42a7-acdd-3d9f5114c240">function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-149949619-1");</script><script id="js-clientConfig" type="text/json">{"host":"zhihu.com","protocol":"https:","wwwHost":"www.zhihu.com","fetchRoot":{"www":"https:\u002F\u002Fwww.zhihu.com","api":"https:\u002F\u002Fapi.zhihu.com","zhuanlan":"https:\u002F\u002Fzhuanlan.zhihu.com"}}</script><script id="js-initialData" type="text/json">{"initialState":{"common":{"ask":{}},"loading":{"global":{"count":0},"local":{"env\u002FgetIpinfo\u002F":false,"article\u002Fget\u002F":false,"brand\u002FgetUrl\u002F":false}},"club":{"tags":{}},"entities":{"users":{"zhang-chu-heng":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"清华大学 交叉信息院博士在读"}],"exposedMedal":{"medalId":"1124316222665379841","medalName":"我的知乎 2019","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2592b0b52e1fac99f69b38e00252413b_r.png","miniAvatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ad363cc3088dc8de7544fd08b1c4987a_is.png","description":"参与「我的知乎 2019」即可获得"}}},"questions":{},"answers":{},"articles":{"58053501":{"trackUrl":["https:\u002F\u002Fsugar.zhihu.com\u002Fplutus_adreaper\u002Fpage_monitor_log?si=__SESSIONID__&ti=__ATOKEN__&at=view&pf=__OS__&ed=__MEMBERID__&idfa=__IDFA__&imei=__IMEI__&androidid=__ANDROIDID__&oaid=__OAID__&ci=__CREATIVEID__"],"id":58053501,"title":"【强化学习 41】Go-Explore","type":"article","excerptTitle":"","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F58053501","imageUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-11210974f862247312ff89351b4edac2_b.jpg","titleImage":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-11210974f862247312ff89351b4edac2_b.jpg","excerpt":"\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6e079415c7c253e564af7a48f6f45148_200x112.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1924\" data-rawheight=\"456\" data-watermark=\"watermark\" data-original-src=\"v2-6e079415c7c253e564af7a48f6f45148\" data-watermark-src=\"v2-5d98fa033d78ac3a9323afbad1e3535e\" data-private-watermark-src=\"\" class=\"origin_image inline-img zh-lightbox-thumb\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6e079415c7c253e564af7a48f6f45148_r.png\"\u002F\u003EGo-Explore是uber团队开发的算法，直观的意思是走到最好的状态（Go），然后从这个状态开始探索（Explore）。\u003Cb\u003E原文传送门\u003C\u002Fb\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fpdf\u002F1901.10995\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EEcoffet, Adrien, et al. &#34;Go-Explore: a New Approach for Hard-Exploration Problems.&#34; arXiv preprint arXiv:1901.10995 (2019).\u003C\u002Fa\u003E\u003Cb\u003E特色\u003C\u002Fb\u003E…","created":1551489453,"updated":1551489453,"author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"清华大学 交叉信息院博士在读"}],"exposedMedal":{"medalId":"1124316222665379841","medalName":"我的知乎 2019","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2592b0b52e1fac99f69b38e00252413b_r.png","miniAvatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ad363cc3088dc8de7544fd08b1c4987a_is.png","description":"参与「我的知乎 2019」即可获得"}},"commentPermission":"all","state":"published","imageWidth":1373,"imageHeight":694,"content":"\u003Cp\u003EGo-Explore是uber团队开发的算法，直观的意思是走到最好的状态（Go），然后从这个状态开始探索（Explore）。\u003C\u002Fp\u003E\u003Ch2\u003E\u003Cb\u003E原文传送门\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Farxiv.org\u002Fpdf\u002F1901.10995\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EEcoffet, Adrien, et al. &#34;Go-Explore: a New Approach for Hard-Exploration Problems.&#34; arXiv preprint arXiv:1901.10995 (2019).\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Ch2\u003E\u003Cb\u003E特色\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003EGo-Explore旨在解决探索困难（hard-exploration）的问题，这类问题通常奖励稀疏（sparse）并且会有误导性的奖励（deceptive）。这篇文章通过一系列算法设计，使得它在 Montezuma&#39;s Revenge 和 Pitfall 游戏上的表现相比于之前的算法有了质的飞跃。\u003C\u002Fp\u003E\u003Ch2\u003E\u003Cb\u003E过程\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E\u003Cb\u003E1. 任务困难之处\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E文章中讲到的探索困难的问题主要包括两个难点。\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E第一个难点在于其任务给的奖励很稀疏，即需要作出特定的一连串动作才可能得到一个非零的奖励，对于每一步都随机探索的很多算法来说，很可能在整个探索过程中都遇不到一个非零的奖励。比如在 Montezuma&#39;s Revenge 里面需要走很多步去获取钥匙或者进入新的房间才会有一个奖励。\u003C\u002Fli\u003E\u003Cli\u003E第二个难点在于任务给的奖励具有误导性。比如在 Pitfall 这个游戏里面不仅奖励很稀疏，而且很多小动作会导致负奖励，这会使得智能体在学习到如何获取奖励之前，反而由于这些负奖励而原地不动、停止探索。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003E在此之前的算法为了更加有效地探索，通常使用使用 intrinsic motivation （IM）或者 intrinsic reward（IR）技术，除了尽量获取更多的奖励之外，也尽可能激励智能体去探索没有遇到过的状态空间。这方面的算法可以参考本专栏的其他文章（比如 RND、VIME、ICM 等）。\u003C\u002Fp\u003E\u003Cp\u003E但是 IM 类方法具有 detachment 和 derailment 的缺点。前者指的是，算法虽然鼓励智能体去探索未知的状态空间，但是当前状态到被探索状态空间的边界之间隔着很多被探索过的状态，算法并不能激励智能体越过这些 IR 很小的状态走到边界上再去探索。因此，当前状态到未被探索过的状态之间是“分离”的，这限制了有效的探索。那么自然有一个想法就是让智能体先走到已被探索过的状态的边界上，然后再去探索新的状态，但是现有的算法会在走到边界的半路上“边走边探索”，最后偏离的轨迹，无法到达边界，这就是 derailment 所描述的问题。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E2. 算法大致流程\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E如下图所示，算法分为两个部分。其中第一部分（Phase 1）的最终目的是通过在环境中探索生成一系列高奖励的轨迹；第二部分（Phase 2）使用第一部分生成的轨迹做 imitation learning 并获得最终的策略。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-5d98fa033d78ac3a9323afbad1e3535e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1924\" data-rawheight=\"456\" class=\"origin_image zh-lightbox-thumb\" width=\"1924\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-5d98fa033d78ac3a9323afbad1e3535e_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1924&#39; height=&#39;456&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1924\" data-rawheight=\"456\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1924\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-5d98fa033d78ac3a9323afbad1e3535e_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-5d98fa033d78ac3a9323afbad1e3535e_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E第一部分限定在确定性（deterministic）并且可以重启（resettable）的环境中进行，这样的好处是记录下行动序列就可以确定性地到达之前到达的状态上。第一部分的主要思想是维护一个存档（archive），保存着从起始状态到达各个已经探索到状态的路径。每一轮都选择一个已经达到过的状态，然后利用存档中的信息走到这个状态上，接着从这个状态出发做探索，如果探索到了新的状态或者有用的路径，就记录下来加入存档中。注意到这个部分纯粹是做探索并且记录状态和行动序列，这里面并没有使用神经网络。（该部分具体细节见后）\u003C\u002Fp\u003E\u003Cp\u003E第二部分使用第一部分生成的轨迹做训练。这不仅仅是因为第一部分其实压根没有学习到概括性的策略，而且也是因为第一部分实在确定性的环境中探索的，其策略没法适应真实的随机性环境。文中使用了一种 learning from demostration 的方法 Backward Algorithm。大致上来说，拿到一条高奖励的轨迹之后，先把智能体放在离轨迹末端较近的位置，让智能体能够学习到如何从这个离目标很近状态走到目标，然后再逐步把智能体放在轨迹上离目标更远一些的地方。通过这种方式智能体就能逐步学习到如何从初始位置走到目标位置。其学习的算法还是使用的通用的强化学习算法，比如 PPO 等。这个过程也可以看做是一个课程学习（curriculum learning），使用第一部分生成的反向轨迹来作为由易到难设定的课程。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E3. 算法细节\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E【状态的表示】\u003C\u002Fp\u003E\u003Cp\u003E文章中算法的输入是游戏视频，这是一个高维度的状态表示，如果把每个不同的高维度状态表示都放到存档里面显然是不可能的，因为不同的状态太多了。文章通过转化为灰度图像和下采样的方法把这些高维度的状态都转化为了状态单元（cell），如下图所示。算法第一部分的所说的各种状态都是针对这个状态单元（cell）而言的。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-458c7ebd65b489d5171b3611787453c3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1940\" data-rawheight=\"710\" class=\"origin_image zh-lightbox-thumb\" width=\"1940\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-458c7ebd65b489d5171b3611787453c3_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1940&#39; height=&#39;710&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1940\" data-rawheight=\"710\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1940\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-458c7ebd65b489d5171b3611787453c3_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-458c7ebd65b489d5171b3611787453c3_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E同时文章还测试了加上与任务特定知识有关的信息（domain knowledge）。他们在上面提取的状态的基础上还使用编写的程序从图中提取一些与游戏相关的信息作为状态特征，比如智能体的x, y坐标，当前房间的位置，当前处于的关卡数等。\u003C\u002Fp\u003E\u003Cp\u003E【从存档中选择要前往的状态】\u003C\u002Fp\u003E\u003Cp\u003E显然我们更希望找出那些离未探索区域更近的状态，因为从这些状态出发能够更容易找到未探索过的状态。文章中使用了一些启发式的评价指标，并且以更大的概率选择那些具有更高得分的状态。文章中使用的评价指标主要包括三类：1）该状态是否更少被访问过，并且之前对它的访问都有较好的结果；2）该状态附近是否有更多未被探索过的状态；3）该状态是否处于更高的关卡中。\u003C\u002Fp\u003E\u003Cp\u003E【从初始状态出发前往探索的起点】\u003C\u002Fp\u003E\u003Cp\u003E从存档中选择了要前往的状态之后，就需要开始行动前往这个状态。由于在算法的第一部分中环境都是确定性并且可以重启的，因此这一部分就变得很容易了，只需要把存档中的行动序列读出来然后按照原来的行动序列行动就可以到达指定的状态了。\u003C\u002Fp\u003E\u003Cp\u003E注意到为了更加充分地利用存档中储存的信息，轨迹中途经的各个状态也会被记录下来，如果要前往这些状态也可以复用前半部分的轨迹。\u003C\u002Fp\u003E\u003Cp\u003E【从这个状态出发探索】\u003C\u002Fp\u003E\u003Cp\u003E这个探索的过程相对来说比较直接，就是做 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=k%3D100\" alt=\"k=100\" eeimg=\"1\"\u002F\u003E 步的随机行动采样，并且有95%的概率重复上一步的动作，然后看看能够到达什么状态。\u003C\u002Fp\u003E\u003Cp\u003E【更新存档】\u003C\u002Fp\u003E\u003Cp\u003E存档会记录以下信息不仅会记录到达某状态的轨迹，而且还会记录下所获得的奖励和轨迹长度。\u003C\u002Fp\u003E\u003Cp\u003E当遇到以下两种情况之一的时候会更新存档。一种是遇到了之前没有遇到过的状态；另一种遇到了已经存在于存档中的状态，但是其走到该状态的路径更优。这里说的更优指的是获得了更多的奖励或者获得了相同的奖励但是轨迹长度更短。这样原本的状态对应的轨迹就会被更新成新的轨迹。\u003C\u002Fp\u003E\u003Cp\u003E假如，之前从 A 到 B 的轨迹被更新了，同时存档中还存在一条从 A 经 B 到 C 的轨迹，后面这条轨迹不会被更新，因为这里讲的状态 B 是很多可能的状态集合起来的状态单元，前面一条轨迹中的 B 可能和后者中的 B 不一样。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E4. 算法核心思想\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E文章总结了 Go-Explore 算法成功的三大核心思想，文章称这三大核心思想是该算法成功的关键。\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E记录下之前访问过的状态；\u003C\u002Fli\u003E\u003Cli\u003E优先考虑返回更有可能探索到新状态的状态，返回的过程中采用确定性环境，这样一定能够返回到特定的状态；\u003C\u002Fli\u003E\u003Cli\u003E现在确定性的环境中探索出可能比较脆弱的高奖励轨迹，然后再利用该轨迹学习到鲁棒的策略。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Ch2\u003E\u003Cb\u003E实验结果\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E这里只放 Montezuma&#39;s Revenge 上的结果，Pitfall 上的结果类似。不使用 domain knowledge 的结果就超越了人类专家的水平。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1e0ccb42bab1c4d60b779fbcade38832_b.jpg\" data-size=\"normal\" data-rawwidth=\"1908\" data-rawheight=\"890\" class=\"origin_image zh-lightbox-thumb\" width=\"1908\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1e0ccb42bab1c4d60b779fbcade38832_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1908&#39; height=&#39;890&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1908\" data-rawheight=\"890\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1908\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1e0ccb42bab1c4d60b779fbcade38832_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1e0ccb42bab1c4d60b779fbcade38832_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E不使用 domain knowledge就在 Montezuma&amp;#39;s Revenge 游戏上超过人类专家的水平\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E下图展示了 Go-Explore 算法和其他算法得分的比较，可以看到该算法相比于其他算法也有了很大的提升。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-10a1e159ee0843fdb430de5b74f08306_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2026\" data-rawheight=\"1298\" class=\"origin_image zh-lightbox-thumb\" width=\"2026\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-10a1e159ee0843fdb430de5b74f08306_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2026&#39; height=&#39;1298&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2026\" data-rawheight=\"1298\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2026\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-10a1e159ee0843fdb430de5b74f08306_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-10a1e159ee0843fdb430de5b74f08306_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E使用了专家知识之后，效果又提升了一大截，通过这个也说明如果能够使用更强的 representation 将给算法效果带来更大的提升。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-5917947c25a18318c32db8ebbe20af7c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1968\" data-rawheight=\"960\" class=\"origin_image zh-lightbox-thumb\" width=\"1968\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-5917947c25a18318c32db8ebbe20af7c_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1968&#39; height=&#39;960&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1968\" data-rawheight=\"960\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1968\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-5917947c25a18318c32db8ebbe20af7c_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-5917947c25a18318c32db8ebbe20af7c_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Chr\u002F\u003E\u003Cp\u003E\u003Cb\u003E评述\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E该工作在实验效果上取得了巨大的成就，不过目前看来有以下的不足之处。\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E算法的第一部分把高维度的状态都做了离散化，这是为了确切地区分某两个状态是相同的还是不同的，并且把不同的状态都存在存档里面。这样的做法不方便 scale up，可能会限制该算法解决更困难的问题。另外，文章中把游戏图像下采样的方法虽然说是没有用到游戏的 domain knowledge，但是这其实还是利用了一个先验，即这个游戏都是“格子”类的游戏，通过下采样刚好反映了各个格子上的状态。这样的方法能不能用于更为困难的游戏值得商榷。\u003C\u002Fli\u003E\u003Cli\u003E算法及其依赖于确定性的训练环境，当无法获取一个确定性的训练环境的时候算法将失效（这一点文章也提到了）。当然作者也说了，这种情况下可以再学一个 goal-conditioned policy，让智能体返回特定的状态，不过感觉这么操作就有点复杂了。下一步可能需要研究如何简化这个过程，并且保证相当的返回特定状态的概率。\u003C\u002Fli\u003E\u003Cli\u003E同时，个人感觉，当环境极其复杂的时候，单一确定性环境中训练得到的轨迹们可能无法有效表征对应随机环境的特征，这种情况下第二部分算法能否通过这些轨迹有效地学习值得进一步实验观察。\u003C\u002Fli\u003E\u003Cli\u003E本文的思路可能更适合文章实验的这两款以探索为目的的游戏，对其他游戏不一定能试用。毕竟文章中也提到了，Go-Explore 解决的是 hard-exploration。目前还有一类比较困难的游戏，比如即时战略类游戏，其难点可能在于 temporal abstract。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003E不过不管怎样，文章中提出的思路非常有价值，即需要直接走到最前沿的某个状态，然后再探索，它确实能有效解决目前强化学习探索上的痛点。这个思路也很符合人类平时探索的思维模式。\u003C\u002Fp\u003E","adminClosedComment":false,"topics":[{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F20039099","type":"topic","id":"20039099","name":"强化学习 (Reinforcement Learning)"}],"voteupCount":16,"voting":0,"column":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"},"commentCount":2,"contributions":[{"id":20335211,"state":"accepted","type":"first_publish","column":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}}],"isTitleImageFullScreen":false,"upvotedFollowees":[],"commercialInfo":{"isCommercial":false,"plugin":{}},"suggestEdit":{"status":false,"reason":"","tip":"","url":"","title":""},"reason":"","annotationAction":[],"canTip":false,"tipjarorsCount":0,"isLabeled":false,"hasPublishingDraft":false,"isFavorited":false,"isNormal":true,"status":0,"shareText":"【强化学习 41】Go-Explore - 来自知乎专栏「强化学习前沿」，作者: 张楚珩 https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F58053501 （想看更多？下载 @知乎 App：http:\u002F\u002Fweibo.com\u002Fp\u002F100404711598 ）","canComment":{"status":true,"reason":""},"mcnFpShow":-1,"isVisible":true,"isLiked":false,"likedCount":0,"visibleOnlyToAuthor":false}},"columns":{"reinforcementlearning":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}},"topics":{},"roundtables":{},"favlists":{},"comments":{},"notifications":{},"ebooks":{},"activities":{},"feeds":{},"pins":{},"promotions":{},"drafts":{},"chats":{},"posts":{},"clubs":{},"clubTags":{}},"currentUser":"","account":{"lockLevel":{},"unlockTicketStatus":false,"unlockTicket":null,"challenge":[],"errorStatus":false,"message":"","isFetching":false,"accountInfo":{},"urlToken":{"loading":false}},"settings":{"socialBind":null,"inboxMsg":null,"notification":{},"email":{},"privacyFlag":null,"blockedUsers":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"blockedFollowees":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"ignoredTopics":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"restrictedTopics":null,"laboratory":{}},"notification":{},"people":{"profileStatus":{},"activitiesByUser":{},"answersByUser":{},"answersSortByVotesByUser":{},"answersIncludedByUser":{},"votedAnswersByUser":{},"thankedAnswersByUser":{},"voteAnswersByUser":{},"thankAnswersByUser":{},"topicAnswersByUser":{},"zvideosByUser":{},"articlesByUser":{},"articlesSortByVotesByUser":{},"articlesIncludedByUser":{},"pinsByUser":{},"questionsByUser":{},"commercialQuestionsByUser":{},"favlistsByUser":{},"followingByUser":{},"followersByUser":{},"mutualsByUser":{},"followingColumnsByUser":{},"followingQuestionsByUser":{},"followingFavlistsByUser":{},"followingTopicsByUser":{},"publicationsByUser":{},"columnsByUser":{},"allFavlistsByUser":{},"brands":null,"creationsByUser":{},"creationsSortByVotesByUser":{},"creationsFeed":{}},"env":{"ab":{"config":{"experiments":[{"expId":"launch-gw_mweb_rec-1","expPrefix":"gw_mweb_rec","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-qa_hdpimg-2","expPrefix":"qa_hdpimg","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-us_foltopic_user-10","expPrefix":"us_foltopic_user","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_bullet_second-2","expPrefix":"vd_bullet_second","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_zvideo_link-10","expPrefix":"vd_zvideo_link","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false}],"params":[{"id":"se_webtimebox","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_android_join","type":"String","value":"1","chainId":"_all_"},{"id":"li_catalog_card","type":"String","value":"1","chainId":"_all_"},{"id":"gue_thanks","type":"String","value":"0"},{"id":"se_cate_l3","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_rec","type":"String","value":"1","chainId":"_all_"},{"id":"soc_leave_recommend","type":"String","value":"2","chainId":"_all_"},{"id":"tsp_vote","type":"String","value":"2","chainId":"_all_"},{"id":"li_ebook_read","type":"String","value":"0","chainId":"_all_"},{"id":"se_ffzx_jushen1","type":"String","value":"0","chainId":"_all_"},{"id":"se_presearch_ab","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sft","type":"String","value":"a","chainId":"_all_"},{"id":"top_ydyq","type":"String","value":"X","chainId":"_all_"},{"id":"li_ebok_chap","type":"String","value":"0","chainId":"_all_"},{"id":"qap_payc_invite","type":"String","value":"0","chainId":"_all_"},{"id":"se_payconsult","type":"String","value":"0","chainId":"_all_"},{"id":"ug_follow_topic_1","type":"String","value":"2","chainId":"_all_"},{"id":"gue_zvideo_link","type":"String","value":"1"},{"id":"ls_recommend_test","type":"String","value":"0","chainId":"_all_"},{"id":"li_yxzl_new_style_a","type":"String","value":"1","chainId":"_all_"},{"id":"zw_payc_qaedit","type":"String","value":"0","chainId":"_all_"},{"id":"zr_slot_training","type":"String","value":"1","chainId":"_all_"},{"id":"se_entity_model","type":"String","value":"0","chainId":"_all_"},{"id":"se_page_quality","type":"String","value":"0","chainId":"_all_"},{"id":"li_answer_card","type":"String","value":"0","chainId":"_all_"},{"id":"tp_qa_metacard","type":"String","value":"1","chainId":"_all_"},{"id":"li_answers_link","type":"String","value":"0","chainId":"_all_"},{"id":"ug_follow_answerer_0","type":"String","value":"0","chainId":"_all_"},{"id":"se_topicfeed","type":"String","value":"0","chainId":"_all_"},{"id":"se_college_cm","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_head","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zuichangfangwen","type":"String","value":"0","chainId":"_all_"},{"id":"top_test_4_liguangyi","type":"String","value":"1","chainId":"_all_"},{"id":"se_webmajorob","type":"String","value":"0","chainId":"_all_"},{"id":"se_pek_test","type":"String","value":"1","chainId":"_all_"},{"id":"se_relation_1","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_header","type":"String","value":"1","chainId":"_all_"},{"id":"top_ebook","type":"String","value":"0","chainId":"_all_"},{"id":"tp_discover_copy","type":"String","value":"0","chainId":"_all_"},{"id":"ug_zero_follow","type":"String","value":"0","chainId":"_all_"},{"id":"li_purchase_test","type":"String","value":"0","chainId":"_all_"},{"id":"se_webrs","type":"String","value":"1","chainId":"_all_"},{"id":"se_waterfall","type":"String","value":"0","chainId":"_all_"},{"id":"se_backsearch","type":"String","value":"0","chainId":"_all_"},{"id":"tp_discovery_ab_1","type":"String","value":"0","chainId":"_all_"},{"id":"se_zu_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_featured","type":"String","value":"1","chainId":"_all_"},{"id":"se_cardrank_3","type":"String","value":"0","chainId":"_all_"},{"id":"pf_noti_entry_num","type":"String","value":"0","chainId":"_all_"},{"id":"soc_stickypush","type":"String","value":"1","chainId":"_all_"},{"id":"soc_zcfw_shipinshiti","type":"String","value":"1","chainId":"_all_"},{"id":"li_vip_verti_search","type":"String","value":"0","chainId":"_all_"},{"id":"web_collect","type":"String","value":"0"},{"id":"zr_video_rank","type":"String","value":"new_rank","chainId":"_all_"},{"id":"se_new_topic","type":"String","value":"0","chainId":"_all_"},{"id":"se_hotsearch","type":"String","value":"0","chainId":"_all_"},{"id":"li_qa_btn_text","type":"String","value":"0","chainId":"_all_"},{"id":"gue_goods_card","type":"String","value":"0"},{"id":"gue_self_censoring","type":"String","value":"1"},{"id":"se_likebutton","type":"String","value":"0","chainId":"_all_"},{"id":"se_highlight","type":"String","value":"0","chainId":"_all_"},{"id":"web_column_auto_invite","type":"String","value":"0"},{"id":"se_college","type":"String","value":"default","chainId":"_all_"},{"id":"se_p_slideshow","type":"String","value":"0","chainId":"_all_"},{"id":"gue_bullet_second","type":"String","value":"1"},{"id":"se_time_threshold","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iosintimacy","type":"String","value":"2","chainId":"_all_"},{"id":"web_n_web_msg","type":"String","value":"0"},{"id":"web_creator_route","type":"String","value":"1"},{"id":"zr_art_rec","type":"String","value":"base","chainId":"_all_"},{"id":"se_rf_w","type":"String","value":"0","chainId":"_all_"},{"id":"se_zu_recommend","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_discover","type":"String","value":"0","chainId":"_all_"},{"id":"soc_userrec","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_media_icon","type":"String","value":"1","chainId":"_all_"},{"id":"web_sec672","type":"String","value":"0"},{"id":"zr_slot_cold_start","type":"String","value":"aver","chainId":"_all_"},{"id":"se_preset_label","type":"String","value":"1","chainId":"_all_"},{"id":"soc_ri_merge","type":"String","value":"0","chainId":"_all_"},{"id":"web_mweb_rec_length","type":"String","value":"1"},{"id":"zr_answer_rec_cp","type":"String","value":"open","chainId":"_all_"},{"id":"web_unfriendly_comm","type":"String","value":"0"},{"id":"se_prf","type":"String","value":"0","chainId":"_all_"},{"id":"se_article_icon","type":"String","value":"0","chainId":"_all_"},{"id":"web_audit_01","type":"String","value":"case1"},{"id":"se_timebox_up","type":"String","value":"0","chainId":"_all_"},{"id":"se_site_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_use_zitem","type":"String","value":"0","chainId":"_all_"},{"id":"top_v_album","type":"String","value":"1","chainId":"_all_"},{"id":"qap_question_visitor","type":"String","value":" 0","chainId":"_all_"},{"id":"pf_foltopic_usernum","type":"String","value":"50","chainId":"_all_"},{"id":"pf_creator_card","type":"String","value":"1","chainId":"_all_"},{"id":"web_mini_review","type":"String","value":"0"},{"id":"zr_video_rank_nn","type":"String","value":"new_rank","chainId":"_all_"},{"id":"se_sug","type":"String","value":"1","chainId":"_all_"},{"id":"se_billboardsearch","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adreadline","type":"String","value":"0","chainId":"_all_"},{"id":"li_salt_hot","type":"String","value":"1","chainId":"_all_"},{"id":"se_hotmore","type":"String","value":"2","chainId":"_all_"},{"id":"se_adxtest","type":"String","value":"1","chainId":"_all_"},{"id":"gue_video_autoplay","type":"String","value":"0"},{"id":"web_sem_ab","type":"String","value":"1"},{"id":"sem_up_growth","type":"String","value":"in_app","chainId":"_all_"},{"id":"se_relationship","type":"String","value":"1","chainId":"_all_"},{"id":"tp_qa_toast","type":"String","value":"1","chainId":"_all_"},{"id":"soc_zcfw_broadcast","type":"String","value":"0","chainId":"_all_"},{"id":"ls_fmp4","type":"String","value":"0","chainId":"_all_"},{"id":"web_heifetz_grow_ad","type":"String","value":"1"},{"id":"zr_training_boost","type":"String","value":"false","chainId":"_all_"},{"id":"zr_search_sim","type":"String","value":"0","chainId":"_all_"},{"id":"zr_article_new","type":"String","value":"close","chainId":"_all_"},{"id":"se_hot_timebox","type":"String","value":"0","chainId":"_all_"},{"id":"li_assessment_show","type":"String","value":"1","chainId":"_all_"},{"id":"zw_sameq_sorce","type":"String","value":"999","chainId":"_all_"},{"id":"se_whitelist","type":"String","value":"0","chainId":"_all_"},{"id":"ug_newtag","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adsort","type":"String","value":"0","chainId":"_all_"},{"id":"pf_newguide_vertical","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_style","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iosreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"soc_newfeed","type":"String","value":"2","chainId":"_all_"},{"id":"gue_zhuantikapian","type":"String","value":"0"},{"id":"se_ltr_video","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_4","type":"String","value":"1","chainId":"_all_"},{"id":"soc_iosreadline","type":"String","value":"0","chainId":"_all_"},{"id":"pf_fuceng","type":"String","value":"1","chainId":"_all_"},{"id":"se_related_index","type":"String","value":"3","chainId":"_all_"},{"id":"se_pek_test3","type":"String","value":"1","chainId":"_all_"},{"id":"tsp_videobillboard","type":"String","value":"1","chainId":"_all_"},{"id":"qap_question_author","type":"String","value":"0","chainId":"_all_"},{"id":"web_question_invite","type":"String","value":"B"},{"id":"se_ctx_rerank","type":"String","value":"1","chainId":"_all_"},{"id":"soc_adreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"soc_special","type":"String","value":"0","chainId":"_all_"},{"id":"se_expired_ob","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_join","type":"String","value":"0","chainId":"_all_"},{"id":"soc_notification","type":"String","value":"0","chainId":"_all_"},{"id":"soc_yxzl_zcfw","type":"String","value":"0","chainId":"_all_"},{"id":"pf_adjust","type":"String","value":"0","chainId":"_all_"},{"id":"li_svip_cardshow","type":"String","value":"1","chainId":"_all_"},{"id":"se_agency","type":"String","value":" 0","chainId":"_all_"},{"id":"tp_qa_metacard_top","type":"String","value":"top","chainId":"_all_"},{"id":"tp_club_android_feed","type":"String","value":"old","chainId":"_all_"},{"id":"se_ad_index","type":"String","value":"10","chainId":"_all_"},{"id":"tp_club_feed","type":"String","value":"1","chainId":"_all_"},{"id":"web_ad_banner","type":"String","value":"0"},{"id":"zr_search_paid","type":"String","value":"0","chainId":"_all_"},{"id":"zr_intervene","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_1","type":"String","value":"0","chainId":"_all_"},{"id":"se_colorfultab","type":"String","value":"1","chainId":"_all_"},{"id":"se_hotsearch_num","type":"String","value":"0","chainId":"_all_"},{"id":"se_preset_tech","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iospinweight","type":"String","value":"0","chainId":"_all_"},{"id":"soc_brdcst3","type":"String","value":"0","chainId":"_all_"},{"id":"ug_zero_follow_0","type":"String","value":"0","chainId":"_all_"},{"id":"gue_card_test","type":"String","value":"1"},{"id":"zr_video_recall","type":"String","value":"current_recall","chainId":"_all_"},{"id":"web_answer_update","type":"String","value":"0"},{"id":"tp_topic_tab_new","type":"String","value":"0-0-0","chainId":"_all_"},{"id":"top_new_feed","type":"String","value":"5","chainId":"_all_"},{"id":"li_education_box","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_2","type":"String","value":"1","chainId":"_all_"},{"id":"tp_topic_tab","type":"String","value":"0","chainId":"_all_"},{"id":"tp_m_intro_re_topic","type":"String","value":"1","chainId":"_all_"},{"id":"se_famous","type":"String","value":"1","chainId":"_all_"},{"id":"soc_feed_intimacy","type":"String","value":"2","chainId":"_all_"},{"id":"ug_fw_answ_aut_1","type":"String","value":"0","chainId":"_all_"},{"id":"li_pay_banner_type","type":"String","value":"6","chainId":"_all_"},{"id":"se_ios_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"se_aa_base","type":"String","value":"0","chainId":"_all_"},{"id":"se_dnn_mt_v2","type":"String","value":"0","chainId":"_all_"},{"id":"top_quality","type":"String","value":"0","chainId":"_all_"},{"id":"li_hot_voted","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_pic_swiper","type":"String","value":"1","chainId":"_all_"},{"id":"tp_header_style","type":"String","value":"1","chainId":"_all_"},{"id":"qap_ques_invite","type":"String","value":"0","chainId":"_all_"},{"id":"web_answer_list_ad","type":"String","value":"1"},{"id":"zr_expslotpaid","type":"String","value":"1","chainId":"_all_"},{"id":"se_search_feed","type":"String","value":"N","chainId":"_all_"},{"id":"se_topiclabel","type":"String","value":"1","chainId":"_all_"},{"id":"zr_rec_answer_cp","type":"String","value":"close","chainId":"_all_"},{"id":"se_specialbutton","type":"String","value":"0","chainId":"_all_"},{"id":"tsp_hotlist_ui","type":"String","value":"1","chainId":"_all_"},{"id":"soc_update","type":"String","value":"1","chainId":"_all_"},{"id":"soc_cardheight","type":"String","value":"2","chainId":"_all_"},{"id":"se_club_post","type":"String","value":"5","chainId":"_all_"},{"id":"se_new_merger","type":"String","value":"1","chainId":"_all_"},{"id":"se_pek_test2","type":"String","value":"1","chainId":"_all_"},{"id":"se_amovietab","type":"String","value":"1","chainId":"_all_"},{"id":"se_sug_term","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_section","type":"String","value":"0","chainId":"_all_"},{"id":"li_video_section","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sft_v2","type":"String","value":"d","chainId":"_all_"},{"id":"soc_wonderuser_recom","type":"String","value":"2","chainId":"_all_"},{"id":"web_ask","type":"String","value":"0"},{"id":"zr_update_merge_size","type":"String","value":"1","chainId":"_all_"},{"id":"se_mobileweb","type":"String","value":"1","chainId":"_all_"},{"id":"tp_score_1","type":"String","value":"a","chainId":"_all_"},{"id":"tp_club_qa_pic","type":"String","value":"1","chainId":"_all_"},{"id":"li_paid_answer_exp","type":"String","value":"0","chainId":"_all_"},{"id":"zr_slotpaidexp","type":"String","value":"1","chainId":"_all_"},{"id":"se_auto_syn","type":"String","value":"0","chainId":"_all_"},{"id":"se_cbert_index","type":"String","value":"0","chainId":"_all_"},{"id":"ug_goodcomment_0","type":"String","value":"1","chainId":"_all_"},{"id":"li_se_edu","type":"String","value":"1","chainId":"_all_"},{"id":"qap_thanks","type":"String","value":"1","chainId":"_all_"},{"id":"zr_rel_search","type":"String","value":"base","chainId":"_all_"},{"id":"se_movietab","type":"String","value":"1","chainId":"_all_"},{"id":"web_mweb_launch","type":"String","value":"0"},{"id":"li_se_heat","type":"String","value":"1","chainId":"_all_"},{"id":"se_new_p","type":"String","value":"0","chainId":"_all_"},{"id":"se_wannasearch","type":"String","value":"0","chainId":"_all_"},{"id":"ls_videoad","type":"String","value":"2","chainId":"_all_"},{"id":"soc_authormore","type":"String","value":"2","chainId":"_all_"},{"id":"ug_follow_answerer","type":"String","value":"0","chainId":"_all_"},{"id":"li_svip_tab_search","type":"String","value":"0","chainId":"_all_"},{"id":"qap_article_like","type":"String","value":"1","chainId":"_all_"},{"id":"zr_km_answer","type":"String","value":"open_cvr","chainId":"_all_"},{"id":"se_entity_model_14","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adpinweight","type":"String","value":"0","chainId":"_all_"},{"id":"zr_ans_rec","type":"String","value":"gbrank","chainId":"_all_"},{"id":"se_subtext","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sticky_android","type":"String","value":"2","chainId":"_all_"},{"id":"tp_club_tab_feed","type":"String","value":"0","chainId":"_all_"},{"id":"top_root","type":"String","value":"0","chainId":"_all_"},{"id":"li_android_vip","type":"String","value":"0","chainId":"_all_"},{"id":"li_sku_bottom_bar_re","type":"String","value":"0","chainId":"_all_"},{"id":"zr_test_aa1","type":"String","value":"0","chainId":"_all_"},{"id":"se_aa","type":"String","value":"0","chainId":"_all_"},{"id":"se_multianswer","type":"String","value":"2","chainId":"_all_"},{"id":"se_searchwiki","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_entry","type":"String","value":"0","chainId":"_all_"},{"id":"se_click_club","type":"String","value":"1","chainId":"_all_"},{"id":"soc_bignew","type":"String","value":"1","chainId":"_all_"},{"id":"soc_bigone","type":"String","value":"0","chainId":"_all_"},{"id":"web_answerlist_ad","type":"String","value":"0"},{"id":"web_upload","type":"String","value":"1"},{"id":"web_hdpimg","type":"String","value":"1"},{"id":"zr_training_first","type":"String","value":"false","chainId":"_all_"},{"id":"soc_iossort","type":"String","value":"0","chainId":"_all_"},{"id":"li_answer_label","type":"String","value":"0","chainId":"_all_"},{"id":"zr_km_feed_nlp","type":"String","value":"old","chainId":"_all_"},{"id":"se_sug_entrance","type":"String","value":"1","chainId":"_all_"},{"id":"top_universalebook","type":"String","value":"1","chainId":"_all_"},{"id":"gue_new_special_page","type":"String","value":"1"},{"id":"tp_club_pic","type":"String","value":"0.6","chainId":"_all_"},{"id":"tp_club_pk","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_tab","type":"String","value":"0","chainId":"_all_"},{"id":"top_hotcommerce","type":"String","value":"1","chainId":"_all_"},{"id":"soc_zcfw_badcase","type":"String","value":"0","chainId":"_all_"},{"id":"li_qa_new_cover","type":"String","value":"1","chainId":"_all_"},{"id":"li_se_across","type":"String","value":"1","chainId":"_all_"},{"id":"se_hotsearch_2","type":"String","value":"1","chainId":"_all_"},{"id":"se_content0","type":"String","value":"0","chainId":"_all_"},{"id":"tp_meta_card","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zcfw_broadcast2","type":"String","value":"1","chainId":"_all_"},{"id":"se_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"se_col_boost","type":"String","value":"0","chainId":"_all_"},{"id":"se_lottery","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_qa","type":"String","value":"1","chainId":"_all_"},{"id":"tp_discover","type":"String","value":"0","chainId":"_all_"},{"id":"li_ebook_gen_search","type":"String","value":"0","chainId":"_all_"},{"id":"soc_brdcst4","type":"String","value":"3","chainId":"_all_"},{"id":"gue_video_replay","type":"String","value":"0"},{"id":"se_websearch","type":"String","value":"3","chainId":"_all_"},{"id":"soc_authormore2","type":"String","value":"2","chainId":"_all_"},{"id":"gue_bullet_guide","type":"String","value":"发个弹幕聊聊…"}],"chains":[{"chainId":"_all_"}]},"triggers":{}},"userAgent":{"Edge":false,"Wechat":false,"Weibo":false,"QQ":false,"MQQBrowser":false,"Qzone":false,"Mobile":false,"Android":false,"iOS":false,"isAppleDevice":false,"Zhihu":false,"ZhihuHybrid":false,"isBot":false,"Tablet":false,"UC":false,"Sogou":false,"Qihoo":false,"Baidu":false,"BaiduApp":false,"Safari":false,"GoogleBot":false,"AndroidDaily":false,"iOSDaily":false,"isWebView":false,"origin":"Mozilla\u002F5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\u002F537.36 (KHTML, like Gecko) Chrome\u002F80.0.3987.100 Safari\u002F537.36"},"appViewConfig":{},"ctx":{"path":"\u002Fp\u002F58053501","query":{},"href":"http:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F58053501","host":"zhuanlan.zhihu.com"},"trafficSource":"production","edition":{"baidu":false,"sogou":false,"baiduBeijing":false,"sogouBeijing":false,"sogouInput":false},"theme":"light","enableShortcut":true,"referer":"","conf":{},"ipInfo":{"cityName":"德州","countryName":"中国","regionName":"山东","countryCode":"CN"},"logged":false},"me":{"columnContributions":[]},"label":{"recognizerLists":{}},"ecommerce":{},"comments":{"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"parent":{}},"commentsV2":{"stickers":[],"commentWithPicPermission":{},"notificationsComments":{},"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"conversationMore":{},"parent":{}},"pushNotifications":{"default":{"isFetching":false,"isDrained":false,"ids":[]},"follow":{"isFetching":false,"isDrained":false,"ids":[]},"vote_thank":{"isFetching":false,"isDrained":false,"ids":[]},"currentTab":"default","notificationsCount":{"default":0,"follow":0,"vote_thank":0}},"messages":{"data":{},"currentTab":"common","messageCount":0},"register":{"registerValidateSucceeded":null,"registerValidateErrors":{},"registerConfirmError":null,"sendDigitsError":null,"registerConfirmSucceeded":null},"login":{"loginUnregisteredError":false,"loginBindWechatError":false,"loginConfirmError":null,"sendDigitsError":null,"needSMSIdentify":false,"validateDigitsError":false,"loginConfirmSucceeded":null,"qrcodeLoginToken":"","qrcodeLoginScanStatus":0,"qrcodeLoginError":null,"qrcodeLoginReturnNewToken":false},"active":{"sendDigitsError":null,"activeConfirmSucceeded":null,"activeConfirmError":null},"switches":{},"captcha":{"captchaNeeded":false,"captchaValidated":false,"captchaBase64String":null,"captchaValidationMessage":null,"loginCaptchaExpires":false},"sms":{"supportedCountries":[]},"chat":{"chats":{},"inbox":{"recents":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"strangers":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"friends":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"search":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"config":{"newCount":0,"strangerMessageSwitch":false,"strangerMessageUnread":false,"friendCount":0}},"global":{"isChatMqttExisted":false}},"emoticons":{"emoticonGroupList":[],"emoticonGroupDetail":{}},"creator":{"currentCreatorUrlToken":null,"homeData":{"recommendQuestions":[]},"tools":{"question":{"invitationCount":{"questionFolloweeCount":0,"questionTotalCount":0},"goodatTopics":[]},"customPromotion":{"itemLists":{}},"recommend":{"recommendTimes":{}}},"explore":{"academy":{"tabs":[],"article":{}}},"rights":[],"rightsStatus":{},"levelUpperLimit":10,"account":{"growthLevel":{}},"mcn":{},"applyStatus":{}},"recommendation":{"homeRecommendations":[]},"shareTexts":{},"articles":{"voters":{}},"previewPost":{},"favlists":{"relations":{}},"columns":{"voters":{}},"reward":{"answer":{},"article":{},"question":{}},"video":{"data":{},"shareVideoDetail":{},"last":{}},"topstory":{"recommend":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"follow":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followWonderful":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"sidebar":null,"announcement":{},"hotListCategories":[],"hotList":[],"guestFeeds":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followExtra":{"isNewUser":null,"isFetched":false,"followCount":0,"followers":[]}},"readStatus":{},"column":{},"requestColumn":{"categories":[],"error":null},"articleContribution":{"contributeRequests":[],"deleteContributeIdList":[],"handledContributeIdList":[],"recommendedColumns":[],"pinnedColumns":[],"sentContributeRequestsIdList":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"reinforcementlearning"]},"columnContribution":{"contributeRequests":[],"autoInviteEnabled":false,"recommendedContributors":[],"contributionInvitation":null},"draftHistory":{"history":{},"drafts":{}},"upload":{},"articleDraft":{"titleImage":"","titleImageSize":{},"isTitleImageFullScreen":false,"canTitleImageFullScreen":false,"title":"","titleImageUploading":false,"error":"","content":"","draftLoading":false,"updating":false,"globalLoading":false,"pendingVideo":{"resource":null,"error":null},"deleteFail":{"fail":false},"recommendTopics":[],"selectedColumn":0,"articleDisclaimers":[]},"articleDrafts":{"isDrained":false,"isLoading":false,"items":[]},"columnAutocomplete":{"users":[],"friends":[]},"columnCollection":{},"mcn":{"bindInfo":{},"memberCategoryList":[],"producerList":[],"categoryList":[]}},"fetchHost":"www.zhihu.com","subAppName":"column"}</script><script src="https://static.zhihu.com/heifetz/vendor.7b36fae46082fd30a0db.js"></script><script src="https://static.zhihu.com/heifetz/column.app.76e02b16e87eec249f44.js"></script></body><script src="https://hm.baidu.com/hm.js?98beee57fd2ef70ccdd5ca52b9740c49" async=""></script><script src="https://zz.bdstatic.com/linksubmit/push.js" async=""></script></html>