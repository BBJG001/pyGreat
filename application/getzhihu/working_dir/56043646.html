<!doctype html>
<html lang="zh" data-hairline="true" data-theme="light"><head><meta charSet="utf-8"/><title data-react-helmet="true">AlphaStar之IMPALA - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"/><meta name="renderer" content="webkit"/><meta name="force-rendering" content="webkit"/><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg"/><meta data-react-helmet="true" name="keywords" content="强化学习 (Reinforcement Learning)"/><meta data-react-helmet="true" name="description" content="前两天DeepMind终于爆出了在星际2上的最新进展，我是看着羡慕（详见：AlphaStar: Mastering the Real-Time Strategy Game StarCraft II | DeepMind）。里面提到了应用到的各种技术：Transformer, LSTM, pointer ne…"/><meta data-react-helmet="true" property="og:title" content="AlphaStar之IMPALA"/><meta data-react-helmet="true" property="og:url" content="https://zhuanlan.zhihu.com/p/56043646"/><meta data-react-helmet="true" property="og:description" content="前两天DeepMind终于爆出了在星际2上的最新进展，我是看着羡慕（详见：AlphaStar: Mastering the Real-Time Strategy Game StarCraft II | DeepMind）。里面提到了应用到的各种技术：Transformer, LSTM, pointer ne…"/><meta data-react-helmet="true" property="og:image" content="https://pic4.zhimg.com/v2-94f9308f50f6183575daed66f99ca160_b.jpg"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" property="og:site_name" content="知乎专栏"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png" sizes="152x152"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-120.b3e6278d.png" sizes="120x120"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-76.7a750095.png" sizes="76x76"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-60.a4a761d4.png" sizes="60x60"/><link rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/static/favicon.ico"/><link rel="search" type="application/opensearchdescription+xml" href="https://static.zhihu.com/static/search.xml" title="知乎"/><link rel="dns-prefetch" href="//static.zhimg.com"/><link rel="dns-prefetch" href="//pic1.zhimg.com"/><link rel="dns-prefetch" href="//pic2.zhimg.com"/><link rel="dns-prefetch" href="//pic3.zhimg.com"/><link rel="dns-prefetch" href="//pic4.zhimg.com"/><style>
.u-safeAreaInset-top {
  height: constant(safe-area-inset-top) !important;
  height: env(safe-area-inset-top) !important;
  
}
.u-safeAreaInset-bottom {
  height: constant(safe-area-inset-bottom) !important;
  height: env(safe-area-inset-bottom) !important;
  
}
</style><link href="https://static.zhihu.com/heifetz/column.app.a9ced452148fee3a55c8.css" rel="stylesheet"/><script defer="" crossorigin="anonymous" src="https://unpkg.zhimg.com/@cfe/sentry-script@latest/dist/init.js" data-sentry-config="{&quot;dsn&quot;:&quot;https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224&quot;,&quot;sampleRate&quot;:0.1,&quot;release&quot;:&quot;683-127b14ad&quot;,&quot;ignoreErrorNames&quot;:[&quot;NetworkError&quot;,&quot;SecurityError&quot;],&quot;ignoreErrors&quot;:[&quot;origin message&quot;,&quot;Network request failed&quot;,&quot;Loading chunk&quot;,&quot;这个系统不支持该功能。&quot;,&quot;Can&#x27;t find variable: webkit&quot;,&quot;Can&#x27;t find variable: $&quot;,&quot;内存不足&quot;,&quot;out of memory&quot;,&quot;DOM Exception 18&quot;,&quot;The operation is insecure&quot;,&quot;[object Event]&quot;,&quot;[object FileError]&quot;,&quot;[object DOMError]&quot;,&quot;[object Object]&quot;,&quot;拒绝访问。&quot;,&quot;Maximum call stack size exceeded&quot;,&quot;UploadError&quot;,&quot;无法 fetch&quot;,&quot;draft-js&quot;,&quot;缺少 JavaScript 对象&quot;,&quot;componentWillEnter&quot;,&quot;componentWillLeave&quot;,&quot;componentWillAppear&quot;,&quot;getInlineStyleAt&quot;,&quot;getCharacterList&quot;],&quot;whitelistUrls&quot;:[&quot;static.zhihu.com&quot;]}"></script></head><body class="WhiteBg-body"><div id="root"><div class="App"><div class="LoadingBar"></div><main role="main" class="App-main"><div class="Post-content" data-zop-usertoken="{&quot;userToken&quot;:&quot;&quot;}" data-zop="{&quot;authorName&quot;:&quot;starimpact&quot;,&quot;itemId&quot;:56043646,&quot;title&quot;:&quot;AlphaStar之IMPALA&quot;,&quot;type&quot;:&quot;article&quot;}"><div class="ColumnPageHeader-Wrapper"><div><div class="Sticky ColumnPageHeader"><div class="ColumnPageHeader-content"><a href="//www.zhihu.com" aria-label="知乎"><svg viewBox="0 0 200 91" fill="#0084FF" width="64" height="30"><path d="M53.29 80.035l7.32.002 2.41 8.24 13.128-8.24h15.477v-67.98H53.29v67.978zm7.79-60.598h22.756v53.22h-8.73l-8.718 5.473-1.587-5.46-3.72-.012v-53.22zM46.818 43.162h-16.35c.545-8.467.687-16.12.687-22.955h15.987s.615-7.05-2.68-6.97H16.807c1.09-4.1 2.46-8.332 4.1-12.708 0 0-7.523 0-10.085 6.74-1.06 2.78-4.128 13.48-9.592 24.41 1.84-.2 7.927-.37 11.512-6.94.66-1.84.785-2.08 1.605-4.54h9.02c0 3.28-.374 20.9-.526 22.95H6.51c-3.67 0-4.863 7.38-4.863 7.38H22.14C20.765 66.11 13.385 79.24 0 89.62c6.403 1.828 12.784-.29 15.937-3.094 0 0 7.182-6.53 11.12-21.64L43.92 85.18s2.473-8.402-.388-12.496c-2.37-2.788-8.768-10.33-11.496-13.064l-4.57 3.627c1.363-4.368 2.183-8.61 2.46-12.71H49.19s-.027-7.38-2.372-7.38zm128.752-.502c6.51-8.013 14.054-18.302 14.054-18.302s-5.827-4.625-8.556-1.27c-1.874 2.548-11.51 15.063-11.51 15.063l6.012 4.51zm-46.903-18.462c-2.814-2.577-8.096.667-8.096.667s12.35 17.2 12.85 17.953l6.08-4.29s-8.02-11.752-10.83-14.33zM199.99 46.5c-6.18 0-40.908.292-40.953.292v-31.56c1.503 0 3.882-.124 7.14-.376 12.773-.753 21.914-1.25 27.427-1.504 0 0 3.817-8.496-.185-10.45-.96-.37-7.24 1.43-7.24 1.43s-51.63 5.153-72.61 5.64c.5 2.756 2.38 5.336 4.93 6.11 4.16 1.087 7.09.53 15.36.277 7.76-.5 13.65-.76 17.66-.76v31.19h-41.71s.88 6.97 7.97 7.14h33.73v22.16c0 4.364-3.498 6.87-7.65 6.6-4.4.034-8.15-.36-13.027-.566.623 1.24 1.977 4.496 6.035 6.824 3.087 1.502 5.054 2.053 8.13 2.053 9.237 0 14.27-5.4 14.027-14.16V53.93h38.235c3.026 0 2.72-7.432 2.72-7.432z" fill-rule="evenodd"></path></svg></a><i class="ColumnPageHeader-Line"></i><div class="ColumnPageHeader-Title"><a class="ColumnLink ColumnPageHeader-Link" href="/sharerl"><img class="Avatar Avatar--round" width="30" height="30" src="https://pic2.zhimg.com/4b70deef7_is.jpg" srcSet="https://pic2.zhimg.com/4b70deef7_im.jpg 2x" alt="强化学习知识大讲堂"/></a><div class="ColumnPageHeader-TitleName"><span class="ColumnPageHeader-TitleMeta">首发于</span><a class="ColumnLink ColumnPageHeader-TitleColumn" href="/sharerl">强化学习知识大讲堂</a></div></div><div class="ColumnPageHeader-Button"><button type="button" class="Button ColumnPageHeader-WriteButton Button--blue"><svg class="Zi Zi--EditSurround" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M18.453 7.992l-1.833-1.65.964-.978a1.223 1.223 0 0 1 1.73-.012l.005.006a1.24 1.24 0 0 1 .007 1.748l-.873.886zm-1.178 1.194l-5.578 5.66-1.935.697a.393.393 0 0 1-.504-.504l.697-1.935 5.488-5.567 1.832 1.65zM7.58 5.848l5.654.006-1.539 1.991-3.666.012A1.02 1.02 0 0 0 7 8.868v7.993c0 .558.46 1.01 1.029 1.01l7.941-.01c.568 0 1.03-.453 1.03-1.012v-4.061l2-1.442v6.002c0 1.397-1.2 2.501-2.62 2.501H7.574C6.153 19.85 5 18.717 5 17.32V8.35c0-1.397 1.16-2.502 2.58-2.502z"></path></svg>写文章</button></div></div></div></div></div><img class="TitleImage" src="https://pic4.zhimg.com/v2-94f9308f50f6183575daed66f99ca160_1200x500.jpg" alt="AlphaStar之IMPALA"/><article class="Post-Main Post-NormalMain" tabindex="-1"><header class="Post-Header"><h1 class="Post-Title">AlphaStar之IMPALA</h1><div class="Post-Author"><div class="AuthorInfo" itemProp="author" itemscope="" itemType="http://schema.org/Person"><meta itemProp="name" content="starimpact"/><meta itemProp="image" content="https://pic2.zhimg.com/a7f705d126a5c3ca8cac811c1ea0f596_l.jpg"/><meta itemProp="url" content="https://www.zhihu.com/people/zhang-ming-28-20"/><meta itemProp="zhihu:followerCount"/><span class="UserLink AuthorInfo-avatarWrapper"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/zhang-ming-28-20"><img class="Avatar Avatar--round AuthorInfo-avatar" width="38" height="38" src="https://pic2.zhimg.com/a7f705d126a5c3ca8cac811c1ea0f596_xs.jpg" srcSet="https://pic2.zhimg.com/a7f705d126a5c3ca8cac811c1ea0f596_l.jpg 2x" alt="starimpact"/></a></div></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/zhang-ming-28-20">starimpact</a></div></div><style data-emotion-css="1cd9gw4">.css-1cd9gw4{margin-left:.3em;}</style></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="ztext AuthorInfo-badgeText">计算视觉</div></div></div></div></div></div><div><span class="Voters"><button type="button" class="Button Button--plain">68 人<!-- -->赞同了该文章</button></span></div></header><div class="Post-RichTextContainer"><div class="RichText ztext Post-RichText"><p>    前两天DeepMind终于爆出了在星际2上的最新进展，我是看着羡慕（详见：<a href="https://link.zhihu.com/?target=https%3A//deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/" class=" wrap external" target="_blank" rel="nofollow noreferrer">AlphaStar: Mastering the Real-Time Strategy Game StarCraft II | DeepMind</a>）。里面提到了应用到的各种技术：Transformer, LSTM, pointer network, novel off-policy actor-critic rl, self-imitation learning, policy distillation等等。前面几个网络结构都可以搜到中文，但是后面若干算法就比较难找了。在这里，我先说一下novel off-policy actor-critic rl，即IMPALA。</p><p>    强化学习需要大量在线得到的样本。这就涉及到其中一个问题：产生的样本怎么处理？如果是on-policy的RL算法，样本用过一次就扔掉，十分浪费（千辛万苦采到的样本，就用一次？太浪费了！哪个监督学习里的样本不用个百八十次的~）。如果off-policy的RL算法就可以做到以前的样本反复利用（有RL基础的同学可以马上联想到Deep Q-Learning的Replay Buffer）。</p><p>    涉及到的第二个问题：如何高效的产生样本？当然是并行或分布式啦！Actor和Learner各干各的，谁都不要等谁。Actor们（不只一个）不断地将采到的样本放到Replay Buffer里，并周期性地从Learner那拿到最新的参数。Learner不断地从Replay Buffer里拿样本过来训练自己的参数。要达到这样的目的，也只有off-policy的方法可以这么干了。而如果是on-policy的方法就要遵循：Actor放样本到buffer-&gt;Learner取样本训练参数-&gt;Actor取最新的参数-&gt;Actor执行动作收集样本-&gt;Actor放样本到buffer，这个过程按顺序来的，无法并行。</p><p>    涉及到的第三个问题：off-policy的方法是可以让样本收集和学习变成并行，还可以利用老样本，但是那些比较老的样本就这么直接拿来更新当前的参数，也会产生利用效率不高的问题（可以理解成并不能有效提升当前的Agent水平）。</p><p>    好啦，谁能解决上面三个问题？IMPALA的V-trace！</p><p>    IMPALA这么怪的名字？<b>IMP</b>ortance weighted <b>A</b>ctor-<b>L</b>earner <b>A</b>rchitecture！大家都以为是六个单词的首字母~现在的简写真是没有底线了^_^。</p><p>    先上一下V-trace target本尊：</p><p><img src="https://www.zhihu.com/equation?tex=v_%7Bs%7D+%3D+V_%7Bx_%7Bs%7D%7D%2B%5Csum_%7Bt%3Ds%7D%5E%7Bs%2Bn-1%7D%7B%5Cgamma%5E%7Bt-s%7D%28%5CPi_%7Bi%3Ds%7D%5E%7Bt-1%7D%7Bc_%7Bi%7D%7D%29%5Cdelta_%7Bt%7DV%7D+" alt="v_{s} = V_{x_{s}}+\sum_{t=s}^{s+n-1}{\gamma^{t-s}(\Pi_{i=s}^{t-1}{c_{i}})\delta_{t}V} " eeimg="1"/> --------(1)</p><p>    非常复杂，看不懂，有没有？看看里面一些变量的定义是什么：</p><p><img src="https://www.zhihu.com/equation?tex=%5Cdelta_%7Bt%7DV%3D%5Crho_%7Bt%7D%28r_%7Bt%7D%2B%5Cgamma+V_%7Bx_%7Bt%2B1%7D%7D-V_%7Bx_%7Bt%7D%7D%29" alt="\delta_{t}V=\rho_{t}(r_{t}+\gamma V_{x_{t+1}}-V_{x_{t}})" eeimg="1"/> </p><p>    括号里的表达式是Temporal Difference，然而外面的 <img src="https://www.zhihu.com/equation?tex=%5Crho_%7Bt%7D" alt="\rho_{t}" eeimg="1"/> 是什么含义了？</p><p><img src="https://www.zhihu.com/equation?tex=%5Crho_%7Bt%7D+%3D+min%28%5Cbar%7B%5Crho%7D%2C+%5Cfrac%7B%5Cpi%28a_t%7Cx_t%29%7D%7B%5Cmu%28a_t%7Cx_t%29%7D%29" alt="\rho_{t} = min(\bar{\rho}, \frac{\pi(a_t|x_t)}{\mu(a_t|x_t)})" eeimg="1"/> </p><p>    还有其它变量的定义：</p><p><img src="https://www.zhihu.com/equation?tex=c_i+%3D+min%28%5Cbar%7Bc%7D%2C+%5Cfrac%7B%5Cpi%28a_i%7Cx_i%29%7D%7B%5Cmu%28a_i%7Cx_i%29%7D%29" alt="c_i = min(\bar{c}, \frac{\pi(a_i|x_i)}{\mu(a_i|x_i)})" eeimg="1"/> </p><p><img src="https://www.zhihu.com/equation?tex=%5Cbar%7B%5Crho%7D+%5Cgeq+%5Cbar%7Bc%7D" alt="\bar{\rho} \geq \bar{c}" eeimg="1"/> </p><p>    看到 <img src="https://www.zhihu.com/equation?tex=%5Crho_t" alt="\rho_t" eeimg="1"/> 和 <img src="https://www.zhihu.com/equation?tex=c_i" alt="c_i" eeimg="1"/> 的表达式，是不是联想起什么了？这就是<b>I</b>mportance <b>S</b>ampling。从策略 <img src="https://www.zhihu.com/equation?tex=%5Cmu" alt="\mu" eeimg="1"/> 中采样，更新当前的策略 <img src="https://www.zhihu.com/equation?tex=%5Cpi" alt="\pi" eeimg="1"/> 。只不过加上了最大值的限制，不能超过 <img src="https://www.zhihu.com/equation?tex=%5Cbar%7B%5Crho%7D" alt="\bar{\rho}" eeimg="1"/> 和 <img src="https://www.zhihu.com/equation?tex=%5Cbar%7Bc%7D" alt="\bar{c}" eeimg="1"/> ，也就是说进行了截断处理，一般情况下这两个值可以设置成1啦。</p><p>    要进一步理解 <img src="https://www.zhihu.com/equation?tex=%5Crho_t" alt="\rho_t" eeimg="1"/> 的意义可以看下面的表达式（为什么会出现这样的表达式，这个要看原论文）：</p><p><img src="https://www.zhihu.com/equation?tex=%5Cpi_%7B%5Cbar%7B%5Crho%7D%7D%28a%7Cx%29%3D%5Cfrac%7Bmin%28%5Cbar%7B%5Crho%7D%5Cmu%28a%7Cx%29%2C+%5Cpi%28a%7Cx%29%29%7D%7B%5Csum_%7Bb+%5Cin+x%7D%7Bmin%28%5Cbar%7B%5Crho%7D%5Cmu%28b%7Cx%29%2C+%5Cpi%28b%7Cx%29%29%7D%7D" alt="\pi_{\bar{\rho}}(a|x)=\frac{min(\bar{\rho}\mu(a|x), \pi(a|x))}{\sum_{b \in x}{min(\bar{\rho}\mu(b|x), \pi(b|x))}}" eeimg="1"/> </p><p><img src="https://www.zhihu.com/equation?tex=%5Cpi_%7B%5Cbar%7B%5Crho%7D%7D" alt="\pi_{\bar{\rho}}" eeimg="1"/>是一个介于 <img src="https://www.zhihu.com/equation?tex=%5Cpi" alt="\pi" eeimg="1"/> 和 <img src="https://www.zhihu.com/equation?tex=%5Cmu" alt="\mu" eeimg="1"/> 的中间态的策略。为什么这么定义了？如果当 <img src="https://www.zhihu.com/equation?tex=%5Cbar%7B%5Crho%7D%3D%5Cinfty" alt="\bar{\rho}=\infty" eeimg="1"/> ，那么 <img src="https://www.zhihu.com/equation?tex=%5Cpi_%7B%5Cbar%7B%5Crho%7D%7D" alt="\pi_{\bar{\rho}}" eeimg="1"/> 就会变成策略 <img src="https://www.zhihu.com/equation?tex=%5Cpi" alt="\pi" eeimg="1"/> ，如果 <img src="https://www.zhihu.com/equation?tex=%5Cbar%7B%5Crho%7D%5CRightarrow+0" alt="\bar{\rho}\Rightarrow 0" eeimg="1"/> （是接近于0，不是等于），那么<img src="https://www.zhihu.com/equation?tex=%5Cpi_%7B%5Cbar%7B%5Crho%7D%7D" alt="\pi_{\bar{\rho}}" eeimg="1"/>就会变成策略 <img src="https://www.zhihu.com/equation?tex=%5Cmu" alt="\mu" eeimg="1"/> 。（所以 <img src="https://www.zhihu.com/equation?tex=%5Cbar%7B%5Crho%7D" alt="\bar{\rho}" eeimg="1"/> 越大，那么off-policy学习的bias就越小，相应的variance就越大。）</p><p><img src="https://www.zhihu.com/equation?tex=c_i" alt="c_i" eeimg="1"/> 的乘积表示 <img src="https://www.zhihu.com/equation?tex=%5Cdelta_tV" alt="\delta_tV" eeimg="1"/> 在时刻 <img src="https://www.zhihu.com/equation?tex=t" alt="t" eeimg="1"/> 影响前面时刻 <img src="https://www.zhihu.com/equation?tex=s" alt="s" eeimg="1"/> 的值函数更新的强弱程度。 <img src="https://www.zhihu.com/equation?tex=%5Cpi" alt="\pi" eeimg="1"/> 和 <img src="https://www.zhihu.com/equation?tex=%5Cmu" alt="\mu" eeimg="1"/> 差距越大，那么off-poliocy越明显，那么这个乘积的variance就越大。这里用了截断方法来控制这种variance。</p><p><img src="https://www.zhihu.com/equation?tex=%5Cbar%7B%5Crho%7D" alt="\bar{\rho}" eeimg="1"/> 影响的是要收敛到什么样的值函数，而 <img src="https://www.zhihu.com/equation?tex=%5Cbar%7Bc%7D" alt="\bar{c}" eeimg="1"/> 影响的是收敛到这个值函数的速度。（突然间出来了值函数，有什么样的策略就有什么样的值函数，二者是对应的，就这么理解吧。）</p><p>    要注意的是， <img src="https://www.zhihu.com/equation?tex=v_s" alt="v_s" eeimg="1"/> 在on-policy的情况下（即 <img src="https://www.zhihu.com/equation?tex=%5Cpi+%3D+%5Cmu" alt="\pi = \mu" eeimg="1"/>），并让 <img src="https://www.zhihu.com/equation?tex=c_i+%3D+1" alt="c_i = 1" eeimg="1"/> ，且 <img src="https://www.zhihu.com/equation?tex=%5Crho_t+%3D+1" alt="\rho_t = 1" eeimg="1"/> ，就会变成下式：</p><p><img src="https://www.zhihu.com/equation?tex=v_s+%3D+V%28x_s%29+%2B+%5Csum_%7Bt%3Ds%7D%5E%7Bs%2Bn-1%7D%7B%5Cgamma%5E%7Bt-s%7D%28r_t%2B%5Cgamma+V%28x_%7Bt%2B1%7D%29-V%28x_t%29%29%7D+%3D%5Csum_%7Bt%3Ds%7D%5E%7Bs%2Bn-1%7D%7B%5Cgamma%5E%7Bt-s%7Dr_t%7D%2B%5Cgamma%5E%7Bn%7DV%28x_%7Bs%2Bn%7D%29" alt="v_s = V(x_s) + \sum_{t=s}^{s+n-1}{\gamma^{t-s}(r_t+\gamma V(x_{t+1})-V(x_t))} =\sum_{t=s}^{s+n-1}{\gamma^{t-s}r_t}+\gamma^{n}V(x_{s+n})" eeimg="1"/> --------(2)</p><p>    这个式子是Bellman Target (类似于TD Target)。也就是说式(1)在on-policy的特殊情况下就变成了式(2)。于是，同样的算法可以把off和on两种policy通吃了。</p><p>    V-trace targets 可以用迭代的方式进行计算（让人联想到back view TD( <img src="https://www.zhihu.com/equation?tex=%5Clambda" alt="\lambda" eeimg="1"/> )，实际上在某些条件下确实也可以将它转化到TD( <img src="https://www.zhihu.com/equation?tex=%5Clambda" alt="\lambda" eeimg="1"/> )，具体看论文）：</p><p><img src="https://www.zhihu.com/equation?tex=v_s+%3D+V%28x_s%29+%2B+%5Cdelta_sV%2B%5Cgamma+c_s+%28v_%7Bs%2B1%7D+-+V%28x_%7Bs%2B1%7D%29%29" alt="v_s = V(x_s) + \delta_sV+\gamma c_s (v_{s+1} - V(x_{s+1}))" eeimg="1"/> </p><p>--------------------我是可爱的分割线--------------------</p><p>    其实重点基本都讲完了，下面讲怎么用 <img src="https://www.zhihu.com/equation?tex=v_s" alt="v_s" eeimg="1"/> 。这实际上就是actor-crtitic的标准训练方法了。</p><p>    首先，更新critic时用的梯度：</p><p><img src="https://www.zhihu.com/equation?tex=%28v_s+-+V_%5Ctheta%28x_s%29%29%5CDelta_%5Ctheta+V_%5Ctheta%28x_s%29" alt="(v_s - V_\theta(x_s))\Delta_\theta V_\theta(x_s)" eeimg="1"/> </p><p>    然后，更新actor时用的梯度：</p><p><img src="https://www.zhihu.com/equation?tex=%5Crho_s+%5CDelta_%5Comega+log+%5Cpi_%5Comega%28a_s%7Cx_s%29%28r_s%2B%5Cgamma+v_%7Bs%2B1%7D+-+V_%5Ctheta+%28x_s%29%29" alt="\rho_s \Delta_\omega log \pi_\omega(a_s|x_s)(r_s+\gamma v_{s+1} - V_\theta (x_s))" eeimg="1"/> </p><p>    为了防止过早的收敛，为actor的梯度加一个policy entropy(熵)的惩罚：</p><p><img src="https://www.zhihu.com/equation?tex=-%5CDelta_%5Comega+%5Csum_%7Ba%7D%7B%5Cpi_%5Comega%28a%7Cx_s%29log+%5Cpi_%5Comega%28a%7Cx_s%29%7D" alt="-\Delta_\omega \sum_{a}{\pi_\omega(a|x_s)log \pi_\omega(a|x_s)}" eeimg="1"/> </p><p>--------------------我是可爱的分割线--------------------</p><p>    下面简单看看实验部分。先看看网络是啥样子（做了大小网络实验）：</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-be7932caddcfcea97a4322f2395dbced_b.jpg" data-caption="" data-size="normal" data-rawwidth="1972" data-rawheight="1522" class="origin_image zh-lightbox-thumb" width="1972" data-original="https://pic2.zhimg.com/v2-be7932caddcfcea97a4322f2395dbced_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1972&#39; height=&#39;1522&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1972" data-rawheight="1522" class="origin_image zh-lightbox-thumb lazy" width="1972" data-original="https://pic2.zhimg.com/v2-be7932caddcfcea97a4322f2395dbced_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-be7932caddcfcea97a4322f2395dbced_b.jpg"/></figure><p>    再看看Replay Buffer对比实验：</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-f361ff8d4613bc98b6c28ab017d9791a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1650" data-rawheight="1334" class="origin_image zh-lightbox-thumb" width="1650" data-original="https://pic3.zhimg.com/v2-f361ff8d4613bc98b6c28ab017d9791a_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1650&#39; height=&#39;1334&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1650" data-rawheight="1334" class="origin_image zh-lightbox-thumb lazy" width="1650" data-original="https://pic3.zhimg.com/v2-f361ff8d4613bc98b6c28ab017d9791a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-f361ff8d4613bc98b6c28ab017d9791a_b.jpg"/></figure><p>    在应用完整V-trace的情况下Replay Buffer的提升作用明显。如果去掉了off-policy的correction部分，那么就会产生负作用，可以看上面的No-correction行。</p><p>    最后看看训练速度，数据吞吐率：</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-468cfa59a3d2b598b76e4e3bfdc1b4b8_b.jpg" data-caption="" data-size="normal" data-rawwidth="1826" data-rawheight="1950" class="origin_image zh-lightbox-thumb" width="1826" data-original="https://pic1.zhimg.com/v2-468cfa59a3d2b598b76e4e3bfdc1b4b8_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1826&#39; height=&#39;1950&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1826" data-rawheight="1950" class="origin_image zh-lightbox-thumb lazy" width="1826" data-original="https://pic1.zhimg.com/v2-468cfa59a3d2b598b76e4e3bfdc1b4b8_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-468cfa59a3d2b598b76e4e3bfdc1b4b8_b.jpg"/></figure><p>    所以，CPU搞多点去跑actors，GPU搞一个用来跑learner就行啦~</p><p>    论文中还做了一些与A3C，A2C效果的对比，基本上是对超参更不敏感，在大多数任务中能达到更好的效果，当然吞吐量也是好得很。</p><p>--------------------我是可爱的分割线--------------------</p><p>    对于星际这种搜索空间超大的任务来说，选择off-policy的方法是必然的。V-trace保证了在off-policy情况下的稳定的效果，加上对replay buffer的充分应用，使最终actor和learner可以异步进行，为数据吞吐量的提升提供了保障。</p><p>    在IMPALA中，我们同样看到了policy entropy的身影。它似乎已经变成了RL可以稳定训练的一个必备组成。在soft q learning和soft actor critic等一些任务中，我们都可以看到它的优秀表现。</p><p>    和同样是off-policy的sac(bair出品)来比，谁又更有优势了？sac可是能直接在真机上提升采样效率的方法。</p></div></div><div class="ContentItem-time">编辑于 2019-02-17</div><div class="Post-topicsAndReviewer"><div class="TopicList Post-Topics"><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/20039099" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习 (Reinforcement Learning)</div></div></a></span></div></div></div><div><div class="Sticky RichContent-actions is-bottom"><div class="ContentItem-actions"><span><button aria-label="赞同 68 " type="button" class="Button VoteButton VoteButton--up"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleUp VoteButton-TriangleUp" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M2 18.242c0-.326.088-.532.237-.896l7.98-13.203C10.572 3.57 11.086 3 12 3c.915 0 1.429.571 1.784 1.143l7.98 13.203c.15.364.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H3.955c-1.08 0-1.955-.517-1.955-1.9z" fill-rule="evenodd"></path></svg></span>赞同 68</button><button aria-label="反对" type="button" class="Button VoteButton VoteButton--down"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleDown" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M20.044 3H3.956C2.876 3 2 3.517 2 4.9c0 .326.087.533.236.896L10.216 19c.355.571.87 1.143 1.784 1.143s1.429-.572 1.784-1.143l7.98-13.204c.149-.363.236-.57.236-.896 0-1.386-.876-1.9-1.956-1.9z" fill-rule="evenodd"></path></svg></span></button></span><button type="button" class="Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Comment Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M10.241 19.313a.97.97 0 0 0-.77.2 7.908 7.908 0 0 1-3.772 1.482.409.409 0 0 1-.38-.637 5.825 5.825 0 0 0 1.11-2.237.605.605 0 0 0-.227-.59A7.935 7.935 0 0 1 3 11.25C3 6.7 7.03 3 12 3s9 3.7 9 8.25-4.373 9.108-10.759 8.063z" fill-rule="evenodd"></path></svg></span>10 条评论</button><div class="Popover ShareMenu"><div class="ShareMenu-toggler" id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Share Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2.931 7.89c-1.067.24-1.275 1.669-.318 2.207l5.277 2.908 8.168-4.776c.25-.127.477.198.273.39L9.05 14.66l.927 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.242c.584-.892-.212-2.029-1.234-1.796L2.93 7.89z" fill-rule="evenodd"></path></svg></span>分享</button></div></div><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Heart Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2 8.437C2 5.505 4.294 3.094 7.207 3 9.243 3 11.092 4.19 12 6c.823-1.758 2.649-3 4.651-3C19.545 3 22 5.507 22 8.432 22 16.24 13.842 21 12 21 10.158 21 2 16.24 2 8.437z" fill-rule="evenodd"></path></svg></span>喜欢</button><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Star Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5.515 19.64l.918-5.355-3.89-3.792c-.926-.902-.639-1.784.64-1.97L8.56 7.74l2.404-4.871c.572-1.16 1.5-1.16 2.072 0L15.44 7.74l5.377.782c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.219 1.274-.532 1.82-1.676 1.218L12 18.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z" fill-rule="evenodd"></path></svg></span>收藏</button><div class="Post-ActionMenuButton"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Dots Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5 14a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4z" fill-rule="evenodd"></path></svg></span></button></div></div></div></div></div></div></article><div class="Post-Sub Post-NormalSub"><div class="PostIndex-Contributions"><h3 class="BlockTitle">文章被以下专栏收录</h3><ul><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="/sharerl"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><img class="Avatar Avatar--medium Avatar--round" width="40" height="40" src="https://pic2.zhimg.com/4b70deef7_xs.jpg" srcSet="https://pic2.zhimg.com/4b70deef7_l.jpg 2x" alt="强化学习知识大讲堂"/></div></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><a class="ColumnLink ColumnItem-Title" href="/sharerl"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习知识大讲堂</div></div></a></h2><div class="ContentItem-meta">让机器人学会思考</div></div><div class="ContentItem-extra"><a href="/sharerl" type="button" class="Button">进入专栏</a></div></div></div><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><img class="Avatar Avatar--medium Avatar--round" width="40" height="40" src="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_xs.jpg" srcSet="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_l.jpg 2x" alt="强化学习前沿"/></div></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><a class="ColumnLink ColumnItem-Title" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习前沿</div></div></a></h2><div class="ContentItem-meta">读呀读paper</div></div><div class="ContentItem-extra"><a href="/reinforcementlearning" type="button" class="Button">进入专栏</a></div></div></div></ul></div></div></div></main></div></div><script nonce="271ff977-6666-4a96-8c23-620b22846e23" async="" src="https://www.googletagmanager.com/gtag/js?id=UA-149949619-1"></script><script nonce="271ff977-6666-4a96-8c23-620b22846e23">function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-149949619-1");</script><script id="js-clientConfig" type="text/json">{"host":"zhihu.com","protocol":"https:","wwwHost":"www.zhihu.com","fetchRoot":{"www":"https:\u002F\u002Fwww.zhihu.com","api":"https:\u002F\u002Fapi.zhihu.com","zhuanlan":"https:\u002F\u002Fzhuanlan.zhihu.com"}}</script><script id="js-initialData" type="text/json">{"initialState":{"common":{"ask":{}},"loading":{"global":{"count":0},"local":{"env\u002FgetIpinfo\u002F":false,"article\u002Fget\u002F":false,"brand\u002FgetUrl\u002F":false}},"club":{"tags":{}},"entities":{"users":{"zhang-ming-28-20":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic2.zhimg.com\u002Fa7f705d126a5c3ca8cac811c1ea0f596_{size}.jpg","uid":"681207051770793984","userType":"people","isFollowing":false,"urlToken":"zhang-ming-28-20","id":"cfe3bfe923caa874d68c94bd1de2151d","description":"不够勤奋的工程师","name":"starimpact","isAdvertiser":false,"headline":"计算视觉","gender":1,"url":"\u002Fpeople\u002Fcfe3bfe923caa874d68c94bd1de2151d","avatarUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fa7f705d126a5c3ca8cac811c1ea0f596_l.jpg","isOrg":false,"type":"people","vipInfo":{"isVip":true,"vipIcon":{"url":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4812630bc27d642f7cafcd6cdeca3d7a_r.png","nightModeUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c9686ff064ea3579730756ac6c289978_r.png"}},"badge":[],"exposedMedal":{"medalId":"972465637922213888","medalName":"给自己证明","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-95e2940e8968c11fac86cb9f3c59ca97_r.png","miniAvatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b8cb24c96e95d6274794c29f35c912e_is.png","description":"已完善全部个人资料"}}},"questions":{},"answers":{},"articles":{"56043646":{"trackUrl":["https:\u002F\u002Fsugar.zhihu.com\u002Fplutus_adreaper\u002Fpage_monitor_log?si=__SESSIONID__&ti=__ATOKEN__&at=view&pf=__OS__&ed=__MEMBERID__&idfa=__IDFA__&imei=__IMEI__&androidid=__ANDROIDID__&oaid=__OAID__&ci=__CREATIVEID__"],"id":56043646,"title":"AlphaStar之IMPALA","type":"article","excerptTitle":"","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F56043646","imageUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-94f9308f50f6183575daed66f99ca160_b.jpg","titleImage":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-94f9308f50f6183575daed66f99ca160_b.jpg","excerpt":"\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a87b97ec21e37a7fa1e3113e683f29d1_200x112.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1972\" data-rawheight=\"1522\" data-watermark=\"watermark\" data-original-src=\"v2-a87b97ec21e37a7fa1e3113e683f29d1\" data-watermark-src=\"v2-be7932caddcfcea97a4322f2395dbced\" data-private-watermark-src=\"\" class=\"origin_image inline-img zh-lightbox-thumb\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a87b97ec21e37a7fa1e3113e683f29d1_r.png\"\u002F\u003E前两天DeepMind终于爆出了在星际2上的最新进展，我是看着羡慕（详见：\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fdeepmind.com\u002Fblog\u002Falphastar-mastering-real-time-strategy-game-starcraft-ii\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EAlphaStar: Mastering the Real-Time Strategy Game StarCraft II | DeepMind\u003C\u002Fa\u003E）。里面提到了应用到的各种技术：Transformer, LSTM, pointer network, novel off-policy actor-critic rl,…","created":1548860860,"updated":1550387224,"author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic2.zhimg.com\u002Fa7f705d126a5c3ca8cac811c1ea0f596_{size}.jpg","uid":"681207051770793984","userType":"people","isFollowing":false,"urlToken":"zhang-ming-28-20","id":"cfe3bfe923caa874d68c94bd1de2151d","description":"不够勤奋的工程师","name":"starimpact","isAdvertiser":false,"headline":"计算视觉","gender":1,"url":"\u002Fpeople\u002Fcfe3bfe923caa874d68c94bd1de2151d","avatarUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fa7f705d126a5c3ca8cac811c1ea0f596_l.jpg","isOrg":false,"type":"people","vipInfo":{"isVip":true,"vipIcon":{"url":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4812630bc27d642f7cafcd6cdeca3d7a_r.png","nightModeUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c9686ff064ea3579730756ac6c289978_r.png"}},"badge":[],"exposedMedal":{"medalId":"972465637922213888","medalName":"给自己证明","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-95e2940e8968c11fac86cb9f3c59ca97_r.png","miniAvatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b8cb24c96e95d6274794c29f35c912e_is.png","description":"已完善全部个人资料"}},"commentPermission":"all","state":"published","imageWidth":1274,"imageHeight":635,"content":"\u003Cp\u003E    前两天DeepMind终于爆出了在星际2上的最新进展，我是看着羡慕（详见：\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fdeepmind.com\u002Fblog\u002Falphastar-mastering-real-time-strategy-game-starcraft-ii\u002F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EAlphaStar: Mastering the Real-Time Strategy Game StarCraft II | DeepMind\u003C\u002Fa\u003E）。里面提到了应用到的各种技术：Transformer, LSTM, pointer network, novel off-policy actor-critic rl, self-imitation learning, policy distillation等等。前面几个网络结构都可以搜到中文，但是后面若干算法就比较难找了。在这里，我先说一下novel off-policy actor-critic rl，即IMPALA。\u003C\u002Fp\u003E\u003Cp\u003E    强化学习需要大量在线得到的样本。这就涉及到其中一个问题：产生的样本怎么处理？如果是on-policy的RL算法，样本用过一次就扔掉，十分浪费（千辛万苦采到的样本，就用一次？太浪费了！哪个监督学习里的样本不用个百八十次的~）。如果off-policy的RL算法就可以做到以前的样本反复利用（有RL基础的同学可以马上联想到Deep Q-Learning的Replay Buffer）。\u003C\u002Fp\u003E\u003Cp\u003E    涉及到的第二个问题：如何高效的产生样本？当然是并行或分布式啦！Actor和Learner各干各的，谁都不要等谁。Actor们（不只一个）不断地将采到的样本放到Replay Buffer里，并周期性地从Learner那拿到最新的参数。Learner不断地从Replay Buffer里拿样本过来训练自己的参数。要达到这样的目的，也只有off-policy的方法可以这么干了。而如果是on-policy的方法就要遵循：Actor放样本到buffer-&gt;Learner取样本训练参数-&gt;Actor取最新的参数-&gt;Actor执行动作收集样本-&gt;Actor放样本到buffer，这个过程按顺序来的，无法并行。\u003C\u002Fp\u003E\u003Cp\u003E    涉及到的第三个问题：off-policy的方法是可以让样本收集和学习变成并行，还可以利用老样本，但是那些比较老的样本就这么直接拿来更新当前的参数，也会产生利用效率不高的问题（可以理解成并不能有效提升当前的Agent水平）。\u003C\u002Fp\u003E\u003Cp\u003E    好啦，谁能解决上面三个问题？IMPALA的V-trace！\u003C\u002Fp\u003E\u003Cp\u003E    IMPALA这么怪的名字？\u003Cb\u003EIMP\u003C\u002Fb\u003Eortance weighted \u003Cb\u003EA\u003C\u002Fb\u003Ector-\u003Cb\u003EL\u003C\u002Fb\u003Eearner \u003Cb\u003EA\u003C\u002Fb\u003Erchitecture！大家都以为是六个单词的首字母~现在的简写真是没有底线了^_^。\u003C\u002Fp\u003E\u003Cp\u003E    先上一下V-trace target本尊：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=v_%7Bs%7D+%3D+V_%7Bx_%7Bs%7D%7D%2B%5Csum_%7Bt%3Ds%7D%5E%7Bs%2Bn-1%7D%7B%5Cgamma%5E%7Bt-s%7D%28%5CPi_%7Bi%3Ds%7D%5E%7Bt-1%7D%7Bc_%7Bi%7D%7D%29%5Cdelta_%7Bt%7DV%7D+\" alt=\"v_{s} = V_{x_{s}}+\\sum_{t=s}^{s+n-1}{\\gamma^{t-s}(\\Pi_{i=s}^{t-1}{c_{i}})\\delta_{t}V} \" eeimg=\"1\"\u002F\u003E --------(1)\u003C\u002Fp\u003E\u003Cp\u003E    非常复杂，看不懂，有没有？看看里面一些变量的定义是什么：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta_%7Bt%7DV%3D%5Crho_%7Bt%7D%28r_%7Bt%7D%2B%5Cgamma+V_%7Bx_%7Bt%2B1%7D%7D-V_%7Bx_%7Bt%7D%7D%29\" alt=\"\\delta_{t}V=\\rho_{t}(r_{t}+\\gamma V_{x_{t+1}}-V_{x_{t}})\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E    括号里的表达式是Temporal Difference，然而外面的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Crho_%7Bt%7D\" alt=\"\\rho_{t}\" eeimg=\"1\"\u002F\u003E 是什么含义了？\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Crho_%7Bt%7D+%3D+min%28%5Cbar%7B%5Crho%7D%2C+%5Cfrac%7B%5Cpi%28a_t%7Cx_t%29%7D%7B%5Cmu%28a_t%7Cx_t%29%7D%29\" alt=\"\\rho_{t} = min(\\bar{\\rho}, \\frac{\\pi(a_t|x_t)}{\\mu(a_t|x_t)})\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E    还有其它变量的定义：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=c_i+%3D+min%28%5Cbar%7Bc%7D%2C+%5Cfrac%7B%5Cpi%28a_i%7Cx_i%29%7D%7B%5Cmu%28a_i%7Cx_i%29%7D%29\" alt=\"c_i = min(\\bar{c}, \\frac{\\pi(a_i|x_i)}{\\mu(a_i|x_i)})\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbar%7B%5Crho%7D+%5Cgeq+%5Cbar%7Bc%7D\" alt=\"\\bar{\\rho} \\geq \\bar{c}\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E    看到 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Crho_t\" alt=\"\\rho_t\" eeimg=\"1\"\u002F\u003E 和 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=c_i\" alt=\"c_i\" eeimg=\"1\"\u002F\u003E 的表达式，是不是联想起什么了？这就是\u003Cb\u003EI\u003C\u002Fb\u003Emportance \u003Cb\u003ES\u003C\u002Fb\u003Eampling。从策略 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"\u002F\u003E 中采样，更新当前的策略 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cpi\" alt=\"\\pi\" eeimg=\"1\"\u002F\u003E 。只不过加上了最大值的限制，不能超过 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbar%7B%5Crho%7D\" alt=\"\\bar{\\rho}\" eeimg=\"1\"\u002F\u003E 和 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbar%7Bc%7D\" alt=\"\\bar{c}\" eeimg=\"1\"\u002F\u003E ，也就是说进行了截断处理，一般情况下这两个值可以设置成1啦。\u003C\u002Fp\u003E\u003Cp\u003E    要进一步理解 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Crho_t\" alt=\"\\rho_t\" eeimg=\"1\"\u002F\u003E 的意义可以看下面的表达式（为什么会出现这样的表达式，这个要看原论文）：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cpi_%7B%5Cbar%7B%5Crho%7D%7D%28a%7Cx%29%3D%5Cfrac%7Bmin%28%5Cbar%7B%5Crho%7D%5Cmu%28a%7Cx%29%2C+%5Cpi%28a%7Cx%29%29%7D%7B%5Csum_%7Bb+%5Cin+x%7D%7Bmin%28%5Cbar%7B%5Crho%7D%5Cmu%28b%7Cx%29%2C+%5Cpi%28b%7Cx%29%29%7D%7D\" alt=\"\\pi_{\\bar{\\rho}}(a|x)=\\frac{min(\\bar{\\rho}\\mu(a|x), \\pi(a|x))}{\\sum_{b \\in x}{min(\\bar{\\rho}\\mu(b|x), \\pi(b|x))}}\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cpi_%7B%5Cbar%7B%5Crho%7D%7D\" alt=\"\\pi_{\\bar{\\rho}}\" eeimg=\"1\"\u002F\u003E是一个介于 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cpi\" alt=\"\\pi\" eeimg=\"1\"\u002F\u003E 和 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"\u002F\u003E 的中间态的策略。为什么这么定义了？如果当 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbar%7B%5Crho%7D%3D%5Cinfty\" alt=\"\\bar{\\rho}=\\infty\" eeimg=\"1\"\u002F\u003E ，那么 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cpi_%7B%5Cbar%7B%5Crho%7D%7D\" alt=\"\\pi_{\\bar{\\rho}}\" eeimg=\"1\"\u002F\u003E 就会变成策略 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cpi\" alt=\"\\pi\" eeimg=\"1\"\u002F\u003E ，如果 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbar%7B%5Crho%7D%5CRightarrow+0\" alt=\"\\bar{\\rho}\\Rightarrow 0\" eeimg=\"1\"\u002F\u003E （是接近于0，不是等于），那么\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cpi_%7B%5Cbar%7B%5Crho%7D%7D\" alt=\"\\pi_{\\bar{\\rho}}\" eeimg=\"1\"\u002F\u003E就会变成策略 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"\u002F\u003E 。（所以 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbar%7B%5Crho%7D\" alt=\"\\bar{\\rho}\" eeimg=\"1\"\u002F\u003E 越大，那么off-policy学习的bias就越小，相应的variance就越大。）\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=c_i\" alt=\"c_i\" eeimg=\"1\"\u002F\u003E 的乘积表示 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta_tV\" alt=\"\\delta_tV\" eeimg=\"1\"\u002F\u003E 在时刻 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=t\" alt=\"t\" eeimg=\"1\"\u002F\u003E 影响前面时刻 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=s\" alt=\"s\" eeimg=\"1\"\u002F\u003E 的值函数更新的强弱程度。 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cpi\" alt=\"\\pi\" eeimg=\"1\"\u002F\u003E 和 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"\u002F\u003E 差距越大，那么off-poliocy越明显，那么这个乘积的variance就越大。这里用了截断方法来控制这种variance。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbar%7B%5Crho%7D\" alt=\"\\bar{\\rho}\" eeimg=\"1\"\u002F\u003E 影响的是要收敛到什么样的值函数，而 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbar%7Bc%7D\" alt=\"\\bar{c}\" eeimg=\"1\"\u002F\u003E 影响的是收敛到这个值函数的速度。（突然间出来了值函数，有什么样的策略就有什么样的值函数，二者是对应的，就这么理解吧。）\u003C\u002Fp\u003E\u003Cp\u003E    要注意的是， \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=v_s\" alt=\"v_s\" eeimg=\"1\"\u002F\u003E 在on-policy的情况下（即 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cpi+%3D+%5Cmu\" alt=\"\\pi = \\mu\" eeimg=\"1\"\u002F\u003E），并让 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=c_i+%3D+1\" alt=\"c_i = 1\" eeimg=\"1\"\u002F\u003E ，且 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Crho_t+%3D+1\" alt=\"\\rho_t = 1\" eeimg=\"1\"\u002F\u003E ，就会变成下式：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=v_s+%3D+V%28x_s%29+%2B+%5Csum_%7Bt%3Ds%7D%5E%7Bs%2Bn-1%7D%7B%5Cgamma%5E%7Bt-s%7D%28r_t%2B%5Cgamma+V%28x_%7Bt%2B1%7D%29-V%28x_t%29%29%7D+%3D%5Csum_%7Bt%3Ds%7D%5E%7Bs%2Bn-1%7D%7B%5Cgamma%5E%7Bt-s%7Dr_t%7D%2B%5Cgamma%5E%7Bn%7DV%28x_%7Bs%2Bn%7D%29\" alt=\"v_s = V(x_s) + \\sum_{t=s}^{s+n-1}{\\gamma^{t-s}(r_t+\\gamma V(x_{t+1})-V(x_t))} =\\sum_{t=s}^{s+n-1}{\\gamma^{t-s}r_t}+\\gamma^{n}V(x_{s+n})\" eeimg=\"1\"\u002F\u003E --------(2)\u003C\u002Fp\u003E\u003Cp\u003E    这个式子是Bellman Target (类似于TD Target)。也就是说式(1)在on-policy的特殊情况下就变成了式(2)。于是，同样的算法可以把off和on两种policy通吃了。\u003C\u002Fp\u003E\u003Cp\u003E    V-trace targets 可以用迭代的方式进行计算（让人联想到back view TD( \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Clambda\" alt=\"\\lambda\" eeimg=\"1\"\u002F\u003E )，实际上在某些条件下确实也可以将它转化到TD( \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Clambda\" alt=\"\\lambda\" eeimg=\"1\"\u002F\u003E )，具体看论文）：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=v_s+%3D+V%28x_s%29+%2B+%5Cdelta_sV%2B%5Cgamma+c_s+%28v_%7Bs%2B1%7D+-+V%28x_%7Bs%2B1%7D%29%29\" alt=\"v_s = V(x_s) + \\delta_sV+\\gamma c_s (v_{s+1} - V(x_{s+1}))\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E--------------------我是可爱的分割线--------------------\u003C\u002Fp\u003E\u003Cp\u003E    其实重点基本都讲完了，下面讲怎么用 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=v_s\" alt=\"v_s\" eeimg=\"1\"\u002F\u003E 。这实际上就是actor-crtitic的标准训练方法了。\u003C\u002Fp\u003E\u003Cp\u003E    首先，更新critic时用的梯度：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%28v_s+-+V_%5Ctheta%28x_s%29%29%5CDelta_%5Ctheta+V_%5Ctheta%28x_s%29\" alt=\"(v_s - V_\\theta(x_s))\\Delta_\\theta V_\\theta(x_s)\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E    然后，更新actor时用的梯度：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Crho_s+%5CDelta_%5Comega+log+%5Cpi_%5Comega%28a_s%7Cx_s%29%28r_s%2B%5Cgamma+v_%7Bs%2B1%7D+-+V_%5Ctheta+%28x_s%29%29\" alt=\"\\rho_s \\Delta_\\omega log \\pi_\\omega(a_s|x_s)(r_s+\\gamma v_{s+1} - V_\\theta (x_s))\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E    为了防止过早的收敛，为actor的梯度加一个policy entropy(熵)的惩罚：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=-%5CDelta_%5Comega+%5Csum_%7Ba%7D%7B%5Cpi_%5Comega%28a%7Cx_s%29log+%5Cpi_%5Comega%28a%7Cx_s%29%7D\" alt=\"-\\Delta_\\omega \\sum_{a}{\\pi_\\omega(a|x_s)log \\pi_\\omega(a|x_s)}\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E--------------------我是可爱的分割线--------------------\u003C\u002Fp\u003E\u003Cp\u003E    下面简单看看实验部分。先看看网络是啥样子（做了大小网络实验）：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-be7932caddcfcea97a4322f2395dbced_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1972\" data-rawheight=\"1522\" class=\"origin_image zh-lightbox-thumb\" width=\"1972\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-be7932caddcfcea97a4322f2395dbced_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1972&#39; height=&#39;1522&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1972\" data-rawheight=\"1522\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1972\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-be7932caddcfcea97a4322f2395dbced_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-be7932caddcfcea97a4322f2395dbced_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E    再看看Replay Buffer对比实验：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f361ff8d4613bc98b6c28ab017d9791a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1650\" data-rawheight=\"1334\" class=\"origin_image zh-lightbox-thumb\" width=\"1650\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f361ff8d4613bc98b6c28ab017d9791a_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1650&#39; height=&#39;1334&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1650\" data-rawheight=\"1334\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1650\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f361ff8d4613bc98b6c28ab017d9791a_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f361ff8d4613bc98b6c28ab017d9791a_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E    在应用完整V-trace的情况下Replay Buffer的提升作用明显。如果去掉了off-policy的correction部分，那么就会产生负作用，可以看上面的No-correction行。\u003C\u002Fp\u003E\u003Cp\u003E    最后看看训练速度，数据吞吐率：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-468cfa59a3d2b598b76e4e3bfdc1b4b8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1826\" data-rawheight=\"1950\" class=\"origin_image zh-lightbox-thumb\" width=\"1826\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-468cfa59a3d2b598b76e4e3bfdc1b4b8_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1826&#39; height=&#39;1950&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1826\" data-rawheight=\"1950\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1826\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-468cfa59a3d2b598b76e4e3bfdc1b4b8_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-468cfa59a3d2b598b76e4e3bfdc1b4b8_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E    所以，CPU搞多点去跑actors，GPU搞一个用来跑learner就行啦~\u003C\u002Fp\u003E\u003Cp\u003E    论文中还做了一些与A3C，A2C效果的对比，基本上是对超参更不敏感，在大多数任务中能达到更好的效果，当然吞吐量也是好得很。\u003C\u002Fp\u003E\u003Cp\u003E--------------------我是可爱的分割线--------------------\u003C\u002Fp\u003E\u003Cp\u003E    对于星际这种搜索空间超大的任务来说，选择off-policy的方法是必然的。V-trace保证了在off-policy情况下的稳定的效果，加上对replay buffer的充分应用，使最终actor和learner可以异步进行，为数据吞吐量的提升提供了保障。\u003C\u002Fp\u003E\u003Cp\u003E    在IMPALA中，我们同样看到了policy entropy的身影。它似乎已经变成了RL可以稳定训练的一个必备组成。在soft q learning和soft actor critic等一些任务中，我们都可以看到它的优秀表现。\u003C\u002Fp\u003E\u003Cp\u003E    和同样是off-policy的sac(bair出品)来比，谁又更有优势了？sac可是能直接在真机上提升采样效率的方法。\u003C\u002Fp\u003E","adminClosedComment":false,"topics":[{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F20039099","type":"topic","id":"20039099","name":"强化学习 (Reinforcement Learning)"}],"voteupCount":68,"voting":0,"column":{"description":"让机器人学会思考","canManage":false,"intro":"专注强化学习算法分享，欢迎投稿到该专栏","isFollowing":false,"urlToken":"sharerl","id":"sharerl","articlesCount":81,"acceptSubmission":true,"title":"强化学习知识大讲堂","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fsharerl","commentPermission":"all","created":1488426681,"updated":1491483474,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002F4b70deef7_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fda8e974dc_{size}.jpg","uid":"709699123573444608","userType":"people","isFollowing":false,"urlToken":"guoxiansia","id":"e4c3ab8d582243e86cc2ce5a52bdfa2f","description":"","name":"天津包子馅儿","isAdvertiser":false,"headline":"机器人学博士，让机器人学会运动和思考","gender":1,"url":"\u002Fpeople\u002Fe4c3ab8d582243e86cc2ce5a52bdfa2f","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fda8e974dc_l.jpg","isOrg":false,"type":"people"},"followers":16305,"type":"column"},"commentCount":10,"contributions":[{"id":20219986,"state":"accepted","type":"include","column":{"description":"让机器人学会思考","canManage":false,"intro":"专注强化学习算法分享，欢迎投稿到该专栏","isFollowing":false,"urlToken":"sharerl","id":"sharerl","articlesCount":81,"acceptSubmission":true,"title":"强化学习知识大讲堂","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fsharerl","commentPermission":"all","created":1488426681,"updated":1491483474,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002F4b70deef7_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fda8e974dc_{size}.jpg","uid":"709699123573444608","userType":"people","isFollowing":false,"urlToken":"guoxiansia","id":"e4c3ab8d582243e86cc2ce5a52bdfa2f","description":"","name":"天津包子馅儿","isAdvertiser":false,"headline":"机器人学博士，让机器人学会运动和思考","gender":1,"url":"\u002Fpeople\u002Fe4c3ab8d582243e86cc2ce5a52bdfa2f","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fda8e974dc_l.jpg","isOrg":false,"type":"people"},"followers":16305,"type":"column"}},{"id":20260034,"state":"accepted","type":"include","column":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}}],"isTitleImageFullScreen":false,"upvotedFollowees":[],"commercialInfo":{"isCommercial":false,"plugin":{}},"suggestEdit":{"status":false,"reason":"","tip":"","url":"","title":""},"reason":"","annotationAction":[],"canTip":false,"tipjarorsCount":0,"isLabeled":false,"hasPublishingDraft":false,"isFavorited":false,"isNormal":true,"status":0,"shareText":"AlphaStar之IMPALA - 来自知乎专栏「强化学习知识大讲堂」，作者: starimpact https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F56043646 （想看更多？下载 @知乎 App：http:\u002F\u002Fweibo.com\u002Fp\u002F100404711598 ）","canComment":{"status":true,"reason":""},"mcnFpShow":-1,"isVisible":true,"isLiked":false,"likedCount":0,"visibleOnlyToAuthor":false}},"columns":{"sharerl":{"description":"让机器人学会思考","canManage":false,"intro":"专注强化学习算法分享，欢迎投稿到该专栏","isFollowing":false,"urlToken":"sharerl","id":"sharerl","articlesCount":81,"acceptSubmission":true,"title":"强化学习知识大讲堂","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fsharerl","commentPermission":"all","created":1488426681,"updated":1491483474,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002F4b70deef7_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fda8e974dc_{size}.jpg","uid":"709699123573444608","userType":"people","isFollowing":false,"urlToken":"guoxiansia","id":"e4c3ab8d582243e86cc2ce5a52bdfa2f","description":"","name":"天津包子馅儿","isAdvertiser":false,"headline":"机器人学博士，让机器人学会运动和思考","gender":1,"url":"\u002Fpeople\u002Fe4c3ab8d582243e86cc2ce5a52bdfa2f","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fda8e974dc_l.jpg","isOrg":false,"type":"people"},"followers":16305,"type":"column"},"reinforcementlearning":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}},"topics":{},"roundtables":{},"favlists":{},"comments":{},"notifications":{},"ebooks":{},"activities":{},"feeds":{},"pins":{},"promotions":{},"drafts":{},"chats":{},"posts":{},"clubs":{},"clubTags":{}},"currentUser":"","account":{"lockLevel":{},"unlockTicketStatus":false,"unlockTicket":null,"challenge":[],"errorStatus":false,"message":"","isFetching":false,"accountInfo":{},"urlToken":{"loading":false}},"settings":{"socialBind":null,"inboxMsg":null,"notification":{},"email":{},"privacyFlag":null,"blockedUsers":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"blockedFollowees":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"ignoredTopics":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"restrictedTopics":null,"laboratory":{}},"notification":{},"people":{"profileStatus":{},"activitiesByUser":{},"answersByUser":{},"answersSortByVotesByUser":{},"answersIncludedByUser":{},"votedAnswersByUser":{},"thankedAnswersByUser":{},"voteAnswersByUser":{},"thankAnswersByUser":{},"topicAnswersByUser":{},"zvideosByUser":{},"articlesByUser":{},"articlesSortByVotesByUser":{},"articlesIncludedByUser":{},"pinsByUser":{},"questionsByUser":{},"commercialQuestionsByUser":{},"favlistsByUser":{},"followingByUser":{},"followersByUser":{},"mutualsByUser":{},"followingColumnsByUser":{},"followingQuestionsByUser":{},"followingFavlistsByUser":{},"followingTopicsByUser":{},"publicationsByUser":{},"columnsByUser":{},"allFavlistsByUser":{},"brands":null,"creationsByUser":{},"creationsSortByVotesByUser":{},"creationsFeed":{}},"env":{"ab":{"config":{"experiments":[{"expId":"launch-gw_mweb_rec-1","expPrefix":"gw_mweb_rec","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-qa_hdpimg-2","expPrefix":"qa_hdpimg","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-us_foltopic_user-10","expPrefix":"us_foltopic_user","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_bullet_second-2","expPrefix":"vd_bullet_second","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_zvideo_link-10","expPrefix":"vd_zvideo_link","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"vd_bullet_gui-1","expPrefix":"vd_bullet_gui","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"se_topicfeed-3","expPrefix":"se_topicfeed","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false}],"params":[{"id":"ls_recommend_test","type":"String","value":"0","chainId":"_all_"},{"id":"se_webrs","type":"String","value":"1","chainId":"_all_"},{"id":"li_video_section","type":"String","value":"0","chainId":"_all_"},{"id":"se_p_slideshow","type":"String","value":"0","chainId":"_all_"},{"id":"se_cbert_index","type":"String","value":"0","chainId":"_all_"},{"id":"se_sug_term","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adpinweight","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adsort","type":"String","value":"0","chainId":"_all_"},{"id":"top_ydyq","type":"String","value":"X","chainId":"_all_"},{"id":"se_zu_recommend","type":"String","value":"0","chainId":"_all_"},{"id":"zr_article_new","type":"String","value":"close","chainId":"_all_"},{"id":"li_se_edu","type":"String","value":"1","chainId":"_all_"},{"id":"li_answers_link","type":"String","value":"0","chainId":"_all_"},{"id":"se_subtext","type":"String","value":"0","chainId":"_all_"},{"id":"li_qa_new_cover","type":"String","value":"1","chainId":"_all_"},{"id":"se_amovietab","type":"String","value":"1","chainId":"_all_"},{"id":"soc_feed_intimacy","type":"String","value":"2","chainId":"_all_"},{"id":"se_college","type":"String","value":"default","chainId":"_all_"},{"id":"li_hot_voted","type":"String","value":"0","chainId":"_all_"},{"id":"web_ask","type":"String","value":"0"},{"id":"se_relation_1","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_entry","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zuichangfangwen","type":"String","value":"0","chainId":"_all_"},{"id":"web_sem_ab","type":"String","value":"1"},{"id":"se_likebutton","type":"String","value":"0","chainId":"_all_"},{"id":"se_content0","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iosreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"soc_authormore","type":"String","value":"2","chainId":"_all_"},{"id":"web_n_web_msg","type":"String","value":"0"},{"id":"gue_zvideo_link","type":"String","value":"1"},{"id":"web_hdpimg","type":"String","value":"1"},{"id":"se_dnn_mt_v2","type":"String","value":"0","chainId":"_all_"},{"id":"top_new_feed","type":"String","value":"5","chainId":"_all_"},{"id":"li_pay_banner_type","type":"String","value":"6","chainId":"_all_"},{"id":"se_cardrank_2","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_pic","type":"String","value":"0.6","chainId":"_all_"},{"id":"top_quality","type":"String","value":"0","chainId":"_all_"},{"id":"zr_art_rec","type":"String","value":"base","chainId":"_all_"},{"id":"se_pek_test","type":"String","value":"1","chainId":"_all_"},{"id":"se_zu_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_tab_new","type":"String","value":"0-0-0","chainId":"_all_"},{"id":"se_new_merger","type":"String","value":"1","chainId":"_all_"},{"id":"web_audit_01","type":"String","value":"case1"},{"id":"soc_leave_recommend","type":"String","value":"2","chainId":"_all_"},{"id":"soc_brdcst3","type":"String","value":"0","chainId":"_all_"},{"id":"top_v_album","type":"String","value":"1","chainId":"_all_"},{"id":"li_education_box","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_head","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_across","type":"String","value":"1","chainId":"_all_"},{"id":"zr_test_aa1","type":"String","value":"0","chainId":"_all_"},{"id":"se_aa_base","type":"String","value":"0","chainId":"_all_"},{"id":"se_whitelist","type":"String","value":"0","chainId":"_all_"},{"id":"se_backsearch","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_style","type":"String","value":"0","chainId":"_all_"},{"id":"top_root","type":"String","value":"0","chainId":"_all_"},{"id":"li_vip_verti_search","type":"String","value":"0","chainId":"_all_"},{"id":"li_assessment_show","type":"String","value":"1","chainId":"_all_"},{"id":"zr_rel_search","type":"String","value":"base","chainId":"_all_"},{"id":"se_preset_tech","type":"String","value":"0","chainId":"_all_"},{"id":"se_lottery","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iossort","type":"String","value":"0","chainId":"_all_"},{"id":"pf_noti_entry_num","type":"String","value":"0","chainId":"_all_"},{"id":"sem_up_growth","type":"String","value":"in_app","chainId":"_all_"},{"id":"se_wannasearch","type":"String","value":"0","chainId":"_all_"},{"id":"tp_qa_metacard","type":"String","value":"1","chainId":"_all_"},{"id":"soc_update","type":"String","value":"1","chainId":"_all_"},{"id":"li_paid_answer_exp","type":"String","value":"0","chainId":"_all_"},{"id":"qap_question_visitor","type":"String","value":" 0","chainId":"_all_"},{"id":"web_answerlist_ad","type":"String","value":"0"},{"id":"zr_training_boost","type":"String","value":"false","chainId":"_all_"},{"id":"se_hotsearch_num","type":"String","value":"0","chainId":"_all_"},{"id":"se_highlight","type":"String","value":"0","chainId":"_all_"},{"id":"li_android_vip","type":"String","value":"0","chainId":"_all_"},{"id":"pf_newguide_vertical","type":"String","value":"0","chainId":"_all_"},{"id":"ug_fw_answ_aut_1","type":"String","value":"0","chainId":"_all_"},{"id":"li_qa_btn_text","type":"String","value":"0","chainId":"_all_"},{"id":"zr_expslotpaid","type":"String","value":"1","chainId":"_all_"},{"id":"se_ad_index","type":"String","value":"10","chainId":"_all_"},{"id":"se_site_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"ug_follow_answerer_0","type":"String","value":"0","chainId":"_all_"},{"id":"li_answer_label","type":"String","value":"0","chainId":"_all_"},{"id":"zw_payc_qaedit","type":"String","value":"0","chainId":"_all_"},{"id":"se_payconsult","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_tab","type":"String","value":"0","chainId":"_all_"},{"id":"tsp_vote","type":"String","value":"2","chainId":"_all_"},{"id":"qap_article_like","type":"String","value":"1","chainId":"_all_"},{"id":"li_se_section","type":"String","value":"0","chainId":"_all_"},{"id":"zr_intervene","type":"String","value":"0","chainId":"_all_"},{"id":"zr_video_rank_nn","type":"String","value":"new_rank","chainId":"_all_"},{"id":"soc_special","type":"String","value":"0","chainId":"_all_"},{"id":"top_hotcommerce","type":"String","value":"1","chainId":"_all_"},{"id":"web_creator_route","type":"String","value":"1"},{"id":"li_yxzl_new_style_a","type":"String","value":"1","chainId":"_all_"},{"id":"se_ltr_video","type":"String","value":"0","chainId":"_all_"},{"id":"se_page_quality","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_3","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_1","type":"String","value":"0","chainId":"_all_"},{"id":"se_search_feed","type":"String","value":"N","chainId":"_all_"},{"id":"web_heifetz_grow_ad","type":"String","value":"1"},{"id":"se_webtimebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_ffzx_jushen1","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iosintimacy","type":"String","value":"2","chainId":"_all_"},{"id":"soc_yxzl_zcfw","type":"String","value":"0","chainId":"_all_"},{"id":"gue_thanks","type":"String","value":"0"},{"id":"zr_search_sim","type":"String","value":"0","chainId":"_all_"},{"id":"se_hotsearch_2","type":"String","value":"1","chainId":"_all_"},{"id":"se_use_zitem","type":"String","value":"0","chainId":"_all_"},{"id":"top_test_4_liguangyi","type":"String","value":"1","chainId":"_all_"},{"id":"pf_adjust","type":"String","value":"0","chainId":"_all_"},{"id":"web_answer_update","type":"String","value":"0"},{"id":"tp_sft_v2","type":"String","value":"d","chainId":"_all_"},{"id":"tp_club_tab_feed","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zcfw_broadcast","type":"String","value":"0","chainId":"_all_"},{"id":"web_answer_list_ad","type":"String","value":"1"},{"id":"se_new_topic","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_pk","type":"String","value":"1","chainId":"_all_"},{"id":"tp_discovery_ab_1","type":"String","value":"0","chainId":"_all_"},{"id":"li_ebook_read","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_4","type":"String","value":"1","chainId":"_all_"},{"id":"soc_adreadline","type":"String","value":"0","chainId":"_all_"},{"id":"soc_authormore2","type":"String","value":"2","chainId":"_all_"},{"id":"ug_zero_follow","type":"String","value":"0","chainId":"_all_"},{"id":"se_hotsearch","type":"String","value":"0","chainId":"_all_"},{"id":"se_ios_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"se_pek_test2","type":"String","value":"1","chainId":"_all_"},{"id":"se_presearch_ab","type":"String","value":"0","chainId":"_all_"},{"id":"zr_slotpaidexp","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_android_join","type":"String","value":"1","chainId":"_all_"},{"id":"ug_follow_answerer","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_android_feed","type":"String","value":"old","chainId":"_all_"},{"id":"se_ctx_rerank","type":"String","value":"1","chainId":"_all_"},{"id":"se_movietab","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_header","type":"String","value":"1","chainId":"_all_"},{"id":"soc_iosreadline","type":"String","value":"0","chainId":"_all_"},{"id":"ls_videoad","type":"String","value":"2","chainId":"_all_"},{"id":"se_entity_model","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_qa","type":"String","value":"1","chainId":"_all_"},{"id":"gue_card_test","type":"String","value":"1"},{"id":"tsp_videobillboard","type":"String","value":"1","chainId":"_all_"},{"id":"pf_fuceng","type":"String","value":"1","chainId":"_all_"},{"id":"zr_km_feed_nlp","type":"String","value":"old","chainId":"_all_"},{"id":"zr_training_first","type":"String","value":"false","chainId":"_all_"},{"id":"tp_sft","type":"String","value":"a","chainId":"_all_"},{"id":"zr_search_paid","type":"String","value":"0","chainId":"_all_"},{"id":"soc_bigone","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zcfw_badcase","type":"String","value":"0","chainId":"_all_"},{"id":"gue_self_censoring","type":"String","value":"1"},{"id":"web_question_invite","type":"String","value":"B"},{"id":"se_preset_label","type":"String","value":"1","chainId":"_all_"},{"id":"se_cate_l3","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iospinweight","type":"String","value":"0","chainId":"_all_"},{"id":"web_mini_review","type":"String","value":"0"},{"id":"se_billboardsearch","type":"String","value":"0","chainId":"_all_"},{"id":"ug_goodcomment_0","type":"String","value":"1","chainId":"_all_"},{"id":"zr_answer_rec_cp","type":"String","value":"open","chainId":"_all_"},{"id":"se_time_threshold","type":"String","value":"0","chainId":"_all_"},{"id":"soc_wonderuser_recom","type":"String","value":"2","chainId":"_all_"},{"id":"pf_creator_card","type":"String","value":"1","chainId":"_all_"},{"id":"se_timebox_up","type":"String","value":"0","chainId":"_all_"},{"id":"se_searchwiki","type":"String","value":"0","chainId":"_all_"},{"id":"se_adxtest","type":"String","value":"1","chainId":"_all_"},{"id":"soc_userrec","type":"String","value":"0","chainId":"_all_"},{"id":"soc_stickypush","type":"String","value":"1","chainId":"_all_"},{"id":"gue_bullet_guide","type":"String","value":"发个弹幕聊聊…"},{"id":"ls_fmp4","type":"String","value":"0","chainId":"_all_"},{"id":"se_col_boost","type":"String","value":"0","chainId":"_all_"},{"id":"tp_qa_metacard_top","type":"String","value":"top","chainId":"_all_"},{"id":"se_pek_test3","type":"String","value":"1","chainId":"_all_"},{"id":"soc_zcfw_broadcast2","type":"String","value":"1","chainId":"_all_"},{"id":"se_mobileweb","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_qa_pic","type":"String","value":"1","chainId":"_all_"},{"id":"soc_brdcst4","type":"String","value":"3","chainId":"_all_"},{"id":"top_ebook","type":"String","value":"0","chainId":"_all_"},{"id":"zr_ans_rec","type":"String","value":"gbrank","chainId":"_all_"},{"id":"gue_goods_card","type":"String","value":"0"},{"id":"se_hotmore","type":"String","value":"2","chainId":"_all_"},{"id":"pf_foltopic_usernum","type":"String","value":"50","chainId":"_all_"},{"id":"gue_new_special_page","type":"String","value":"1"},{"id":"se_prf","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_tab","type":"String","value":"0","chainId":"_all_"},{"id":"tp_score_1","type":"String","value":"a","chainId":"_all_"},{"id":"qap_ques_invite","type":"String","value":"0","chainId":"_all_"},{"id":"se_expired_ob","type":"String","value":"0","chainId":"_all_"},{"id":"se_agency","type":"String","value":" 0","chainId":"_all_"},{"id":"se_college_cm","type":"String","value":"0","chainId":"_all_"},{"id":"qap_payc_invite","type":"String","value":"0","chainId":"_all_"},{"id":"se_sug","type":"String","value":"1","chainId":"_all_"},{"id":"li_answer_card","type":"String","value":"0","chainId":"_all_"},{"id":"tp_discover","type":"String","value":"0","chainId":"_all_"},{"id":"li_catalog_card","type":"String","value":"1","chainId":"_all_"},{"id":"zr_slot_training","type":"String","value":"1","chainId":"_all_"},{"id":"zr_rec_answer_cp","type":"String","value":"close","chainId":"_all_"},{"id":"tp_meta_card","type":"String","value":"0","chainId":"_all_"},{"id":"soc_cardheight","type":"String","value":"2","chainId":"_all_"},{"id":"ug_follow_topic_1","type":"String","value":"2","chainId":"_all_"},{"id":"li_ebok_chap","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_pic_swiper","type":"String","value":"1","chainId":"_all_"},{"id":"zr_update_merge_size","type":"String","value":"1","chainId":"_all_"},{"id":"web_upload","type":"String","value":"1"},{"id":"se_waterfall","type":"String","value":"0","chainId":"_all_"},{"id":"qap_thanks","type":"String","value":"1","chainId":"_all_"},{"id":"zr_slot_cold_start","type":"String","value":"aver","chainId":"_all_"},{"id":"web_unfriendly_comm","type":"String","value":"0"},{"id":"se_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"se_auto_syn","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zcfw_shipinshiti","type":"String","value":"1","chainId":"_all_"},{"id":"li_salt_hot","type":"String","value":"1","chainId":"_all_"},{"id":"se_related_index","type":"String","value":"3","chainId":"_all_"},{"id":"tp_sticky_android","type":"String","value":"2","chainId":"_all_"},{"id":"gue_zhuantikapian","type":"String","value":"0"},{"id":"web_sec672","type":"String","value":"0"},{"id":"tp_qa_toast","type":"String","value":"1","chainId":"_all_"},{"id":"gue_bullet_second","type":"String","value":"1"},{"id":"qap_question_author","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_heat","type":"String","value":"1","chainId":"_all_"},{"id":"zr_video_recall","type":"String","value":"current_recall","chainId":"_all_"},{"id":"se_article_icon","type":"String","value":"0","chainId":"_all_"},{"id":"top_universalebook","type":"String","value":"1","chainId":"_all_"},{"id":"gue_video_replay","type":"String","value":"0"},{"id":"web_ad_banner","type":"String","value":"0"},{"id":"li_sku_bottom_bar_re","type":"String","value":"0","chainId":"_all_"},{"id":"zr_video_rank","type":"String","value":"new_rank","chainId":"_all_"},{"id":"se_webmajorob","type":"String","value":"0","chainId":"_all_"},{"id":"se_club_post","type":"String","value":"5","chainId":"_all_"},{"id":"se_websearch","type":"String","value":"3","chainId":"_all_"},{"id":"se_multianswer","type":"String","value":"2","chainId":"_all_"},{"id":"ug_zero_follow_0","type":"String","value":"0","chainId":"_all_"},{"id":"web_mweb_rec_length","type":"String","value":"1"},{"id":"li_svip_cardshow","type":"String","value":"1","chainId":"_all_"},{"id":"soc_notification","type":"String","value":"0","chainId":"_all_"},{"id":"se_relationship","type":"String","value":"1","chainId":"_all_"},{"id":"se_entity_model_14","type":"String","value":"0","chainId":"_all_"},{"id":"se_topicfeed","type":"String","value":"1","chainId":"_all_"},{"id":"se_specialbutton","type":"String","value":"0","chainId":"_all_"},{"id":"tp_discover_copy","type":"String","value":"0","chainId":"_all_"},{"id":"web_mweb_launch","type":"String","value":"0"},{"id":"li_svip_tab_search","type":"String","value":"0","chainId":"_all_"},{"id":"web_column_auto_invite","type":"String","value":"0"},{"id":"se_featured","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_discover","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"soc_newfeed","type":"String","value":"2","chainId":"_all_"},{"id":"li_purchase_test","type":"String","value":"0","chainId":"_all_"},{"id":"web_collect","type":"String","value":"0"},{"id":"zw_sameq_sorce","type":"String","value":"999","chainId":"_all_"},{"id":"se_click_club","type":"String","value":"1","chainId":"_all_"},{"id":"se_new_p","type":"String","value":"0","chainId":"_all_"},{"id":"tp_m_intro_re_topic","type":"String","value":"1","chainId":"_all_"},{"id":"soc_ri_merge","type":"String","value":"0","chainId":"_all_"},{"id":"gue_video_autoplay","type":"String","value":"0"},{"id":"li_ebook_gen_search","type":"String","value":"0","chainId":"_all_"},{"id":"se_colorfultab","type":"String","value":"1","chainId":"_all_"},{"id":"tp_header_style","type":"String","value":"1","chainId":"_all_"},{"id":"soc_bignew","type":"String","value":"1","chainId":"_all_"},{"id":"li_se_media_icon","type":"String","value":"1","chainId":"_all_"},{"id":"se_aa","type":"String","value":"0","chainId":"_all_"},{"id":"se_hot_timebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_rf_w","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_rec","type":"String","value":"1","chainId":"_all_"},{"id":"se_topiclabel","type":"String","value":"1","chainId":"_all_"},{"id":"se_famous","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_join","type":"String","value":"0","chainId":"_all_"},{"id":"ug_newtag","type":"String","value":"0","chainId":"_all_"},{"id":"se_sug_entrance","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_feed","type":"String","value":"1","chainId":"_all_"},{"id":"tsp_hotlist_ui","type":"String","value":"1","chainId":"_all_"},{"id":"zr_km_answer","type":"String","value":"open_cvr","chainId":"_all_"}],"chains":[{"chainId":"_all_"}]},"triggers":{}},"userAgent":{"Edge":false,"Wechat":false,"Weibo":false,"QQ":false,"MQQBrowser":false,"Qzone":false,"Mobile":false,"Android":false,"iOS":false,"isAppleDevice":false,"Zhihu":false,"ZhihuHybrid":false,"isBot":false,"Tablet":false,"UC":false,"Sogou":false,"Qihoo":false,"Baidu":false,"BaiduApp":false,"Safari":false,"GoogleBot":false,"AndroidDaily":false,"iOSDaily":false,"isWebView":false,"origin":"Mozilla\u002F5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\u002F537.36 (KHTML, like Gecko) Chrome\u002F80.0.3987.100 Safari\u002F537.36"},"appViewConfig":{},"ctx":{"path":"\u002Fp\u002F56043646","query":{},"href":"http:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F56043646","host":"zhuanlan.zhihu.com"},"trafficSource":"production","edition":{"baidu":false,"sogou":false,"baiduBeijing":false,"sogouBeijing":false,"sogouInput":false},"theme":"light","enableShortcut":true,"referer":"","conf":{},"ipInfo":{"cityName":"德州","countryName":"中国","regionName":"山东","countryCode":"CN"},"logged":false},"me":{"columnContributions":[]},"label":{"recognizerLists":{}},"ecommerce":{},"comments":{"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"parent":{}},"commentsV2":{"stickers":[],"commentWithPicPermission":{},"notificationsComments":{},"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"conversationMore":{},"parent":{}},"pushNotifications":{"default":{"isFetching":false,"isDrained":false,"ids":[]},"follow":{"isFetching":false,"isDrained":false,"ids":[]},"vote_thank":{"isFetching":false,"isDrained":false,"ids":[]},"currentTab":"default","notificationsCount":{"default":0,"follow":0,"vote_thank":0}},"messages":{"data":{},"currentTab":"common","messageCount":0},"register":{"registerValidateSucceeded":null,"registerValidateErrors":{},"registerConfirmError":null,"sendDigitsError":null,"registerConfirmSucceeded":null},"login":{"loginUnregisteredError":false,"loginBindWechatError":false,"loginConfirmError":null,"sendDigitsError":null,"needSMSIdentify":false,"validateDigitsError":false,"loginConfirmSucceeded":null,"qrcodeLoginToken":"","qrcodeLoginScanStatus":0,"qrcodeLoginError":null,"qrcodeLoginReturnNewToken":false},"active":{"sendDigitsError":null,"activeConfirmSucceeded":null,"activeConfirmError":null},"switches":{},"captcha":{"captchaNeeded":false,"captchaValidated":false,"captchaBase64String":null,"captchaValidationMessage":null,"loginCaptchaExpires":false},"sms":{"supportedCountries":[]},"chat":{"chats":{},"inbox":{"recents":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"strangers":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"friends":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"search":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"config":{"newCount":0,"strangerMessageSwitch":false,"strangerMessageUnread":false,"friendCount":0}},"global":{"isChatMqttExisted":false}},"emoticons":{"emoticonGroupList":[],"emoticonGroupDetail":{}},"creator":{"currentCreatorUrlToken":null,"homeData":{"recommendQuestions":[]},"tools":{"question":{"invitationCount":{"questionFolloweeCount":0,"questionTotalCount":0},"goodatTopics":[]},"customPromotion":{"itemLists":{}},"recommend":{"recommendTimes":{}}},"explore":{"academy":{"tabs":[],"article":{}}},"rights":[],"rightsStatus":{},"levelUpperLimit":10,"account":{"growthLevel":{}},"mcn":{},"applyStatus":{}},"recommendation":{"homeRecommendations":[]},"shareTexts":{},"articles":{"voters":{}},"previewPost":{},"favlists":{"relations":{}},"columns":{"voters":{}},"reward":{"answer":{},"article":{},"question":{}},"video":{"data":{},"shareVideoDetail":{},"last":{}},"topstory":{"recommend":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"follow":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followWonderful":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"sidebar":null,"announcement":{},"hotListCategories":[],"hotList":[],"guestFeeds":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followExtra":{"isNewUser":null,"isFetched":false,"followCount":0,"followers":[]}},"readStatus":{},"column":{},"requestColumn":{"categories":[],"error":null},"articleContribution":{"contributeRequests":[],"deleteContributeIdList":[],"handledContributeIdList":[],"recommendedColumns":[],"pinnedColumns":[],"sentContributeRequestsIdList":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"sharerl","reinforcementlearning"]},"columnContribution":{"contributeRequests":[],"autoInviteEnabled":false,"recommendedContributors":[],"contributionInvitation":null},"draftHistory":{"history":{},"drafts":{}},"upload":{},"articleDraft":{"titleImage":"","titleImageSize":{},"isTitleImageFullScreen":false,"canTitleImageFullScreen":false,"title":"","titleImageUploading":false,"error":"","content":"","draftLoading":false,"updating":false,"globalLoading":false,"pendingVideo":{"resource":null,"error":null},"deleteFail":{"fail":false},"recommendTopics":[],"selectedColumn":0,"articleDisclaimers":[]},"articleDrafts":{"isDrained":false,"isLoading":false,"items":[]},"columnAutocomplete":{"users":[],"friends":[]},"columnCollection":{},"mcn":{"bindInfo":{},"memberCategoryList":[],"producerList":[],"categoryList":[]}},"fetchHost":"www.zhihu.com","subAppName":"column"}</script><script src="https://static.zhihu.com/heifetz/vendor.7b36fae46082fd30a0db.js"></script><script src="https://static.zhihu.com/heifetz/column.app.76e02b16e87eec249f44.js"></script></body><script src="https://hm.baidu.com/hm.js?98beee57fd2ef70ccdd5ca52b9740c49" async=""></script><script src="https://zz.bdstatic.com/linksubmit/push.js" async=""></script></html>