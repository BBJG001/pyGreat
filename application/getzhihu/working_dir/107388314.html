<!doctype html>
<html lang="zh" data-hairline="true" data-theme="light"><head><meta charSet="utf-8"/><title data-react-helmet="true">【强化学习 104】Mean-field for Semi-supervised，也聊 Ising - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"/><meta name="renderer" content="webkit"/><meta name="force-rendering" content="webkit"/><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg"/><meta data-react-helmet="true" name="keywords" content="量子场论,理论物理,强化学习 (Reinforcement Learning)"/><meta data-react-helmet="true" name="description" content="本文提出使用 Ising 模型的平均场论解法来解决半监督学习问题。原文传送门Wang, Fei, et al. &amp;#34;Semi-supervised mean fields.&amp;#34; Artificial Intelligence and Statistics. 2007.特色这篇文章先介绍了 Ising …"/><meta data-react-helmet="true" property="og:title" content="【强化学习 104】Mean-field for Semi-supervised，也聊 Ising"/><meta data-react-helmet="true" property="og:url" content="https://zhuanlan.zhihu.com/p/107388314"/><meta data-react-helmet="true" property="og:description" content="本文提出使用 Ising 模型的平均场论解法来解决半监督学习问题。原文传送门Wang, Fei, et al. &amp;#34;Semi-supervised mean fields.&amp;#34; Artificial Intelligence and Statistics. 2007.特色这篇文章先介绍了 Ising …"/><meta data-react-helmet="true" property="og:image" content="https://pic4.zhimg.com/v2-5b99901916cac006d5ed0f1a586ba2fb_b.jpg"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" property="og:site_name" content="知乎专栏"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png" sizes="152x152"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-120.b3e6278d.png" sizes="120x120"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-76.7a750095.png" sizes="76x76"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-60.a4a761d4.png" sizes="60x60"/><link rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/static/favicon.ico"/><link rel="search" type="application/opensearchdescription+xml" href="https://static.zhihu.com/static/search.xml" title="知乎"/><link rel="dns-prefetch" href="//static.zhimg.com"/><link rel="dns-prefetch" href="//pic1.zhimg.com"/><link rel="dns-prefetch" href="//pic2.zhimg.com"/><link rel="dns-prefetch" href="//pic3.zhimg.com"/><link rel="dns-prefetch" href="//pic4.zhimg.com"/><style>
.u-safeAreaInset-top {
  height: constant(safe-area-inset-top) !important;
  height: env(safe-area-inset-top) !important;
  
}
.u-safeAreaInset-bottom {
  height: constant(safe-area-inset-bottom) !important;
  height: env(safe-area-inset-bottom) !important;
  
}
</style><link href="https://static.zhihu.com/heifetz/column.app.a9ced452148fee3a55c8.css" rel="stylesheet"/><script defer="" crossorigin="anonymous" src="https://unpkg.zhimg.com/@cfe/sentry-script@latest/dist/init.js" data-sentry-config="{&quot;dsn&quot;:&quot;https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224&quot;,&quot;sampleRate&quot;:0.1,&quot;release&quot;:&quot;683-127b14ad&quot;,&quot;ignoreErrorNames&quot;:[&quot;NetworkError&quot;,&quot;SecurityError&quot;],&quot;ignoreErrors&quot;:[&quot;origin message&quot;,&quot;Network request failed&quot;,&quot;Loading chunk&quot;,&quot;这个系统不支持该功能。&quot;,&quot;Can&#x27;t find variable: webkit&quot;,&quot;Can&#x27;t find variable: $&quot;,&quot;内存不足&quot;,&quot;out of memory&quot;,&quot;DOM Exception 18&quot;,&quot;The operation is insecure&quot;,&quot;[object Event]&quot;,&quot;[object FileError]&quot;,&quot;[object DOMError]&quot;,&quot;[object Object]&quot;,&quot;拒绝访问。&quot;,&quot;Maximum call stack size exceeded&quot;,&quot;UploadError&quot;,&quot;无法 fetch&quot;,&quot;draft-js&quot;,&quot;缺少 JavaScript 对象&quot;,&quot;componentWillEnter&quot;,&quot;componentWillLeave&quot;,&quot;componentWillAppear&quot;,&quot;getInlineStyleAt&quot;,&quot;getCharacterList&quot;],&quot;whitelistUrls&quot;:[&quot;static.zhihu.com&quot;]}"></script></head><body class="WhiteBg-body"><div id="root"><div class="App"><div class="LoadingBar"></div><main role="main" class="App-main"><div class="Post-content" data-zop-usertoken="{&quot;userToken&quot;:&quot;&quot;}" data-zop="{&quot;authorName&quot;:&quot;张楚珩&quot;,&quot;itemId&quot;:107388314,&quot;title&quot;:&quot;【强化学习 104】Mean-field for Semi-supervised，也聊 Ising&quot;,&quot;type&quot;:&quot;article&quot;}"><div class="ColumnPageHeader-Wrapper"><div><div class="Sticky ColumnPageHeader"><div class="ColumnPageHeader-content"><a href="//www.zhihu.com" aria-label="知乎"><svg viewBox="0 0 200 91" fill="#0084FF" width="64" height="30"><path d="M53.29 80.035l7.32.002 2.41 8.24 13.128-8.24h15.477v-67.98H53.29v67.978zm7.79-60.598h22.756v53.22h-8.73l-8.718 5.473-1.587-5.46-3.72-.012v-53.22zM46.818 43.162h-16.35c.545-8.467.687-16.12.687-22.955h15.987s.615-7.05-2.68-6.97H16.807c1.09-4.1 2.46-8.332 4.1-12.708 0 0-7.523 0-10.085 6.74-1.06 2.78-4.128 13.48-9.592 24.41 1.84-.2 7.927-.37 11.512-6.94.66-1.84.785-2.08 1.605-4.54h9.02c0 3.28-.374 20.9-.526 22.95H6.51c-3.67 0-4.863 7.38-4.863 7.38H22.14C20.765 66.11 13.385 79.24 0 89.62c6.403 1.828 12.784-.29 15.937-3.094 0 0 7.182-6.53 11.12-21.64L43.92 85.18s2.473-8.402-.388-12.496c-2.37-2.788-8.768-10.33-11.496-13.064l-4.57 3.627c1.363-4.368 2.183-8.61 2.46-12.71H49.19s-.027-7.38-2.372-7.38zm128.752-.502c6.51-8.013 14.054-18.302 14.054-18.302s-5.827-4.625-8.556-1.27c-1.874 2.548-11.51 15.063-11.51 15.063l6.012 4.51zm-46.903-18.462c-2.814-2.577-8.096.667-8.096.667s12.35 17.2 12.85 17.953l6.08-4.29s-8.02-11.752-10.83-14.33zM199.99 46.5c-6.18 0-40.908.292-40.953.292v-31.56c1.503 0 3.882-.124 7.14-.376 12.773-.753 21.914-1.25 27.427-1.504 0 0 3.817-8.496-.185-10.45-.96-.37-7.24 1.43-7.24 1.43s-51.63 5.153-72.61 5.64c.5 2.756 2.38 5.336 4.93 6.11 4.16 1.087 7.09.53 15.36.277 7.76-.5 13.65-.76 17.66-.76v31.19h-41.71s.88 6.97 7.97 7.14h33.73v22.16c0 4.364-3.498 6.87-7.65 6.6-4.4.034-8.15-.36-13.027-.566.623 1.24 1.977 4.496 6.035 6.824 3.087 1.502 5.054 2.053 8.13 2.053 9.237 0 14.27-5.4 14.027-14.16V53.93h38.235c3.026 0 2.72-7.432 2.72-7.432z" fill-rule="evenodd"></path></svg></a><i class="ColumnPageHeader-Line"></i><div class="ColumnPageHeader-Title"><a class="ColumnLink ColumnPageHeader-Link" href="/reinforcementlearning"><img class="Avatar Avatar--round" width="30" height="30" src="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_is.jpg" srcSet="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_im.jpg 2x" alt="强化学习前沿"/></a><div class="ColumnPageHeader-TitleName"><span class="ColumnPageHeader-TitleMeta">首发于</span><a class="ColumnLink ColumnPageHeader-TitleColumn" href="/reinforcementlearning">强化学习前沿</a></div></div><div class="ColumnPageHeader-Button"><button type="button" class="Button ColumnPageHeader-WriteButton Button--blue"><svg class="Zi Zi--EditSurround" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M18.453 7.992l-1.833-1.65.964-.978a1.223 1.223 0 0 1 1.73-.012l.005.006a1.24 1.24 0 0 1 .007 1.748l-.873.886zm-1.178 1.194l-5.578 5.66-1.935.697a.393.393 0 0 1-.504-.504l.697-1.935 5.488-5.567 1.832 1.65zM7.58 5.848l5.654.006-1.539 1.991-3.666.012A1.02 1.02 0 0 0 7 8.868v7.993c0 .558.46 1.01 1.029 1.01l7.941-.01c.568 0 1.03-.453 1.03-1.012v-4.061l2-1.442v6.002c0 1.397-1.2 2.501-2.62 2.501H7.574C6.153 19.85 5 18.717 5 17.32V8.35c0-1.397 1.16-2.502 2.58-2.502z"></path></svg>写文章</button></div></div></div></div></div><img class="TitleImage" src="https://pic4.zhimg.com/v2-5b99901916cac006d5ed0f1a586ba2fb_1200x500.jpg" alt="【强化学习 104】Mean-field for Semi-supervised，也聊 Ising"/><article class="Post-Main Post-NormalMain" tabindex="-1"><header class="Post-Header"><h1 class="Post-Title">【强化学习 104】Mean-field for Semi-supervised，也聊 Ising</h1><div class="Post-Author"><div class="AuthorInfo" itemProp="author" itemscope="" itemType="http://schema.org/Person"><meta itemProp="name" content="张楚珩"/><meta itemProp="image" content="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg"/><meta itemProp="url" content="https://www.zhihu.com/people/zhang-chu-heng"/><meta itemProp="zhihu:followerCount"/><span class="UserLink AuthorInfo-avatarWrapper"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/zhang-chu-heng"><img class="Avatar Avatar--round AuthorInfo-avatar" width="38" height="38" src="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_xs.jpg" srcSet="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg 2x" alt="张楚珩"/></a></div></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/zhang-chu-heng">张楚珩</a></div></div><style data-emotion-css="1cd9gw4">.css-1cd9gw4{margin-left:.3em;}</style><style data-emotion-css="1pc1mic">.css-1pc1mic{box-sizing:border-box;margin:0;min-width:0;color:#175199;display:inline-block;width:18px;height:18px;margin-left:.3em;}</style><a href="https://www.zhihu.com/question/48510028" target="_blank" class="css-1pc1mic" data-tooltip="已认证的个人" aria-label="已认证的个人"><style data-emotion-css="18biwo">.css-18biwo{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><span class="css-18biwo">​<svg viewBox="0 0 24 24" width="18" height="18"><svg viewBox="0 0 24 24" x="-3" y="-3" fill="#FFFFFF" width="30" height="30"><path d="M3.56231227,13.8535307 C2.40051305,12.768677 2.41398885,11.0669203 3.59484487,9.99979213 L3.59222085,9.99654885 C4.26730143,9.45036719 4.79446755,8.21005186 4.7184197,7.34453784 L4.72305873,7.34412719 C4.66942824,5.75539997 5.8824188,4.56066914 7.47188965,4.64242381 L7.47229112,4.6386236 C8.33515314,4.72977993 9.58467253,4.22534048 10.1426329,3.55925173 L10.1462611,3.56228565 C11.2316055,2.40008701 12.9353108,2.41394456 14.0015072,3.59634088 L14.0047263,3.59374004 C14.5498229,4.26841874 15.7896857,4.79521622 16.6545744,4.71844347 L16.6549836,4.72304294 C18.245027,4.66894057 19.4396947,5.88213996 19.3575031,7.47241135 L19.3623099,7.47292747 C19.2704388,8.3358681 19.7742711,9.58421483 20.4407199,10.1424506 L20.437686,10.1460789 C21.5997217,11.2312209 21.5860695,12.9345218 20.4042441,14.0007396 L20.4072865,14.0045125 C19.7325967,14.5495925 19.2055209,15.7896954 19.2815865,16.6561959 L19.2770449,16.6565978 C19.3315454,18.2453037 18.1173775,19.4393568 16.5274188,19.3571512 L16.5269029,19.3619539 C15.6647098,19.270083 14.415408,19.7741709 13.8573671,20.4403558 L13.8537409,20.4373235 C12.76842,21.5995708 11.0650432,21.5864553 9.99899434,20.4039226 L9.99527367,20.406923 C9.45025436,19.7323399 8.21017638,19.2051872 7.34461983,19.2812352 L7.344304,19.2776405 C5.75448683,19.3312904 4.55977145,18.1170085 4.64254978,16.527117 L4.63769921,16.5265942 C4.72957031,15.6644394 4.22547659,14.4151814 3.55928015,13.8571569 L3.56231227,13.8535307 Z"></path></svg><path d="M2.63951518,13.3895441 C3.70763333,14.2842292 4.44777637,16.1226061 4.30075305,17.5023312 L4.32211542,17.3063047 C4.17509209,18.6910561 5.17786655,19.7063729 6.5613937,19.5844846 L6.364106,19.6008202 C7.75140298,19.4789319 9.57474349,20.2554985 10.4468305,21.3349009 L10.3224262,21.1803415 C11.1982831,22.2647703 12.6257916,22.2723098 13.5167278,21.2079863 L13.3898102,21.3600325 C14.2845162,20.2919393 16.1229361,19.5518136 17.5026934,19.6988334 L17.3054057,19.6774716 C18.6914461,19.8244915 19.7067866,18.8217404 19.5836389,17.4395022 L19.6012314,17.6367853 C19.4793403,16.2482641 20.255925,14.4249662 21.3353526,13.5528995 L21.1807897,13.677301 C22.2639871,12.8014646 22.2727834,11.3739894 21.2084351,10.483074 L21.3604848,10.6099886 C20.2923667,9.71530351 19.5522236,7.87818322 19.6992469,6.49720154 L19.6778846,6.69448464 C19.8249079,5.30847665 18.8221335,4.2944164 17.4386063,4.41630468 L17.635894,4.39871256 C16.248597,4.52185742 14.4252565,3.74529084 13.5531695,2.66588842 L13.6775738,2.81919121 C12.8017169,1.73601905 11.3742084,1.72722299 10.4832722,2.79154644 L10.6101898,2.63950024 C9.71548377,3.70759343 7.87706394,4.44771919 6.49730661,4.30195588 L6.69459432,4.32206116 C5.30855394,4.17504128 4.29447,5.17904888 4.41636114,6.56128713 L4.3987686,6.36400404 C4.52065973,7.75126861 3.74407501,9.57456653 2.66464737,10.4478898 L2.81921035,10.3222318 C1.73601288,11.1993248 1.72721662,12.6255433 2.79156494,13.5164587 L2.63951518,13.3895441 Z" fill="#0084FF"></path><svg class="Zi Zi--Check" fill="#fff" x="6" y="6" viewBox="0 0 24 24" width="12" height="12"><path d="M10.229 17.516c-.318.327-.75.484-1.199.484-.453 0-.884-.16-1.202-.488l-4.335-4.47a1.77 1.77 0 0 1 .007-2.459 1.663 1.663 0 0 1 2.397.01l3.137 3.246 9.072-9.329a1.662 1.662 0 0 1 2.397 0c.663.681.663 1.786 0 2.466L10.23 17.516z" fill-rule="evenodd"></path></svg></svg></span></a></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="AuthorInfo-badgeText">清华大学 交叉信息院博士在读</div></div></div></div></div></div><div><span class="Voters"><button type="button" class="Button Button--plain">34 人<!-- -->赞同了该文章</button></span></div></header><div class="Post-RichTextContainer"><div class="RichText ztext Post-RichText"><p>本文提出使用 Ising 模型的平均场论解法来解决半监督学习问题。</p><h2>原文传送门</h2><p><a href="https://link.zhihu.com/?target=http%3A//www.jmlr.org/proceedings/papers/v2/wang07c/wang07c.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Wang, Fei, et al. &#34;Semi-supervised mean fields.&#34; Artificial Intelligence and Statistics. 2007.</a></p><h2>特色</h2><p>这篇文章先介绍了 Ising 模型（这是一个很有趣的模型，记得本科电磁学课的小作业还写过 Ising 模型的模拟程序）。接下来这篇文章把半监督学习问题用 Ising 模型来建模，并且使用平均场方法（naive mean field approach）来解决。文章还指出，贝叶斯方法和该方法在本质上的联系；特别地，半监督学习问题的本质就是要利用数据标签在数据空间上的平滑特性，可以把数据空间建模为一个图（graph），这又和我们前面在研究的 spectral graph theory 有一定的联系。</p><h2>过程</h2><h3>1. Ising 模型</h3><p>考虑 N 个粒子，每个原子有一个自旋（spin），自旋是二值量子化的，只能够取向上或者向下两种情况，即 <img src="https://www.zhihu.com/equation?tex=S_i+%5Cin+%5C%7B-1+%2C+%2B1%5C%7D" alt="S_i \in \{-1 , +1\}" eeimg="1"/> 。这样，原子的自旋方向的状态（configuration）就有 <img src="https://www.zhihu.com/equation?tex=2%5EN" alt="2^N" eeimg="1"/> 种情形，记这样的状态为加粗的 <img src="https://www.zhihu.com/equation?tex=%5Cbm+S" alt="\bm S" eeimg="1"/> 。</p><p>那么系统究竟处于哪一种状态下呢？考虑这是一个热力学系统，系统会以一定的概率处于某一个状态下，根据热力学的知识，一个粒子可分辨系统处于不同状态的概念遵循玻尔兹曼分辨，即系统处于状态 <img src="https://www.zhihu.com/equation?tex=%5Cbm+S" alt="\bm S" eeimg="1"/> 的概率为 <img src="https://www.zhihu.com/equation?tex=P%28%7B%5Cbm+S%7D%29+%3D+%5Cdfrac%7B1%7D%7BZ%7D+%5Cexp%28-E%28%7B%5Cbm+S%7D%29+%2F+kT%29" alt="P({\bm S}) = \dfrac{1}{Z} \exp(-E({\bm S}) / kT)" eeimg="1"/> ，其中 k 为玻尔兹曼常数，T 为系统当前的温度，E 为系统处于该状态时的能量，Z 为配分函数，也可以理解它为归一化系数；在这里可以认为 kT=1。可以看到，当温度较低时，系统处于最低能量状态的概念会大大超过其他状态，因此系统会基本上处于最低的能量状态；当温度较高时，系统处于各个能量状态的概率基本上一样，因此系统会以几乎差不多的概率分布在各个状态上。</p><p>某个状态下的能量函数定义如下</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-15d6f3e7f5fde1701307e9967580e3d7_b.png" data-caption="" data-size="normal" data-rawwidth="395" data-rawheight="48" class="content_image" width="395"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;395&#39; height=&#39;48&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="395" data-rawheight="48" class="content_image lazy" width="395" data-actualsrc="https://pic4.zhimg.com/v2-15d6f3e7f5fde1701307e9967580e3d7_b.png"/></figure><p>其中求和符号表示对于系统中任意两个粒子对进行求和， J 表示这两个粒子对的相互作用能， <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="\theta" eeimg="1"/> 表示外场对于某个粒子的作用能。</p><p>有了这样的模型之后，我们的问题是：如果给定相互作用能 J 和外场作用能 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="\theta" eeimg="1"/> ，如何求到每一个粒子所处自旋状态的概率分布或者均值。我们可以把第 i 个粒子处于状态 <img src="https://www.zhihu.com/equation?tex=S_i" alt="S_i" eeimg="1"/> 的概率分布写作整个系统状态分布的边缘分布：</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-832011360f5be02a9c02c2999fa808e1_b.png" data-caption="" data-size="normal" data-rawwidth="440" data-rawheight="49" class="origin_image zh-lightbox-thumb" width="440" data-original="https://pic2.zhimg.com/v2-832011360f5be02a9c02c2999fa808e1_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;440&#39; height=&#39;49&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="440" data-rawheight="49" class="origin_image zh-lightbox-thumb lazy" width="440" data-original="https://pic2.zhimg.com/v2-832011360f5be02a9c02c2999fa808e1_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-832011360f5be02a9c02c2999fa808e1_b.png"/></figure><p> 即，对于所有在第 i 个粒子上处于状态 <img src="https://www.zhihu.com/equation?tex=S_i" alt="S_i" eeimg="1"/> 的状态的概率的和。</p><p>接着，我们还可以写出该粒子自旋状态的均值：</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-97d91f5e1e60f62f0cadaa5824c43b29_b.png" data-caption="" data-size="normal" data-rawwidth="432" data-rawheight="47" class="origin_image zh-lightbox-thumb" width="432" data-original="https://pic2.zhimg.com/v2-97d91f5e1e60f62f0cadaa5824c43b29_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;432&#39; height=&#39;47&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="432" data-rawheight="47" class="origin_image zh-lightbox-thumb lazy" width="432" data-original="https://pic2.zhimg.com/v2-97d91f5e1e60f62f0cadaa5824c43b29_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-97d91f5e1e60f62f0cadaa5824c43b29_b.png"/></figure><p>我们可以看到，这里计算的难点就在于要计算几乎所有可能的状态的概率，并对其求和。然而，系统的状态数目随着粒子的数目呈指数级增长，因此这样直接计算的方法是不可行的。</p><h3>2. 平均场方法求解 Ising 模型</h3><p>其实，如果系统处于某个状态的概率（联合概率分布）如果具有某些好的性质，比如能拆分成多个独立的项，其实我们也能够比较方便地进行计算。观察系统处于某个状态的概率：</p><p><img src="https://www.zhihu.com/equation?tex=P%28%7B%5Cbm+S%7D%29+%3D+%5Cdfrac%7B1%7D%7BZ%7D+%5Cexp%5Cleft%28%5Csum_i+%28%5Ctheta_i+%2B+%5Csum_j+J_%7Bij%7D+S_j%29S_i%5Cright%29+%5Cpropto+%5Cprod_i+%5Cexp%5Cleft%28%28%5Ctheta_i+%2B+%5Csum_j+J_%7Bij%7D+S_j%29S_i%5Cright%29" alt="P({\bm S}) = \dfrac{1}{Z} \exp\left(\sum_i (\theta_i + \sum_j J_{ij} S_j)S_i\right) \propto \prod_i \exp\left((\theta_i + \sum_j J_{ij} S_j)S_i\right)" eeimg="1"/> </p><p>但是注意到，它并没有被拆分为多个独立的项，因为每一项都还是与全局其他粒子的自旋相关。接下来，就到了最为关键的一步了，就是把外界对于每一个粒子的作用都用一个<b>平均场 </b><img src="https://www.zhihu.com/equation?tex=%5Ctilde+m_i" alt="\tilde m_i" eeimg="1"/> 来代替。把这样近似后的概率分布函数写作 Q。令</p><p><img src="https://www.zhihu.com/equation?tex=Q%28%7B%5Cbm+S%7D%29+%3D+%5Cprod_i+Q_i%28S_i%29%2C+%5Cquad+Q_i%28S_i%29+%3D+%5Cdfrac%7B%5Cexp%28%5Ctilde+m_i+S_i%29%7D%7B%5Csum_%7BS_i%7D%5Cexp%28%5Ctilde++m_iS_i%29%7D+%5Capprox+%5Cdfrac%7B1%2BS_im_i%7D%7B2%7D" alt="Q({\bm S}) = \prod_i Q_i(S_i), \quad Q_i(S_i) = \dfrac{\exp(\tilde m_i S_i)}{\sum_{S_i}\exp(\tilde  m_iS_i)} \approx \dfrac{1+S_im_i}{2}" eeimg="1"/> </p><p>考虑到每个粒子只有两种状态，而这两种状态对应的 <img src="https://www.zhihu.com/equation?tex=Q_i" alt="Q_i" eeimg="1"/> 之和为 1，因此也可以被写作后面一种形式；同时，注意到 <img src="https://www.zhihu.com/equation?tex=m_i" alt="m_i" eeimg="1"/> 也可以看做是分布 Q 的一个参数；如果是后一种情形， <img src="https://www.zhihu.com/equation?tex=m_i" alt="m_i" eeimg="1"/> 也可以被解释为一个隐变量，代表着粒子 i 处的平均自旋， <img src="https://www.zhihu.com/equation?tex=m_i+%3D+%5Clangle+S_i+%5Crangle_Q" alt="m_i = \langle S_i \rangle_Q" eeimg="1"/> 。</p><p>下面我们要做的就是求解出近似的概率分布 Q，也就是要求解出相应的平均场。我们最小化分布 P 和分布 Q 之间的 KL divergence</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-01532f2c76c812182815d48bc81d7427_b.png" data-caption="" data-size="normal" data-rawwidth="413" data-rawheight="48" class="content_image" width="413"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;413&#39; height=&#39;48&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="413" data-rawheight="48" class="content_image lazy" width="413" data-actualsrc="https://pic4.zhimg.com/v2-01532f2c76c812182815d48bc81d7427_b.png"/></figure><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-9513e69a48d832278fc1be9c29ecd80f_b.png" data-caption="" data-size="normal" data-rawwidth="432" data-rawheight="33" class="origin_image zh-lightbox-thumb" width="432" data-original="https://pic4.zhimg.com/v2-9513e69a48d832278fc1be9c29ecd80f_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;432&#39; height=&#39;33&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="432" data-rawheight="33" class="origin_image zh-lightbox-thumb lazy" width="432" data-original="https://pic4.zhimg.com/v2-9513e69a48d832278fc1be9c29ecd80f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-9513e69a48d832278fc1be9c29ecd80f_b.png"/></figure><p>其中 S 为分布 Q 的熵</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-a8be487a2111f86965ff6514cf568a71_b.png" data-caption="" data-size="normal" data-rawwidth="420" data-rawheight="41" class="content_image" width="420"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;420&#39; height=&#39;41&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="420" data-rawheight="41" class="content_image lazy" width="420" data-actualsrc="https://pic2.zhimg.com/v2-a8be487a2111f86965ff6514cf568a71_b.png"/></figure><p>V 为 variational entropy</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-bd54d35112879836f52ac20bb9dee899_b.png" data-caption="" data-size="normal" data-rawwidth="429" data-rawheight="43" class="origin_image zh-lightbox-thumb" width="429" data-original="https://pic2.zhimg.com/v2-bd54d35112879836f52ac20bb9dee899_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;429&#39; height=&#39;43&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="429" data-rawheight="43" class="origin_image zh-lightbox-thumb lazy" width="429" data-original="https://pic2.zhimg.com/v2-bd54d35112879836f52ac20bb9dee899_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-bd54d35112879836f52ac20bb9dee899_b.png"/></figure><p>带入到 KL divergence 中，然后求导，可以求解出每个粒子的平均自旋 <img src="https://www.zhihu.com/equation?tex=m_i" alt="m_i" eeimg="1"/> </p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-b88b7de43c86f1dd29ef0f2361b1318f_b.png" data-caption="" data-size="normal" data-rawwidth="435" data-rawheight="70" class="origin_image zh-lightbox-thumb" width="435" data-original="https://pic4.zhimg.com/v2-b88b7de43c86f1dd29ef0f2361b1318f_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;435&#39; height=&#39;70&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="435" data-rawheight="70" class="origin_image zh-lightbox-thumb lazy" width="435" data-original="https://pic4.zhimg.com/v2-b88b7de43c86f1dd29ef0f2361b1318f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-b88b7de43c86f1dd29ef0f2361b1318f_b.png"/></figure><p>注意到每个位置的平均自旋的解是通过其他位置的解来定义的，因此要准确求出还需要做数值迭代，即通过下面的算法来得到。</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-8ce3a0f9974407d3a7165cde6f437877_b.jpg" data-caption="" data-size="normal" data-rawwidth="397" data-rawheight="381" class="content_image" width="397"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;397&#39; height=&#39;381&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="397" data-rawheight="381" class="content_image lazy" width="397" data-actualsrc="https://pic4.zhimg.com/v2-8ce3a0f9974407d3a7165cde6f437877_b.jpg"/></figure><p><b>平均场近似究竟在什么地方做了近似？</b></p><p>首先，平均场近似的结果肯定不是准确的结果。在平均场中，原本的“粒子-粒子”相互作用，通过一个平均场来作为中介，变成了“粒子-平均场-粒子”的相互作用。观察到，原本 P 函数中存在交叉项 <img src="https://www.zhihu.com/equation?tex=S_i+S_j" alt="S_i S_j" eeimg="1"/> 。假设在热平衡状态下，每个粒子的平均状态为 <img src="https://www.zhihu.com/equation?tex=%5Clangle+S_i++%5Crangle" alt="\langle S_i  \rangle" eeimg="1"/> ，定义粒子偏离平均状态的量为 <img src="https://www.zhihu.com/equation?tex=%5Cdelta+S_i+%3D+S_i+-+%5Clangle+S_i+%5Crangle" alt="\delta S_i = S_i - \langle S_i \rangle" eeimg="1"/> 。在平均场中，其实做了如下的近似</p><p><img src="https://www.zhihu.com/equation?tex=S_i+S_j+%3D+%5Clangle+S_i+%5Crangle+%5Clangle+S_j+%5Crangle+%2B+%5Cdelta+S_i++%5Clangle+S_j+%5Crangle+%2B+%5Clangle+S_i+%5Crangle+%5Cdelta+S_j+%2B+%5Cdelta+S_i+%5C+%5Cdelta+S_j+%5Capprox+%5Clangle+S_i+%5Crangle+%5Clangle+S_j+%5Crangle+%2B+%5Cdelta+S_i++%5Clangle+S_j+%5Crangle+%2B+%5Clangle+S_i+%5Crangle+%5Cdelta+S_j" alt="S_i S_j = \langle S_i \rangle \langle S_j \rangle + \delta S_i  \langle S_j \rangle + \langle S_i \rangle \delta S_j + \delta S_i \ \delta S_j \approx \langle S_i \rangle \langle S_j \rangle + \delta S_i  \langle S_j \rangle + \langle S_i \rangle \delta S_j" eeimg="1"/> </p><p><img src="https://www.zhihu.com/equation?tex=%5CRightarrow+2+S_i+S_j+%5Capprox+S_i+%5Clangle+S_j+%5Crangle+%2B+S_j++%5Clangle+S_i+%5Crangle" alt="\Rightarrow 2 S_i S_j \approx S_i \langle S_j \rangle + S_j  \langle S_i \rangle" eeimg="1"/> </p><p>这样，原本的“粒子 i-粒子 j”变成了“粒子 i-平均场-粒子 j”。最后加上外面的求和，就可以得到最后的平均场近似。文章里面直接用了一个 tractable 的 Q 分布，然后最小化它和真实概率分布的 KL 散度，这种方法叙述会更简单，但是容易使人忽略其物理实质，同时也让人对于“平均场”这个词不太理解。建议大家参看更为严格的物理推导：</p><p><a href="https://link.zhihu.com/?target=https%3A//cpb-us-w2.wpmucdn.com/u.osu.edu/dist/3/67057/files/2018/09/Ising_model_MFT-25b1klj.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Franz Utermohlen: Notes on &#34;Mean Field Theory Solution of the Ising Model&#34;</a></p><p>接下来，我们来看看究竟在哪里做了近似，其实最直接的就是这里假设了 <img src="https://www.zhihu.com/equation?tex=+%5Cdelta+S_i+%5C+%5Cdelta+S_j+%5Capprox+0" alt=" \delta S_i \ \delta S_j \approx 0" eeimg="1"/> ；在热扰动（thermal fluctuation）较小的时候，这个式子成立。物理上来理解，在维度较低的时候，热扰动可能会比较明显，因此平均场可能不太准确；在维度较高的时候，会更准确。</p><h3>3. Ising 模型的临界温度</h3><p>既然我们得到了这个解</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-fcf47b74a1a275ce46d74853135ffe02_b.png" data-caption="" data-size="normal" data-rawwidth="430" data-rawheight="62" class="origin_image zh-lightbox-thumb" width="430" data-original="https://pic3.zhimg.com/v2-fcf47b74a1a275ce46d74853135ffe02_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;430&#39; height=&#39;62&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="430" data-rawheight="62" class="origin_image zh-lightbox-thumb lazy" width="430" data-original="https://pic3.zhimg.com/v2-fcf47b74a1a275ce46d74853135ffe02_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-fcf47b74a1a275ce46d74853135ffe02_b.png"/></figure><p>那么下面可以顺水推舟，顺便讲一下系统的临界温度问题。现在考虑这 N 个粒子构成了一块固体，每个粒子的自旋就是其磁矩，那么这个物体就会因此产生一个宏观的磁矩 m。这个磁矩以及外场的作用在该物体的任何位置应该都是一样的，因此我们可以抹去上述公式的下标。同时，注意到，我们前面把温度等一些物理相关的常数去掉了，现在我们把它们捡回来，可以得到</p><p><img src="https://www.zhihu.com/equation?tex=m+%3D+%5Ctanh+%28%5Cdfrac%7B%5Ctheta+%2B+J+m%7D%7BkT%7D%29%2C+%5C+%5C++J+%3D+%5Csum_j+J_%7Bij%7D" alt="m = \tanh (\dfrac{\theta + J m}{kT}), \ \  J = \sum_j J_{ij}" eeimg="1"/> <img src="https://www.zhihu.com/equation?tex=J_%7Bij%7D+%3E+0" alt="J_{ij} &gt; 0" eeimg="1"/> ，</p><p>先考虑没有外场的情形（ <img src="https://www.zhihu.com/equation?tex=%5Ctheta+%3D+0" alt="\theta = 0" eeimg="1"/> ）。我们发现当温度较高的时候，即 <img src="https://www.zhihu.com/equation?tex=J%2FkT+%3C+1" alt="J/kT &lt; 1" eeimg="1"/> 的时候，上述方程只有一个解 m=0；我们把这种状态下的材料称为顺磁性材料（paramagnetic），这种材料在出现外场的时候，会顺着外磁场产生一定的磁矩，相应的比例就是磁化率。当温度较低的时候，即 <img src="https://www.zhihu.com/equation?tex=J%2FkT+%3E+1" alt="J/kT &gt; 1" eeimg="1"/> 的时候，上述方程只有两个稳定解 <img src="https://www.zhihu.com/equation?tex=m+%3D+%5Cpm+m_0" alt="m = \pm m_0" eeimg="1"/> ，则意味着概材料在没有外磁场的情况下也具有一定的磁性，我们称这种材料为铁磁性材料（ferromagnetic）。而相应的临界温度 <img src="https://www.zhihu.com/equation?tex=T+%3D+J+%2Fk" alt="T = J /k" eeimg="1"/> 就成为系统的临界温度。</p><h3>4. MCMC 方法求解 Ising 模型</h3><p>关于 Ising 模型，我们前面研究的问题是：对于任意一个粒子，其自旋状态的边缘分布怎样。为了解决这样一个问题，我们做了平均场近似，即把其他粒子对某一粒子的作用等效为一个平均场对于该粒子的作用，从而实现了联合概率分布的解耦合，使得我们可以顺利求解这个系统。该方法不仅可以求某个粒子状态的边缘分布、求解系统的宏观状态，还可以从分布中采样。</p><p>我们现在只考虑采样问题：当 <img src="https://www.zhihu.com/equation?tex=J_%7Bij%7D%2C+%5Ctheta_i" alt="J_{ij}, \theta_i" eeimg="1"/> 都确定下来之后，其联合概率分布函数 P 就确定下来了，如何从这个分布中采集一个系统状态的样本？这时候我们还可以利用 Markov Chain Monte Carlo （MCMC）方法来进行求解。</p><p>考虑系统的每一个状态（configuration）也是马科夫链上的一个状态（state），它们一一对应。如果马科夫链满足遍历性（ergodicity）和细致平稳（detailed balance），那么该马科夫链就具有唯一的稳态分布；即从该马科夫链上的任意一个状态出发，经过无限步之后所处状态的分布就是该唯一状态分布。从联合概率分布函数 P 中采样的问题，可以转化为设计一个马科夫链的概率转移矩阵，使得它：1）满足遍历性和细致平稳；2）其稳态分布是 P。</p><p>考虑这样一个马科夫链：每一个状态描述 N 粒子系统的一个状态 <img src="https://www.zhihu.com/equation?tex=s%5Cin+%5C%7B-1%2C+%2B1%5C%7D%5EN" alt="s\in \{-1, +1\}^N" eeimg="1"/> ，而每次只考虑翻转一个粒子，即当且仅当 s 和 s&#39; 只有至多一个粒子上的自旋不一样时， s 可以一步转移到 s&#39; 。</p><p><b><u>遍历性</u></b>：我们注意到，只要我们能够保证从任意一个状态出发，它转移到任意和它只有一个粒子不同的状态的概率不为零，就能够保证整个系统的遍历性；即从任意状态出发都一定能以非零的概率以最多 N 步转移到任意一个其他状态。</p><p><img src="https://www.zhihu.com/equation?tex=P_%7Bs+%5Cto+s%27%7D+%3E+0%2C+%5C+%5C+%5Cforall+d%28s%27%2Cs%29+%5Cle+1" alt="P_{s \to s&#39;} &gt; 0, \ \ \forall d(s&#39;,s) \le 1" eeimg="1"/> </p><p>其中，P 表示一步概率转移矩阵，d 两个状态之间的距离，它表示两个状态之间有多少个粒子自旋不同。</p><p><b><u>细致平稳</u></b>：细致平稳讲的是达到稳态分布之后，从任意状态流向另一任意状态的概率流等于反向的概率流，假设稳态分布在状态 s 上的概率为 <img src="https://www.zhihu.com/equation?tex=d_s" alt="d_s" eeimg="1"/> ，那么细致平稳条件可以写作</p><p><img src="https://www.zhihu.com/equation?tex=d_s+P_%7Bs%5Cto+s%27%7D+%3D+d_%7Bs%27%7D+P_%7Bs%27+%5Cto+s%7D" alt="d_s P_{s\to s&#39;} = d_{s&#39;} P_{s&#39; \to s}" eeimg="1"/> </p><p><b><u>稳态分布</u></b>：我们希望设计的这个马科夫链的稳态分布是 P（不好意思，符号有点乱，稳态分布的 P 我们用函数形式表示，一步转移矩阵 P 我们用下标形式表示，大家区分一下），那么该条件可以写作</p><p><img src="https://www.zhihu.com/equation?tex=%5Cdfrac%7Bd_s%7D%7Bd_%7Bs%27%7D%7D+%3D+%5Cdfrac%7BP%28s%29%7D%7BP%28s%27%29%7D+%3D%5Cexp%28%5CDelta+E_%7Bs%27%2Cs%7D%29%2C+%5C+%5C+%5CDelta+E_%7Bs%27%2Cs%7D+%3A%3D+E%28s%27%29+-+E%28s%29" alt="\dfrac{d_s}{d_{s&#39;}} = \dfrac{P(s)}{P(s&#39;)} =\exp(\Delta E_{s&#39;,s}), \ \ \Delta E_{s&#39;,s} := E(s&#39;) - E(s)" eeimg="1"/> </p><p>我们同时注意到，由于 s 和 s&#39; 只相差了一个粒子，因此，其能量差距可以较为容易得计算得到。</p><p><b><u>收敛速率</u></b>：虽然只要满足以上条件，就可以保证从马科夫链上任意状态出发经过无穷多步之后能够收敛到稳态分布，但是我们还是希望这个收敛的过程需要快一些，因此我们希望各个状态之间的转移概率足够大。不妨假设 s&#39; 的能量大于等于 s 的能量，联立上述方程，有</p><p><img src="https://www.zhihu.com/equation?tex=%5Cdfrac%7BP_%7Bs%27%5Cto+s%7D%7D%7BP_%7Bs%5Cto+s%27%7D%7D+%3D+%5Cexp%28%5CDelta+E_%7Bs%27%2C+s%7D%29+%5Cge+1" alt="\dfrac{P_{s&#39;\to s}}{P_{s\to s&#39;}} = \exp(\Delta E_{s&#39;, s}) \ge 1" eeimg="1"/> </p><p>要使得收敛速率最大，可以令 <img src="https://www.zhihu.com/equation?tex=P_%7Bs%27%5Cto+s%7D+%3D+1" alt="P_{s&#39;\to s} = 1" eeimg="1"/> ， <img src="https://www.zhihu.com/equation?tex=P_%7Bs%5Cto+s%27%7D+%3D+%5Cexp%28-%5CDelta+E_%7Bs%27%2C+s%7D%29" alt="P_{s\to s&#39;} = \exp(-\Delta E_{s&#39;, s})" eeimg="1"/>  。</p><p><b><u>转移方案</u></b>：把上述条件全部考虑进来，我们可以得到如下的概率转移方案：</p><p>在状态 s 上，以某一个概率分布从 N 个粒子中采样一个粒子，该概率分布需要以非零的概率采集任意一个粒子。考虑翻转该粒子形成状态 s&#39;，并且计算 <img src="https://www.zhihu.com/equation?tex=%5CDelta+E_%7Bs%27%2C+s%7D" alt="\Delta E_{s&#39;, s}" eeimg="1"/> 。如果 <img src="https://www.zhihu.com/equation?tex=%5CDelta+E_%7Bs%27%2C+s%7D+%5Cle+0" alt="\Delta E_{s&#39;, s} \le 0" eeimg="1"/> 就以 100% 的概率转移到状态 s&#39;；如果 <img src="https://www.zhihu.com/equation?tex=%5CDelta+E_%7Bs%27%2C+s%7D+%3E+0" alt="\Delta E_{s&#39;, s} &gt; 0" eeimg="1"/> ，就以 <img src="https://www.zhihu.com/equation?tex=+%5Cexp%28-%5CDelta+E_%7Bs%27%2C+s%7D%29" alt=" \exp(-\Delta E_{s&#39;, s})" eeimg="1"/> 的概率转移到状态 s&#39;。</p><p><b><u>比较</u></b>：下面我们来比较一下 MCMC 方法和平均场方法。</p><ul><li>平均场方法没有考虑热扰动，做了近似，但是 MCMC 方法没有该近似。</li><li>平均场方法可以求解出系统和各个热力学统计量之间的关系，便于我们理解系统的宏观规律，而 MCMC 方法基于数值模拟，无法让我们得到更多对于物理系统的观察。</li><li>相比平均场方法而言，MCMC 方法在计算上比较慢，并且由于 MCMC 方法基于马科夫链，因此其本质上是一个 sequential 的方法，比较难并行化或者向量化加速。不过值得一提的是，我们刚刚讲的这种每次考虑翻转一个粒子的方法叫做 Matropolis-Hastings 算法，后续还发展了又每次翻转一坨粒子（cluster）的 Swendsen–Wang 算法和 Wolff 算法，它们可以一定程度上加速 MCMC。</li></ul><p>注：以上比较来源于一篇比较老的文献 [1]，因此不确定还有没有更新的研究进展。关于更详细的介绍以及 Wolff 算法可以参考这一系列知乎 [2]。</p><h3>5. 用 Ising 模型建模半监督学习问题</h3><p>绕了一圈再回到文章中的这个问题，即如何用 Ising 模型来建模半监督学习问题。先考虑一个半监督学习问题，它有一个数据集 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BX%7D" alt="\mathcal{X}" eeimg="1"/> ；其中一部分数据有 -1 或者 +1 的标签，记这一部分数据为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BX%7D_L" alt="\mathcal{X}_L" eeimg="1"/> ；另一部分数据没有标签，记这一部分数据为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BX%7D_U" alt="\mathcal{X}_U" eeimg="1"/> 。在这种情况下，我们可以把 N 个数据点看做是 N 个粒子，而这些数据点的标签看做是 N 个粒子的自旋状态；用粒子间相互作用 <img src="https://www.zhihu.com/equation?tex=J_%7Bij%7D" alt="J_{ij}" eeimg="1"/> 来刻画不同数据点之间的相似程度；用外场作用 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_i" alt="\theta_i" eeimg="1"/> 来刻画有标签数据点的标签。通过求解热平衡状态下的系统，根据粒子的期望自旋状态 <img src="https://www.zhihu.com/equation?tex=%5Clangle+S_i+%5Crangle" alt="\langle S_i \rangle" eeimg="1"/> 来推断无标签数据点的标签。</p><p><b><u>粒子-粒子相互作用 <img src="https://www.zhihu.com/equation?tex=J_%7Bij%7D" alt="J_{ij}" eeimg="1"/></u></b> </p><p>文章先定义了数据点之间的距离度量，然后再根据距离度量来定义相似性，并且把相似性作为 <img src="https://www.zhihu.com/equation?tex=J_%7Bij%7D" alt="J_{ij}" eeimg="1"/> ；可以发现，相似性越高，说明这两个数据点之间的标签越可能相似，因此赋予其一个较大的相互作用常数。注意到距离度量和相似性度量都需要根据一定的先验知识来选取适用于相应数据的度量，文章里面比较了很多种，这里就介绍一下文章里面提到的比较特别的（也是最后实验使用到的）度量。</p><p>首先，相似性可以根据通过距离来度量，度量方式为 weighted exponential similarity</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-bd56788c3a8390d801dc2ebd718fb211_b.png" data-caption="" data-size="normal" data-rawwidth="351" data-rawheight="47" class="content_image" width="351"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;351&#39; height=&#39;47&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="351" data-rawheight="47" class="content_image lazy" width="351" data-actualsrc="https://pic2.zhimg.com/v2-bd56788c3a8390d801dc2ebd718fb211_b.png"/></figure><p>接下来，定义距离度量为 connectivity distance</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-153496c0ea54fb57b999c3d25f43ad27_b.png" data-caption="" data-size="normal" data-rawwidth="371" data-rawheight="43" class="content_image" width="371"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;371&#39; height=&#39;43&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="371" data-rawheight="43" class="content_image lazy" width="371" data-actualsrc="https://pic4.zhimg.com/v2-153496c0ea54fb57b999c3d25f43ad27_b.png"/></figure><p>其想法是考虑有一条路径连接第 i 个数据点和第 j 个数据点，那么这条路径上面两两数据点之间的最大距离可以刻画这两个数据点之间的是不是被其他的数据点较好地“联通”；同时，在所有的路径之间找一条路径，使得这两个数据点能够被最好的联通。注意到，在这里，这个距离度量的定义仍然是基于数据点之间的欧氏距离来定义的（上标 E）。</p><p>该距离度量有一个 soften 的版本，定义如下</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-74605cc51a322d9166b262e415093654_b.jpg" data-caption="" data-size="normal" data-rawwidth="388" data-rawheight="69" class="content_image" width="388"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;388&#39; height=&#39;69&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="388" data-rawheight="69" class="content_image lazy" width="388" data-actualsrc="https://pic1.zhimg.com/v2-74605cc51a322d9166b262e415093654_b.jpg"/></figure><p>其中有一个参数 <img src="https://www.zhihu.com/equation?tex=%5Crho" alt="\rho" eeimg="1"/> ；它趋向于零的时候，上述度量更接近于度量路径的总长度；它趋向于无穷大的时候上述度量更接近于度量路径中的最大一段的长度（即前面没有 softened 的版本）。</p><p><b><u>外场作用 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_i" alt="\theta_i" eeimg="1"/></u></b> </p><p>如果有标签，外场作用就设置为标签；如果没有标签就设置外场作用为零。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-f5018099d3d61963af499ceb6816c72a_b.png" data-caption="" data-size="normal" data-rawwidth="411" data-rawheight="56" class="content_image" width="411"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;411&#39; height=&#39;56&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="411" data-rawheight="56" class="content_image lazy" width="411" data-actualsrc="https://pic3.zhimg.com/v2-f5018099d3d61963af499ceb6816c72a_b.png"/></figure><p><b><u>算法</u></b></p><p>最后的算法就是先计算相互作用和外场，然后利用前面的平均场方法来求解到每个粒子的平均自旋，根据平均自旋的符号来给出标签的推断。只需要注意一点就是，相似性矩阵计算出来之后，还又经过了一个归一化处理。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-e7272c8d9a46445f3c140c429bfe055c_b.jpg" data-caption="" data-size="normal" data-rawwidth="375" data-rawheight="374" class="content_image" width="375"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;375&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="375" data-rawheight="374" class="content_image lazy" width="375" data-actualsrc="https://pic1.zhimg.com/v2-e7272c8d9a46445f3c140c429bfe055c_b.jpg"/></figure><h3>6. 平均场方法和贝叶斯方法的联系</h3><p>考虑如下概率图模型，即从数据 X 生成一个数据的类别隐变量 y，然后从该隐变量生成数据的标签 t。</p><p>那么从半监督学习数据集中做推断，可以写作</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-f98808ec15b7c0bf3fcd3143481f84dc_b.png" data-caption="" data-size="normal" data-rawwidth="388" data-rawheight="35" class="content_image" width="388"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;388&#39; height=&#39;35&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="388" data-rawheight="35" class="content_image lazy" width="388" data-actualsrc="https://pic1.zhimg.com/v2-f98808ec15b7c0bf3fcd3143481f84dc_b.png"/></figure><p>其中，花 D 表示半监督学习数据集；后一个等式是贝叶斯公式，只不过把分母有归一化常数代替；最后的推断由两部分构成，前一项表示数据集上的先验信息，后一项表示产生已有标签的 likelihood。</p><p><b><u>Prior Information term</u></b></p><p>为了计算得到前一项先验信息，我们可以把数据看做一个全连接的图：图上的每一个节点就是一个数据点，图之间的连边强度就是数据点之间的相似性。做半监督学习的基本假设就是数据和标签之间需要平滑，在图上，我们可以定义一个数据的平滑性指标（smoothness）</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-341207dbded238fba39d936d39ea13a7_b.png" data-caption="" data-size="normal" data-rawwidth="386" data-rawheight="33" class="content_image" width="386"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;386&#39; height=&#39;33&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="386" data-rawheight="33" class="content_image lazy" width="386" data-actualsrc="https://pic4.zhimg.com/v2-341207dbded238fba39d936d39ea13a7_b.png"/></figure><p>其中，向量 y 为数据的标签，每一个维度分别对应一个数据；M 为 smoothness matrix，根据我另外一个专栏你们讲的 spectral graph theory，可以自然想到，使用 normalized graph Laplacian 来作为 M 矩阵</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-e7ee31da1a952f585268a0029a26170d_b.png" data-caption="" data-size="normal" data-rawwidth="393" data-rawheight="33" class="content_image" width="393"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;393&#39; height=&#39;33&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="393" data-rawheight="33" class="content_image lazy" width="393" data-actualsrc="https://pic2.zhimg.com/v2-e7ee31da1a952f585268a0029a26170d_b.png"/></figure><p>因此，可以规定 prior information term 为</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-cac2fc9aed901d76fd191519a2e1697b_b.png" data-caption="" data-size="normal" data-rawwidth="399" data-rawheight="38" class="content_image" width="399"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;399&#39; height=&#39;38&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="399" data-rawheight="38" class="content_image lazy" width="399" data-actualsrc="https://pic4.zhimg.com/v2-cac2fc9aed901d76fd191519a2e1697b_b.png"/></figure><p><b><u>Likelihood term</u></b></p><p>考虑到数据标签只有两类，并且假设有标签的数据相互独立，因此这一项可以被定义为</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-f200f1eb7e28e54f24973af678dad6eb_b.jpg" data-caption="" data-size="normal" data-rawwidth="395" data-rawheight="68" class="content_image" width="395"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;395&#39; height=&#39;68&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="395" data-rawheight="68" class="content_image lazy" width="395" data-actualsrc="https://pic4.zhimg.com/v2-f200f1eb7e28e54f24973af678dad6eb_b.jpg"/></figure><p>最后综合起来，可以得到</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-96f2167d8e8993196ef20c0decadc56d_b.png" data-caption="" data-size="normal" data-rawwidth="393" data-rawheight="57" class="content_image" width="393"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;393&#39; height=&#39;57&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="393" data-rawheight="57" class="content_image lazy" width="393" data-actualsrc="https://pic2.zhimg.com/v2-96f2167d8e8993196ef20c0decadc56d_b.png"/></figure><p>其中 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="\theta" eeimg="1"/> 就是数据的标签。考虑到可以对 y 做标准化，因此半监督学习问题就变成了最大化如下函数</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-ef2deb929a18146ed25c520614b2122d_b.png" data-caption="" data-size="normal" data-rawwidth="386" data-rawheight="62" class="content_image" width="386"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;386&#39; height=&#39;62&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="386" data-rawheight="62" class="content_image lazy" width="386" data-actualsrc="https://pic2.zhimg.com/v2-ef2deb929a18146ed25c520614b2122d_b.png"/></figure><p>和前面的 Ising 模型的对比可以看出，这里需要在最小化能量的同时也最大化隐变量 y 的分布；而 Ising 模型是在“软化地”最小化能量（服从 Boltzmann 分布）。</p><p>文章中还说到，用平均场解这个问题复杂度会比直接优化该目标更低。</p><hr/><h3>One more thing</h3><p>有一点需要注意的是文章中的 Ising 模型讲的是任意两个粒子/数据点间都有相互作用；但是在实际的系统中，距离越远的粒子，相互作用越弱，在很多文献中经常考虑的只是最近邻粒子之间的相互作用。这样的简化并不会改变问题的性质。</p><p>这篇文章发表在 2007 的 AISTATS 上，有若干公式打印有误。这里在截图之后已经做了更正。</p><hr/><h3>参考资料</h3><p>[1] Fiig, Thomas, et al. &#34;Mean-field and Monte Carlo calculations of the three-dimensional structure factor for YBa 2 Cu 3 O 6+ x.&#34;<i>Physical Review B</i>54.1 (1996): 556.</p><p>[2] <a href="https://zhuanlan.zhihu.com/p/42836754" class="internal">hlpyatne：当蒙特卡罗方法遇见伊辛模型（下）</a></p><p></p></div></div><div class="ContentItem-time">编辑于 2020-02-18</div><div class="Post-topicsAndReviewer"><div class="TopicList Post-Topics"><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/19582799" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">量子场论</div></div></a></span></div><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/19567442" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">理论物理</div></div></a></span></div><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/20039099" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习 (Reinforcement Learning)</div></div></a></span></div></div></div><div><div class="Sticky RichContent-actions is-bottom"><div class="ContentItem-actions"><span><button aria-label="赞同 34 " type="button" class="Button VoteButton VoteButton--up"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleUp VoteButton-TriangleUp" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M2 18.242c0-.326.088-.532.237-.896l7.98-13.203C10.572 3.57 11.086 3 12 3c.915 0 1.429.571 1.784 1.143l7.98 13.203c.15.364.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H3.955c-1.08 0-1.955-.517-1.955-1.9z" fill-rule="evenodd"></path></svg></span>赞同 34</button><button aria-label="反对" type="button" class="Button VoteButton VoteButton--down"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleDown" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M20.044 3H3.956C2.876 3 2 3.517 2 4.9c0 .326.087.533.236.896L10.216 19c.355.571.87 1.143 1.784 1.143s1.429-.572 1.784-1.143l7.98-13.204c.149-.363.236-.57.236-.896 0-1.386-.876-1.9-1.956-1.9z" fill-rule="evenodd"></path></svg></span></button></span><button type="button" class="Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Comment Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M10.241 19.313a.97.97 0 0 0-.77.2 7.908 7.908 0 0 1-3.772 1.482.409.409 0 0 1-.38-.637 5.825 5.825 0 0 0 1.11-2.237.605.605 0 0 0-.227-.59A7.935 7.935 0 0 1 3 11.25C3 6.7 7.03 3 12 3s9 3.7 9 8.25-4.373 9.108-10.759 8.063z" fill-rule="evenodd"></path></svg></span>1 条评论</button><div class="Popover ShareMenu"><div class="ShareMenu-toggler" id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Share Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2.931 7.89c-1.067.24-1.275 1.669-.318 2.207l5.277 2.908 8.168-4.776c.25-.127.477.198.273.39L9.05 14.66l.927 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.242c.584-.892-.212-2.029-1.234-1.796L2.93 7.89z" fill-rule="evenodd"></path></svg></span>分享</button></div></div><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Heart Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2 8.437C2 5.505 4.294 3.094 7.207 3 9.243 3 11.092 4.19 12 6c.823-1.758 2.649-3 4.651-3C19.545 3 22 5.507 22 8.432 22 16.24 13.842 21 12 21 10.158 21 2 16.24 2 8.437z" fill-rule="evenodd"></path></svg></span>喜欢</button><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Star Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5.515 19.64l.918-5.355-3.89-3.792c-.926-.902-.639-1.784.64-1.97L8.56 7.74l2.404-4.871c.572-1.16 1.5-1.16 2.072 0L15.44 7.74l5.377.782c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.219 1.274-.532 1.82-1.676 1.218L12 18.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z" fill-rule="evenodd"></path></svg></span>收藏</button><div class="Post-ActionMenuButton"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Dots Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5 14a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4z" fill-rule="evenodd"></path></svg></span></button></div></div></div></div></div></div></article><div class="Post-Sub Post-NormalSub"><div class="PostIndex-Contributions"><h3 class="BlockTitle">文章被以下专栏收录</h3><ul><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><img class="Avatar Avatar--medium Avatar--round" width="40" height="40" src="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_xs.jpg" srcSet="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_l.jpg 2x" alt="强化学习前沿"/></div></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><a class="ColumnLink ColumnItem-Title" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习前沿</div></div></a></h2><div class="ContentItem-meta">读呀读paper</div></div><div class="ContentItem-extra"><a href="/reinforcementlearning" type="button" class="Button">进入专栏</a></div></div></div></ul></div></div></div></main></div></div><script nonce="abe7b2a9-1f72-4d19-95f5-204719985d7d" async="" src="https://www.googletagmanager.com/gtag/js?id=UA-149949619-1"></script><script nonce="abe7b2a9-1f72-4d19-95f5-204719985d7d">function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-149949619-1");</script><script id="js-clientConfig" type="text/json">{"host":"zhihu.com","protocol":"https:","wwwHost":"www.zhihu.com","fetchRoot":{"www":"https:\u002F\u002Fwww.zhihu.com","api":"https:\u002F\u002Fapi.zhihu.com","zhuanlan":"https:\u002F\u002Fzhuanlan.zhihu.com"}}</script><script id="js-initialData" type="text/json">{"initialState":{"common":{"ask":{}},"loading":{"global":{"count":0},"local":{"env\u002FgetIpinfo\u002F":false,"article\u002Fget\u002F":false,"brand\u002FgetUrl\u002F":false}},"club":{"tags":{}},"entities":{"users":{"zhang-chu-heng":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"清华大学 交叉信息院博士在读"}],"exposedMedal":{"medalId":"1124316222665379841","medalName":"我的知乎 2019","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2592b0b52e1fac99f69b38e00252413b_r.png","miniAvatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ad363cc3088dc8de7544fd08b1c4987a_is.png","description":"参与「我的知乎 2019」即可获得"}}},"questions":{},"answers":{},"articles":{"107388314":{"trackUrl":["https:\u002F\u002Fsugar.zhihu.com\u002Fplutus_adreaper\u002Fpage_monitor_log?si=__SESSIONID__&ti=__ATOKEN__&at=view&pf=__OS__&ed=__MEMBERID__&idfa=__IDFA__&imei=__IMEI__&androidid=__ANDROIDID__&oaid=__OAID__&ci=__CREATIVEID__"],"id":107388314,"title":"【强化学习 104】Mean-field for Semi-supervised，也聊 Ising","type":"article","excerptTitle":"","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F107388314","imageUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-5b99901916cac006d5ed0f1a586ba2fb_b.jpg","titleImage":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-5b99901916cac006d5ed0f1a586ba2fb_b.jpg","excerpt":"\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-3009bcc61a0eb87fda4ad6ee7b4e6b2e_200x112.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"397\" data-rawheight=\"381\" data-watermark=\"watermark\" data-original-src=\"v2-3009bcc61a0eb87fda4ad6ee7b4e6b2e\" data-watermark-src=\"v2-8ce3a0f9974407d3a7165cde6f437877\" data-private-watermark-src=\"\" class=\"origin_image inline-img zh-lightbox-thumb\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-3009bcc61a0eb87fda4ad6ee7b4e6b2e_r.png\"\u002F\u003E本文提出使用 Ising 模型的平均场论解法来解决半监督学习问题。原文传送门\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=http%3A\u002F\u002Fwww.jmlr.org\u002Fproceedings\u002Fpapers\u002Fv2\u002Fwang07c\u002Fwang07c.pdf\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EWang, Fei, et al. &#34;Semi-supervised mean fields.&#34; Artificial Intelligence and Statistics. 2007.\u003C\u002Fa\u003E特色这篇文章先介绍了 Ising 模型（这是一个很有趣的模型，记得本科电磁学课的小…","created":1581997722,"updated":1581997895,"author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"清华大学 交叉信息院博士在读"}],"exposedMedal":{"medalId":"1124316222665379841","medalName":"我的知乎 2019","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2592b0b52e1fac99f69b38e00252413b_r.png","miniAvatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ad363cc3088dc8de7544fd08b1c4987a_is.png","description":"参与「我的知乎 2019」即可获得"}},"commentPermission":"all","state":"published","imageWidth":813,"imageHeight":304,"content":"\u003Cp\u003E本文提出使用 Ising 模型的平均场论解法来解决半监督学习问题。\u003C\u002Fp\u003E\u003Ch2\u003E原文传送门\u003C\u002Fh2\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=http%3A\u002F\u002Fwww.jmlr.org\u002Fproceedings\u002Fpapers\u002Fv2\u002Fwang07c\u002Fwang07c.pdf\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EWang, Fei, et al. &#34;Semi-supervised mean fields.&#34; Artificial Intelligence and Statistics. 2007.\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Ch2\u003E特色\u003C\u002Fh2\u003E\u003Cp\u003E这篇文章先介绍了 Ising 模型（这是一个很有趣的模型，记得本科电磁学课的小作业还写过 Ising 模型的模拟程序）。接下来这篇文章把半监督学习问题用 Ising 模型来建模，并且使用平均场方法（naive mean field approach）来解决。文章还指出，贝叶斯方法和该方法在本质上的联系；特别地，半监督学习问题的本质就是要利用数据标签在数据空间上的平滑特性，可以把数据空间建模为一个图（graph），这又和我们前面在研究的 spectral graph theory 有一定的联系。\u003C\u002Fp\u003E\u003Ch2\u003E过程\u003C\u002Fh2\u003E\u003Ch3\u003E1. Ising 模型\u003C\u002Fh3\u003E\u003Cp\u003E考虑 N 个粒子，每个原子有一个自旋（spin），自旋是二值量子化的，只能够取向上或者向下两种情况，即 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=S_i+%5Cin+%5C%7B-1+%2C+%2B1%5C%7D\" alt=\"S_i \\in \\{-1 , +1\\}\" eeimg=\"1\"\u002F\u003E 。这样，原子的自旋方向的状态（configuration）就有 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=2%5EN\" alt=\"2^N\" eeimg=\"1\"\u002F\u003E 种情形，记这样的状态为加粗的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm+S\" alt=\"\\bm S\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Cp\u003E那么系统究竟处于哪一种状态下呢？考虑这是一个热力学系统，系统会以一定的概率处于某一个状态下，根据热力学的知识，一个粒子可分辨系统处于不同状态的概念遵循玻尔兹曼分辨，即系统处于状态 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm+S\" alt=\"\\bm S\" eeimg=\"1\"\u002F\u003E 的概率为 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=P%28%7B%5Cbm+S%7D%29+%3D+%5Cdfrac%7B1%7D%7BZ%7D+%5Cexp%28-E%28%7B%5Cbm+S%7D%29+%2F+kT%29\" alt=\"P({\\bm S}) = \\dfrac{1}{Z} \\exp(-E({\\bm S}) \u002F kT)\" eeimg=\"1\"\u002F\u003E ，其中 k 为玻尔兹曼常数，T 为系统当前的温度，E 为系统处于该状态时的能量，Z 为配分函数，也可以理解它为归一化系数；在这里可以认为 kT=1。可以看到，当温度较低时，系统处于最低能量状态的概念会大大超过其他状态，因此系统会基本上处于最低的能量状态；当温度较高时，系统处于各个能量状态的概率基本上一样，因此系统会以几乎差不多的概率分布在各个状态上。\u003C\u002Fp\u003E\u003Cp\u003E某个状态下的能量函数定义如下\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-15d6f3e7f5fde1701307e9967580e3d7_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"395\" data-rawheight=\"48\" class=\"content_image\" width=\"395\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;395&#39; height=&#39;48&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"395\" data-rawheight=\"48\" class=\"content_image lazy\" width=\"395\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-15d6f3e7f5fde1701307e9967580e3d7_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中求和符号表示对于系统中任意两个粒子对进行求和， J 表示这两个粒子对的相互作用能， \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"\u002F\u003E 表示外场对于某个粒子的作用能。\u003C\u002Fp\u003E\u003Cp\u003E有了这样的模型之后，我们的问题是：如果给定相互作用能 J 和外场作用能 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"\u002F\u003E ，如何求到每一个粒子所处自旋状态的概率分布或者均值。我们可以把第 i 个粒子处于状态 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=S_i\" alt=\"S_i\" eeimg=\"1\"\u002F\u003E 的概率分布写作整个系统状态分布的边缘分布：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-832011360f5be02a9c02c2999fa808e1_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"440\" data-rawheight=\"49\" class=\"origin_image zh-lightbox-thumb\" width=\"440\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-832011360f5be02a9c02c2999fa808e1_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;440&#39; height=&#39;49&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"440\" data-rawheight=\"49\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"440\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-832011360f5be02a9c02c2999fa808e1_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-832011360f5be02a9c02c2999fa808e1_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E 即，对于所有在第 i 个粒子上处于状态 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=S_i\" alt=\"S_i\" eeimg=\"1\"\u002F\u003E 的状态的概率的和。\u003C\u002Fp\u003E\u003Cp\u003E接着，我们还可以写出该粒子自旋状态的均值：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-97d91f5e1e60f62f0cadaa5824c43b29_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"432\" data-rawheight=\"47\" class=\"origin_image zh-lightbox-thumb\" width=\"432\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-97d91f5e1e60f62f0cadaa5824c43b29_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;432&#39; height=&#39;47&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"432\" data-rawheight=\"47\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"432\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-97d91f5e1e60f62f0cadaa5824c43b29_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-97d91f5e1e60f62f0cadaa5824c43b29_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E我们可以看到，这里计算的难点就在于要计算几乎所有可能的状态的概率，并对其求和。然而，系统的状态数目随着粒子的数目呈指数级增长，因此这样直接计算的方法是不可行的。\u003C\u002Fp\u003E\u003Ch3\u003E2. 平均场方法求解 Ising 模型\u003C\u002Fh3\u003E\u003Cp\u003E其实，如果系统处于某个状态的概率（联合概率分布）如果具有某些好的性质，比如能拆分成多个独立的项，其实我们也能够比较方便地进行计算。观察系统处于某个状态的概率：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=P%28%7B%5Cbm+S%7D%29+%3D+%5Cdfrac%7B1%7D%7BZ%7D+%5Cexp%5Cleft%28%5Csum_i+%28%5Ctheta_i+%2B+%5Csum_j+J_%7Bij%7D+S_j%29S_i%5Cright%29+%5Cpropto+%5Cprod_i+%5Cexp%5Cleft%28%28%5Ctheta_i+%2B+%5Csum_j+J_%7Bij%7D+S_j%29S_i%5Cright%29\" alt=\"P({\\bm S}) = \\dfrac{1}{Z} \\exp\\left(\\sum_i (\\theta_i + \\sum_j J_{ij} S_j)S_i\\right) \\propto \\prod_i \\exp\\left((\\theta_i + \\sum_j J_{ij} S_j)S_i\\right)\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E但是注意到，它并没有被拆分为多个独立的项，因为每一项都还是与全局其他粒子的自旋相关。接下来，就到了最为关键的一步了，就是把外界对于每一个粒子的作用都用一个\u003Cb\u003E平均场 \u003C\u002Fb\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctilde+m_i\" alt=\"\\tilde m_i\" eeimg=\"1\"\u002F\u003E 来代替。把这样近似后的概率分布函数写作 Q。令\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=Q%28%7B%5Cbm+S%7D%29+%3D+%5Cprod_i+Q_i%28S_i%29%2C+%5Cquad+Q_i%28S_i%29+%3D+%5Cdfrac%7B%5Cexp%28%5Ctilde+m_i+S_i%29%7D%7B%5Csum_%7BS_i%7D%5Cexp%28%5Ctilde++m_iS_i%29%7D+%5Capprox+%5Cdfrac%7B1%2BS_im_i%7D%7B2%7D\" alt=\"Q({\\bm S}) = \\prod_i Q_i(S_i), \\quad Q_i(S_i) = \\dfrac{\\exp(\\tilde m_i S_i)}{\\sum_{S_i}\\exp(\\tilde  m_iS_i)} \\approx \\dfrac{1+S_im_i}{2}\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E考虑到每个粒子只有两种状态，而这两种状态对应的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=Q_i\" alt=\"Q_i\" eeimg=\"1\"\u002F\u003E 之和为 1，因此也可以被写作后面一种形式；同时，注意到 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=m_i\" alt=\"m_i\" eeimg=\"1\"\u002F\u003E 也可以看做是分布 Q 的一个参数；如果是后一种情形， \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=m_i\" alt=\"m_i\" eeimg=\"1\"\u002F\u003E 也可以被解释为一个隐变量，代表着粒子 i 处的平均自旋， \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=m_i+%3D+%5Clangle+S_i+%5Crangle_Q\" alt=\"m_i = \\langle S_i \\rangle_Q\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Cp\u003E下面我们要做的就是求解出近似的概率分布 Q，也就是要求解出相应的平均场。我们最小化分布 P 和分布 Q 之间的 KL divergence\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-01532f2c76c812182815d48bc81d7427_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"413\" data-rawheight=\"48\" class=\"content_image\" width=\"413\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;413&#39; height=&#39;48&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"413\" data-rawheight=\"48\" class=\"content_image lazy\" width=\"413\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-01532f2c76c812182815d48bc81d7427_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9513e69a48d832278fc1be9c29ecd80f_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"432\" data-rawheight=\"33\" class=\"origin_image zh-lightbox-thumb\" width=\"432\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9513e69a48d832278fc1be9c29ecd80f_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;432&#39; height=&#39;33&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"432\" data-rawheight=\"33\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"432\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9513e69a48d832278fc1be9c29ecd80f_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9513e69a48d832278fc1be9c29ecd80f_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中 S 为分布 Q 的熵\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a8be487a2111f86965ff6514cf568a71_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"420\" data-rawheight=\"41\" class=\"content_image\" width=\"420\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;420&#39; height=&#39;41&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"420\" data-rawheight=\"41\" class=\"content_image lazy\" width=\"420\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a8be487a2111f86965ff6514cf568a71_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EV 为 variational entropy\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-bd54d35112879836f52ac20bb9dee899_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"429\" data-rawheight=\"43\" class=\"origin_image zh-lightbox-thumb\" width=\"429\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-bd54d35112879836f52ac20bb9dee899_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;429&#39; height=&#39;43&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"429\" data-rawheight=\"43\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"429\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-bd54d35112879836f52ac20bb9dee899_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-bd54d35112879836f52ac20bb9dee899_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E带入到 KL divergence 中，然后求导，可以求解出每个粒子的平均自旋 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=m_i\" alt=\"m_i\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-b88b7de43c86f1dd29ef0f2361b1318f_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"435\" data-rawheight=\"70\" class=\"origin_image zh-lightbox-thumb\" width=\"435\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-b88b7de43c86f1dd29ef0f2361b1318f_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;435&#39; height=&#39;70&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"435\" data-rawheight=\"70\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"435\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-b88b7de43c86f1dd29ef0f2361b1318f_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-b88b7de43c86f1dd29ef0f2361b1318f_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E注意到每个位置的平均自旋的解是通过其他位置的解来定义的，因此要准确求出还需要做数值迭代，即通过下面的算法来得到。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-8ce3a0f9974407d3a7165cde6f437877_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"397\" data-rawheight=\"381\" class=\"content_image\" width=\"397\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;397&#39; height=&#39;381&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"397\" data-rawheight=\"381\" class=\"content_image lazy\" width=\"397\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-8ce3a0f9974407d3a7165cde6f437877_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cb\u003E平均场近似究竟在什么地方做了近似？\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E首先，平均场近似的结果肯定不是准确的结果。在平均场中，原本的“粒子-粒子”相互作用，通过一个平均场来作为中介，变成了“粒子-平均场-粒子”的相互作用。观察到，原本 P 函数中存在交叉项 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=S_i+S_j\" alt=\"S_i S_j\" eeimg=\"1\"\u002F\u003E 。假设在热平衡状态下，每个粒子的平均状态为 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Clangle+S_i++%5Crangle\" alt=\"\\langle S_i  \\rangle\" eeimg=\"1\"\u002F\u003E ，定义粒子偏离平均状态的量为 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta+S_i+%3D+S_i+-+%5Clangle+S_i+%5Crangle\" alt=\"\\delta S_i = S_i - \\langle S_i \\rangle\" eeimg=\"1\"\u002F\u003E 。在平均场中，其实做了如下的近似\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=S_i+S_j+%3D+%5Clangle+S_i+%5Crangle+%5Clangle+S_j+%5Crangle+%2B+%5Cdelta+S_i++%5Clangle+S_j+%5Crangle+%2B+%5Clangle+S_i+%5Crangle+%5Cdelta+S_j+%2B+%5Cdelta+S_i+%5C+%5Cdelta+S_j+%5Capprox+%5Clangle+S_i+%5Crangle+%5Clangle+S_j+%5Crangle+%2B+%5Cdelta+S_i++%5Clangle+S_j+%5Crangle+%2B+%5Clangle+S_i+%5Crangle+%5Cdelta+S_j\" alt=\"S_i S_j = \\langle S_i \\rangle \\langle S_j \\rangle + \\delta S_i  \\langle S_j \\rangle + \\langle S_i \\rangle \\delta S_j + \\delta S_i \\ \\delta S_j \\approx \\langle S_i \\rangle \\langle S_j \\rangle + \\delta S_i  \\langle S_j \\rangle + \\langle S_i \\rangle \\delta S_j\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5CRightarrow+2+S_i+S_j+%5Capprox+S_i+%5Clangle+S_j+%5Crangle+%2B+S_j++%5Clangle+S_i+%5Crangle\" alt=\"\\Rightarrow 2 S_i S_j \\approx S_i \\langle S_j \\rangle + S_j  \\langle S_i \\rangle\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E这样，原本的“粒子 i-粒子 j”变成了“粒子 i-平均场-粒子 j”。最后加上外面的求和，就可以得到最后的平均场近似。文章里面直接用了一个 tractable 的 Q 分布，然后最小化它和真实概率分布的 KL 散度，这种方法叙述会更简单，但是容易使人忽略其物理实质，同时也让人对于“平均场”这个词不太理解。建议大家参看更为严格的物理推导：\u003C\u002Fp\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fcpb-us-w2.wpmucdn.com\u002Fu.osu.edu\u002Fdist\u002F3\u002F67057\u002Ffiles\u002F2018\u002F09\u002FIsing_model_MFT-25b1klj.pdf\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EFranz Utermohlen: Notes on &#34;Mean Field Theory Solution of the Ising Model&#34;\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cp\u003E接下来，我们来看看究竟在哪里做了近似，其实最直接的就是这里假设了 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=+%5Cdelta+S_i+%5C+%5Cdelta+S_j+%5Capprox+0\" alt=\" \\delta S_i \\ \\delta S_j \\approx 0\" eeimg=\"1\"\u002F\u003E ；在热扰动（thermal fluctuation）较小的时候，这个式子成立。物理上来理解，在维度较低的时候，热扰动可能会比较明显，因此平均场可能不太准确；在维度较高的时候，会更准确。\u003C\u002Fp\u003E\u003Ch3\u003E3. Ising 模型的临界温度\u003C\u002Fh3\u003E\u003Cp\u003E既然我们得到了这个解\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-fcf47b74a1a275ce46d74853135ffe02_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"430\" data-rawheight=\"62\" class=\"origin_image zh-lightbox-thumb\" width=\"430\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-fcf47b74a1a275ce46d74853135ffe02_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;430&#39; height=&#39;62&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"430\" data-rawheight=\"62\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"430\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-fcf47b74a1a275ce46d74853135ffe02_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-fcf47b74a1a275ce46d74853135ffe02_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E那么下面可以顺水推舟，顺便讲一下系统的临界温度问题。现在考虑这 N 个粒子构成了一块固体，每个粒子的自旋就是其磁矩，那么这个物体就会因此产生一个宏观的磁矩 m。这个磁矩以及外场的作用在该物体的任何位置应该都是一样的，因此我们可以抹去上述公式的下标。同时，注意到，我们前面把温度等一些物理相关的常数去掉了，现在我们把它们捡回来，可以得到\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=m+%3D+%5Ctanh+%28%5Cdfrac%7B%5Ctheta+%2B+J+m%7D%7BkT%7D%29%2C+%5C+%5C++J+%3D+%5Csum_j+J_%7Bij%7D\" alt=\"m = \\tanh (\\dfrac{\\theta + J m}{kT}), \\ \\  J = \\sum_j J_{ij}\" eeimg=\"1\"\u002F\u003E \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=J_%7Bij%7D+%3E+0\" alt=\"J_{ij} &gt; 0\" eeimg=\"1\"\u002F\u003E ，\u003C\u002Fp\u003E\u003Cp\u003E先考虑没有外场的情形（ \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctheta+%3D+0\" alt=\"\\theta = 0\" eeimg=\"1\"\u002F\u003E ）。我们发现当温度较高的时候，即 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=J%2FkT+%3C+1\" alt=\"J\u002FkT &lt; 1\" eeimg=\"1\"\u002F\u003E 的时候，上述方程只有一个解 m=0；我们把这种状态下的材料称为顺磁性材料（paramagnetic），这种材料在出现外场的时候，会顺着外磁场产生一定的磁矩，相应的比例就是磁化率。当温度较低的时候，即 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=J%2FkT+%3E+1\" alt=\"J\u002FkT &gt; 1\" eeimg=\"1\"\u002F\u003E 的时候，上述方程只有两个稳定解 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=m+%3D+%5Cpm+m_0\" alt=\"m = \\pm m_0\" eeimg=\"1\"\u002F\u003E ，则意味着概材料在没有外磁场的情况下也具有一定的磁性，我们称这种材料为铁磁性材料（ferromagnetic）。而相应的临界温度 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=T+%3D+J+%2Fk\" alt=\"T = J \u002Fk\" eeimg=\"1\"\u002F\u003E 就成为系统的临界温度。\u003C\u002Fp\u003E\u003Ch3\u003E4. MCMC 方法求解 Ising 模型\u003C\u002Fh3\u003E\u003Cp\u003E关于 Ising 模型，我们前面研究的问题是：对于任意一个粒子，其自旋状态的边缘分布怎样。为了解决这样一个问题，我们做了平均场近似，即把其他粒子对某一粒子的作用等效为一个平均场对于该粒子的作用，从而实现了联合概率分布的解耦合，使得我们可以顺利求解这个系统。该方法不仅可以求某个粒子状态的边缘分布、求解系统的宏观状态，还可以从分布中采样。\u003C\u002Fp\u003E\u003Cp\u003E我们现在只考虑采样问题：当 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=J_%7Bij%7D%2C+%5Ctheta_i\" alt=\"J_{ij}, \\theta_i\" eeimg=\"1\"\u002F\u003E 都确定下来之后，其联合概率分布函数 P 就确定下来了，如何从这个分布中采集一个系统状态的样本？这时候我们还可以利用 Markov Chain Monte Carlo （MCMC）方法来进行求解。\u003C\u002Fp\u003E\u003Cp\u003E考虑系统的每一个状态（configuration）也是马科夫链上的一个状态（state），它们一一对应。如果马科夫链满足遍历性（ergodicity）和细致平稳（detailed balance），那么该马科夫链就具有唯一的稳态分布；即从该马科夫链上的任意一个状态出发，经过无限步之后所处状态的分布就是该唯一状态分布。从联合概率分布函数 P 中采样的问题，可以转化为设计一个马科夫链的概率转移矩阵，使得它：1）满足遍历性和细致平稳；2）其稳态分布是 P。\u003C\u002Fp\u003E\u003Cp\u003E考虑这样一个马科夫链：每一个状态描述 N 粒子系统的一个状态 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=s%5Cin+%5C%7B-1%2C+%2B1%5C%7D%5EN\" alt=\"s\\in \\{-1, +1\\}^N\" eeimg=\"1\"\u002F\u003E ，而每次只考虑翻转一个粒子，即当且仅当 s 和 s&#39; 只有至多一个粒子上的自旋不一样时， s 可以一步转移到 s&#39; 。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003E遍历性\u003C\u002Fu\u003E\u003C\u002Fb\u003E：我们注意到，只要我们能够保证从任意一个状态出发，它转移到任意和它只有一个粒子不同的状态的概率不为零，就能够保证整个系统的遍历性；即从任意状态出发都一定能以非零的概率以最多 N 步转移到任意一个其他状态。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=P_%7Bs+%5Cto+s%27%7D+%3E+0%2C+%5C+%5C+%5Cforall+d%28s%27%2Cs%29+%5Cle+1\" alt=\"P_{s \\to s&#39;} &gt; 0, \\ \\ \\forall d(s&#39;,s) \\le 1\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E其中，P 表示一步概率转移矩阵，d 两个状态之间的距离，它表示两个状态之间有多少个粒子自旋不同。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003E细致平稳\u003C\u002Fu\u003E\u003C\u002Fb\u003E：细致平稳讲的是达到稳态分布之后，从任意状态流向另一任意状态的概率流等于反向的概率流，假设稳态分布在状态 s 上的概率为 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=d_s\" alt=\"d_s\" eeimg=\"1\"\u002F\u003E ，那么细致平稳条件可以写作\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=d_s+P_%7Bs%5Cto+s%27%7D+%3D+d_%7Bs%27%7D+P_%7Bs%27+%5Cto+s%7D\" alt=\"d_s P_{s\\to s&#39;} = d_{s&#39;} P_{s&#39; \\to s}\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003E稳态分布\u003C\u002Fu\u003E\u003C\u002Fb\u003E：我们希望设计的这个马科夫链的稳态分布是 P（不好意思，符号有点乱，稳态分布的 P 我们用函数形式表示，一步转移矩阵 P 我们用下标形式表示，大家区分一下），那么该条件可以写作\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdfrac%7Bd_s%7D%7Bd_%7Bs%27%7D%7D+%3D+%5Cdfrac%7BP%28s%29%7D%7BP%28s%27%29%7D+%3D%5Cexp%28%5CDelta+E_%7Bs%27%2Cs%7D%29%2C+%5C+%5C+%5CDelta+E_%7Bs%27%2Cs%7D+%3A%3D+E%28s%27%29+-+E%28s%29\" alt=\"\\dfrac{d_s}{d_{s&#39;}} = \\dfrac{P(s)}{P(s&#39;)} =\\exp(\\Delta E_{s&#39;,s}), \\ \\ \\Delta E_{s&#39;,s} := E(s&#39;) - E(s)\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E我们同时注意到，由于 s 和 s&#39; 只相差了一个粒子，因此，其能量差距可以较为容易得计算得到。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003E收敛速率\u003C\u002Fu\u003E\u003C\u002Fb\u003E：虽然只要满足以上条件，就可以保证从马科夫链上任意状态出发经过无穷多步之后能够收敛到稳态分布，但是我们还是希望这个收敛的过程需要快一些，因此我们希望各个状态之间的转移概率足够大。不妨假设 s&#39; 的能量大于等于 s 的能量，联立上述方程，有\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdfrac%7BP_%7Bs%27%5Cto+s%7D%7D%7BP_%7Bs%5Cto+s%27%7D%7D+%3D+%5Cexp%28%5CDelta+E_%7Bs%27%2C+s%7D%29+%5Cge+1\" alt=\"\\dfrac{P_{s&#39;\\to s}}{P_{s\\to s&#39;}} = \\exp(\\Delta E_{s&#39;, s}) \\ge 1\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E要使得收敛速率最大，可以令 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=P_%7Bs%27%5Cto+s%7D+%3D+1\" alt=\"P_{s&#39;\\to s} = 1\" eeimg=\"1\"\u002F\u003E ， \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=P_%7Bs%5Cto+s%27%7D+%3D+%5Cexp%28-%5CDelta+E_%7Bs%27%2C+s%7D%29\" alt=\"P_{s\\to s&#39;} = \\exp(-\\Delta E_{s&#39;, s})\" eeimg=\"1\"\u002F\u003E  。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003E转移方案\u003C\u002Fu\u003E\u003C\u002Fb\u003E：把上述条件全部考虑进来，我们可以得到如下的概率转移方案：\u003C\u002Fp\u003E\u003Cp\u003E在状态 s 上，以某一个概率分布从 N 个粒子中采样一个粒子，该概率分布需要以非零的概率采集任意一个粒子。考虑翻转该粒子形成状态 s&#39;，并且计算 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5CDelta+E_%7Bs%27%2C+s%7D\" alt=\"\\Delta E_{s&#39;, s}\" eeimg=\"1\"\u002F\u003E 。如果 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5CDelta+E_%7Bs%27%2C+s%7D+%5Cle+0\" alt=\"\\Delta E_{s&#39;, s} \\le 0\" eeimg=\"1\"\u002F\u003E 就以 100% 的概率转移到状态 s&#39;；如果 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5CDelta+E_%7Bs%27%2C+s%7D+%3E+0\" alt=\"\\Delta E_{s&#39;, s} &gt; 0\" eeimg=\"1\"\u002F\u003E ，就以 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=+%5Cexp%28-%5CDelta+E_%7Bs%27%2C+s%7D%29\" alt=\" \\exp(-\\Delta E_{s&#39;, s})\" eeimg=\"1\"\u002F\u003E 的概率转移到状态 s&#39;。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003E比较\u003C\u002Fu\u003E\u003C\u002Fb\u003E：下面我们来比较一下 MCMC 方法和平均场方法。\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E平均场方法没有考虑热扰动，做了近似，但是 MCMC 方法没有该近似。\u003C\u002Fli\u003E\u003Cli\u003E平均场方法可以求解出系统和各个热力学统计量之间的关系，便于我们理解系统的宏观规律，而 MCMC 方法基于数值模拟，无法让我们得到更多对于物理系统的观察。\u003C\u002Fli\u003E\u003Cli\u003E相比平均场方法而言，MCMC 方法在计算上比较慢，并且由于 MCMC 方法基于马科夫链，因此其本质上是一个 sequential 的方法，比较难并行化或者向量化加速。不过值得一提的是，我们刚刚讲的这种每次考虑翻转一个粒子的方法叫做 Matropolis-Hastings 算法，后续还发展了又每次翻转一坨粒子（cluster）的 Swendsen–Wang 算法和 Wolff 算法，它们可以一定程度上加速 MCMC。\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003E注：以上比较来源于一篇比较老的文献 [1]，因此不确定还有没有更新的研究进展。关于更详细的介绍以及 Wolff 算法可以参考这一系列知乎 [2]。\u003C\u002Fp\u003E\u003Ch3\u003E5. 用 Ising 模型建模半监督学习问题\u003C\u002Fh3\u003E\u003Cp\u003E绕了一圈再回到文章中的这个问题，即如何用 Ising 模型来建模半监督学习问题。先考虑一个半监督学习问题，它有一个数据集 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathcal%7BX%7D\" alt=\"\\mathcal{X}\" eeimg=\"1\"\u002F\u003E ；其中一部分数据有 -1 或者 +1 的标签，记这一部分数据为 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathcal%7BX%7D_L\" alt=\"\\mathcal{X}_L\" eeimg=\"1\"\u002F\u003E ；另一部分数据没有标签，记这一部分数据为 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathcal%7BX%7D_U\" alt=\"\\mathcal{X}_U\" eeimg=\"1\"\u002F\u003E 。在这种情况下，我们可以把 N 个数据点看做是 N 个粒子，而这些数据点的标签看做是 N 个粒子的自旋状态；用粒子间相互作用 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=J_%7Bij%7D\" alt=\"J_{ij}\" eeimg=\"1\"\u002F\u003E 来刻画不同数据点之间的相似程度；用外场作用 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctheta_i\" alt=\"\\theta_i\" eeimg=\"1\"\u002F\u003E 来刻画有标签数据点的标签。通过求解热平衡状态下的系统，根据粒子的期望自旋状态 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Clangle+S_i+%5Crangle\" alt=\"\\langle S_i \\rangle\" eeimg=\"1\"\u002F\u003E 来推断无标签数据点的标签。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003E粒子-粒子相互作用 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=J_%7Bij%7D\" alt=\"J_{ij}\" eeimg=\"1\"\u002F\u003E\u003C\u002Fu\u003E\u003C\u002Fb\u003E \u003C\u002Fp\u003E\u003Cp\u003E文章先定义了数据点之间的距离度量，然后再根据距离度量来定义相似性，并且把相似性作为 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=J_%7Bij%7D\" alt=\"J_{ij}\" eeimg=\"1\"\u002F\u003E ；可以发现，相似性越高，说明这两个数据点之间的标签越可能相似，因此赋予其一个较大的相互作用常数。注意到距离度量和相似性度量都需要根据一定的先验知识来选取适用于相应数据的度量，文章里面比较了很多种，这里就介绍一下文章里面提到的比较特别的（也是最后实验使用到的）度量。\u003C\u002Fp\u003E\u003Cp\u003E首先，相似性可以根据通过距离来度量，度量方式为 weighted exponential similarity\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-bd56788c3a8390d801dc2ebd718fb211_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"351\" data-rawheight=\"47\" class=\"content_image\" width=\"351\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;351&#39; height=&#39;47&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"351\" data-rawheight=\"47\" class=\"content_image lazy\" width=\"351\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-bd56788c3a8390d801dc2ebd718fb211_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E接下来，定义距离度量为 connectivity distance\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-153496c0ea54fb57b999c3d25f43ad27_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"371\" data-rawheight=\"43\" class=\"content_image\" width=\"371\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;371&#39; height=&#39;43&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"371\" data-rawheight=\"43\" class=\"content_image lazy\" width=\"371\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-153496c0ea54fb57b999c3d25f43ad27_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其想法是考虑有一条路径连接第 i 个数据点和第 j 个数据点，那么这条路径上面两两数据点之间的最大距离可以刻画这两个数据点之间的是不是被其他的数据点较好地“联通”；同时，在所有的路径之间找一条路径，使得这两个数据点能够被最好的联通。注意到，在这里，这个距离度量的定义仍然是基于数据点之间的欧氏距离来定义的（上标 E）。\u003C\u002Fp\u003E\u003Cp\u003E该距离度量有一个 soften 的版本，定义如下\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-74605cc51a322d9166b262e415093654_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"388\" data-rawheight=\"69\" class=\"content_image\" width=\"388\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;388&#39; height=&#39;69&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"388\" data-rawheight=\"69\" class=\"content_image lazy\" width=\"388\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-74605cc51a322d9166b262e415093654_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中有一个参数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Crho\" alt=\"\\rho\" eeimg=\"1\"\u002F\u003E ；它趋向于零的时候，上述度量更接近于度量路径的总长度；它趋向于无穷大的时候上述度量更接近于度量路径中的最大一段的长度（即前面没有 softened 的版本）。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003E外场作用 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctheta_i\" alt=\"\\theta_i\" eeimg=\"1\"\u002F\u003E\u003C\u002Fu\u003E\u003C\u002Fb\u003E \u003C\u002Fp\u003E\u003Cp\u003E如果有标签，外场作用就设置为标签；如果没有标签就设置外场作用为零。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f5018099d3d61963af499ceb6816c72a_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"411\" data-rawheight=\"56\" class=\"content_image\" width=\"411\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;411&#39; height=&#39;56&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"411\" data-rawheight=\"56\" class=\"content_image lazy\" width=\"411\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f5018099d3d61963af499ceb6816c72a_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003E算法\u003C\u002Fu\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E最后的算法就是先计算相互作用和外场，然后利用前面的平均场方法来求解到每个粒子的平均自旋，根据平均自旋的符号来给出标签的推断。只需要注意一点就是，相似性矩阵计算出来之后，还又经过了一个归一化处理。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-e7272c8d9a46445f3c140c429bfe055c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"375\" data-rawheight=\"374\" class=\"content_image\" width=\"375\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;375&#39; height=&#39;374&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"375\" data-rawheight=\"374\" class=\"content_image lazy\" width=\"375\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-e7272c8d9a46445f3c140c429bfe055c_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Ch3\u003E6. 平均场方法和贝叶斯方法的联系\u003C\u002Fh3\u003E\u003Cp\u003E考虑如下概率图模型，即从数据 X 生成一个数据的类别隐变量 y，然后从该隐变量生成数据的标签 t。\u003C\u002Fp\u003E\u003Cp\u003E那么从半监督学习数据集中做推断，可以写作\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-f98808ec15b7c0bf3fcd3143481f84dc_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"388\" data-rawheight=\"35\" class=\"content_image\" width=\"388\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;388&#39; height=&#39;35&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"388\" data-rawheight=\"35\" class=\"content_image lazy\" width=\"388\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-f98808ec15b7c0bf3fcd3143481f84dc_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中，花 D 表示半监督学习数据集；后一个等式是贝叶斯公式，只不过把分母有归一化常数代替；最后的推断由两部分构成，前一项表示数据集上的先验信息，后一项表示产生已有标签的 likelihood。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003EPrior Information term\u003C\u002Fu\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E为了计算得到前一项先验信息，我们可以把数据看做一个全连接的图：图上的每一个节点就是一个数据点，图之间的连边强度就是数据点之间的相似性。做半监督学习的基本假设就是数据和标签之间需要平滑，在图上，我们可以定义一个数据的平滑性指标（smoothness）\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-341207dbded238fba39d936d39ea13a7_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"386\" data-rawheight=\"33\" class=\"content_image\" width=\"386\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;386&#39; height=&#39;33&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"386\" data-rawheight=\"33\" class=\"content_image lazy\" width=\"386\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-341207dbded238fba39d936d39ea13a7_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中，向量 y 为数据的标签，每一个维度分别对应一个数据；M 为 smoothness matrix，根据我另外一个专栏你们讲的 spectral graph theory，可以自然想到，使用 normalized graph Laplacian 来作为 M 矩阵\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e7ee31da1a952f585268a0029a26170d_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"393\" data-rawheight=\"33\" class=\"content_image\" width=\"393\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;393&#39; height=&#39;33&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"393\" data-rawheight=\"33\" class=\"content_image lazy\" width=\"393\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e7ee31da1a952f585268a0029a26170d_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E因此，可以规定 prior information term 为\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-cac2fc9aed901d76fd191519a2e1697b_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"399\" data-rawheight=\"38\" class=\"content_image\" width=\"399\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;399&#39; height=&#39;38&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"399\" data-rawheight=\"38\" class=\"content_image lazy\" width=\"399\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-cac2fc9aed901d76fd191519a2e1697b_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cb\u003E\u003Cu\u003ELikelihood term\u003C\u002Fu\u003E\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E考虑到数据标签只有两类，并且假设有标签的数据相互独立，因此这一项可以被定义为\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f200f1eb7e28e54f24973af678dad6eb_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"395\" data-rawheight=\"68\" class=\"content_image\" width=\"395\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;395&#39; height=&#39;68&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"395\" data-rawheight=\"68\" class=\"content_image lazy\" width=\"395\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f200f1eb7e28e54f24973af678dad6eb_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E最后综合起来，可以得到\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-96f2167d8e8993196ef20c0decadc56d_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"393\" data-rawheight=\"57\" class=\"content_image\" width=\"393\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;393&#39; height=&#39;57&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"393\" data-rawheight=\"57\" class=\"content_image lazy\" width=\"393\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-96f2167d8e8993196ef20c0decadc56d_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E其中 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"\u002F\u003E 就是数据的标签。考虑到可以对 y 做标准化，因此半监督学习问题就变成了最大化如下函数\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ef2deb929a18146ed25c520614b2122d_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"386\" data-rawheight=\"62\" class=\"content_image\" width=\"386\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;386&#39; height=&#39;62&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"386\" data-rawheight=\"62\" class=\"content_image lazy\" width=\"386\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ef2deb929a18146ed25c520614b2122d_b.png\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E和前面的 Ising 模型的对比可以看出，这里需要在最小化能量的同时也最大化隐变量 y 的分布；而 Ising 模型是在“软化地”最小化能量（服从 Boltzmann 分布）。\u003C\u002Fp\u003E\u003Cp\u003E文章中还说到，用平均场解这个问题复杂度会比直接优化该目标更低。\u003C\u002Fp\u003E\u003Chr\u002F\u003E\u003Ch3\u003EOne more thing\u003C\u002Fh3\u003E\u003Cp\u003E有一点需要注意的是文章中的 Ising 模型讲的是任意两个粒子\u002F数据点间都有相互作用；但是在实际的系统中，距离越远的粒子，相互作用越弱，在很多文献中经常考虑的只是最近邻粒子之间的相互作用。这样的简化并不会改变问题的性质。\u003C\u002Fp\u003E\u003Cp\u003E这篇文章发表在 2007 的 AISTATS 上，有若干公式打印有误。这里在截图之后已经做了更正。\u003C\u002Fp\u003E\u003Chr\u002F\u003E\u003Ch3\u003E参考资料\u003C\u002Fh3\u003E\u003Cp\u003E[1] Fiig, Thomas, et al. &#34;Mean-field and Monte Carlo calculations of the three-dimensional structure factor for YBa 2 Cu 3 O 6+ x.&#34;\u003Ci\u003EPhysical Review B\u003C\u002Fi\u003E54.1 (1996): 556.\u003C\u002Fp\u003E\u003Cp\u003E[2] \u003Ca href=\"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F42836754\" class=\"internal\"\u003Ehlpyatne：当蒙特卡罗方法遇见伊辛模型（下）\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cp\u003E\u003C\u002Fp\u003E","adminClosedComment":false,"topics":[{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F19582799","type":"topic","id":"19582799","name":"量子场论"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F19567442","type":"topic","id":"19567442","name":"理论物理"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F20039099","type":"topic","id":"20039099","name":"强化学习 (Reinforcement Learning)"}],"voteupCount":34,"voting":0,"column":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"},"commentCount":1,"contributions":[{"id":23027967,"state":"accepted","type":"first_publish","column":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}}],"isTitleImageFullScreen":false,"upvotedFollowees":[],"commercialInfo":{"isCommercial":false,"plugin":{}},"suggestEdit":{"status":false,"reason":"","tip":"","url":"","title":""},"reason":"","annotationAction":[],"canTip":false,"tipjarorsCount":0,"isLabeled":false,"hasPublishingDraft":false,"isFavorited":false,"isNormal":true,"status":0,"shareText":"【强化学习 104】Mean-field for Semi-supervised，也聊 Ising - 来自知乎专栏「强化学习前沿」，作者: 张楚珩 https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F107388314 （想看更多？下载 @知乎 App：http:\u002F\u002Fweibo.com\u002Fp\u002F100404711598 ）","canComment":{"status":true,"reason":""},"mcnFpShow":-1,"isVisible":true,"isLiked":false,"likedCount":0,"visibleOnlyToAuthor":false}},"columns":{"reinforcementlearning":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}},"topics":{},"roundtables":{},"favlists":{},"comments":{},"notifications":{},"ebooks":{},"activities":{},"feeds":{},"pins":{},"promotions":{},"drafts":{},"chats":{},"posts":{},"clubs":{},"clubTags":{}},"currentUser":"","account":{"lockLevel":{},"unlockTicketStatus":false,"unlockTicket":null,"challenge":[],"errorStatus":false,"message":"","isFetching":false,"accountInfo":{},"urlToken":{"loading":false}},"settings":{"socialBind":null,"inboxMsg":null,"notification":{},"email":{},"privacyFlag":null,"blockedUsers":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"blockedFollowees":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"ignoredTopics":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"restrictedTopics":null,"laboratory":{}},"notification":{},"people":{"profileStatus":{},"activitiesByUser":{},"answersByUser":{},"answersSortByVotesByUser":{},"answersIncludedByUser":{},"votedAnswersByUser":{},"thankedAnswersByUser":{},"voteAnswersByUser":{},"thankAnswersByUser":{},"topicAnswersByUser":{},"zvideosByUser":{},"articlesByUser":{},"articlesSortByVotesByUser":{},"articlesIncludedByUser":{},"pinsByUser":{},"questionsByUser":{},"commercialQuestionsByUser":{},"favlistsByUser":{},"followingByUser":{},"followersByUser":{},"mutualsByUser":{},"followingColumnsByUser":{},"followingQuestionsByUser":{},"followingFavlistsByUser":{},"followingTopicsByUser":{},"publicationsByUser":{},"columnsByUser":{},"allFavlistsByUser":{},"brands":null,"creationsByUser":{},"creationsSortByVotesByUser":{},"creationsFeed":{}},"env":{"ab":{"config":{"experiments":[{"expId":"launch-gw_mweb_rec-1","expPrefix":"gw_mweb_rec","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-qa_hdpimg-2","expPrefix":"qa_hdpimg","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-us_foltopic_user-10","expPrefix":"us_foltopic_user","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_bullet_second-2","expPrefix":"vd_bullet_second","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_zvideo_link-10","expPrefix":"vd_zvideo_link","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"se_topicfeed-4","expPrefix":"se_topicfeed","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"gw_mweb_launch-1","expPrefix":"gw_mweb_launch","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false}],"params":[{"id":"web_sec672","type":"String","value":"0"},{"id":"soc_adpinweight","type":"String","value":"0","chainId":"_all_"},{"id":"web_hdpimg","type":"String","value":"1"},{"id":"soc_userrec","type":"String","value":"0","chainId":"_all_"},{"id":"li_answers_link","type":"String","value":"0","chainId":"_all_"},{"id":"web_answerlist_ad","type":"String","value":"0"},{"id":"se_prf","type":"String","value":"0","chainId":"_all_"},{"id":"gue_bullet_second","type":"String","value":"1"},{"id":"li_android_vip","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_section","type":"String","value":"0","chainId":"_all_"},{"id":"soc_special","type":"String","value":"0","chainId":"_all_"},{"id":"ls_videoad","type":"String","value":"2","chainId":"_all_"},{"id":"li_qa_btn_text","type":"String","value":"0","chainId":"_all_"},{"id":"zr_article_new","type":"String","value":"close","chainId":"_all_"},{"id":"top_quality","type":"String","value":"0","chainId":"_all_"},{"id":"tsp_vote","type":"String","value":"2","chainId":"_all_"},{"id":"tp_topic_entry","type":"String","value":"0","chainId":"_all_"},{"id":"ug_zero_follow","type":"String","value":"0","chainId":"_all_"},{"id":"se_webmajorob","type":"String","value":"0","chainId":"_all_"},{"id":"se_use_zitem","type":"String","value":"0","chainId":"_all_"},{"id":"tp_qa_toast","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_android_join","type":"String","value":"1","chainId":"_all_"},{"id":"soc_brdcst3","type":"String","value":"0","chainId":"_all_"},{"id":"tp_header_style","type":"String","value":"1","chainId":"_all_"},{"id":"top_test_4_liguangyi","type":"String","value":"1","chainId":"_all_"},{"id":"web_ask","type":"String","value":"0"},{"id":"zr_answer_rec_cp","type":"String","value":"open","chainId":"_all_"},{"id":"pf_adjust","type":"String","value":"0","chainId":"_all_"},{"id":"se_click_club","type":"String","value":"1","chainId":"_all_"},{"id":"tp_topic_style","type":"String","value":"0","chainId":"_all_"},{"id":"soc_leave_recommend","type":"String","value":"2","chainId":"_all_"},{"id":"se_backsearch","type":"String","value":"0","chainId":"_all_"},{"id":"se_college_cm","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zcfw_broadcast","type":"String","value":"0","chainId":"_all_"},{"id":"zr_km_answer","type":"String","value":"open_cvr","chainId":"_all_"},{"id":"zr_training_boost","type":"String","value":"false","chainId":"_all_"},{"id":"li_sku_bottom_bar_re","type":"String","value":"0","chainId":"_all_"},{"id":"se_dnn_mt_v2","type":"String","value":"0","chainId":"_all_"},{"id":"se_webtimebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_related_index","type":"String","value":"3","chainId":"_all_"},{"id":"web_mweb_rec_length","type":"String","value":"1"},{"id":"qap_thanks","type":"String","value":"1","chainId":"_all_"},{"id":"zr_intervene","type":"String","value":"0","chainId":"_all_"},{"id":"se_cate_l3","type":"String","value":"0","chainId":"_all_"},{"id":"soc_stickypush","type":"String","value":"1","chainId":"_all_"},{"id":"top_v_album","type":"String","value":"1","chainId":"_all_"},{"id":"top_ebook","type":"String","value":"0","chainId":"_all_"},{"id":"ug_fw_answ_aut_1","type":"String","value":"0","chainId":"_all_"},{"id":"li_ebook_gen_search","type":"String","value":"0","chainId":"_all_"},{"id":"zr_expslotpaid","type":"String","value":"1","chainId":"_all_"},{"id":"se_highlight","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_feed","type":"String","value":"1","chainId":"_all_"},{"id":"soc_bignew","type":"String","value":"1","chainId":"_all_"},{"id":"soc_authormore2","type":"String","value":"2","chainId":"_all_"},{"id":"se_col_boost","type":"String","value":"0","chainId":"_all_"},{"id":"se_mobileweb","type":"String","value":"1","chainId":"_all_"},{"id":"se_adxtest","type":"String","value":"1","chainId":"_all_"},{"id":"se_waterfall","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_discover","type":"String","value":"0","chainId":"_all_"},{"id":"top_ydyq","type":"String","value":"X","chainId":"_all_"},{"id":"li_assessment_show","type":"String","value":"1","chainId":"_all_"},{"id":"gue_self_censoring","type":"String","value":"1"},{"id":"web_audit_01","type":"String","value":"case1"},{"id":"se_likebutton","type":"String","value":"0","chainId":"_all_"},{"id":"se_search_feed","type":"String","value":"N","chainId":"_all_"},{"id":"tp_discover_copy","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iosreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"soc_yxzl_zcfw","type":"String","value":"0","chainId":"_all_"},{"id":"se_time_threshold","type":"String","value":"0","chainId":"_all_"},{"id":"gue_bullet_guide","type":"String","value":"发个弹幕聊聊…"},{"id":"soc_bigone","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zcfw_broadcast2","type":"String","value":"1","chainId":"_all_"},{"id":"li_vip_verti_search","type":"String","value":"0","chainId":"_all_"},{"id":"se_ios_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_2","type":"String","value":"1","chainId":"_all_"},{"id":"se_new_topic","type":"String","value":"0","chainId":"_all_"},{"id":"se_p_slideshow","type":"String","value":"0","chainId":"_all_"},{"id":"se_preset_tech","type":"String","value":"0","chainId":"_all_"},{"id":"web_mweb_launch","type":"String","value":"1"},{"id":"zr_update_merge_size","type":"String","value":"1","chainId":"_all_"},{"id":"web_unfriendly_comm","type":"String","value":"0"},{"id":"tp_club_android_feed","type":"String","value":"old","chainId":"_all_"},{"id":"gue_video_autoplay","type":"String","value":"0"},{"id":"pf_creator_card","type":"String","value":"1","chainId":"_all_"},{"id":"gue_video_replay","type":"String","value":"0"},{"id":"gue_zhuantikapian","type":"String","value":"0"},{"id":"web_answer_list_ad","type":"String","value":"1"},{"id":"se_new_p","type":"String","value":"0","chainId":"_all_"},{"id":"se_timebox_up","type":"String","value":"0","chainId":"_all_"},{"id":"se_multianswer","type":"String","value":"2","chainId":"_all_"},{"id":"tp_qa_metacard","type":"String","value":"1","chainId":"_all_"},{"id":"qap_article_like","type":"String","value":"1","chainId":"_all_"},{"id":"se_rf_w","type":"String","value":"0","chainId":"_all_"},{"id":"se_ltr_video","type":"String","value":"0","chainId":"_all_"},{"id":"se_movietab","type":"String","value":"1","chainId":"_all_"},{"id":"se_famous","type":"String","value":"1","chainId":"_all_"},{"id":"gue_zvideo_link","type":"String","value":"1"},{"id":"li_education_box","type":"String","value":"0","chainId":"_all_"},{"id":"zr_art_rec","type":"String","value":"base","chainId":"_all_"},{"id":"tp_topic_tab","type":"String","value":"0","chainId":"_all_"},{"id":"soc_authormore","type":"String","value":"2","chainId":"_all_"},{"id":"web_upload","type":"String","value":"1"},{"id":"zr_video_recall","type":"String","value":"current_recall","chainId":"_all_"},{"id":"se_topiclabel","type":"String","value":"1","chainId":"_all_"},{"id":"se_billboardsearch","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_qa_pic","type":"String","value":"1","chainId":"_all_"},{"id":"soc_ri_merge","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_media_icon","type":"String","value":"1","chainId":"_all_"},{"id":"se_ctx_rerank","type":"String","value":"1","chainId":"_all_"},{"id":"se_relation_1","type":"String","value":"0","chainId":"_all_"},{"id":"se_content0","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_qa","type":"String","value":"1","chainId":"_all_"},{"id":"tp_topic_rec","type":"String","value":"1","chainId":"_all_"},{"id":"li_hot_voted","type":"String","value":"0","chainId":"_all_"},{"id":"zr_search_paid","type":"String","value":"0","chainId":"_all_"},{"id":"zr_training_first","type":"String","value":"false","chainId":"_all_"},{"id":"se_sug_entrance","type":"String","value":"1","chainId":"_all_"},{"id":"soc_update","type":"String","value":"1","chainId":"_all_"},{"id":"li_se_across","type":"String","value":"1","chainId":"_all_"},{"id":"zr_km_feed_nlp","type":"String","value":"old","chainId":"_all_"},{"id":"se_club_post","type":"String","value":"5","chainId":"_all_"},{"id":"web_column_auto_invite","type":"String","value":"0"},{"id":"tsp_hotlist_ui","type":"String","value":"1","chainId":"_all_"},{"id":"tsp_videobillboard","type":"String","value":"1","chainId":"_all_"},{"id":"pf_foltopic_usernum","type":"String","value":"50","chainId":"_all_"},{"id":"gue_goods_card","type":"String","value":"0"},{"id":"zr_search_sim","type":"String","value":"0","chainId":"_all_"},{"id":"zr_video_rank_nn","type":"String","value":"new_rank","chainId":"_all_"},{"id":"tp_club_tab","type":"String","value":"0","chainId":"_all_"},{"id":"soc_notification","type":"String","value":"0","chainId":"_all_"},{"id":"li_video_section","type":"String","value":"0","chainId":"_all_"},{"id":"li_ebok_chap","type":"String","value":"0","chainId":"_all_"},{"id":"qap_payc_invite","type":"String","value":"0","chainId":"_all_"},{"id":"se_new_merger","type":"String","value":"1","chainId":"_all_"},{"id":"soc_feed_intimacy","type":"String","value":"2","chainId":"_all_"},{"id":"ug_goodcomment_0","type":"String","value":"1","chainId":"_all_"},{"id":"se_expired_ob","type":"String","value":"0","chainId":"_all_"},{"id":"tp_qa_metacard_top","type":"String","value":"top","chainId":"_all_"},{"id":"top_new_feed","type":"String","value":"5","chainId":"_all_"},{"id":"web_n_web_msg","type":"String","value":"0"},{"id":"se_entity_model_14","type":"String","value":"0","chainId":"_all_"},{"id":"se_colorfultab","type":"String","value":"1","chainId":"_all_"},{"id":"se_aa","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_3","type":"String","value":"0","chainId":"_all_"},{"id":"li_svip_tab_search","type":"String","value":"0","chainId":"_all_"},{"id":"zw_sameq_sorce","type":"String","value":"999","chainId":"_all_"},{"id":"zr_slot_training","type":"String","value":"1","chainId":"_all_"},{"id":"soc_wonderuser_recom","type":"String","value":"2","chainId":"_all_"},{"id":"ug_follow_topic_1","type":"String","value":"2","chainId":"_all_"},{"id":"gue_new_special_page","type":"String","value":"1"},{"id":"zr_slotpaidexp","type":"String","value":"1","chainId":"_all_"},{"id":"se_payconsult","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_tab_new","type":"String","value":"0-0-0","chainId":"_all_"},{"id":"pf_noti_entry_num","type":"String","value":"0","chainId":"_all_"},{"id":"ug_zero_follow_0","type":"String","value":"0","chainId":"_all_"},{"id":"se_college","type":"String","value":"default","chainId":"_all_"},{"id":"se_wannasearch","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adreadline","type":"String","value":"0","chainId":"_all_"},{"id":"top_universalebook","type":"String","value":"1","chainId":"_all_"},{"id":"qap_question_author","type":"String","value":"0","chainId":"_all_"},{"id":"zw_payc_qaedit","type":"String","value":"0","chainId":"_all_"},{"id":"zr_test_aa1","type":"String","value":"0","chainId":"_all_"},{"id":"se_topicfeed","type":"String","value":"1","chainId":"_all_"},{"id":"top_root","type":"String","value":"0","chainId":"_all_"},{"id":"li_catalog_card","type":"String","value":"1","chainId":"_all_"},{"id":"gue_thanks","type":"String","value":"0"},{"id":"se_hotsearch_num","type":"String","value":"0","chainId":"_all_"},{"id":"se_lottery","type":"String","value":"0","chainId":"_all_"},{"id":"tp_m_intro_re_topic","type":"String","value":"1","chainId":"_all_"},{"id":"soc_iosintimacy","type":"String","value":"2","chainId":"_all_"},{"id":"qap_ques_invite","type":"String","value":"0","chainId":"_all_"},{"id":"se_agency","type":"String","value":" 0","chainId":"_all_"},{"id":"tp_club_pic","type":"String","value":"0.6","chainId":"_all_"},{"id":"se_presearch_ab","type":"String","value":"0","chainId":"_all_"},{"id":"li_qa_new_cover","type":"String","value":"1","chainId":"_all_"},{"id":"web_answer_update","type":"String","value":"0"},{"id":"web_collect","type":"String","value":"0"},{"id":"se_hotmore","type":"String","value":"2","chainId":"_all_"},{"id":"li_answer_card","type":"String","value":"0","chainId":"_all_"},{"id":"se_websearch","type":"String","value":"3","chainId":"_all_"},{"id":"zr_ans_rec","type":"String","value":"gbrank","chainId":"_all_"},{"id":"se_article_icon","type":"String","value":"0","chainId":"_all_"},{"id":"se_hot_timebox","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_join","type":"String","value":"0","chainId":"_all_"},{"id":"li_salt_hot","type":"String","value":"1","chainId":"_all_"},{"id":"se_hotsearch_2","type":"String","value":"1","chainId":"_all_"},{"id":"se_pek_test2","type":"String","value":"1","chainId":"_all_"},{"id":"ug_follow_answerer_0","type":"String","value":"0","chainId":"_all_"},{"id":"se_subtext","type":"String","value":"0","chainId":"_all_"},{"id":"zr_rel_search","type":"String","value":"base","chainId":"_all_"},{"id":"ls_fmp4","type":"String","value":"0","chainId":"_all_"},{"id":"li_paid_answer_exp","type":"String","value":"0","chainId":"_all_"},{"id":"web_question_invite","type":"String","value":"B"},{"id":"se_searchwiki","type":"String","value":"0","chainId":"_all_"},{"id":"se_ffzx_jushen1","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iossort","type":"String","value":"0","chainId":"_all_"},{"id":"soc_newfeed","type":"String","value":"2","chainId":"_all_"},{"id":"zr_rec_answer_cp","type":"String","value":"close","chainId":"_all_"},{"id":"se_specialbutton","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_pic_swiper","type":"String","value":"1","chainId":"_all_"},{"id":"pf_fuceng","type":"String","value":"1","chainId":"_all_"},{"id":"ug_follow_answerer","type":"String","value":"0","chainId":"_all_"},{"id":"li_purchase_test","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_4","type":"String","value":"1","chainId":"_all_"},{"id":"se_featured","type":"String","value":"1","chainId":"_all_"},{"id":"tp_sft_v2","type":"String","value":"d","chainId":"_all_"},{"id":"li_se_heat","type":"String","value":"1","chainId":"_all_"},{"id":"se_preset_label","type":"String","value":"1","chainId":"_all_"},{"id":"soc_iosreadline","type":"String","value":"0","chainId":"_all_"},{"id":"pf_newguide_vertical","type":"String","value":"0","chainId":"_all_"},{"id":"se_page_quality","type":"String","value":"0","chainId":"_all_"},{"id":"se_sug_term","type":"String","value":"0","chainId":"_all_"},{"id":"tp_discovery_ab_1","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sticky_android","type":"String","value":"2","chainId":"_all_"},{"id":"tp_topic_head","type":"String","value":"0","chainId":"_all_"},{"id":"soc_brdcst4","type":"String","value":"3","chainId":"_all_"},{"id":"se_ad_index","type":"String","value":"10","chainId":"_all_"},{"id":"tp_club_header","type":"String","value":"1","chainId":"_all_"},{"id":"soc_zcfw_shipinshiti","type":"String","value":"1","chainId":"_all_"},{"id":"ug_newtag","type":"String","value":"0","chainId":"_all_"},{"id":"li_pay_banner_type","type":"String","value":"6","chainId":"_all_"},{"id":"se_entity_model","type":"String","value":"0","chainId":"_all_"},{"id":"se_relationship","type":"String","value":"1","chainId":"_all_"},{"id":"se_cbert_index","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iospinweight","type":"String","value":"0","chainId":"_all_"},{"id":"qap_question_visitor","type":"String","value":" 0","chainId":"_all_"},{"id":"tp_score_1","type":"String","value":"a","chainId":"_all_"},{"id":"soc_zcfw_badcase","type":"String","value":"0","chainId":"_all_"},{"id":"web_heifetz_grow_ad","type":"String","value":"1"},{"id":"li_svip_cardshow","type":"String","value":"1","chainId":"_all_"},{"id":"li_se_edu","type":"String","value":"1","chainId":"_all_"},{"id":"tp_discover","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_tab_feed","type":"String","value":"0","chainId":"_all_"},{"id":"se_webrs","type":"String","value":"1","chainId":"_all_"},{"id":"se_pek_test","type":"String","value":"1","chainId":"_all_"},{"id":"se_pek_test3","type":"String","value":"1","chainId":"_all_"},{"id":"se_amovietab","type":"String","value":"1","chainId":"_all_"},{"id":"soc_zuichangfangwen","type":"String","value":"0","chainId":"_all_"},{"id":"li_ebook_read","type":"String","value":"0","chainId":"_all_"},{"id":"zr_slot_cold_start","type":"String","value":"aver","chainId":"_all_"},{"id":"se_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"se_aa_base","type":"String","value":"0","chainId":"_all_"},{"id":"se_whitelist","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_pk","type":"String","value":"1","chainId":"_all_"},{"id":"web_ad_banner","type":"String","value":"0"},{"id":"se_site_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_zu_recommend","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"li_yxzl_new_style_a","type":"String","value":"1","chainId":"_all_"},{"id":"zr_video_rank","type":"String","value":"new_rank","chainId":"_all_"},{"id":"se_auto_syn","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sft","type":"String","value":"a","chainId":"_all_"},{"id":"web_sem_ab","type":"String","value":"1"},{"id":"sem_up_growth","type":"String","value":"in_app","chainId":"_all_"},{"id":"li_answer_label","type":"String","value":"0","chainId":"_all_"},{"id":"gue_card_test","type":"String","value":"1"},{"id":"soc_adsort","type":"String","value":"0","chainId":"_all_"},{"id":"web_creator_route","type":"String","value":"1"},{"id":"web_mini_review","type":"String","value":"0"},{"id":"se_cardrank_1","type":"String","value":"0","chainId":"_all_"},{"id":"se_zu_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_sug","type":"String","value":"1","chainId":"_all_"},{"id":"soc_cardheight","type":"String","value":"2","chainId":"_all_"},{"id":"se_hotsearch","type":"String","value":"0","chainId":"_all_"},{"id":"tp_meta_card","type":"String","value":"0","chainId":"_all_"},{"id":"top_hotcommerce","type":"String","value":"1","chainId":"_all_"},{"id":"ls_recommend_test","type":"String","value":"0","chainId":"_all_"}],"chains":[{"chainId":"_all_"}]},"triggers":{}},"userAgent":{"Edge":false,"Wechat":false,"Weibo":false,"QQ":false,"MQQBrowser":false,"Qzone":false,"Mobile":false,"Android":false,"iOS":false,"isAppleDevice":false,"Zhihu":false,"ZhihuHybrid":false,"isBot":false,"Tablet":false,"UC":false,"Sogou":false,"Qihoo":false,"Baidu":false,"BaiduApp":false,"Safari":false,"GoogleBot":false,"AndroidDaily":false,"iOSDaily":false,"isWebView":false,"origin":"Mozilla\u002F5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\u002F537.36 (KHTML, like Gecko) Chrome\u002F80.0.3987.100 Safari\u002F537.36"},"appViewConfig":{},"ctx":{"path":"\u002Fp\u002F107388314","query":{},"href":"http:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F107388314","host":"zhuanlan.zhihu.com"},"trafficSource":"production","edition":{"baidu":false,"sogou":false,"baiduBeijing":false,"sogouBeijing":false,"sogouInput":false},"theme":"light","enableShortcut":true,"referer":"","conf":{},"ipInfo":{"cityName":"德州","countryName":"中国","regionName":"山东","countryCode":"CN"},"logged":false},"me":{"columnContributions":[]},"label":{"recognizerLists":{}},"ecommerce":{},"comments":{"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"parent":{}},"commentsV2":{"stickers":[],"commentWithPicPermission":{},"notificationsComments":{},"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"conversationMore":{},"parent":{}},"pushNotifications":{"default":{"isFetching":false,"isDrained":false,"ids":[]},"follow":{"isFetching":false,"isDrained":false,"ids":[]},"vote_thank":{"isFetching":false,"isDrained":false,"ids":[]},"currentTab":"default","notificationsCount":{"default":0,"follow":0,"vote_thank":0}},"messages":{"data":{},"currentTab":"common","messageCount":0},"register":{"registerValidateSucceeded":null,"registerValidateErrors":{},"registerConfirmError":null,"sendDigitsError":null,"registerConfirmSucceeded":null},"login":{"loginUnregisteredError":false,"loginBindWechatError":false,"loginConfirmError":null,"sendDigitsError":null,"needSMSIdentify":false,"validateDigitsError":false,"loginConfirmSucceeded":null,"qrcodeLoginToken":"","qrcodeLoginScanStatus":0,"qrcodeLoginError":null,"qrcodeLoginReturnNewToken":false},"active":{"sendDigitsError":null,"activeConfirmSucceeded":null,"activeConfirmError":null},"switches":{},"captcha":{"captchaNeeded":false,"captchaValidated":false,"captchaBase64String":null,"captchaValidationMessage":null,"loginCaptchaExpires":false},"sms":{"supportedCountries":[]},"chat":{"chats":{},"inbox":{"recents":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"strangers":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"friends":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"search":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"config":{"newCount":0,"strangerMessageSwitch":false,"strangerMessageUnread":false,"friendCount":0}},"global":{"isChatMqttExisted":false}},"emoticons":{"emoticonGroupList":[],"emoticonGroupDetail":{}},"creator":{"currentCreatorUrlToken":null,"homeData":{"recommendQuestions":[]},"tools":{"question":{"invitationCount":{"questionFolloweeCount":0,"questionTotalCount":0},"goodatTopics":[]},"customPromotion":{"itemLists":{}},"recommend":{"recommendTimes":{}}},"explore":{"academy":{"tabs":[],"article":{}}},"rights":[],"rightsStatus":{},"levelUpperLimit":10,"account":{"growthLevel":{}},"mcn":{},"applyStatus":{}},"recommendation":{"homeRecommendations":[]},"shareTexts":{},"articles":{"voters":{}},"previewPost":{},"favlists":{"relations":{}},"columns":{"voters":{}},"reward":{"answer":{},"article":{},"question":{}},"video":{"data":{},"shareVideoDetail":{},"last":{}},"topstory":{"recommend":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"follow":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followWonderful":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"sidebar":null,"announcement":{},"hotListCategories":[],"hotList":[],"guestFeeds":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followExtra":{"isNewUser":null,"isFetched":false,"followCount":0,"followers":[]}},"readStatus":{},"column":{},"requestColumn":{"categories":[],"error":null},"articleContribution":{"contributeRequests":[],"deleteContributeIdList":[],"handledContributeIdList":[],"recommendedColumns":[],"pinnedColumns":[],"sentContributeRequestsIdList":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"reinforcementlearning"]},"columnContribution":{"contributeRequests":[],"autoInviteEnabled":false,"recommendedContributors":[],"contributionInvitation":null},"draftHistory":{"history":{},"drafts":{}},"upload":{},"articleDraft":{"titleImage":"","titleImageSize":{},"isTitleImageFullScreen":false,"canTitleImageFullScreen":false,"title":"","titleImageUploading":false,"error":"","content":"","draftLoading":false,"updating":false,"globalLoading":false,"pendingVideo":{"resource":null,"error":null},"deleteFail":{"fail":false},"recommendTopics":[],"selectedColumn":0,"articleDisclaimers":[]},"articleDrafts":{"isDrained":false,"isLoading":false,"items":[]},"columnAutocomplete":{"users":[],"friends":[]},"columnCollection":{},"mcn":{"bindInfo":{},"memberCategoryList":[],"producerList":[],"categoryList":[]}},"fetchHost":"www.zhihu.com","subAppName":"column"}</script><script src="https://static.zhihu.com/heifetz/vendor.7b36fae46082fd30a0db.js"></script><script src="https://static.zhihu.com/heifetz/column.app.76e02b16e87eec249f44.js"></script></body><script src="https://hm.baidu.com/hm.js?98beee57fd2ef70ccdd5ca52b9740c49" async=""></script><script src="https://zz.bdstatic.com/linksubmit/push.js" async=""></script></html>