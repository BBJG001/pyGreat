<!doctype html>
<html lang="zh" data-hairline="true" data-theme="light"><head><meta charSet="utf-8"/><title data-react-helmet="true">【ICLR2020】通过强化学习和稀疏奖励进行模仿学习 - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"/><meta name="renderer" content="webkit"/><meta name="force-rendering" content="webkit"/><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg"/><meta data-react-helmet="true" name="keywords" content="强化学习 (Reinforcement Learning),机器学习,深度学习（Deep Learning）"/><meta data-react-helmet="true" name="description" content="论文题目：SQIL: Imitation Learning via Reinforcement Learning with Sparse Rewards所解决的问题？ 从高维的状态动作空间中进行模仿学习是比较困难的，以往的行为克隆算法(behavioral cloning BC)算法容易产生…"/><meta data-react-helmet="true" property="og:title" content="【ICLR2020】通过强化学习和稀疏奖励进行模仿学习"/><meta data-react-helmet="true" property="og:url" content="https://zhuanlan.zhihu.com/p/113124696"/><meta data-react-helmet="true" property="og:description" content="论文题目：SQIL: Imitation Learning via Reinforcement Learning with Sparse Rewards所解决的问题？ 从高维的状态动作空间中进行模仿学习是比较困难的，以往的行为克隆算法(behavioral cloning BC)算法容易产生…"/><meta data-react-helmet="true" property="og:image" content="https://pic4.zhimg.com/v2-589f12d2003902a555e8c5dac043beee_b.jpg"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" property="og:site_name" content="知乎专栏"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png" sizes="152x152"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-120.b3e6278d.png" sizes="120x120"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-76.7a750095.png" sizes="76x76"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-60.a4a761d4.png" sizes="60x60"/><link rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/static/favicon.ico"/><link rel="search" type="application/opensearchdescription+xml" href="https://static.zhihu.com/static/search.xml" title="知乎"/><link rel="dns-prefetch" href="//static.zhimg.com"/><link rel="dns-prefetch" href="//pic1.zhimg.com"/><link rel="dns-prefetch" href="//pic2.zhimg.com"/><link rel="dns-prefetch" href="//pic3.zhimg.com"/><link rel="dns-prefetch" href="//pic4.zhimg.com"/><style>
.u-safeAreaInset-top {
  height: constant(safe-area-inset-top) !important;
  height: env(safe-area-inset-top) !important;
  
}
.u-safeAreaInset-bottom {
  height: constant(safe-area-inset-bottom) !important;
  height: env(safe-area-inset-bottom) !important;
  
}
</style><link href="https://static.zhihu.com/heifetz/column.app.a9ced452148fee3a55c8.css" rel="stylesheet"/><script defer="" crossorigin="anonymous" src="https://unpkg.zhimg.com/@cfe/sentry-script@latest/dist/init.js" data-sentry-config="{&quot;dsn&quot;:&quot;https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224&quot;,&quot;sampleRate&quot;:0.1,&quot;release&quot;:&quot;683-127b14ad&quot;,&quot;ignoreErrorNames&quot;:[&quot;NetworkError&quot;,&quot;SecurityError&quot;],&quot;ignoreErrors&quot;:[&quot;origin message&quot;,&quot;Network request failed&quot;,&quot;Loading chunk&quot;,&quot;这个系统不支持该功能。&quot;,&quot;Can&#x27;t find variable: webkit&quot;,&quot;Can&#x27;t find variable: $&quot;,&quot;内存不足&quot;,&quot;out of memory&quot;,&quot;DOM Exception 18&quot;,&quot;The operation is insecure&quot;,&quot;[object Event]&quot;,&quot;[object FileError]&quot;,&quot;[object DOMError]&quot;,&quot;[object Object]&quot;,&quot;拒绝访问。&quot;,&quot;Maximum call stack size exceeded&quot;,&quot;UploadError&quot;,&quot;无法 fetch&quot;,&quot;draft-js&quot;,&quot;缺少 JavaScript 对象&quot;,&quot;componentWillEnter&quot;,&quot;componentWillLeave&quot;,&quot;componentWillAppear&quot;,&quot;getInlineStyleAt&quot;,&quot;getCharacterList&quot;],&quot;whitelistUrls&quot;:[&quot;static.zhihu.com&quot;]}"></script></head><body class="WhiteBg-body"><div id="root"><div class="App"><div class="LoadingBar"></div><main role="main" class="App-main"><div class="Post-content" data-zop-usertoken="{&quot;userToken&quot;:&quot;&quot;}" data-zop="{&quot;authorName&quot;:&quot;小小何先生&quot;,&quot;itemId&quot;:113124696,&quot;title&quot;:&quot;【ICLR2020】通过强化学习和稀疏奖励进行模仿学习&quot;,&quot;type&quot;:&quot;article&quot;}"><div class="ColumnPageHeader-Wrapper"><div><div class="Sticky ColumnPageHeader"><div class="ColumnPageHeader-content"><a href="//www.zhihu.com" aria-label="知乎"><svg viewBox="0 0 200 91" fill="#0084FF" width="64" height="30"><path d="M53.29 80.035l7.32.002 2.41 8.24 13.128-8.24h15.477v-67.98H53.29v67.978zm7.79-60.598h22.756v53.22h-8.73l-8.718 5.473-1.587-5.46-3.72-.012v-53.22zM46.818 43.162h-16.35c.545-8.467.687-16.12.687-22.955h15.987s.615-7.05-2.68-6.97H16.807c1.09-4.1 2.46-8.332 4.1-12.708 0 0-7.523 0-10.085 6.74-1.06 2.78-4.128 13.48-9.592 24.41 1.84-.2 7.927-.37 11.512-6.94.66-1.84.785-2.08 1.605-4.54h9.02c0 3.28-.374 20.9-.526 22.95H6.51c-3.67 0-4.863 7.38-4.863 7.38H22.14C20.765 66.11 13.385 79.24 0 89.62c6.403 1.828 12.784-.29 15.937-3.094 0 0 7.182-6.53 11.12-21.64L43.92 85.18s2.473-8.402-.388-12.496c-2.37-2.788-8.768-10.33-11.496-13.064l-4.57 3.627c1.363-4.368 2.183-8.61 2.46-12.71H49.19s-.027-7.38-2.372-7.38zm128.752-.502c6.51-8.013 14.054-18.302 14.054-18.302s-5.827-4.625-8.556-1.27c-1.874 2.548-11.51 15.063-11.51 15.063l6.012 4.51zm-46.903-18.462c-2.814-2.577-8.096.667-8.096.667s12.35 17.2 12.85 17.953l6.08-4.29s-8.02-11.752-10.83-14.33zM199.99 46.5c-6.18 0-40.908.292-40.953.292v-31.56c1.503 0 3.882-.124 7.14-.376 12.773-.753 21.914-1.25 27.427-1.504 0 0 3.817-8.496-.185-10.45-.96-.37-7.24 1.43-7.24 1.43s-51.63 5.153-72.61 5.64c.5 2.756 2.38 5.336 4.93 6.11 4.16 1.087 7.09.53 15.36.277 7.76-.5 13.65-.76 17.66-.76v31.19h-41.71s.88 6.97 7.97 7.14h33.73v22.16c0 4.364-3.498 6.87-7.65 6.6-4.4.034-8.15-.36-13.027-.566.623 1.24 1.977 4.496 6.035 6.824 3.087 1.502 5.054 2.053 8.13 2.053 9.237 0 14.27-5.4 14.027-14.16V53.93h38.235c3.026 0 2.72-7.432 2.72-7.432z" fill-rule="evenodd"></path></svg></a><i class="ColumnPageHeader-Line"></i><div class="ColumnPageHeader-Title"><a class="ColumnLink ColumnPageHeader-Link" href="/reinforcement"><img class="Avatar Avatar--round" width="30" height="30" src="https://pic2.zhimg.com/v2-b993d155c18470e92ba3c391023c6561_is.jpg" srcSet="https://pic2.zhimg.com/v2-b993d155c18470e92ba3c391023c6561_im.jpg 2x" alt="强化学习"/></a><div class="ColumnPageHeader-TitleName"><span class="ColumnPageHeader-TitleMeta">首发于</span><a class="ColumnLink ColumnPageHeader-TitleColumn" href="/reinforcement">强化学习</a></div></div><div class="ColumnPageHeader-Button"><button type="button" class="Button ColumnPageHeader-WriteButton Button--blue"><svg class="Zi Zi--EditSurround" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M18.453 7.992l-1.833-1.65.964-.978a1.223 1.223 0 0 1 1.73-.012l.005.006a1.24 1.24 0 0 1 .007 1.748l-.873.886zm-1.178 1.194l-5.578 5.66-1.935.697a.393.393 0 0 1-.504-.504l.697-1.935 5.488-5.567 1.832 1.65zM7.58 5.848l5.654.006-1.539 1.991-3.666.012A1.02 1.02 0 0 0 7 8.868v7.993c0 .558.46 1.01 1.029 1.01l7.941-.01c.568 0 1.03-.453 1.03-1.012v-4.061l2-1.442v6.002c0 1.397-1.2 2.501-2.62 2.501H7.574C6.153 19.85 5 18.717 5 17.32V8.35c0-1.397 1.16-2.502 2.58-2.502z"></path></svg>写文章</button></div></div></div></div></div><img class="TitleImage" src="https://pic4.zhimg.com/v2-589f12d2003902a555e8c5dac043beee_1200x500.jpg" alt="【ICLR2020】通过强化学习和稀疏奖励进行模仿学习"/><article class="Post-Main Post-NormalMain" tabindex="-1"><header class="Post-Header"><h1 class="Post-Title">【ICLR2020】通过强化学习和稀疏奖励进行模仿学习</h1><div class="Post-Author"><div class="AuthorInfo" itemProp="author" itemscope="" itemType="http://schema.org/Person"><meta itemProp="name" content="小小何先生"/><meta itemProp="image" content="https://pic1.zhimg.com/v2-e7f3a66aff8bc0fda395148d2ca35b55_l.jpg"/><meta itemProp="url" content="https://www.zhihu.com/people/he-zhi-qiang-52-74"/><meta itemProp="zhihu:followerCount"/><span class="UserLink AuthorInfo-avatarWrapper"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/he-zhi-qiang-52-74"><img class="Avatar Avatar--round AuthorInfo-avatar" width="38" height="38" src="https://pic1.zhimg.com/v2-e7f3a66aff8bc0fda395148d2ca35b55_xs.jpg" srcSet="https://pic1.zhimg.com/v2-e7f3a66aff8bc0fda395148d2ca35b55_l.jpg 2x" alt="小小何先生"/></a></div></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/he-zhi-qiang-52-74">小小何先生</a></div></div><style data-emotion-css="1cd9gw4">.css-1cd9gw4{margin-left:.3em;}</style><style data-emotion-css="1pc1mic">.css-1pc1mic{box-sizing:border-box;margin:0;min-width:0;color:#175199;display:inline-block;width:18px;height:18px;margin-left:.3em;}</style><a href="https://www.zhihu.com/question/48510028" target="_blank" class="css-1pc1mic" data-tooltip="已认证的个人" aria-label="已认证的个人"><style data-emotion-css="18biwo">.css-18biwo{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><span class="css-18biwo">​<svg viewBox="0 0 24 24" width="18" height="18"><svg viewBox="0 0 24 24" x="-3" y="-3" fill="#FFFFFF" width="30" height="30"><path d="M3.56231227,13.8535307 C2.40051305,12.768677 2.41398885,11.0669203 3.59484487,9.99979213 L3.59222085,9.99654885 C4.26730143,9.45036719 4.79446755,8.21005186 4.7184197,7.34453784 L4.72305873,7.34412719 C4.66942824,5.75539997 5.8824188,4.56066914 7.47188965,4.64242381 L7.47229112,4.6386236 C8.33515314,4.72977993 9.58467253,4.22534048 10.1426329,3.55925173 L10.1462611,3.56228565 C11.2316055,2.40008701 12.9353108,2.41394456 14.0015072,3.59634088 L14.0047263,3.59374004 C14.5498229,4.26841874 15.7896857,4.79521622 16.6545744,4.71844347 L16.6549836,4.72304294 C18.245027,4.66894057 19.4396947,5.88213996 19.3575031,7.47241135 L19.3623099,7.47292747 C19.2704388,8.3358681 19.7742711,9.58421483 20.4407199,10.1424506 L20.437686,10.1460789 C21.5997217,11.2312209 21.5860695,12.9345218 20.4042441,14.0007396 L20.4072865,14.0045125 C19.7325967,14.5495925 19.2055209,15.7896954 19.2815865,16.6561959 L19.2770449,16.6565978 C19.3315454,18.2453037 18.1173775,19.4393568 16.5274188,19.3571512 L16.5269029,19.3619539 C15.6647098,19.270083 14.415408,19.7741709 13.8573671,20.4403558 L13.8537409,20.4373235 C12.76842,21.5995708 11.0650432,21.5864553 9.99899434,20.4039226 L9.99527367,20.406923 C9.45025436,19.7323399 8.21017638,19.2051872 7.34461983,19.2812352 L7.344304,19.2776405 C5.75448683,19.3312904 4.55977145,18.1170085 4.64254978,16.527117 L4.63769921,16.5265942 C4.72957031,15.6644394 4.22547659,14.4151814 3.55928015,13.8571569 L3.56231227,13.8535307 Z"></path></svg><path d="M2.63951518,13.3895441 C3.70763333,14.2842292 4.44777637,16.1226061 4.30075305,17.5023312 L4.32211542,17.3063047 C4.17509209,18.6910561 5.17786655,19.7063729 6.5613937,19.5844846 L6.364106,19.6008202 C7.75140298,19.4789319 9.57474349,20.2554985 10.4468305,21.3349009 L10.3224262,21.1803415 C11.1982831,22.2647703 12.6257916,22.2723098 13.5167278,21.2079863 L13.3898102,21.3600325 C14.2845162,20.2919393 16.1229361,19.5518136 17.5026934,19.6988334 L17.3054057,19.6774716 C18.6914461,19.8244915 19.7067866,18.8217404 19.5836389,17.4395022 L19.6012314,17.6367853 C19.4793403,16.2482641 20.255925,14.4249662 21.3353526,13.5528995 L21.1807897,13.677301 C22.2639871,12.8014646 22.2727834,11.3739894 21.2084351,10.483074 L21.3604848,10.6099886 C20.2923667,9.71530351 19.5522236,7.87818322 19.6992469,6.49720154 L19.6778846,6.69448464 C19.8249079,5.30847665 18.8221335,4.2944164 17.4386063,4.41630468 L17.635894,4.39871256 C16.248597,4.52185742 14.4252565,3.74529084 13.5531695,2.66588842 L13.6775738,2.81919121 C12.8017169,1.73601905 11.3742084,1.72722299 10.4832722,2.79154644 L10.6101898,2.63950024 C9.71548377,3.70759343 7.87706394,4.44771919 6.49730661,4.30195588 L6.69459432,4.32206116 C5.30855394,4.17504128 4.29447,5.17904888 4.41636114,6.56128713 L4.3987686,6.36400404 C4.52065973,7.75126861 3.74407501,9.57456653 2.66464737,10.4478898 L2.81921035,10.3222318 C1.73601288,11.1993248 1.72721662,12.6255433 2.79156494,13.5164587 L2.63951518,13.3895441 Z" fill="#0084FF"></path><svg class="Zi Zi--Check" fill="#fff" x="6" y="6" viewBox="0 0 24 24" width="12" height="12"><path d="M10.229 17.516c-.318.327-.75.484-1.199.484-.453 0-.884-.16-1.202-.488l-4.335-4.47a1.77 1.77 0 0 1 .007-2.459 1.663 1.663 0 0 1 2.397.01l3.137 3.246 9.072-9.329a1.662 1.662 0 0 1 2.397 0c.663.681.663 1.786 0 2.466L10.23 17.516z" fill-rule="evenodd"></path></svg></svg></span></a></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="AuthorInfo-badgeText">东北大学 信息科学与工程学院硕士在读</div></div></div></div></div></div><div><span class="Voters"><button type="button" class="Button Button--plain">20 人<!-- -->赞同了该文章</button></span></div></header><div class="Post-RichTextContainer"><div class="RichText ztext Post-RichText"><ul><li><b>论文题目</b>：<b>SQIL</b>: Imitation Learning via Reinforcement Learning with Sparse Rewards</li></ul><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-704131a78697f2459fb8b2568dff0fcc_b.jpg" data-caption="" data-size="normal" data-rawwidth="818" data-rawheight="220" class="origin_image zh-lightbox-thumb" width="818" data-original="https://pic1.zhimg.com/v2-704131a78697f2459fb8b2568dff0fcc_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;818&#39; height=&#39;220&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="818" data-rawheight="220" class="origin_image zh-lightbox-thumb lazy" width="818" data-original="https://pic1.zhimg.com/v2-704131a78697f2459fb8b2568dff0fcc_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-704131a78697f2459fb8b2568dff0fcc_b.jpg"/></figure><h2><b>所解决的问题？</b></h2><p>  从高维的状态动作空间中进行模仿学习是比较困难的，以往的行为克隆算法(<code>behavioral cloning BC</code>)算法容易产生分布漂移(<code>distribution shift</code>)，而最近做得比较好的就是生成对抗模仿学习算法(generative adversarial imitation learning (<code>GAIL</code>))，是逆强化(<code>Inverse RL</code>)学习算法与生成对抗网络结合的一种模仿学习算法，这个算法使用<code>adversarial training</code>技术学<code>reward function</code>，而作者提出的算法不需要<code>reward function</code>。整篇文章是在证明<code>constant reward</code>的<code>RL</code>方法与复杂的学习<code>reward function</code>的强化学习算法一样有效。</p><p>  文章的主要贡献在于提出了一种简单易于实现版本的模仿学习算法，用于高维、连续、动态环境中。能够很好克服模仿学习中的<code>distribution shift</code>问题。</p><h2><b>背景</b></h2><p>  模仿学习的问题在于<code>behavior shift</code>，并且误差会累计，因为智能体并不知道如何回到<code>expert</code>的轨迹状态上来。最近做地比较好的就是<code>GAIL</code>，<code>GAIL</code>做模仿学习最大的好处就是 <code>encourage long-horizon imitation</code>。那为什么<code>GAIL</code>能够做到<code>long-horizon imitation</code>呢？模型学习一般分为两步，在某个<code>state</code>下采取某个<code>action</code>，一般的<code>BC</code>算法都这么做的，而<code>GAIL</code>除此之外还考虑了采取这个<code>action</code>之后还回到<code>expert</code> 轨迹的下一个状态上。而作者也采纳了<code>GAIL</code>的上述两点优势，但是并未使用<code>GAIL</code>算法中的<code>adversarial training</code>技术，而是使用一个<code>constant reward</code>。如果matching the demonstrated action in a demonstrated state，reward = +1；对于其他的情况 reward =0。整个问题就变成了一个奖励稀疏的强化学习问题。</p><h2><b>所采用的方法？</b></h2><p>  作者引入<code>soft-q-learning</code>算法，将<code>expert demonstrations</code>的奖励设置为1，而与环境互动得到的新的<code>experiences</code>奖励设置为0。由于<code>soft Q-Learning</code>算法是<code>off-policy</code>的算法，因此有<code>data</code>就可以训练了。整个算法作者命名为 soft Q imitation learning (<code>SQIL</code>)。</p><h3><b>Soft Q Imitation Learning算法</b></h3><p><code>SQIL</code>在<code>soft q learning</code>算法上面做了三个小的修正：</p><ol><li>用<code>expert demonstration</code>初始化填入<code>agent</code>的<code>experience replay buffer</code>，其<code>reward</code>设置为<code>+1</code>；</li><li><code>agent</code>与环境互动得到新的<code>data</code>也加入到<code>experience replay buffer</code>里面，其<code>reward</code>设置为<code>0</code>；</li><li>平衡<code>demonstration experiences</code>和<code>new experiences</code>各<img src="https://www.zhihu.com/equation?tex=50%5C%25" alt="50\%" eeimg="1"/>。这个方法在<code>GAIL</code>和<code>adversarial IRL</code> 算法上面也都有应用。</li></ol><p><code>SQIL</code>算法如下所示：</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-b64ec1ab8feefc281dcfbb81394ceea9_b.jpg" data-caption="" data-size="normal" data-rawwidth="810" data-rawheight="195" class="origin_image zh-lightbox-thumb" width="810" data-original="https://pic2.zhimg.com/v2-b64ec1ab8feefc281dcfbb81394ceea9_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;810&#39; height=&#39;195&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="810" data-rawheight="195" class="origin_image zh-lightbox-thumb lazy" width="810" data-original="https://pic2.zhimg.com/v2-b64ec1ab8feefc281dcfbb81394ceea9_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-b64ec1ab8feefc281dcfbb81394ceea9_b.jpg"/></figure><p>  其中<img src="https://www.zhihu.com/equation?tex=Q_%7B%5Ctheta%7D" alt="Q_{\theta}" eeimg="1"/>表示的是<code>soft q function</code>，<img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BD%7D_%7Bdemo%7D" alt="\mathcal{D}_{demo}" eeimg="1"/>是<code>demonstrations</code>，<img src="https://www.zhihu.com/equation?tex=%5Cdelta%5E%7B2%7D" alt="\delta^{2}" eeimg="1"/>表示的是<code>soft bellman error</code>。<code>Equation 1</code>表示为：</p><p><img src="https://www.zhihu.com/equation?tex=%5Cdelta%5E%7B2%7D%28%5Cmathcal%7BD%7D%2C+r%29+%5Ctriangleq+%5Cfrac%7B1%7D%7B%7C%5Cmathcal%7BD%7D%7C%7D+%5Csum_%7B%5Cleft%28s%2C+a%2C+s%5E%7B%5Cprime%7D%5Cright%29+%5Cin+%5Cmathcal%7BD%7D%7D%5Cleft%28Q_%7B%5Cboldsymbol%7B%5Ctheta%7D%7D%28s%2C+a%29-%5Cleft%28r%2B%5Cgamma+%5Clog+%5Cleft%28%5Csum_%7Ba%5E%7B%5Cprime%7D+%5Cin+%5Cmathcal%7BA%7D%7D+%5Cexp+%5Cleft%28Q_%7B%5Cboldsymbol%7B%5Ctheta%7D%7D%5Cleft%28s%5E%7B%5Cprime%7D%2C+a%5E%7B%5Cprime%7D%5Cright%29%5Cright%29%5Cright%29%5Cright%29%5Cright%29%5E%7B2%7D+%5C%5C" alt="\delta^{2}(\mathcal{D}, r) \triangleq \frac{1}{|\mathcal{D}|} \sum_{\left(s, a, s^{\prime}\right) \in \mathcal{D}}\left(Q_{\boldsymbol{\theta}}(s, a)-\left(r+\gamma \log \left(\sum_{a^{\prime} \in \mathcal{A}} \exp \left(Q_{\boldsymbol{\theta}}\left(s^{\prime}, a^{\prime}\right)\right)\right)\right)\right)^{2} \\" eeimg="1"/></p><p>  其中奖励<img src="https://www.zhihu.com/equation?tex=r" alt="r" eeimg="1"/>只有<code>0</code>，<code>1</code>两个取值。上述公式的理解就是希望<code>demonstrated action</code>能够获得比较高的<img src="https://www.zhihu.com/equation?tex=Q" alt="Q" eeimg="1"/>值，而周围的<code>nearby state</code>的<code>action</code>分布就不期望那么突出，期望均匀一点，这里就跟熵联系起来了。</p><h2><b>取得的效果？</b></h2><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-414a4b1e2a1062aeafc5168a4c24bcb2_b.jpg" data-caption="" data-size="normal" data-rawwidth="502" data-rawheight="231" class="origin_image zh-lightbox-thumb" width="502" data-original="https://pic3.zhimg.com/v2-414a4b1e2a1062aeafc5168a4c24bcb2_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;502&#39; height=&#39;231&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="502" data-rawheight="231" class="origin_image zh-lightbox-thumb lazy" width="502" data-original="https://pic3.zhimg.com/v2-414a4b1e2a1062aeafc5168a4c24bcb2_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-414a4b1e2a1062aeafc5168a4c24bcb2_b.jpg"/></figure><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-390b4b99780b565dde1d47b5191d74fe_b.jpg" data-caption="" data-size="normal" data-rawwidth="841" data-rawheight="288" class="origin_image zh-lightbox-thumb" width="841" data-original="https://pic3.zhimg.com/v2-390b4b99780b565dde1d47b5191d74fe_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;841&#39; height=&#39;288&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="841" data-rawheight="288" class="origin_image zh-lightbox-thumb lazy" width="841" data-original="https://pic3.zhimg.com/v2-390b4b99780b565dde1d47b5191d74fe_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-390b4b99780b565dde1d47b5191d74fe_b.jpg"/></figure><h2><b>所出版信息？作者信息？</b></h2><p>  作者是来自加利福尼亚伯克利大学的博士生<code>Siddharth Reddy</code>。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-21e832e9a957279f2f5681d943b2a370_b.jpg" data-caption="" data-size="normal" data-rawwidth="128" data-rawheight="128" class="content_image" width="128"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;128&#39; height=&#39;128&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="128" data-rawheight="128" class="content_image lazy" width="128" data-actualsrc="https://pic1.zhimg.com/v2-21e832e9a957279f2f5681d943b2a370_b.jpg"/></figure><h2><b>参考链接</b></h2><ul><li><b>export-demonstration</b>：<a href="https://link.zhihu.com/?target=https%3A//drive.google.com/drive/folders/1h3H4AY_ZBx08hz-Ct0Nxxus-V1melu1U" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">drive.google.com/drive/</span><span class="invisible">folders/1h3H4AY_ZBx08hz-Ct0Nxxus-V1melu1U</span><span class="ellipsis"></span></a></li></ul><h2><b>扩展阅读</b></h2><ul><li><b>Maximum entropy model of expert behavior</b>：</li></ul><p><code>Maximum entropy model of expert behavior</code>：<code>SQIL</code>是基于最大熵<code>expert behavior</code>所得出来的算法。策略<img src="https://www.zhihu.com/equation?tex=%5Cpi" alt="\pi" eeimg="1"/>服从<code>Boltzmann distribution</code>：</p><p><img src="https://www.zhihu.com/equation?tex=%5Cpi%28a+%7C+s%29+%5Ctriangleq+%5Cfrac%7B%5Cexp+%28Q%28s%2C+a%29%29%7D%7B%5Csum_%7Ba%5E%7B%5Cprime%7D+%5Cin+%5Cmathcal%7BA%7D%7D+%5Cexp+%5Cleft%28Q%5Cleft%28s%2C+a%5E%7B%5Cprime%7D%5Cright%29%5Cright%29%7D+%5C%5C" alt="\pi(a | s) \triangleq \frac{\exp (Q(s, a))}{\sum_{a^{\prime} \in \mathcal{A}} \exp \left(Q\left(s, a^{\prime}\right)\right)} \\" eeimg="1"/></p><p><code>Soft Q values</code>可通过<code>soft Bellman equation</code>得到：</p><p><img src="https://www.zhihu.com/equation?tex=Q%28s%2C+a%29+%5Ctriangleq+R%28s%2C+a%29%2B%5Cgamma+%5Cmathbb%7BE%7D_%7Bs%5E%7B%5Cprime%7D%7D%5Cleft%5B%5Clog+%5Cleft%28%5Csum_%7Ba%5E%7B%5Cprime%7D+%5Cin+%5Cmathcal%7BA%7D%7D+%5Cexp+%5Cleft%28Q%5Cleft%28s%5E%7B%5Cprime%7D%2C+a%5E%7B%5Cprime%7D%5Cright%29%5Cright%29%5Cright%29%5Cright%5D+%5C%5C" alt="Q(s, a) \triangleq R(s, a)+\gamma \mathbb{E}_{s^{\prime}}\left[\log \left(\sum_{a^{\prime} \in \mathcal{A}} \exp \left(Q\left(s^{\prime}, a^{\prime}\right)\right)\right)\right] \\" eeimg="1"/></p><p>  在我们的模仿学习设置中，<code>rewards</code>和<code>dynamic</code>是未知的，专家<code>demonstration</code><img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BD%7D_%7Bdemo%7D" alt="\mathcal{D}_{demo}" eeimg="1"/>是一个固定的集合。通过在<code>environment</code>中<code>rolling out</code>策略<img src="https://www.zhihu.com/equation?tex=%5Cpi" alt="\pi" eeimg="1"/> 可以得到<code>state transitions</code> <img src="https://www.zhihu.com/equation?tex=%28s%2Ca%2Cs%5E%7B%5Cprime%7D%29+%5Cin+%5Cmathcal%7BD%7D_%7Bdemo%7D" alt="(s,a,s^{\prime}) \in \mathcal{D}_{demo}" eeimg="1"/>。</p><ul><li><b>Behavioral cloning (BC)</b>：</li></ul><p>  在<code>behavior clone</code>中是去拟合一个参数化的<code>model</code> <img src="https://www.zhihu.com/equation?tex=%5Cpi_%7B%5Ctheta%7D" alt="\pi_{\theta}" eeimg="1"/>，最小化负的<code>log-likelihood loss</code>：</p><p><img src="https://www.zhihu.com/equation?tex=%5Cell_%7B%5Cmathrm%7BBC%7D%7D%28%5Cboldsymbol%7B%5Ctheta%7D%29+%5Ctriangleq+%5Csum_%7B%28s%2C+a%29+%5Cin+%5Cmathcal%7BD%7D_%7Bd+m+o%7D%7D-%5Clog+%5Cpi_%7B%5Cboldsymbol%7B%5Ctheta%7D%7D%28a+%7C+s%29+%5C%5C" alt="\ell_{\mathrm{BC}}(\boldsymbol{\theta}) \triangleq \sum_{(s, a) \in \mathcal{D}_{d m o}}-\log \pi_{\boldsymbol{\theta}}(a | s) \\" eeimg="1"/></p><p>  本文中作者采用的是<code>soft q function</code>，所以最大化的<code>likelihood</code>目标方程如下所示：</p><p><img src="https://www.zhihu.com/equation?tex=%5Cell_%7B%5Cmathrm%7BBC%7D%7D%28%5Cboldsymbol%7B%5Ctheta%7D%29+%5Ctriangleq+%5Csum_%7B%28s%2C+a%29+%5Cin+%5Cmathcal%7BD%7D_%7B%5Ctext+%7Bdemo+%7D%7D%7D-%5Cleft%28Q_%7B%5Cboldsymbol%7B%5Ctheta%7D%7D%28s%2C+a%29-%5Clog+%5Cleft%28%5Csum_%7Ba%5E%7B%5Cprime%7D+%5Cin+%5Cmathcal%7BA%7D%7D+%5Cexp+%5Cleft%28Q_%7B%5Cboldsymbol%7B%5Ctheta%7D%7D%5Cleft%28s%2C+a%5E%7B%5Cprime%7D%5Cright%29%5Cright%29%5Cright%29%5Cright%29+%5C%5C" alt="\ell_{\mathrm{BC}}(\boldsymbol{\theta}) \triangleq \sum_{(s, a) \in \mathcal{D}_{\text {demo }}}-\left(Q_{\boldsymbol{\theta}}(s, a)-\log \left(\sum_{a^{\prime} \in \mathcal{A}} \exp \left(Q_{\boldsymbol{\theta}}\left(s, a^{\prime}\right)\right)\right)\right) \\" eeimg="1"/></p><p>  从这里可以看出作者的目标函数中相比较于行为克隆算法好处在于：后面那一项基于能量的式子是考虑了<code>state transitions</code>。</p><ul><li><b>Regularized Behavior Clone</b></li></ul><p><code>SQIL</code>可以看作是 a sparsity(稀疏) prior on the implicitly-represented rewards的行为克隆算法。</p><p><b>Sparsity regularization</b>：当<code>agent</code>遇见了一个未见过的<code>state</code>的时候，<img src="https://www.zhihu.com/equation?tex=Q_%7B%5Ctheta%7D" alt="Q_{\theta}" eeimg="1"/>也许会输出任意值。(Piot et al., 2014) 等人有通过引入a sparsity prior on the implied rewards 的正则化项。</p><ul><li>Bilal Piot, Matthieu Geist, and Olivier Pietquin. <b>Boosted and reward-regularized classiﬁcation for apprenticeship learning</b>. In Proceedings of the 2014 international conference on Autonomous agents and multi-agent systems, pp. 1249–1256. International Foundation for Autonomous Agents and Multiagent Systems, 2014.</li></ul><p>  作者与上述这篇文章的不同点在于有将其应用于连续的状态空间，还有加了<code>latest imitation policy</code>进行<code>rollouts</code>采样。</p><p>  基于上文的<code>soft Bellman equation</code></p><p><img src="https://www.zhihu.com/equation?tex=Q%28s%2C+a%29+%5Ctriangleq+R%28s%2C+a%29%2B%5Cgamma+%5Cmathbb%7BE%7D_%7Bs%5E%7B%5Cprime%7D%7D%5Cleft%5B%5Clog+%5Cleft%28%5Csum_%7Ba%5E%7B%5Cprime%7D+%5Cin+%5Cmathcal%7BA%7D%7D+%5Cexp+%5Cleft%28Q%5Cleft%28s%5E%7B%5Cprime%7D%2C+a%5E%7B%5Cprime%7D%5Cright%29%5Cright%29%5Cright%29%5Cright%5D+%5C%5C" alt="Q(s, a) \triangleq R(s, a)+\gamma \mathbb{E}_{s^{\prime}}\left[\log \left(\sum_{a^{\prime} \in \mathcal{A}} \exp \left(Q\left(s^{\prime}, a^{\prime}\right)\right)\right)\right] \\" eeimg="1"/></p><p>  我们可以得到<code>reward</code>的表达式子：</p><p><img src="https://www.zhihu.com/equation?tex=R_%7Bq%7D%28s%2C+a%29+%5Ctriangleq+Q_%7B%5Cboldsymbol%7B%5Ctheta%7D%7D%28s%2C+a%29-%5Cgamma+%5Cmathbb%7BE%7D_%7Bs%5E%7B%5Cprime%7D%7D%5Cleft%5B%5Clog+%5Cleft%28%5Csum_%7Ba%5E%7B%5Cprime%7D+%5Cin+%5Cmathcal%7BA%7D%7D+%5Cexp+%5Cleft%28Q_%7B%5Cboldsymbol%7B%5Ctheta%7D%7D%5Cleft%28s%5E%7B%5Cprime%7D%2C+a%5E%7B%5Cprime%7D%5Cright%29%5Cright%29%5Cright%29%5Cright%5D+%5C%5C" alt="R_{q}(s, a) \triangleq Q_{\boldsymbol{\theta}}(s, a)-\gamma \mathbb{E}_{s^{\prime}}\left[\log \left(\sum_{a^{\prime} \in \mathcal{A}} \exp \left(Q_{\boldsymbol{\theta}}\left(s^{\prime}, a^{\prime}\right)\right)\right)\right] \\" eeimg="1"/></p><p>  从中也可以发现其会考虑下一个状态<img src="https://www.zhihu.com/equation?tex=s%5E%7B%5Cprime%7D" alt="s^{\prime}" eeimg="1"/>，而不像<code>BC</code>那样只<code>maximization action likelihood</code>。最终的<code>Regularized BC</code>算法可表示为：</p><p><img src="https://www.zhihu.com/equation?tex=%5Cell_%7B%5Cmathrm%7BRBC%7D%7D%28%5Cboldsymbol%7B%5Ctheta%7D%29+%5Ctriangleq+%5Cell_%7B%5Cmathrm%7BBC%7D%7D%28%5Cboldsymbol%7B%5Ctheta%7D%29%2B%5Clambda+%5Cdelta%5E%7B2%7D%5Cleft%28%5Cmathcal%7BD%7D_%7B%5Ctext+%7Bdemo+%7D%7D+%5Ccup+%5Cmathcal%7BD%7D_%7B%5Cmathrm%7Bsamp%7D%7D%2C+0%5Cright%29+%5C%5C" alt="\ell_{\mathrm{RBC}}(\boldsymbol{\theta}) \triangleq \ell_{\mathrm{BC}}(\boldsymbol{\theta})+\lambda \delta^{2}\left(\mathcal{D}_{\text {demo }} \cup \mathcal{D}_{\mathrm{samp}}, 0\right) \\" eeimg="1"/></p><p>  其中<img src="https://www.zhihu.com/equation?tex=%5Clambda" alt="\lambda" eeimg="1"/>是超参数，<img src="https://www.zhihu.com/equation?tex=%5Cdelta%5E%7B2%7D" alt="\delta^{2}" eeimg="1"/>是<code>soft bellman error</code>的平方。可以看出<code>RBC</code>算法与<code>SQIL</code>有异曲同工之妙。</p><ul><li><b>Connection Between SQIL and Regularized Behavioral Clone</b></li></ul><p><img src="https://www.zhihu.com/equation?tex=%5Cnabla_%7B%5Cboldsymbol%7B%5Ctheta%7D%7D+%5Cell_%7B%5Cmathrm%7BRBC%7D%7D%28%5Cboldsymbol%7B%5Ctheta%7D%29+%5Cpropto+%5Cnabla_%7B%5Cboldsymbol%7B%5Ctheta%7D%7D%5Cleft%28%5Cdelta%5E%7B2%7D%5Cleft%28%5Cmathcal%7BD%7D_%7B%5Ctext+%7Bdemo+%7D%7D%2C+1%5Cright%29%2B%5Clambda_%7B%5Ctext+%7Bsamp+%7D%7D+%5Cdelta%5E%7B2%7D%5Cleft%28%5Cmathcal%7BD%7D_%7B%5Ctext+%7Bsamp+%7D%7D%2C+0%5Cright%29%2BV%5Cleft%28s_%7B0%7D%5Cright%29%5Cright%29+%5C%5C" alt="\nabla_{\boldsymbol{\theta}} \ell_{\mathrm{RBC}}(\boldsymbol{\theta}) \propto \nabla_{\boldsymbol{\theta}}\left(\delta^{2}\left(\mathcal{D}_{\text {demo }}, 1\right)+\lambda_{\text {samp }} \delta^{2}\left(\mathcal{D}_{\text {samp }}, 0\right)+V\left(s_{0}\right)\right) \\" eeimg="1"/></p><p><code>SQIL</code>相比与<code>RBC</code>算法引入了<code>+1</code>和<code>0</code>的<code>reward</code>，相当于是<b>加强了奖励稀疏的先验知识</b>。</p></div></div><div class="ContentItem-time">发布于 2020-03-14</div><div class="Post-topicsAndReviewer"><div class="TopicList Post-Topics"><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/20039099" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习 (Reinforcement Learning)</div></div></a></span></div><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/19559450" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">机器学习</div></div></a></span></div><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/19813032" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">深度学习（Deep Learning）</div></div></a></span></div></div></div><div><div class="Sticky RichContent-actions is-bottom"><div class="ContentItem-actions"><span><button aria-label="赞同 20 " type="button" class="Button VoteButton VoteButton--up"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleUp VoteButton-TriangleUp" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M2 18.242c0-.326.088-.532.237-.896l7.98-13.203C10.572 3.57 11.086 3 12 3c.915 0 1.429.571 1.784 1.143l7.98 13.203c.15.364.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H3.955c-1.08 0-1.955-.517-1.955-1.9z" fill-rule="evenodd"></path></svg></span>赞同 20</button><button aria-label="反对" type="button" class="Button VoteButton VoteButton--down"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleDown" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M20.044 3H3.956C2.876 3 2 3.517 2 4.9c0 .326.087.533.236.896L10.216 19c.355.571.87 1.143 1.784 1.143s1.429-.572 1.784-1.143l7.98-13.204c.149-.363.236-.57.236-.896 0-1.386-.876-1.9-1.956-1.9z" fill-rule="evenodd"></path></svg></span></button></span><button type="button" class="Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Comment Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M10.241 19.313a.97.97 0 0 0-.77.2 7.908 7.908 0 0 1-3.772 1.482.409.409 0 0 1-.38-.637 5.825 5.825 0 0 0 1.11-2.237.605.605 0 0 0-.227-.59A7.935 7.935 0 0 1 3 11.25C3 6.7 7.03 3 12 3s9 3.7 9 8.25-4.373 9.108-10.759 8.063z" fill-rule="evenodd"></path></svg></span>1 条评论</button><div class="Popover ShareMenu"><div class="ShareMenu-toggler" id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Share Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2.931 7.89c-1.067.24-1.275 1.669-.318 2.207l5.277 2.908 8.168-4.776c.25-.127.477.198.273.39L9.05 14.66l.927 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.242c.584-.892-.212-2.029-1.234-1.796L2.93 7.89z" fill-rule="evenodd"></path></svg></span>分享</button></div></div><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Heart Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2 8.437C2 5.505 4.294 3.094 7.207 3 9.243 3 11.092 4.19 12 6c.823-1.758 2.649-3 4.651-3C19.545 3 22 5.507 22 8.432 22 16.24 13.842 21 12 21 10.158 21 2 16.24 2 8.437z" fill-rule="evenodd"></path></svg></span>喜欢</button><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Star Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5.515 19.64l.918-5.355-3.89-3.792c-.926-.902-.639-1.784.64-1.97L8.56 7.74l2.404-4.871c.572-1.16 1.5-1.16 2.072 0L15.44 7.74l5.377.782c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.219 1.274-.532 1.82-1.676 1.218L12 18.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z" fill-rule="evenodd"></path></svg></span>收藏</button><div class="Post-ActionMenuButton"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Dots Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5 14a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4z" fill-rule="evenodd"></path></svg></span></button></div></div></div></div></div></div></article><div class="Post-Sub Post-NormalSub"><div class="PostIndex-Contributions"><h3 class="BlockTitle">文章被以下专栏收录</h3><ul><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="/reinforcement"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><img class="Avatar Avatar--medium Avatar--round" width="40" height="40" src="https://pic2.zhimg.com/v2-b993d155c18470e92ba3c391023c6561_xs.jpg" srcSet="https://pic2.zhimg.com/v2-b993d155c18470e92ba3c391023c6561_l.jpg 2x" alt="强化学习"/></div></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><a class="ColumnLink ColumnItem-Title" href="/reinforcement"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习</div></div></a></h2><div class="ContentItem-meta">人工智能；深度强化学习；多智能体；</div></div><div class="ContentItem-extra"><a href="/reinforcement" type="button" class="Button">进入专栏</a></div></div></div><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><img class="Avatar Avatar--medium Avatar--round" width="40" height="40" src="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_xs.jpg" srcSet="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_l.jpg 2x" alt="强化学习前沿"/></div></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><a class="ColumnLink ColumnItem-Title" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习前沿</div></div></a></h2><div class="ContentItem-meta">读呀读paper</div></div><div class="ContentItem-extra"><a href="/reinforcementlearning" type="button" class="Button">进入专栏</a></div></div></div></ul></div></div></div></main></div></div><script nonce="6ad2af10-fa4b-4c3e-b034-f7ddc4e013ca" async="" src="https://www.googletagmanager.com/gtag/js?id=UA-149949619-1"></script><script nonce="6ad2af10-fa4b-4c3e-b034-f7ddc4e013ca">function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-149949619-1");</script><script id="js-clientConfig" type="text/json">{"host":"zhihu.com","protocol":"https:","wwwHost":"www.zhihu.com","fetchRoot":{"www":"https:\u002F\u002Fwww.zhihu.com","api":"https:\u002F\u002Fapi.zhihu.com","zhuanlan":"https:\u002F\u002Fzhuanlan.zhihu.com"}}</script><script id="js-initialData" type="text/json">{"initialState":{"common":{"ask":{}},"loading":{"global":{"count":0},"local":{"env\u002FgetIpinfo\u002F":false,"article\u002Fget\u002F":false,"brand\u002FgetUrl\u002F":false}},"club":{"tags":{}},"entities":{"users":{"he-zhi-qiang-52-74":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-e7f3a66aff8bc0fda395148d2ca35b55_{size}.jpg","uid":"707172804071538688","userType":"people","isFollowing":false,"urlToken":"he-zhi-qiang-52-74","id":"a2034395b75bf8d0ddc35345035cf54d","description":"个人公众号：深度学习与先进智能决策\n公众号ID：MultiAgent1024\n公众号介绍：主要研究深度学习，强化学习、机器博弈等相关内容！","name":"小小何先生","isAdvertiser":false,"headline":"以爱与青春为名，陪你一路成长。","gender":1,"url":"\u002Fpeople\u002Fa2034395b75bf8d0ddc35345035cf54d","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-e7f3a66aff8bc0fda395148d2ca35b55_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"东北大学 信息科学与工程学院硕士在读"}],"exposedMedal":{"medalId":"1124316222665379841","medalName":"我的知乎 2019","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2592b0b52e1fac99f69b38e00252413b_r.png","miniAvatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ad363cc3088dc8de7544fd08b1c4987a_is.png","description":"参与「我的知乎 2019」即可获得"}}},"questions":{},"answers":{},"articles":{"113124696":{"id":113124696,"title":"【ICLR2020】通过强化学习和稀疏奖励进行模仿学习","type":"article","excerptTitle":"","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F113124696","imageUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-589f12d2003902a555e8c5dac043beee_b.jpg","titleImage":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-589f12d2003902a555e8c5dac043beee_b.jpg","excerpt":"\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-b46308925da1328a16246847f80d61e7_200x112.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"818\" data-rawheight=\"220\" data-watermark=\"watermark\" data-original-src=\"v2-b46308925da1328a16246847f80d61e7\" data-watermark-src=\"v2-704131a78697f2459fb8b2568dff0fcc\" data-private-watermark-src=\"\" class=\"origin_image inline-img zh-lightbox-thumb\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-b46308925da1328a16246847f80d61e7_r.png\"\u002F\u003E\u003Cb\u003E论文题目\u003C\u002Fb\u003E：\u003Cb\u003ESQIL\u003C\u002Fb\u003E: Imitation Learning via Reinforcement Learning with Sparse Rewards\u003Cb\u003E所解决的问题？\u003C\u002Fb\u003E 从高维的状态动作空间中进行模仿学习是比较困难的，以往的行为克隆算法(behavioral cloning BC)算法容易产生分布漂移(distribution shift)，而最近做得…","created":1584158330,"updated":1584158330,"author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-e7f3a66aff8bc0fda395148d2ca35b55_{size}.jpg","uid":"707172804071538688","userType":"people","isFollowing":false,"urlToken":"he-zhi-qiang-52-74","id":"a2034395b75bf8d0ddc35345035cf54d","description":"个人公众号：深度学习与先进智能决策\n公众号ID：MultiAgent1024\n公众号介绍：主要研究深度学习，强化学习、机器博弈等相关内容！","name":"小小何先生","isAdvertiser":false,"headline":"以爱与青春为名，陪你一路成长。","gender":1,"url":"\u002Fpeople\u002Fa2034395b75bf8d0ddc35345035cf54d","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-e7f3a66aff8bc0fda395148d2ca35b55_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"东北大学 信息科学与工程学院硕士在读"}],"exposedMedal":{"medalId":"1124316222665379841","medalName":"我的知乎 2019","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2592b0b52e1fac99f69b38e00252413b_r.png","miniAvatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ad363cc3088dc8de7544fd08b1c4987a_is.png","description":"参与「我的知乎 2019」即可获得"}},"commentPermission":"all","state":"published","imageWidth":900,"imageHeight":383,"content":"\u003Cul\u003E\u003Cli\u003E\u003Cb\u003E论文题目\u003C\u002Fb\u003E：\u003Cb\u003ESQIL\u003C\u002Fb\u003E: Imitation Learning via Reinforcement Learning with Sparse Rewards\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-704131a78697f2459fb8b2568dff0fcc_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"818\" data-rawheight=\"220\" class=\"origin_image zh-lightbox-thumb\" width=\"818\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-704131a78697f2459fb8b2568dff0fcc_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;818&#39; height=&#39;220&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"818\" data-rawheight=\"220\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"818\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-704131a78697f2459fb8b2568dff0fcc_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-704131a78697f2459fb8b2568dff0fcc_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Ch2\u003E\u003Cb\u003E所解决的问题？\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E  从高维的状态动作空间中进行模仿学习是比较困难的，以往的行为克隆算法(\u003Ccode\u003Ebehavioral cloning BC\u003C\u002Fcode\u003E)算法容易产生分布漂移(\u003Ccode\u003Edistribution shift\u003C\u002Fcode\u003E)，而最近做得比较好的就是生成对抗模仿学习算法(generative adversarial imitation learning (\u003Ccode\u003EGAIL\u003C\u002Fcode\u003E))，是逆强化(\u003Ccode\u003EInverse RL\u003C\u002Fcode\u003E)学习算法与生成对抗网络结合的一种模仿学习算法，这个算法使用\u003Ccode\u003Eadversarial training\u003C\u002Fcode\u003E技术学\u003Ccode\u003Ereward function\u003C\u002Fcode\u003E，而作者提出的算法不需要\u003Ccode\u003Ereward function\u003C\u002Fcode\u003E。整篇文章是在证明\u003Ccode\u003Econstant reward\u003C\u002Fcode\u003E的\u003Ccode\u003ERL\u003C\u002Fcode\u003E方法与复杂的学习\u003Ccode\u003Ereward function\u003C\u002Fcode\u003E的强化学习算法一样有效。\u003C\u002Fp\u003E\u003Cp\u003E  文章的主要贡献在于提出了一种简单易于实现版本的模仿学习算法，用于高维、连续、动态环境中。能够很好克服模仿学习中的\u003Ccode\u003Edistribution shift\u003C\u002Fcode\u003E问题。\u003C\u002Fp\u003E\u003Ch2\u003E\u003Cb\u003E背景\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E  模仿学习的问题在于\u003Ccode\u003Ebehavior shift\u003C\u002Fcode\u003E，并且误差会累计，因为智能体并不知道如何回到\u003Ccode\u003Eexpert\u003C\u002Fcode\u003E的轨迹状态上来。最近做地比较好的就是\u003Ccode\u003EGAIL\u003C\u002Fcode\u003E，\u003Ccode\u003EGAIL\u003C\u002Fcode\u003E做模仿学习最大的好处就是 \u003Ccode\u003Eencourage long-horizon imitation\u003C\u002Fcode\u003E。那为什么\u003Ccode\u003EGAIL\u003C\u002Fcode\u003E能够做到\u003Ccode\u003Elong-horizon imitation\u003C\u002Fcode\u003E呢？模型学习一般分为两步，在某个\u003Ccode\u003Estate\u003C\u002Fcode\u003E下采取某个\u003Ccode\u003Eaction\u003C\u002Fcode\u003E，一般的\u003Ccode\u003EBC\u003C\u002Fcode\u003E算法都这么做的，而\u003Ccode\u003EGAIL\u003C\u002Fcode\u003E除此之外还考虑了采取这个\u003Ccode\u003Eaction\u003C\u002Fcode\u003E之后还回到\u003Ccode\u003Eexpert\u003C\u002Fcode\u003E 轨迹的下一个状态上。而作者也采纳了\u003Ccode\u003EGAIL\u003C\u002Fcode\u003E的上述两点优势，但是并未使用\u003Ccode\u003EGAIL\u003C\u002Fcode\u003E算法中的\u003Ccode\u003Eadversarial training\u003C\u002Fcode\u003E技术，而是使用一个\u003Ccode\u003Econstant reward\u003C\u002Fcode\u003E。如果matching the demonstrated action in a demonstrated state，reward = +1；对于其他的情况 reward =0。整个问题就变成了一个奖励稀疏的强化学习问题。\u003C\u002Fp\u003E\u003Ch2\u003E\u003Cb\u003E所采用的方法？\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E  作者引入\u003Ccode\u003Esoft-q-learning\u003C\u002Fcode\u003E算法，将\u003Ccode\u003Eexpert demonstrations\u003C\u002Fcode\u003E的奖励设置为1，而与环境互动得到的新的\u003Ccode\u003Eexperiences\u003C\u002Fcode\u003E奖励设置为0。由于\u003Ccode\u003Esoft Q-Learning\u003C\u002Fcode\u003E算法是\u003Ccode\u003Eoff-policy\u003C\u002Fcode\u003E的算法，因此有\u003Ccode\u003Edata\u003C\u002Fcode\u003E就可以训练了。整个算法作者命名为 soft Q imitation learning (\u003Ccode\u003ESQIL\u003C\u002Fcode\u003E)。\u003C\u002Fp\u003E\u003Ch3\u003E\u003Cb\u003ESoft Q Imitation Learning算法\u003C\u002Fb\u003E\u003C\u002Fh3\u003E\u003Cp\u003E\u003Ccode\u003ESQIL\u003C\u002Fcode\u003E在\u003Ccode\u003Esoft q learning\u003C\u002Fcode\u003E算法上面做了三个小的修正：\u003C\u002Fp\u003E\u003Col\u003E\u003Cli\u003E用\u003Ccode\u003Eexpert demonstration\u003C\u002Fcode\u003E初始化填入\u003Ccode\u003Eagent\u003C\u002Fcode\u003E的\u003Ccode\u003Eexperience replay buffer\u003C\u002Fcode\u003E，其\u003Ccode\u003Ereward\u003C\u002Fcode\u003E设置为\u003Ccode\u003E+1\u003C\u002Fcode\u003E；\u003C\u002Fli\u003E\u003Cli\u003E\u003Ccode\u003Eagent\u003C\u002Fcode\u003E与环境互动得到新的\u003Ccode\u003Edata\u003C\u002Fcode\u003E也加入到\u003Ccode\u003Eexperience replay buffer\u003C\u002Fcode\u003E里面，其\u003Ccode\u003Ereward\u003C\u002Fcode\u003E设置为\u003Ccode\u003E0\u003C\u002Fcode\u003E；\u003C\u002Fli\u003E\u003Cli\u003E平衡\u003Ccode\u003Edemonstration experiences\u003C\u002Fcode\u003E和\u003Ccode\u003Enew experiences\u003C\u002Fcode\u003E各\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=50%5C%25\" alt=\"50\\%\" eeimg=\"1\"\u002F\u003E。这个方法在\u003Ccode\u003EGAIL\u003C\u002Fcode\u003E和\u003Ccode\u003Eadversarial IRL\u003C\u002Fcode\u003E 算法上面也都有应用。\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Cp\u003E\u003Ccode\u003ESQIL\u003C\u002Fcode\u003E算法如下所示：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-b64ec1ab8feefc281dcfbb81394ceea9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"810\" data-rawheight=\"195\" class=\"origin_image zh-lightbox-thumb\" width=\"810\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-b64ec1ab8feefc281dcfbb81394ceea9_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;810&#39; height=&#39;195&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"810\" data-rawheight=\"195\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"810\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-b64ec1ab8feefc281dcfbb81394ceea9_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-b64ec1ab8feefc281dcfbb81394ceea9_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E  其中\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=Q_%7B%5Ctheta%7D\" alt=\"Q_{\\theta}\" eeimg=\"1\"\u002F\u003E表示的是\u003Ccode\u003Esoft q function\u003C\u002Fcode\u003E，\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathcal%7BD%7D_%7Bdemo%7D\" alt=\"\\mathcal{D}_{demo}\" eeimg=\"1\"\u002F\u003E是\u003Ccode\u003Edemonstrations\u003C\u002Fcode\u003E，\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta%5E%7B2%7D\" alt=\"\\delta^{2}\" eeimg=\"1\"\u002F\u003E表示的是\u003Ccode\u003Esoft bellman error\u003C\u002Fcode\u003E。\u003Ccode\u003EEquation 1\u003C\u002Fcode\u003E表示为：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta%5E%7B2%7D%28%5Cmathcal%7BD%7D%2C+r%29+%5Ctriangleq+%5Cfrac%7B1%7D%7B%7C%5Cmathcal%7BD%7D%7C%7D+%5Csum_%7B%5Cleft%28s%2C+a%2C+s%5E%7B%5Cprime%7D%5Cright%29+%5Cin+%5Cmathcal%7BD%7D%7D%5Cleft%28Q_%7B%5Cboldsymbol%7B%5Ctheta%7D%7D%28s%2C+a%29-%5Cleft%28r%2B%5Cgamma+%5Clog+%5Cleft%28%5Csum_%7Ba%5E%7B%5Cprime%7D+%5Cin+%5Cmathcal%7BA%7D%7D+%5Cexp+%5Cleft%28Q_%7B%5Cboldsymbol%7B%5Ctheta%7D%7D%5Cleft%28s%5E%7B%5Cprime%7D%2C+a%5E%7B%5Cprime%7D%5Cright%29%5Cright%29%5Cright%29%5Cright%29%5Cright%29%5E%7B2%7D+%5C%5C\" alt=\"\\delta^{2}(\\mathcal{D}, r) \\triangleq \\frac{1}{|\\mathcal{D}|} \\sum_{\\left(s, a, s^{\\prime}\\right) \\in \\mathcal{D}}\\left(Q_{\\boldsymbol{\\theta}}(s, a)-\\left(r+\\gamma \\log \\left(\\sum_{a^{\\prime} \\in \\mathcal{A}} \\exp \\left(Q_{\\boldsymbol{\\theta}}\\left(s^{\\prime}, a^{\\prime}\\right)\\right)\\right)\\right)\\right)^{2} \\\\\" eeimg=\"1\"\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E  其中奖励\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=r\" alt=\"r\" eeimg=\"1\"\u002F\u003E只有\u003Ccode\u003E0\u003C\u002Fcode\u003E，\u003Ccode\u003E1\u003C\u002Fcode\u003E两个取值。上述公式的理解就是希望\u003Ccode\u003Edemonstrated action\u003C\u002Fcode\u003E能够获得比较高的\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=Q\" alt=\"Q\" eeimg=\"1\"\u002F\u003E值，而周围的\u003Ccode\u003Enearby state\u003C\u002Fcode\u003E的\u003Ccode\u003Eaction\u003C\u002Fcode\u003E分布就不期望那么突出，期望均匀一点，这里就跟熵联系起来了。\u003C\u002Fp\u003E\u003Ch2\u003E\u003Cb\u003E取得的效果？\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-414a4b1e2a1062aeafc5168a4c24bcb2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"502\" data-rawheight=\"231\" class=\"origin_image zh-lightbox-thumb\" width=\"502\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-414a4b1e2a1062aeafc5168a4c24bcb2_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;502&#39; height=&#39;231&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"502\" data-rawheight=\"231\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"502\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-414a4b1e2a1062aeafc5168a4c24bcb2_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-414a4b1e2a1062aeafc5168a4c24bcb2_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-390b4b99780b565dde1d47b5191d74fe_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"841\" data-rawheight=\"288\" class=\"origin_image zh-lightbox-thumb\" width=\"841\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-390b4b99780b565dde1d47b5191d74fe_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;841&#39; height=&#39;288&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"841\" data-rawheight=\"288\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"841\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-390b4b99780b565dde1d47b5191d74fe_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-390b4b99780b565dde1d47b5191d74fe_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Ch2\u003E\u003Cb\u003E所出版信息？作者信息？\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E  作者是来自加利福尼亚伯克利大学的博士生\u003Ccode\u003ESiddharth Reddy\u003C\u002Fcode\u003E。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-21e832e9a957279f2f5681d943b2a370_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"128\" data-rawheight=\"128\" class=\"content_image\" width=\"128\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;128&#39; height=&#39;128&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"128\" data-rawheight=\"128\" class=\"content_image lazy\" width=\"128\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-21e832e9a957279f2f5681d943b2a370_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Ch2\u003E\u003Cb\u003E参考链接\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cul\u003E\u003Cli\u003E\u003Cb\u003Eexport-demonstration\u003C\u002Fb\u003E：\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fdrive.google.com\u002Fdrive\u002Ffolders\u002F1h3H4AY_ZBx08hz-Ct0Nxxus-V1melu1U\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E\u003Cspan class=\"invisible\"\u003Ehttps:\u002F\u002F\u003C\u002Fspan\u003E\u003Cspan class=\"visible\"\u003Edrive.google.com\u002Fdrive\u002F\u003C\u002Fspan\u003E\u003Cspan class=\"invisible\"\u003Efolders\u002F1h3H4AY_ZBx08hz-Ct0Nxxus-V1melu1U\u003C\u002Fspan\u003E\u003Cspan class=\"ellipsis\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Ch2\u003E\u003Cb\u003E扩展阅读\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cul\u003E\u003Cli\u003E\u003Cb\u003EMaximum entropy model of expert behavior\u003C\u002Fb\u003E：\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003E\u003Ccode\u003EMaximum entropy model of expert behavior\u003C\u002Fcode\u003E：\u003Ccode\u003ESQIL\u003C\u002Fcode\u003E是基于最大熵\u003Ccode\u003Eexpert behavior\u003C\u002Fcode\u003E所得出来的算法。策略\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cpi\" alt=\"\\pi\" eeimg=\"1\"\u002F\u003E服从\u003Ccode\u003EBoltzmann distribution\u003C\u002Fcode\u003E：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cpi%28a+%7C+s%29+%5Ctriangleq+%5Cfrac%7B%5Cexp+%28Q%28s%2C+a%29%29%7D%7B%5Csum_%7Ba%5E%7B%5Cprime%7D+%5Cin+%5Cmathcal%7BA%7D%7D+%5Cexp+%5Cleft%28Q%5Cleft%28s%2C+a%5E%7B%5Cprime%7D%5Cright%29%5Cright%29%7D+%5C%5C\" alt=\"\\pi(a | s) \\triangleq \\frac{\\exp (Q(s, a))}{\\sum_{a^{\\prime} \\in \\mathcal{A}} \\exp \\left(Q\\left(s, a^{\\prime}\\right)\\right)} \\\\\" eeimg=\"1\"\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E\u003Ccode\u003ESoft Q values\u003C\u002Fcode\u003E可通过\u003Ccode\u003Esoft Bellman equation\u003C\u002Fcode\u003E得到：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=Q%28s%2C+a%29+%5Ctriangleq+R%28s%2C+a%29%2B%5Cgamma+%5Cmathbb%7BE%7D_%7Bs%5E%7B%5Cprime%7D%7D%5Cleft%5B%5Clog+%5Cleft%28%5Csum_%7Ba%5E%7B%5Cprime%7D+%5Cin+%5Cmathcal%7BA%7D%7D+%5Cexp+%5Cleft%28Q%5Cleft%28s%5E%7B%5Cprime%7D%2C+a%5E%7B%5Cprime%7D%5Cright%29%5Cright%29%5Cright%29%5Cright%5D+%5C%5C\" alt=\"Q(s, a) \\triangleq R(s, a)+\\gamma \\mathbb{E}_{s^{\\prime}}\\left[\\log \\left(\\sum_{a^{\\prime} \\in \\mathcal{A}} \\exp \\left(Q\\left(s^{\\prime}, a^{\\prime}\\right)\\right)\\right)\\right] \\\\\" eeimg=\"1\"\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E  在我们的模仿学习设置中，\u003Ccode\u003Erewards\u003C\u002Fcode\u003E和\u003Ccode\u003Edynamic\u003C\u002Fcode\u003E是未知的，专家\u003Ccode\u003Edemonstration\u003C\u002Fcode\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cmathcal%7BD%7D_%7Bdemo%7D\" alt=\"\\mathcal{D}_{demo}\" eeimg=\"1\"\u002F\u003E是一个固定的集合。通过在\u003Ccode\u003Eenvironment\u003C\u002Fcode\u003E中\u003Ccode\u003Erolling out\u003C\u002Fcode\u003E策略\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cpi\" alt=\"\\pi\" eeimg=\"1\"\u002F\u003E 可以得到\u003Ccode\u003Estate transitions\u003C\u002Fcode\u003E \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%28s%2Ca%2Cs%5E%7B%5Cprime%7D%29+%5Cin+%5Cmathcal%7BD%7D_%7Bdemo%7D\" alt=\"(s,a,s^{\\prime}) \\in \\mathcal{D}_{demo}\" eeimg=\"1\"\u002F\u003E。\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cb\u003EBehavioral cloning (BC)\u003C\u002Fb\u003E：\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003E  在\u003Ccode\u003Ebehavior clone\u003C\u002Fcode\u003E中是去拟合一个参数化的\u003Ccode\u003Emodel\u003C\u002Fcode\u003E \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cpi_%7B%5Ctheta%7D\" alt=\"\\pi_{\\theta}\" eeimg=\"1\"\u002F\u003E，最小化负的\u003Ccode\u003Elog-likelihood loss\u003C\u002Fcode\u003E：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cell_%7B%5Cmathrm%7BBC%7D%7D%28%5Cboldsymbol%7B%5Ctheta%7D%29+%5Ctriangleq+%5Csum_%7B%28s%2C+a%29+%5Cin+%5Cmathcal%7BD%7D_%7Bd+m+o%7D%7D-%5Clog+%5Cpi_%7B%5Cboldsymbol%7B%5Ctheta%7D%7D%28a+%7C+s%29+%5C%5C\" alt=\"\\ell_{\\mathrm{BC}}(\\boldsymbol{\\theta}) \\triangleq \\sum_{(s, a) \\in \\mathcal{D}_{d m o}}-\\log \\pi_{\\boldsymbol{\\theta}}(a | s) \\\\\" eeimg=\"1\"\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E  本文中作者采用的是\u003Ccode\u003Esoft q function\u003C\u002Fcode\u003E，所以最大化的\u003Ccode\u003Elikelihood\u003C\u002Fcode\u003E目标方程如下所示：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cell_%7B%5Cmathrm%7BBC%7D%7D%28%5Cboldsymbol%7B%5Ctheta%7D%29+%5Ctriangleq+%5Csum_%7B%28s%2C+a%29+%5Cin+%5Cmathcal%7BD%7D_%7B%5Ctext+%7Bdemo+%7D%7D%7D-%5Cleft%28Q_%7B%5Cboldsymbol%7B%5Ctheta%7D%7D%28s%2C+a%29-%5Clog+%5Cleft%28%5Csum_%7Ba%5E%7B%5Cprime%7D+%5Cin+%5Cmathcal%7BA%7D%7D+%5Cexp+%5Cleft%28Q_%7B%5Cboldsymbol%7B%5Ctheta%7D%7D%5Cleft%28s%2C+a%5E%7B%5Cprime%7D%5Cright%29%5Cright%29%5Cright%29%5Cright%29+%5C%5C\" alt=\"\\ell_{\\mathrm{BC}}(\\boldsymbol{\\theta}) \\triangleq \\sum_{(s, a) \\in \\mathcal{D}_{\\text {demo }}}-\\left(Q_{\\boldsymbol{\\theta}}(s, a)-\\log \\left(\\sum_{a^{\\prime} \\in \\mathcal{A}} \\exp \\left(Q_{\\boldsymbol{\\theta}}\\left(s, a^{\\prime}\\right)\\right)\\right)\\right) \\\\\" eeimg=\"1\"\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E  从这里可以看出作者的目标函数中相比较于行为克隆算法好处在于：后面那一项基于能量的式子是考虑了\u003Ccode\u003Estate transitions\u003C\u002Fcode\u003E。\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cb\u003ERegularized Behavior Clone\u003C\u002Fb\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003E\u003Ccode\u003ESQIL\u003C\u002Fcode\u003E可以看作是 a sparsity(稀疏) prior on the implicitly-represented rewards的行为克隆算法。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003ESparsity regularization\u003C\u002Fb\u003E：当\u003Ccode\u003Eagent\u003C\u002Fcode\u003E遇见了一个未见过的\u003Ccode\u003Estate\u003C\u002Fcode\u003E的时候，\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=Q_%7B%5Ctheta%7D\" alt=\"Q_{\\theta}\" eeimg=\"1\"\u002F\u003E也许会输出任意值。(Piot et al., 2014) 等人有通过引入a sparsity prior on the implied rewards 的正则化项。\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003EBilal Piot, Matthieu Geist, and Olivier Pietquin. \u003Cb\u003EBoosted and reward-regularized classiﬁcation for apprenticeship learning\u003C\u002Fb\u003E. In Proceedings of the 2014 international conference on Autonomous agents and multi-agent systems, pp. 1249–1256. International Foundation for Autonomous Agents and Multiagent Systems, 2014.\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003E  作者与上述这篇文章的不同点在于有将其应用于连续的状态空间，还有加了\u003Ccode\u003Elatest imitation policy\u003C\u002Fcode\u003E进行\u003Ccode\u003Erollouts\u003C\u002Fcode\u003E采样。\u003C\u002Fp\u003E\u003Cp\u003E  基于上文的\u003Ccode\u003Esoft Bellman equation\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=Q%28s%2C+a%29+%5Ctriangleq+R%28s%2C+a%29%2B%5Cgamma+%5Cmathbb%7BE%7D_%7Bs%5E%7B%5Cprime%7D%7D%5Cleft%5B%5Clog+%5Cleft%28%5Csum_%7Ba%5E%7B%5Cprime%7D+%5Cin+%5Cmathcal%7BA%7D%7D+%5Cexp+%5Cleft%28Q%5Cleft%28s%5E%7B%5Cprime%7D%2C+a%5E%7B%5Cprime%7D%5Cright%29%5Cright%29%5Cright%29%5Cright%5D+%5C%5C\" alt=\"Q(s, a) \\triangleq R(s, a)+\\gamma \\mathbb{E}_{s^{\\prime}}\\left[\\log \\left(\\sum_{a^{\\prime} \\in \\mathcal{A}} \\exp \\left(Q\\left(s^{\\prime}, a^{\\prime}\\right)\\right)\\right)\\right] \\\\\" eeimg=\"1\"\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E  我们可以得到\u003Ccode\u003Ereward\u003C\u002Fcode\u003E的表达式子：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=R_%7Bq%7D%28s%2C+a%29+%5Ctriangleq+Q_%7B%5Cboldsymbol%7B%5Ctheta%7D%7D%28s%2C+a%29-%5Cgamma+%5Cmathbb%7BE%7D_%7Bs%5E%7B%5Cprime%7D%7D%5Cleft%5B%5Clog+%5Cleft%28%5Csum_%7Ba%5E%7B%5Cprime%7D+%5Cin+%5Cmathcal%7BA%7D%7D+%5Cexp+%5Cleft%28Q_%7B%5Cboldsymbol%7B%5Ctheta%7D%7D%5Cleft%28s%5E%7B%5Cprime%7D%2C+a%5E%7B%5Cprime%7D%5Cright%29%5Cright%29%5Cright%29%5Cright%5D+%5C%5C\" alt=\"R_{q}(s, a) \\triangleq Q_{\\boldsymbol{\\theta}}(s, a)-\\gamma \\mathbb{E}_{s^{\\prime}}\\left[\\log \\left(\\sum_{a^{\\prime} \\in \\mathcal{A}} \\exp \\left(Q_{\\boldsymbol{\\theta}}\\left(s^{\\prime}, a^{\\prime}\\right)\\right)\\right)\\right] \\\\\" eeimg=\"1\"\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E  从中也可以发现其会考虑下一个状态\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=s%5E%7B%5Cprime%7D\" alt=\"s^{\\prime}\" eeimg=\"1\"\u002F\u003E，而不像\u003Ccode\u003EBC\u003C\u002Fcode\u003E那样只\u003Ccode\u003Emaximization action likelihood\u003C\u002Fcode\u003E。最终的\u003Ccode\u003ERegularized BC\u003C\u002Fcode\u003E算法可表示为：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cell_%7B%5Cmathrm%7BRBC%7D%7D%28%5Cboldsymbol%7B%5Ctheta%7D%29+%5Ctriangleq+%5Cell_%7B%5Cmathrm%7BBC%7D%7D%28%5Cboldsymbol%7B%5Ctheta%7D%29%2B%5Clambda+%5Cdelta%5E%7B2%7D%5Cleft%28%5Cmathcal%7BD%7D_%7B%5Ctext+%7Bdemo+%7D%7D+%5Ccup+%5Cmathcal%7BD%7D_%7B%5Cmathrm%7Bsamp%7D%7D%2C+0%5Cright%29+%5C%5C\" alt=\"\\ell_{\\mathrm{RBC}}(\\boldsymbol{\\theta}) \\triangleq \\ell_{\\mathrm{BC}}(\\boldsymbol{\\theta})+\\lambda \\delta^{2}\\left(\\mathcal{D}_{\\text {demo }} \\cup \\mathcal{D}_{\\mathrm{samp}}, 0\\right) \\\\\" eeimg=\"1\"\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E  其中\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Clambda\" alt=\"\\lambda\" eeimg=\"1\"\u002F\u003E是超参数，\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cdelta%5E%7B2%7D\" alt=\"\\delta^{2}\" eeimg=\"1\"\u002F\u003E是\u003Ccode\u003Esoft bellman error\u003C\u002Fcode\u003E的平方。可以看出\u003Ccode\u003ERBC\u003C\u002Fcode\u003E算法与\u003Ccode\u003ESQIL\u003C\u002Fcode\u003E有异曲同工之妙。\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cb\u003EConnection Between SQIL and Regularized Behavioral Clone\u003C\u002Fb\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cnabla_%7B%5Cboldsymbol%7B%5Ctheta%7D%7D+%5Cell_%7B%5Cmathrm%7BRBC%7D%7D%28%5Cboldsymbol%7B%5Ctheta%7D%29+%5Cpropto+%5Cnabla_%7B%5Cboldsymbol%7B%5Ctheta%7D%7D%5Cleft%28%5Cdelta%5E%7B2%7D%5Cleft%28%5Cmathcal%7BD%7D_%7B%5Ctext+%7Bdemo+%7D%7D%2C+1%5Cright%29%2B%5Clambda_%7B%5Ctext+%7Bsamp+%7D%7D+%5Cdelta%5E%7B2%7D%5Cleft%28%5Cmathcal%7BD%7D_%7B%5Ctext+%7Bsamp+%7D%7D%2C+0%5Cright%29%2BV%5Cleft%28s_%7B0%7D%5Cright%29%5Cright%29+%5C%5C\" alt=\"\\nabla_{\\boldsymbol{\\theta}} \\ell_{\\mathrm{RBC}}(\\boldsymbol{\\theta}) \\propto \\nabla_{\\boldsymbol{\\theta}}\\left(\\delta^{2}\\left(\\mathcal{D}_{\\text {demo }}, 1\\right)+\\lambda_{\\text {samp }} \\delta^{2}\\left(\\mathcal{D}_{\\text {samp }}, 0\\right)+V\\left(s_{0}\\right)\\right) \\\\\" eeimg=\"1\"\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E\u003Ccode\u003ESQIL\u003C\u002Fcode\u003E相比与\u003Ccode\u003ERBC\u003C\u002Fcode\u003E算法引入了\u003Ccode\u003E+1\u003C\u002Fcode\u003E和\u003Ccode\u003E0\u003C\u002Fcode\u003E的\u003Ccode\u003Ereward\u003C\u002Fcode\u003E，相当于是\u003Cb\u003E加强了奖励稀疏的先验知识\u003C\u002Fb\u003E。\u003C\u002Fp\u003E","adminClosedComment":false,"topics":[{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F20039099","type":"topic","id":"20039099","name":"强化学习 (Reinforcement Learning)"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F19559450","type":"topic","id":"19559450","name":"机器学习"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F19813032","type":"topic","id":"19813032","name":"深度学习（Deep Learning）"}],"voteupCount":20,"voting":0,"column":{"description":"人工智能；深度强化学习；多智能体；","canManage":false,"intro":"深度强化学习学术论文-人工智能","isFollowing":false,"urlToken":"reinforcement","id":"reinforcement","articlesCount":45,"acceptSubmission":true,"title":"强化学习","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcement","commentPermission":"all","created":1545285986,"updated":1563858050,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-b993d155c18470e92ba3c391023c6561_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c5c493b313d04a58551baa7c46220447_{size}.jpg","uid":"611482657599787008","userType":"people","isFollowing":false,"urlToken":"zhang-jie-35-49","id":"9a2cd061d74f8985358994453453b393","description":"~~ ^_^ ~\n为什么右边胡子少一根\nR.L.","name":"张现杰","isAdvertiser":false,"headline":"每天都要开心；Focus on 强化学习","gender":1,"url":"\u002Fpeople\u002F9a2cd061d74f8985358994453453b393","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c5c493b313d04a58551baa7c46220447_l.jpg","isOrg":false,"type":"people"},"followers":524,"type":"column"},"commentCount":1,"contributions":[{"id":23296208,"state":"accepted","type":"include","column":{"description":"人工智能；深度强化学习；多智能体；","canManage":false,"intro":"深度强化学习学术论文-人工智能","isFollowing":false,"urlToken":"reinforcement","id":"reinforcement","articlesCount":45,"acceptSubmission":true,"title":"强化学习","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcement","commentPermission":"all","created":1545285986,"updated":1563858050,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-b993d155c18470e92ba3c391023c6561_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c5c493b313d04a58551baa7c46220447_{size}.jpg","uid":"611482657599787008","userType":"people","isFollowing":false,"urlToken":"zhang-jie-35-49","id":"9a2cd061d74f8985358994453453b393","description":"~~ ^_^ ~\n为什么右边胡子少一根\nR.L.","name":"张现杰","isAdvertiser":false,"headline":"每天都要开心；Focus on 强化学习","gender":1,"url":"\u002Fpeople\u002F9a2cd061d74f8985358994453453b393","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c5c493b313d04a58551baa7c46220447_l.jpg","isOrg":false,"type":"people"},"followers":524,"type":"column"}},{"id":23296212,"state":"accepted","type":"include","column":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}}],"isTitleImageFullScreen":false,"upvotedFollowees":[],"commercialInfo":{"isCommercial":false,"plugin":{}},"suggestEdit":{"status":false,"reason":"","tip":"","url":"","title":""},"reason":"","annotationAction":[],"canTip":true,"tipjarorsCount":0,"isLabeled":false,"hasPublishingDraft":false,"isFavorited":false,"isNormal":true,"status":0,"shareText":"【ICLR2020】通过强化学习和稀疏奖励进行模仿学习 - 来自知乎专栏「强化学习」，作者: 小小何先生 https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F113124696 （想看更多？下载 @知乎 App：http:\u002F\u002Fweibo.com\u002Fp\u002F100404711598 ）","canComment":{"status":true,"reason":""},"mcnFpShow":-1,"isVisible":true,"isLiked":false,"likedCount":2,"visibleOnlyToAuthor":false,"trackUrl":["https:\u002F\u002Fsugar.zhihu.com\u002Fplutus_adreaper\u002Fpage_monitor_log?si=__SESSIONID__&ti=__ATOKEN__&at=view&pf=__OS__&ed=__MEMBERID__&idfa=__IDFA__&imei=__IMEI__&androidid=__ANDROIDID__&oaid=__OAID__&ci=__CREATIVEID__"]}},"columns":{"reinforcement":{"description":"人工智能；深度强化学习；多智能体；","canManage":false,"intro":"深度强化学习学术论文-人工智能","isFollowing":false,"urlToken":"reinforcement","id":"reinforcement","articlesCount":45,"acceptSubmission":true,"title":"强化学习","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcement","commentPermission":"all","created":1545285986,"updated":1563858050,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-b993d155c18470e92ba3c391023c6561_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c5c493b313d04a58551baa7c46220447_{size}.jpg","uid":"611482657599787008","userType":"people","isFollowing":false,"urlToken":"zhang-jie-35-49","id":"9a2cd061d74f8985358994453453b393","description":"~~ ^_^ ~\n为什么右边胡子少一根\nR.L.","name":"张现杰","isAdvertiser":false,"headline":"每天都要开心；Focus on 强化学习","gender":1,"url":"\u002Fpeople\u002F9a2cd061d74f8985358994453453b393","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c5c493b313d04a58551baa7c46220447_l.jpg","isOrg":false,"type":"people"},"followers":524,"type":"column"},"reinforcementlearning":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}},"topics":{},"roundtables":{},"favlists":{},"comments":{},"notifications":{},"ebooks":{},"activities":{},"feeds":{},"pins":{},"promotions":{},"drafts":{},"chats":{},"posts":{},"clubs":{},"clubTags":{}},"currentUser":"","account":{"lockLevel":{},"unlockTicketStatus":false,"unlockTicket":null,"challenge":[],"errorStatus":false,"message":"","isFetching":false,"accountInfo":{},"urlToken":{"loading":false}},"settings":{"socialBind":null,"inboxMsg":null,"notification":{},"email":{},"privacyFlag":null,"blockedUsers":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"blockedFollowees":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"ignoredTopics":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"restrictedTopics":null,"laboratory":{}},"notification":{},"people":{"profileStatus":{},"activitiesByUser":{},"answersByUser":{},"answersSortByVotesByUser":{},"answersIncludedByUser":{},"votedAnswersByUser":{},"thankedAnswersByUser":{},"voteAnswersByUser":{},"thankAnswersByUser":{},"topicAnswersByUser":{},"zvideosByUser":{},"articlesByUser":{},"articlesSortByVotesByUser":{},"articlesIncludedByUser":{},"pinsByUser":{},"questionsByUser":{},"commercialQuestionsByUser":{},"favlistsByUser":{},"followingByUser":{},"followersByUser":{},"mutualsByUser":{},"followingColumnsByUser":{},"followingQuestionsByUser":{},"followingFavlistsByUser":{},"followingTopicsByUser":{},"publicationsByUser":{},"columnsByUser":{},"allFavlistsByUser":{},"brands":null,"creationsByUser":{},"creationsSortByVotesByUser":{},"creationsFeed":{}},"env":{"ab":{"config":{"experiments":[{"expId":"launch-gw_mweb_rec-1","expPrefix":"gw_mweb_rec","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-qa_hdpimg-2","expPrefix":"qa_hdpimg","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-us_foltopic_user-10","expPrefix":"us_foltopic_user","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_bullet_second-2","expPrefix":"vd_bullet_second","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_zvideo_link-10","expPrefix":"vd_zvideo_link","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"gw_mweb_launch-1","expPrefix":"gw_mweb_launch","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false}],"params":[{"id":"soc_adreadline","type":"String","value":"0","chainId":"_all_"},{"id":"li_pay_banner_type","type":"String","value":"6","chainId":"_all_"},{"id":"gue_zhuantikapian","type":"String","value":"0"},{"id":"se_dnn_mt_v2","type":"String","value":"0","chainId":"_all_"},{"id":"se_adxtest","type":"String","value":"1","chainId":"_all_"},{"id":"soc_brdcst4","type":"String","value":"3","chainId":"_all_"},{"id":"pf_adjust","type":"String","value":"0","chainId":"_all_"},{"id":"sem_up_growth","type":"String","value":"in_app","chainId":"_all_"},{"id":"se_pek_test2","type":"String","value":"1","chainId":"_all_"},{"id":"tp_topic_entry","type":"String","value":"0","chainId":"_all_"},{"id":"soc_cardheight","type":"String","value":"2","chainId":"_all_"},{"id":"ug_zero_follow","type":"String","value":"0","chainId":"_all_"},{"id":"tp_m_intro_re_topic","type":"String","value":"1","chainId":"_all_"},{"id":"qap_article_like","type":"String","value":"1","chainId":"_all_"},{"id":"qap_question_author","type":"String","value":"0","chainId":"_all_"},{"id":"web_ask","type":"String","value":"0"},{"id":"se_likebutton","type":"String","value":"0","chainId":"_all_"},{"id":"se_col_boost","type":"String","value":"0","chainId":"_all_"},{"id":"se_relation_1","type":"String","value":"0","chainId":"_all_"},{"id":"se_billboardsearch","type":"String","value":"0","chainId":"_all_"},{"id":"se_movietab","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_discover","type":"String","value":"0","chainId":"_all_"},{"id":"tp_qa_toast","type":"String","value":"1","chainId":"_all_"},{"id":"se_hotsearch","type":"String","value":"0","chainId":"_all_"},{"id":"se_subtext","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_tab","type":"String","value":"0","chainId":"_all_"},{"id":"soc_brdcst3","type":"String","value":"0","chainId":"_all_"},{"id":"top_universalebook","type":"String","value":"1","chainId":"_all_"},{"id":"se_webtimebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_lottery","type":"String","value":"0","chainId":"_all_"},{"id":"se_sug_term","type":"String","value":"0","chainId":"_all_"},{"id":"soc_stickypush","type":"String","value":"1","chainId":"_all_"},{"id":"tsp_vote","type":"String","value":"2","chainId":"_all_"},{"id":"se_zu_recommend","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_pic_swiper","type":"String","value":"1","chainId":"_all_"},{"id":"top_v_album","type":"String","value":"1","chainId":"_all_"},{"id":"soc_leave_recommend","type":"String","value":"2","chainId":"_all_"},{"id":"top_ydyq","type":"String","value":"X","chainId":"_all_"},{"id":"se_expired_ob","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_tab","type":"String","value":"0","chainId":"_all_"},{"id":"pf_creator_card","type":"String","value":"1","chainId":"_all_"},{"id":"se_new_topic","type":"String","value":"0","chainId":"_all_"},{"id":"se_hotsearch_num","type":"String","value":"0","chainId":"_all_"},{"id":"se_college","type":"String","value":"default","chainId":"_all_"},{"id":"se_waterfall","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_pk","type":"String","value":"1","chainId":"_all_"},{"id":"tp_header_style","type":"String","value":"1","chainId":"_all_"},{"id":"tp_discover","type":"String","value":"0","chainId":"_all_"},{"id":"pf_foltopic_usernum","type":"String","value":"50","chainId":"_all_"},{"id":"li_purchase_test","type":"String","value":"0","chainId":"_all_"},{"id":"se_sug","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_header","type":"String","value":"1","chainId":"_all_"},{"id":"soc_adsort","type":"String","value":"0","chainId":"_all_"},{"id":"soc_feed_intimacy","type":"String","value":"2","chainId":"_all_"},{"id":"li_ebook_gen_search","type":"String","value":"0","chainId":"_all_"},{"id":"web_collect","type":"String","value":"0"},{"id":"se_entity_model_14","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iospinweight","type":"String","value":"0","chainId":"_all_"},{"id":"gue_video_autoplay","type":"String","value":"0"},{"id":"zr_video_recall","type":"String","value":"current_recall","chainId":"_all_"},{"id":"tp_topic_style","type":"String","value":"0","chainId":"_all_"},{"id":"top_test_4_liguangyi","type":"String","value":"1","chainId":"_all_"},{"id":"ls_videoad","type":"String","value":"2","chainId":"_all_"},{"id":"se_article_icon","type":"String","value":"0","chainId":"_all_"},{"id":"se_amovietab","type":"String","value":"1","chainId":"_all_"},{"id":"li_ebook_read","type":"String","value":"0","chainId":"_all_"},{"id":"zr_training_first","type":"String","value":"false","chainId":"_all_"},{"id":"se_searchwiki","type":"String","value":"0","chainId":"_all_"},{"id":"ls_recommend_test","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iosreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"ug_follow_answerer_0","type":"String","value":"0","chainId":"_all_"},{"id":"zr_slot_cold_start","type":"String","value":"aver","chainId":"_all_"},{"id":"zr_search_sim","type":"String","value":"0","chainId":"_all_"},{"id":"se_ltr_video","type":"String","value":"0","chainId":"_all_"},{"id":"se_cbert_index","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_join","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_android_feed","type":"String","value":"old","chainId":"_all_"},{"id":"soc_iosintimacy","type":"String","value":"2","chainId":"_all_"},{"id":"li_qa_btn_text","type":"String","value":"0","chainId":"_all_"},{"id":"web_question_invite","type":"String","value":"B"},{"id":"se_highlight","type":"String","value":"0","chainId":"_all_"},{"id":"soc_userrec","type":"String","value":"0","chainId":"_all_"},{"id":"top_hotcommerce","type":"String","value":"1","chainId":"_all_"},{"id":"ls_fmp4","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_section","type":"String","value":"0","chainId":"_all_"},{"id":"soc_update","type":"String","value":"1","chainId":"_all_"},{"id":"soc_zcfw_shipinshiti","type":"String","value":"1","chainId":"_all_"},{"id":"li_vip_verti_search","type":"String","value":"0","chainId":"_all_"},{"id":"web_answerlist_ad","type":"String","value":"0"},{"id":"zr_art_rec","type":"String","value":"base","chainId":"_all_"},{"id":"se_aa_base","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_tab_feed","type":"String","value":"0","chainId":"_all_"},{"id":"soc_special","type":"String","value":"0","chainId":"_all_"},{"id":"zr_test_aa1","type":"String","value":"0","chainId":"_all_"},{"id":"se_featured","type":"String","value":"1","chainId":"_all_"},{"id":"top_quality","type":"String","value":"0","chainId":"_all_"},{"id":"pf_noti_entry_num","type":"String","value":"0","chainId":"_all_"},{"id":"li_assessment_show","type":"String","value":"1","chainId":"_all_"},{"id":"qap_question_visitor","type":"String","value":" 0","chainId":"_all_"},{"id":"zr_rec_answer_cp","type":"String","value":"close","chainId":"_all_"},{"id":"se_related_index","type":"String","value":"3","chainId":"_all_"},{"id":"se_pek_test3","type":"String","value":"1","chainId":"_all_"},{"id":"se_colorfultab","type":"String","value":"1","chainId":"_all_"},{"id":"se_cate_l3","type":"String","value":"0","chainId":"_all_"},{"id":"web_mini_review","type":"String","value":"0"},{"id":"web_heifetz_grow_ad","type":"String","value":"1"},{"id":"web_mweb_launch","type":"String","value":"1"},{"id":"qap_payc_invite","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sticky_android","type":"String","value":"2","chainId":"_all_"},{"id":"soc_notification","type":"String","value":"0","chainId":"_all_"},{"id":"web_column_auto_invite","type":"String","value":"0"},{"id":"web_audit_01","type":"String","value":"case1"},{"id":"gue_zvideo_link","type":"String","value":"1"},{"id":"zr_slotpaidexp","type":"String","value":"1","chainId":"_all_"},{"id":"se_content0","type":"String","value":"0","chainId":"_all_"},{"id":"qap_ques_invite","type":"String","value":"0","chainId":"_all_"},{"id":"zr_km_feed_nlp","type":"String","value":"old","chainId":"_all_"},{"id":"se_hotsearch_2","type":"String","value":"1","chainId":"_all_"},{"id":"se_cardrank_4","type":"String","value":"1","chainId":"_all_"},{"id":"gue_bullet_guide","type":"String","value":"发个弹幕聊聊…"},{"id":"gue_self_censoring","type":"String","value":"1"},{"id":"se_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"se_mobileweb","type":"String","value":"1","chainId":"_all_"},{"id":"se_college_cm","type":"String","value":"0","chainId":"_all_"},{"id":"se_payconsult","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sft_v2","type":"String","value":"d","chainId":"_all_"},{"id":"soc_zcfw_broadcast","type":"String","value":"0","chainId":"_all_"},{"id":"gue_card_test","type":"String","value":"1"},{"id":"zr_intervene","type":"String","value":"0","chainId":"_all_"},{"id":"zr_expslotpaid","type":"String","value":"1","chainId":"_all_"},{"id":"se_rf_w","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_2","type":"String","value":"1","chainId":"_all_"},{"id":"se_topiclabel","type":"String","value":"1","chainId":"_all_"},{"id":"se_relationship","type":"String","value":"1","chainId":"_all_"},{"id":"se_ad_index","type":"String","value":"10","chainId":"_all_"},{"id":"li_catalog_card","type":"String","value":"1","chainId":"_all_"},{"id":"tp_topic_tab_new","type":"String","value":"0-0-0","chainId":"_all_"},{"id":"tsp_videobillboard","type":"String","value":"1","chainId":"_all_"},{"id":"li_svip_tab_search","type":"String","value":"0","chainId":"_all_"},{"id":"zr_video_rank","type":"String","value":"new_rank","chainId":"_all_"},{"id":"se_specialbutton","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"web_ad_banner","type":"String","value":"0"},{"id":"li_se_heat","type":"String","value":"1","chainId":"_all_"},{"id":"se_timebox_up","type":"String","value":"0","chainId":"_all_"},{"id":"se_aa","type":"String","value":"0","chainId":"_all_"},{"id":"se_websearch","type":"String","value":"3","chainId":"_all_"},{"id":"li_android_vip","type":"String","value":"0","chainId":"_all_"},{"id":"web_unfriendly_comm","type":"String","value":"0"},{"id":"se_cardrank_1","type":"String","value":"0","chainId":"_all_"},{"id":"se_presearch_ab","type":"String","value":"0","chainId":"_all_"},{"id":"zr_video_rank_nn","type":"String","value":"new_rank","chainId":"_all_"},{"id":"tp_topic_head","type":"String","value":"0","chainId":"_all_"},{"id":"li_hot_voted","type":"String","value":"0","chainId":"_all_"},{"id":"li_video_section","type":"String","value":"0","chainId":"_all_"},{"id":"se_hot_timebox","type":"String","value":"0","chainId":"_all_"},{"id":"soc_newfeed","type":"String","value":"2","chainId":"_all_"},{"id":"top_root","type":"String","value":"0","chainId":"_all_"},{"id":"ug_goodcomment_0","type":"String","value":"1","chainId":"_all_"},{"id":"zr_search_paid","type":"String","value":"0","chainId":"_all_"},{"id":"se_whitelist","type":"String","value":"0","chainId":"_all_"},{"id":"web_sem_ab","type":"String","value":"1"},{"id":"qap_thanks","type":"String","value":"1","chainId":"_all_"},{"id":"se_agency","type":"String","value":" 0","chainId":"_all_"},{"id":"li_se_edu","type":"String","value":"1","chainId":"_all_"},{"id":"zr_slot_training","type":"String","value":"1","chainId":"_all_"},{"id":"se_page_quality","type":"String","value":"0","chainId":"_all_"},{"id":"tp_meta_card","type":"String","value":"0","chainId":"_all_"},{"id":"ug_zero_follow_0","type":"String","value":"0","chainId":"_all_"},{"id":"ug_newtag","type":"String","value":"0","chainId":"_all_"},{"id":"li_ebok_chap","type":"String","value":"0","chainId":"_all_"},{"id":"zw_sameq_sorce","type":"String","value":"999","chainId":"_all_"},{"id":"zr_update_merge_size","type":"String","value":"1","chainId":"_all_"},{"id":"tp_qa_metacard_top","type":"String","value":"top","chainId":"_all_"},{"id":"li_svip_cardshow","type":"String","value":"1","chainId":"_all_"},{"id":"se_time_threshold","type":"String","value":"0","chainId":"_all_"},{"id":"tp_discovery_ab_1","type":"String","value":"0","chainId":"_all_"},{"id":"soc_authormore","type":"String","value":"2","chainId":"_all_"},{"id":"se_ctx_rerank","type":"String","value":"1","chainId":"_all_"},{"id":"li_se_media_icon","type":"String","value":"1","chainId":"_all_"},{"id":"se_click_club","type":"String","value":"1","chainId":"_all_"},{"id":"soc_iossort","type":"String","value":"0","chainId":"_all_"},{"id":"web_hdpimg","type":"String","value":"1"},{"id":"zr_ans_rec","type":"String","value":"gbrank","chainId":"_all_"},{"id":"tp_club_qa","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_android_join","type":"String","value":"1","chainId":"_all_"},{"id":"soc_zcfw_broadcast2","type":"String","value":"1","chainId":"_all_"},{"id":"top_ebook","type":"String","value":"0","chainId":"_all_"},{"id":"web_answer_update","type":"String","value":"0"},{"id":"web_mweb_rec_length","type":"String","value":"1"},{"id":"gue_goods_card","type":"String","value":"0"},{"id":"se_topicfeed","type":"String","value":"0","chainId":"_all_"},{"id":"se_preset_tech","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sft","type":"String","value":"a","chainId":"_all_"},{"id":"li_answers_link","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iosreadline","type":"String","value":"0","chainId":"_all_"},{"id":"soc_wonderuser_recom","type":"String","value":"2","chainId":"_all_"},{"id":"gue_video_replay","type":"String","value":"0"},{"id":"li_qa_new_cover","type":"String","value":"1","chainId":"_all_"},{"id":"li_answer_label","type":"String","value":"0","chainId":"_all_"},{"id":"li_paid_answer_exp","type":"String","value":"0","chainId":"_all_"},{"id":"zw_payc_qaedit","type":"String","value":"0","chainId":"_all_"},{"id":"se_zu_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"tp_discover_copy","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_feed","type":"String","value":"1","chainId":"_all_"},{"id":"se_new_p","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_pic","type":"String","value":"0.6","chainId":"_all_"},{"id":"gue_new_special_page","type":"String","value":"1"},{"id":"tp_score_1","type":"String","value":"a","chainId":"_all_"},{"id":"soc_zuichangfangwen","type":"String","value":"0","chainId":"_all_"},{"id":"web_upload","type":"String","value":"1"},{"id":"zr_km_answer","type":"String","value":"open_cvr","chainId":"_all_"},{"id":"se_cardrank_3","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_rec","type":"String","value":"1","chainId":"_all_"},{"id":"soc_authormore2","type":"String","value":"2","chainId":"_all_"},{"id":"li_answer_card","type":"String","value":"0","chainId":"_all_"},{"id":"li_yxzl_new_style_a","type":"String","value":"1","chainId":"_all_"},{"id":"se_ffzx_jushen1","type":"String","value":"0","chainId":"_all_"},{"id":"gue_bullet_second","type":"String","value":"1"},{"id":"li_education_box","type":"String","value":"0","chainId":"_all_"},{"id":"se_entity_model","type":"String","value":"0","chainId":"_all_"},{"id":"li_salt_hot","type":"String","value":"1","chainId":"_all_"},{"id":"se_preset_label","type":"String","value":"1","chainId":"_all_"},{"id":"se_new_merger","type":"String","value":"1","chainId":"_all_"},{"id":"se_p_slideshow","type":"String","value":"0","chainId":"_all_"},{"id":"soc_bignew","type":"String","value":"1","chainId":"_all_"},{"id":"web_sec672","type":"String","value":"0"},{"id":"se_ios_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"se_famous","type":"String","value":"1","chainId":"_all_"},{"id":"soc_adpinweight","type":"String","value":"0","chainId":"_all_"},{"id":"gue_thanks","type":"String","value":"0"},{"id":"tp_qa_metacard","type":"String","value":"1","chainId":"_all_"},{"id":"zr_article_new","type":"String","value":"close","chainId":"_all_"},{"id":"se_webmajorob","type":"String","value":"0","chainId":"_all_"},{"id":"se_use_zitem","type":"String","value":"0","chainId":"_all_"},{"id":"se_prf","type":"String","value":"0","chainId":"_all_"},{"id":"se_site_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_backsearch","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_qa_pic","type":"String","value":"1","chainId":"_all_"},{"id":"top_new_feed","type":"String","value":"5","chainId":"_all_"},{"id":"se_wannasearch","type":"String","value":"0","chainId":"_all_"},{"id":"web_creator_route","type":"String","value":"1"},{"id":"pf_newguide_vertical","type":"String","value":"0","chainId":"_all_"},{"id":"ug_follow_answerer","type":"String","value":"0","chainId":"_all_"},{"id":"zr_answer_rec_cp","type":"String","value":"open","chainId":"_all_"},{"id":"zr_rel_search","type":"String","value":"base","chainId":"_all_"},{"id":"se_auto_syn","type":"String","value":"0","chainId":"_all_"},{"id":"se_multianswer","type":"String","value":"2","chainId":"_all_"},{"id":"tsp_hotlist_ui","type":"String","value":"1","chainId":"_all_"},{"id":"li_sku_bottom_bar_re","type":"String","value":"0","chainId":"_all_"},{"id":"zr_training_boost","type":"String","value":"false","chainId":"_all_"},{"id":"se_sug_entrance","type":"String","value":"1","chainId":"_all_"},{"id":"se_search_feed","type":"String","value":"N","chainId":"_all_"},{"id":"soc_zcfw_badcase","type":"String","value":"0","chainId":"_all_"},{"id":"pf_fuceng","type":"String","value":"1","chainId":"_all_"},{"id":"web_n_web_msg","type":"String","value":"0"},{"id":"se_webrs","type":"String","value":"1","chainId":"_all_"},{"id":"se_hotmore","type":"String","value":"2","chainId":"_all_"},{"id":"se_club_post","type":"String","value":"5","chainId":"_all_"},{"id":"ug_fw_answ_aut_1","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_across","type":"String","value":"1","chainId":"_all_"},{"id":"se_pek_test","type":"String","value":"1","chainId":"_all_"},{"id":"soc_yxzl_zcfw","type":"String","value":"0","chainId":"_all_"},{"id":"web_answer_list_ad","type":"String","value":"1"},{"id":"soc_bigone","type":"String","value":"0","chainId":"_all_"},{"id":"soc_ri_merge","type":"String","value":"0","chainId":"_all_"},{"id":"ug_follow_topic_1","type":"String","value":"2","chainId":"_all_"}],"chains":[{"chainId":"_all_"}]},"triggers":{}},"userAgent":{"Edge":false,"Wechat":false,"Weibo":false,"QQ":false,"MQQBrowser":false,"Qzone":false,"Mobile":false,"Android":false,"iOS":false,"isAppleDevice":false,"Zhihu":false,"ZhihuHybrid":false,"isBot":false,"Tablet":false,"UC":false,"Sogou":false,"Qihoo":false,"Baidu":false,"BaiduApp":false,"Safari":false,"GoogleBot":false,"AndroidDaily":false,"iOSDaily":false,"isWebView":false,"origin":"Mozilla\u002F5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\u002F537.36 (KHTML, like Gecko) Chrome\u002F80.0.3987.100 Safari\u002F537.36"},"appViewConfig":{},"ctx":{"path":"\u002Fp\u002F113124696","query":{},"href":"http:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F113124696","host":"zhuanlan.zhihu.com"},"trafficSource":"production","edition":{"baidu":false,"sogou":false,"baiduBeijing":false,"sogouBeijing":false,"sogouInput":false},"theme":"light","enableShortcut":true,"referer":"","conf":{},"ipInfo":{"cityName":"德州","countryName":"中国","regionName":"山东","countryCode":"CN"},"logged":false},"me":{"columnContributions":[]},"label":{"recognizerLists":{}},"ecommerce":{},"comments":{"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"parent":{}},"commentsV2":{"stickers":[],"commentWithPicPermission":{},"notificationsComments":{},"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"conversationMore":{},"parent":{}},"pushNotifications":{"default":{"isFetching":false,"isDrained":false,"ids":[]},"follow":{"isFetching":false,"isDrained":false,"ids":[]},"vote_thank":{"isFetching":false,"isDrained":false,"ids":[]},"currentTab":"default","notificationsCount":{"default":0,"follow":0,"vote_thank":0}},"messages":{"data":{},"currentTab":"common","messageCount":0},"register":{"registerValidateSucceeded":null,"registerValidateErrors":{},"registerConfirmError":null,"sendDigitsError":null,"registerConfirmSucceeded":null},"login":{"loginUnregisteredError":false,"loginBindWechatError":false,"loginConfirmError":null,"sendDigitsError":null,"needSMSIdentify":false,"validateDigitsError":false,"loginConfirmSucceeded":null,"qrcodeLoginToken":"","qrcodeLoginScanStatus":0,"qrcodeLoginError":null,"qrcodeLoginReturnNewToken":false},"active":{"sendDigitsError":null,"activeConfirmSucceeded":null,"activeConfirmError":null},"switches":{},"captcha":{"captchaNeeded":false,"captchaValidated":false,"captchaBase64String":null,"captchaValidationMessage":null,"loginCaptchaExpires":false},"sms":{"supportedCountries":[]},"chat":{"chats":{},"inbox":{"recents":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"strangers":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"friends":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"search":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"config":{"newCount":0,"strangerMessageSwitch":false,"strangerMessageUnread":false,"friendCount":0}},"global":{"isChatMqttExisted":false}},"emoticons":{"emoticonGroupList":[],"emoticonGroupDetail":{}},"creator":{"currentCreatorUrlToken":null,"homeData":{"recommendQuestions":[]},"tools":{"question":{"invitationCount":{"questionFolloweeCount":0,"questionTotalCount":0},"goodatTopics":[]},"customPromotion":{"itemLists":{}},"recommend":{"recommendTimes":{}}},"explore":{"academy":{"tabs":[],"article":{}}},"rights":[],"rightsStatus":{},"levelUpperLimit":10,"account":{"growthLevel":{}},"mcn":{},"applyStatus":{}},"recommendation":{"homeRecommendations":[]},"shareTexts":{},"articles":{"voters":{}},"previewPost":{},"favlists":{"relations":{}},"columns":{"voters":{}},"reward":{"answer":{},"article":{},"question":{}},"video":{"data":{},"shareVideoDetail":{},"last":{}},"topstory":{"recommend":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"follow":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followWonderful":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"sidebar":null,"announcement":{},"hotListCategories":[],"hotList":[],"guestFeeds":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followExtra":{"isNewUser":null,"isFetched":false,"followCount":0,"followers":[]}},"readStatus":{},"column":{},"requestColumn":{"categories":[],"error":null},"articleContribution":{"contributeRequests":[],"deleteContributeIdList":[],"handledContributeIdList":[],"recommendedColumns":[],"pinnedColumns":[],"sentContributeRequestsIdList":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"reinforcement","reinforcementlearning",null]},"columnContribution":{"contributeRequests":[],"autoInviteEnabled":false,"recommendedContributors":[],"contributionInvitation":null},"draftHistory":{"history":{},"drafts":{}},"upload":{},"articleDraft":{"titleImage":"","titleImageSize":{},"isTitleImageFullScreen":false,"canTitleImageFullScreen":false,"title":"","titleImageUploading":false,"error":"","content":"","draftLoading":false,"updating":false,"globalLoading":false,"pendingVideo":{"resource":null,"error":null},"deleteFail":{"fail":false},"recommendTopics":[],"selectedColumn":0,"articleDisclaimers":[]},"articleDrafts":{"isDrained":false,"isLoading":false,"items":[]},"columnAutocomplete":{"users":[],"friends":[]},"columnCollection":{},"mcn":{"bindInfo":{},"memberCategoryList":[],"producerList":[],"categoryList":[]}},"fetchHost":"www.zhihu.com","subAppName":"column"}</script><script src="https://static.zhihu.com/heifetz/vendor.7b36fae46082fd30a0db.js"></script><script src="https://static.zhihu.com/heifetz/column.app.76e02b16e87eec249f44.js"></script></body><script src="https://hm.baidu.com/hm.js?98beee57fd2ef70ccdd5ca52b9740c49" async=""></script><script src="https://zz.bdstatic.com/linksubmit/push.js" async=""></script></html>