<!doctype html>
<html lang="zh" data-hairline="true" data-theme="light"><head><meta charSet="utf-8"/><title data-react-helmet="true">【强化学习实践 30】复现PPO - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"/><meta name="renderer" content="webkit"/><meta name="force-rendering" content="webkit"/><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg"/><meta data-react-helmet="true" name="keywords" content="算法,强化学习 (Reinforcement Learning)"/><meta data-react-helmet="true" name="description" content="序言讲了好多强化学习的paper了，下面是时候仔细考虑一下Implementation matters这句话了。这些常见的算法都有已经调好参数的程序，大家可以直接跑，就在[github]openai.baselines。如果只是为了跑一个对照试验的…"/><meta data-react-helmet="true" property="og:title" content="【强化学习实践 30】复现PPO"/><meta data-react-helmet="true" property="og:url" content="https://zhuanlan.zhihu.com/p/50322028"/><meta data-react-helmet="true" property="og:description" content="序言讲了好多强化学习的paper了，下面是时候仔细考虑一下Implementation matters这句话了。这些常见的算法都有已经调好参数的程序，大家可以直接跑，就在[github]openai.baselines。如果只是为了跑一个对照试验的…"/><meta data-react-helmet="true" property="og:image" content="https://pic1.zhimg.com/v2-9a8b3231d89fc41c9fdbdb28590dba32_b.jpg"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" property="og:site_name" content="知乎专栏"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png" sizes="152x152"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-120.b3e6278d.png" sizes="120x120"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-76.7a750095.png" sizes="76x76"/><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-60.a4a761d4.png" sizes="60x60"/><link rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/static/favicon.ico"/><link rel="search" type="application/opensearchdescription+xml" href="https://static.zhihu.com/static/search.xml" title="知乎"/><link rel="dns-prefetch" href="//static.zhimg.com"/><link rel="dns-prefetch" href="//pic1.zhimg.com"/><link rel="dns-prefetch" href="//pic2.zhimg.com"/><link rel="dns-prefetch" href="//pic3.zhimg.com"/><link rel="dns-prefetch" href="//pic4.zhimg.com"/><style>
.u-safeAreaInset-top {
  height: constant(safe-area-inset-top) !important;
  height: env(safe-area-inset-top) !important;
  
}
.u-safeAreaInset-bottom {
  height: constant(safe-area-inset-bottom) !important;
  height: env(safe-area-inset-bottom) !important;
  
}
</style><link href="https://static.zhihu.com/heifetz/column.app.a9ced452148fee3a55c8.css" rel="stylesheet"/><script defer="" crossorigin="anonymous" src="https://unpkg.zhimg.com/@cfe/sentry-script@latest/dist/init.js" data-sentry-config="{&quot;dsn&quot;:&quot;https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224&quot;,&quot;sampleRate&quot;:0.1,&quot;release&quot;:&quot;683-127b14ad&quot;,&quot;ignoreErrorNames&quot;:[&quot;NetworkError&quot;,&quot;SecurityError&quot;],&quot;ignoreErrors&quot;:[&quot;origin message&quot;,&quot;Network request failed&quot;,&quot;Loading chunk&quot;,&quot;这个系统不支持该功能。&quot;,&quot;Can&#x27;t find variable: webkit&quot;,&quot;Can&#x27;t find variable: $&quot;,&quot;内存不足&quot;,&quot;out of memory&quot;,&quot;DOM Exception 18&quot;,&quot;The operation is insecure&quot;,&quot;[object Event]&quot;,&quot;[object FileError]&quot;,&quot;[object DOMError]&quot;,&quot;[object Object]&quot;,&quot;拒绝访问。&quot;,&quot;Maximum call stack size exceeded&quot;,&quot;UploadError&quot;,&quot;无法 fetch&quot;,&quot;draft-js&quot;,&quot;缺少 JavaScript 对象&quot;,&quot;componentWillEnter&quot;,&quot;componentWillLeave&quot;,&quot;componentWillAppear&quot;,&quot;getInlineStyleAt&quot;,&quot;getCharacterList&quot;],&quot;whitelistUrls&quot;:[&quot;static.zhihu.com&quot;]}"></script></head><body class="WhiteBg-body"><div id="root"><div class="App"><div class="LoadingBar"></div><main role="main" class="App-main"><div class="Post-content" data-zop-usertoken="{&quot;userToken&quot;:&quot;&quot;}" data-zop="{&quot;authorName&quot;:&quot;张楚珩&quot;,&quot;itemId&quot;:50322028,&quot;title&quot;:&quot;【强化学习实践 30】复现PPO&quot;,&quot;type&quot;:&quot;article&quot;}"><div class="ColumnPageHeader-Wrapper"><div><div class="Sticky ColumnPageHeader"><div class="ColumnPageHeader-content"><a href="//www.zhihu.com" aria-label="知乎"><svg viewBox="0 0 200 91" fill="#0084FF" width="64" height="30"><path d="M53.29 80.035l7.32.002 2.41 8.24 13.128-8.24h15.477v-67.98H53.29v67.978zm7.79-60.598h22.756v53.22h-8.73l-8.718 5.473-1.587-5.46-3.72-.012v-53.22zM46.818 43.162h-16.35c.545-8.467.687-16.12.687-22.955h15.987s.615-7.05-2.68-6.97H16.807c1.09-4.1 2.46-8.332 4.1-12.708 0 0-7.523 0-10.085 6.74-1.06 2.78-4.128 13.48-9.592 24.41 1.84-.2 7.927-.37 11.512-6.94.66-1.84.785-2.08 1.605-4.54h9.02c0 3.28-.374 20.9-.526 22.95H6.51c-3.67 0-4.863 7.38-4.863 7.38H22.14C20.765 66.11 13.385 79.24 0 89.62c6.403 1.828 12.784-.29 15.937-3.094 0 0 7.182-6.53 11.12-21.64L43.92 85.18s2.473-8.402-.388-12.496c-2.37-2.788-8.768-10.33-11.496-13.064l-4.57 3.627c1.363-4.368 2.183-8.61 2.46-12.71H49.19s-.027-7.38-2.372-7.38zm128.752-.502c6.51-8.013 14.054-18.302 14.054-18.302s-5.827-4.625-8.556-1.27c-1.874 2.548-11.51 15.063-11.51 15.063l6.012 4.51zm-46.903-18.462c-2.814-2.577-8.096.667-8.096.667s12.35 17.2 12.85 17.953l6.08-4.29s-8.02-11.752-10.83-14.33zM199.99 46.5c-6.18 0-40.908.292-40.953.292v-31.56c1.503 0 3.882-.124 7.14-.376 12.773-.753 21.914-1.25 27.427-1.504 0 0 3.817-8.496-.185-10.45-.96-.37-7.24 1.43-7.24 1.43s-51.63 5.153-72.61 5.64c.5 2.756 2.38 5.336 4.93 6.11 4.16 1.087 7.09.53 15.36.277 7.76-.5 13.65-.76 17.66-.76v31.19h-41.71s.88 6.97 7.97 7.14h33.73v22.16c0 4.364-3.498 6.87-7.65 6.6-4.4.034-8.15-.36-13.027-.566.623 1.24 1.977 4.496 6.035 6.824 3.087 1.502 5.054 2.053 8.13 2.053 9.237 0 14.27-5.4 14.027-14.16V53.93h38.235c3.026 0 2.72-7.432 2.72-7.432z" fill-rule="evenodd"></path></svg></a><i class="ColumnPageHeader-Line"></i><div class="ColumnPageHeader-Title"><a class="ColumnLink ColumnPageHeader-Link" href="/reinforcementlearning"><img class="Avatar Avatar--round" width="30" height="30" src="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_is.jpg" srcSet="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_im.jpg 2x" alt="强化学习前沿"/></a><div class="ColumnPageHeader-TitleName"><span class="ColumnPageHeader-TitleMeta">首发于</span><a class="ColumnLink ColumnPageHeader-TitleColumn" href="/reinforcementlearning">强化学习前沿</a></div></div><div class="ColumnPageHeader-Button"><button type="button" class="Button ColumnPageHeader-WriteButton Button--blue"><svg class="Zi Zi--EditSurround" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M18.453 7.992l-1.833-1.65.964-.978a1.223 1.223 0 0 1 1.73-.012l.005.006a1.24 1.24 0 0 1 .007 1.748l-.873.886zm-1.178 1.194l-5.578 5.66-1.935.697a.393.393 0 0 1-.504-.504l.697-1.935 5.488-5.567 1.832 1.65zM7.58 5.848l5.654.006-1.539 1.991-3.666.012A1.02 1.02 0 0 0 7 8.868v7.993c0 .558.46 1.01 1.029 1.01l7.941-.01c.568 0 1.03-.453 1.03-1.012v-4.061l2-1.442v6.002c0 1.397-1.2 2.501-2.62 2.501H7.574C6.153 19.85 5 18.717 5 17.32V8.35c0-1.397 1.16-2.502 2.58-2.502z"></path></svg>写文章</button></div></div></div></div></div><img class="TitleImage" src="https://pic1.zhimg.com/v2-9a8b3231d89fc41c9fdbdb28590dba32_1200x500.jpg" alt="【强化学习实践 30】复现PPO"/><article class="Post-Main Post-NormalMain" tabindex="-1"><header class="Post-Header"><h1 class="Post-Title">【强化学习实践 30】复现PPO</h1><div class="Post-Author"><div class="AuthorInfo" itemProp="author" itemscope="" itemType="http://schema.org/Person"><meta itemProp="name" content="张楚珩"/><meta itemProp="image" content="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg"/><meta itemProp="url" content="https://www.zhihu.com/people/zhang-chu-heng"/><meta itemProp="zhihu:followerCount"/><span class="UserLink AuthorInfo-avatarWrapper"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/zhang-chu-heng"><img class="Avatar Avatar--round AuthorInfo-avatar" width="38" height="38" src="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_xs.jpg" srcSet="https://pic4.zhimg.com/v2-2b7c11f27a7fd03282819889435815aa_l.jpg 2x" alt="张楚珩"/></a></div></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/zhang-chu-heng">张楚珩</a></div></div><style data-emotion-css="1cd9gw4">.css-1cd9gw4{margin-left:.3em;}</style><style data-emotion-css="1pc1mic">.css-1pc1mic{box-sizing:border-box;margin:0;min-width:0;color:#175199;display:inline-block;width:18px;height:18px;margin-left:.3em;}</style><a href="https://www.zhihu.com/question/48510028" target="_blank" class="css-1pc1mic" data-tooltip="已认证的个人" aria-label="已认证的个人"><style data-emotion-css="18biwo">.css-18biwo{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><span class="css-18biwo">​<svg viewBox="0 0 24 24" width="18" height="18"><svg viewBox="0 0 24 24" x="-3" y="-3" fill="#FFFFFF" width="30" height="30"><path d="M3.56231227,13.8535307 C2.40051305,12.768677 2.41398885,11.0669203 3.59484487,9.99979213 L3.59222085,9.99654885 C4.26730143,9.45036719 4.79446755,8.21005186 4.7184197,7.34453784 L4.72305873,7.34412719 C4.66942824,5.75539997 5.8824188,4.56066914 7.47188965,4.64242381 L7.47229112,4.6386236 C8.33515314,4.72977993 9.58467253,4.22534048 10.1426329,3.55925173 L10.1462611,3.56228565 C11.2316055,2.40008701 12.9353108,2.41394456 14.0015072,3.59634088 L14.0047263,3.59374004 C14.5498229,4.26841874 15.7896857,4.79521622 16.6545744,4.71844347 L16.6549836,4.72304294 C18.245027,4.66894057 19.4396947,5.88213996 19.3575031,7.47241135 L19.3623099,7.47292747 C19.2704388,8.3358681 19.7742711,9.58421483 20.4407199,10.1424506 L20.437686,10.1460789 C21.5997217,11.2312209 21.5860695,12.9345218 20.4042441,14.0007396 L20.4072865,14.0045125 C19.7325967,14.5495925 19.2055209,15.7896954 19.2815865,16.6561959 L19.2770449,16.6565978 C19.3315454,18.2453037 18.1173775,19.4393568 16.5274188,19.3571512 L16.5269029,19.3619539 C15.6647098,19.270083 14.415408,19.7741709 13.8573671,20.4403558 L13.8537409,20.4373235 C12.76842,21.5995708 11.0650432,21.5864553 9.99899434,20.4039226 L9.99527367,20.406923 C9.45025436,19.7323399 8.21017638,19.2051872 7.34461983,19.2812352 L7.344304,19.2776405 C5.75448683,19.3312904 4.55977145,18.1170085 4.64254978,16.527117 L4.63769921,16.5265942 C4.72957031,15.6644394 4.22547659,14.4151814 3.55928015,13.8571569 L3.56231227,13.8535307 Z"></path></svg><path d="M2.63951518,13.3895441 C3.70763333,14.2842292 4.44777637,16.1226061 4.30075305,17.5023312 L4.32211542,17.3063047 C4.17509209,18.6910561 5.17786655,19.7063729 6.5613937,19.5844846 L6.364106,19.6008202 C7.75140298,19.4789319 9.57474349,20.2554985 10.4468305,21.3349009 L10.3224262,21.1803415 C11.1982831,22.2647703 12.6257916,22.2723098 13.5167278,21.2079863 L13.3898102,21.3600325 C14.2845162,20.2919393 16.1229361,19.5518136 17.5026934,19.6988334 L17.3054057,19.6774716 C18.6914461,19.8244915 19.7067866,18.8217404 19.5836389,17.4395022 L19.6012314,17.6367853 C19.4793403,16.2482641 20.255925,14.4249662 21.3353526,13.5528995 L21.1807897,13.677301 C22.2639871,12.8014646 22.2727834,11.3739894 21.2084351,10.483074 L21.3604848,10.6099886 C20.2923667,9.71530351 19.5522236,7.87818322 19.6992469,6.49720154 L19.6778846,6.69448464 C19.8249079,5.30847665 18.8221335,4.2944164 17.4386063,4.41630468 L17.635894,4.39871256 C16.248597,4.52185742 14.4252565,3.74529084 13.5531695,2.66588842 L13.6775738,2.81919121 C12.8017169,1.73601905 11.3742084,1.72722299 10.4832722,2.79154644 L10.6101898,2.63950024 C9.71548377,3.70759343 7.87706394,4.44771919 6.49730661,4.30195588 L6.69459432,4.32206116 C5.30855394,4.17504128 4.29447,5.17904888 4.41636114,6.56128713 L4.3987686,6.36400404 C4.52065973,7.75126861 3.74407501,9.57456653 2.66464737,10.4478898 L2.81921035,10.3222318 C1.73601288,11.1993248 1.72721662,12.6255433 2.79156494,13.5164587 L2.63951518,13.3895441 Z" fill="#0084FF"></path><svg class="Zi Zi--Check" fill="#fff" x="6" y="6" viewBox="0 0 24 24" width="12" height="12"><path d="M10.229 17.516c-.318.327-.75.484-1.199.484-.453 0-.884-.16-1.202-.488l-4.335-4.47a1.77 1.77 0 0 1 .007-2.459 1.663 1.663 0 0 1 2.397.01l3.137 3.246 9.072-9.329a1.662 1.662 0 0 1 2.397 0c.663.681.663 1.786 0 2.466L10.23 17.516z" fill-rule="evenodd"></path></svg></svg></span></a></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="AuthorInfo-badgeText">清华大学 交叉信息院博士在读</div></div></div></div></div></div><div><span class="Voters"><button type="button" class="Button Button--plain">44 人<!-- -->赞同了该文章</button></span></div></header><div class="Post-RichTextContainer"><div class="RichText ztext Post-RichText"><h2><b>序言</b></h2><p>讲了好多强化学习的paper了，下面是时候仔细考虑一下Implementation matters这句话了。这些常见的算法都有已经调好参数的程序，大家可以直接跑，就在<a href="https://link.zhihu.com/?target=https%3A//github.com/openai/baselines" class=" wrap external" target="_blank" rel="nofollow noreferrer">[github]openai.baselines</a>。如果只是为了跑一个对照试验的话，直接使用别人实现的代码就可以了。但是我们对于更多的东西感兴趣，比如，究竟要如何实现一个高性能的算法？有哪些（文章里面不会提到的）小技巧导致我们实现的算法性能低甚至崩溃？</p><h2><b>各种实现小技巧的调研</b></h2><p>首先要知己知彼才可以，我们先通读baselines代码，看看究竟这里面包含了哪些文章里面没有提到的内容。另外也参考了文献[1]里面提到的一些技巧。（注，现在baselines里面的ppo1是马上要弃用了的，但是我当时不知道，主要调研的ppo1，现在更新了多进程版本的ppo2；不过最后实践表明我实现的算法与ppo2跑出来的效果差不多）</p><ol><li><b>超参数设置</b></li></ol><div class="highlight"><pre><code class="language-python3"><span class="c1"># 最多采样多少步，可以用户设定</span>
<span class="n">max_timesteps</span><span class="o">=</span><span class="mf">2e7</span> 
<span class="c1"># 每个batch采样多少步，里面可能包含很多回合的终点，然后起点开始继续采样，直到凑够</span>
<span class="n">timesteps_per_actorbatch</span><span class="o">=</span><span class="mi">2048</span>   
<span class="c1"># PPO的clip参数</span>
<span class="n">clip_param</span><span class="o">=</span><span class="mf">0.2</span>
<span class="c1"># 交叉熵项系数</span>
<span class="n">entcoeff</span><span class="o">=</span><span class="mf">0.0</span>
<span class="c1"># 每次采集一个batch的样本之后过几遍</span>
<span class="n">optim_epochs</span><span class="o">=</span><span class="mi">10</span> 
<span class="c1"># Adam学习率 </span>
<span class="n">optim_stepsize</span><span class="o">=</span><span class="mf">3e-4</span>
<span class="c1"># 优化用的minibatch size</span>
<span class="n">optim_batchsize</span><span class="o">=</span><span class="mi">64</span>
<span class="c1"># discount rate</span>
<span class="n">gamma</span><span class="o">=</span><span class="mf">0.99</span>
<span class="c1"># GAE parameter</span>
<span class="n">lam</span><span class="o">=</span><span class="mf">0.95</span> 
<span class="n">adam_epsilon</span><span class="o">=</span><span class="mf">1e-5</span>  
<span class="n">schedule</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span></code></pre></div><p><b>2. observation normalization and clipping</b></p><div class="highlight"><pre><code class="language-python3"><span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">((</span><span class="n">ob</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">ob_rms</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">ob_rms</span><span class="o">.</span><span class="n">std</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">)</span></code></pre></div><p>即归一化到(0,1)高斯分布，然后再clip掉偏离比较远的。</p><p><b>3. value function clipping</b></p><p>在参考资料[1]和[2]里面都提到了要类似策略的损失函数一样对价值函数的损失函数做类似的clip。但是我在openai.baselines.ppo1里面并没有找到相应的实现。况且参考资料[1]里面也说了这个技巧没啥效果。</p><p><b>4. reward scaling / clipping</b></p><p>同样，在文献[1]里面提到了这个技巧，不过我没有在openai.baselines.ppo1里找到。</p><p><b>5. orthogonal initialization and layer scaling</b></p><p>一般的神经网络实现（TensorFlow、PyTorch等）一般默认xavier初始化[3]，但是在强化学习里面一般都在使用正交初始化[4]。</p><p>在openai.baselines.ppo1里面是独立的正态分布生成权重，然后每一行做归一化</p><div class="highlight"><pre><code class="language-python3"><span class="k">def</span> <span class="nf">normc_initializer</span><span class="p">(</span><span class="n">std</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_initializer</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">partition_info</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># pylint: disable=W0613</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="o">.</span><span class="n">as_numpy_dtype</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">*=</span> <span class="n">std</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">out</span><span class="p">)</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_initializer</span></code></pre></div><p>在openai.baselines.ppo2里面是利用SVD分解来做的</p><div class="highlight"><pre><code class="language-python3"><span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s2">&#34;w&#34;</span><span class="p">,</span> <span class="p">[</span><span class="n">nin</span><span class="p">,</span> <span class="n">nh</span><span class="p">],</span> <span class="n">initializer</span><span class="o">=</span><span class="n">ortho_init</span><span class="p">(</span><span class="n">init_scale</span><span class="p">))</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s2">&#34;b&#34;</span><span class="p">,</span> <span class="p">[</span><span class="n">nh</span><span class="p">],</span> <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="n">init_bias</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">ortho_init</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_ortho_init</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">partition_info</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1">#lasagne ortho init for tf</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">flat_shape</span> <span class="o">=</span> <span class="n">shape</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span> <span class="c1"># assumes NHWC</span>
            <span class="n">flat_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">flat_shape</span><span class="p">)</span>
        <span class="n">u</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">u</span> <span class="k">if</span> <span class="n">u</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">flat_shape</span> <span class="k">else</span> <span class="n">v</span> <span class="c1"># pick the one with the correct shape</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">scale</span> <span class="o">*</span> <span class="n">q</span><span class="p">[:</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_ortho_init</span></code></pre></div><p><b>6. Adam learning rate annealing</b></p><p>在不同的learning epoch使用不断减小的学习率。</p><div class="highlight"><pre><code class="language-python3"><span class="n">cur_lrmult</span> <span class="o">=</span>  <span class="nb">max</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="nb">float</span><span class="p">(</span><span class="n">timesteps_so_far</span><span class="p">)</span> <span class="o">/</span> <span class="n">max_timesteps</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">adam</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">optim_stepsize</span> <span class="o">*</span> <span class="n">cur_lrmult</span><span class="p">)</span></code></pre></div><p><b>7. PPO clip parameter annealing</b></p><p>和上面类似，对于PPO的参数也使用这样的clipping。</p><div class="highlight"><pre><code class="language-python3"><span class="n">cur_lrmult</span> <span class="o">=</span>  <span class="nb">max</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="nb">float</span><span class="p">(</span><span class="n">timesteps_so_far</span><span class="p">)</span> <span class="o">/</span> <span class="n">max_timesteps</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">clip_param</span> <span class="o">=</span> <span class="n">clip_param</span> <span class="o">*</span> <span class="n">lrmult</span>
<span class="n">surr2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">ratio</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">clip_param</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">+</span> <span class="n">clip_param</span><span class="p">)</span> <span class="o">*</span> <span class="n">atarg</span></code></pre></div><p><b>8. 神经网络结构</b></p><div class="highlight"><pre><code class="language-text">hid_size=64
num_hid_layers=2

value network:
    MLP1 tanh(obs_dim, hid_size) init=normc(1.0)
    MLP2 tanh(hid_size, hid_size) init=normc(1.0)
    MLP3 linear(hid_size, 1) init=norm(1.0)
policy network:
    MLP1 tanh(obs_dim, hid_size) init=normc(1.0)
    MLP2 tanh(hid_size, hid_size) init=normc(1.0)
    MLP3 tanh(hid_size, act_dim) init=normc(0.01)  --&gt; mean
    Variable logstd init=zeros                     --&gt; logstd</code></pre></div><h2><b>实现的结果</b></h2><p>最后我实现的结果如下，其中蓝线是运行baselines算法得到的曲线（单次运行），橙线是运行我复现的PPO算法得到的曲线（用不同的随机数种子运行五次取平均）。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-c88e188d9413dab181a387dbb2df7c00_b.jpg" data-caption="" data-size="normal" data-rawwidth="1008" data-rawheight="419" class="origin_image zh-lightbox-thumb" width="1008" data-original="https://pic1.zhimg.com/v2-c88e188d9413dab181a387dbb2df7c00_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1008&#39; height=&#39;419&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1008" data-rawheight="419" class="origin_image zh-lightbox-thumb lazy" width="1008" data-original="https://pic1.zhimg.com/v2-c88e188d9413dab181a387dbb2df7c00_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-c88e188d9413dab181a387dbb2df7c00_b.jpg"/></figure><h2><b>不同小技巧的效果对比（Ablation Study）</b></h2><p>可以看到对于advantage和observation的归一化对于算法的性能影响是比较大的，其他方面影响倒不是很大，这一点和文献[1]里面的结果有一些区别。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-9817a2b6fb4256b41be6568a3079e67c_b.jpg" data-caption="" data-size="normal" data-rawwidth="920" data-rawheight="383" class="origin_image zh-lightbox-thumb" width="920" data-original="https://pic1.zhimg.com/v2-9817a2b6fb4256b41be6568a3079e67c_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;920&#39; height=&#39;383&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="920" data-rawheight="383" class="origin_image zh-lightbox-thumb lazy" width="920" data-original="https://pic1.zhimg.com/v2-9817a2b6fb4256b41be6568a3079e67c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-9817a2b6fb4256b41be6568a3079e67c_b.jpg"/></figure><h2><b>代码</b></h2><p>欢迎大家来围观我复现的代码，这里用不到400行代码达到了和baselines一样的性能。</p><a target="_blank" href="https://link.zhihu.com/?target=https%3A//github.com/zhangchuheng123/Reinforcement-Implementation/blob/master/code/ppo.py" data-draft-node="block" data-draft-type="link-card" class="LinkCard LinkCard--noImage"><span class="LinkCard-content"><span class="LinkCard-text"><span class="LinkCard-title" data-text="true">https://github.com/zhangchuheng123/Reinforcement-Implementation/blob/master/code/ppo.py</span><span class="LinkCard-meta"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--InsertLink" fill="currentColor" viewBox="0 0 24 24" width="17" height="17"><path d="M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z" fill-rule="evenodd"></path></svg></span>github.com</span></span><span class="LinkCard-imageCell"><div class="LinkCard-image LinkCard-image--default"><svg class="Zi Zi--Browser" fill="currentColor" viewBox="0 0 24 24" width="32" height="32"><path d="M11.991 3C7.023 3 3 7.032 3 12s4.023 9 8.991 9C16.968 21 21 16.968 21 12s-4.032-9-9.009-9zm6.237 5.4h-2.655a14.084 14.084 0 0 0-1.242-3.204A7.227 7.227 0 0 1 18.228 8.4zM12 4.836A12.678 12.678 0 0 1 13.719 8.4h-3.438A12.678 12.678 0 0 1 12 4.836zM5.034 13.8A7.418 7.418 0 0 1 4.8 12c0-.621.09-1.224.234-1.8h3.042A14.864 14.864 0 0 0 7.95 12c0 .612.054 1.206.126 1.8H5.034zm.738 1.8h2.655a14.084 14.084 0 0 0 1.242 3.204A7.188 7.188 0 0 1 5.772 15.6zm2.655-7.2H5.772a7.188 7.188 0 0 1 3.897-3.204c-.54.999-.954 2.079-1.242 3.204zM12 19.164a12.678 12.678 0 0 1-1.719-3.564h3.438A12.678 12.678 0 0 1 12 19.164zm2.106-5.364H9.894A13.242 13.242 0 0 1 9.75 12c0-.612.063-1.215.144-1.8h4.212c.081.585.144 1.188.144 1.8 0 .612-.063 1.206-.144 1.8zm.225 5.004c.54-.999.954-2.079 1.242-3.204h2.655a7.227 7.227 0 0 1-3.897 3.204zm1.593-5.004c.072-.594.126-1.188.126-1.8 0-.612-.054-1.206-.126-1.8h3.042c.144.576.234 1.179.234 1.8s-.09 1.224-.234 1.8h-3.042z"></path></svg></div></span></span></a><p class="ztext-empty-paragraph"><br/></p><hr/><p>参考资料</p><p>[1] Ilyas, Andrew, et al. &#34;Are Deep Policy Gradient Algorithms Truly Policy Gradient Algorithms?.&#34;<i>arXiv preprint arXiv:1811.02553</i>(2018).</p><p>[2] <a href="https://link.zhihu.com/?target=https%3A//github.com/Jiankai-Sun/Proximal-Policy-Optimization-in-Pytorch/blob/master/ppo.py" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">github.com/Jiankai-Sun/</span><span class="invisible">Proximal-Policy-Optimization-in-Pytorch/blob/master/ppo.py</span><span class="ellipsis"></span></a></p><p>[3] Glorot, Xavier, and Yoshua Bengio. &#34;Understanding the difficulty of training deep feedforward neural networks.&#34;<i>Proceedings of the thirteenth international conference on artificial intelligence and statistics</i>. 2010.</p><p>[4] Saxe, Andrew M., James L. McClelland, and Surya Ganguli. &#34;Exact solutions to the nonlinear dynamics of learning in deep linear neural networks.&#34;<i>arXiv preprint arXiv:1312.6120</i>(2013).</p><hr/><h2><b>不同Mujoco环境里面的奖励函数的计算方法</b></h2><p>做实验的时候也不能把环境和任务当做一个黑盒子搞呀，还是要注意看看现在训练的究竟是个什么任务。而奖励的计算则尤为重要，因此，我还专门去统计了一个各个环境的奖励函数是如何算出来的。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-b80b9a45c576cc3f33ed9cd5cc5805bc_b.jpg" data-caption="" data-size="normal" data-rawwidth="996" data-rawheight="557" class="origin_image zh-lightbox-thumb" width="996" data-original="https://pic1.zhimg.com/v2-b80b9a45c576cc3f33ed9cd5cc5805bc_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;996&#39; height=&#39;557&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="996" data-rawheight="557" class="origin_image zh-lightbox-thumb lazy" width="996" data-original="https://pic1.zhimg.com/v2-b80b9a45c576cc3f33ed9cd5cc5805bc_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-b80b9a45c576cc3f33ed9cd5cc5805bc_b.jpg"/></figure><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-06ff2115da23de8acd4986241af90f8e_b.jpg" data-caption="" data-size="normal" data-rawwidth="698" data-rawheight="383" class="origin_image zh-lightbox-thumb" width="698" data-original="https://pic3.zhimg.com/v2-06ff2115da23de8acd4986241af90f8e_r.jpg"/><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;698&#39; height=&#39;383&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="698" data-rawheight="383" class="origin_image zh-lightbox-thumb lazy" width="698" data-original="https://pic3.zhimg.com/v2-06ff2115da23de8acd4986241af90f8e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-06ff2115da23de8acd4986241af90f8e_b.jpg"/></figure><p></p></div></div><div class="ContentItem-time">编辑于 2018-12-08</div><div class="Post-topicsAndReviewer"><div class="TopicList Post-Topics"><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/19553510" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">算法</div></div></a></span></div><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/20039099" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习 (Reinforcement Learning)</div></div></a></span></div></div></div><div><div class="Sticky RichContent-actions is-bottom"><div class="ContentItem-actions"><span><button aria-label="赞同 44 " type="button" class="Button VoteButton VoteButton--up"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleUp VoteButton-TriangleUp" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M2 18.242c0-.326.088-.532.237-.896l7.98-13.203C10.572 3.57 11.086 3 12 3c.915 0 1.429.571 1.784 1.143l7.98 13.203c.15.364.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H3.955c-1.08 0-1.955-.517-1.955-1.9z" fill-rule="evenodd"></path></svg></span>赞同 44</button><button aria-label="反对" type="button" class="Button VoteButton VoteButton--down"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleDown" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M20.044 3H3.956C2.876 3 2 3.517 2 4.9c0 .326.087.533.236.896L10.216 19c.355.571.87 1.143 1.784 1.143s1.429-.572 1.784-1.143l7.98-13.204c.149-.363.236-.57.236-.896 0-1.386-.876-1.9-1.956-1.9z" fill-rule="evenodd"></path></svg></span></button></span><button type="button" class="Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Comment Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M10.241 19.313a.97.97 0 0 0-.77.2 7.908 7.908 0 0 1-3.772 1.482.409.409 0 0 1-.38-.637 5.825 5.825 0 0 0 1.11-2.237.605.605 0 0 0-.227-.59A7.935 7.935 0 0 1 3 11.25C3 6.7 7.03 3 12 3s9 3.7 9 8.25-4.373 9.108-10.759 8.063z" fill-rule="evenodd"></path></svg></span>30 条评论</button><div class="Popover ShareMenu"><div class="ShareMenu-toggler" id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Share Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2.931 7.89c-1.067.24-1.275 1.669-.318 2.207l5.277 2.908 8.168-4.776c.25-.127.477.198.273.39L9.05 14.66l.927 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.242c.584-.892-.212-2.029-1.234-1.796L2.93 7.89z" fill-rule="evenodd"></path></svg></span>分享</button></div></div><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Heart Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2 8.437C2 5.505 4.294 3.094 7.207 3 9.243 3 11.092 4.19 12 6c.823-1.758 2.649-3 4.651-3C19.545 3 22 5.507 22 8.432 22 16.24 13.842 21 12 21 10.158 21 2 16.24 2 8.437z" fill-rule="evenodd"></path></svg></span>喜欢</button><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Star Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5.515 19.64l.918-5.355-3.89-3.792c-.926-.902-.639-1.784.64-1.97L8.56 7.74l2.404-4.871c.572-1.16 1.5-1.16 2.072 0L15.44 7.74l5.377.782c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.219 1.274-.532 1.82-1.676 1.218L12 18.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z" fill-rule="evenodd"></path></svg></span>收藏</button><div class="Post-ActionMenuButton"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Dots Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5 14a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4z" fill-rule="evenodd"></path></svg></span></button></div></div></div></div></div></div></article><div class="Post-Sub Post-NormalSub"><div class="PostIndex-Contributions"><h3 class="BlockTitle">文章被以下专栏收录</h3><ul><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><img class="Avatar Avatar--medium Avatar--round" width="40" height="40" src="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_xs.jpg" srcSet="https://pic2.zhimg.com/v2-5d1f04a84f6be8896c07a32a05e1d6d1_l.jpg 2x" alt="强化学习前沿"/></div></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><a class="ColumnLink ColumnItem-Title" href="/reinforcementlearning"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">强化学习前沿</div></div></a></h2><div class="ContentItem-meta">读呀读paper</div></div><div class="ContentItem-extra"><a href="/reinforcementlearning" type="button" class="Button">进入专栏</a></div></div></div></ul></div></div></div></main></div></div><script nonce="3d07ea2a-7816-4181-be02-2205580227d4" async="" src="https://www.googletagmanager.com/gtag/js?id=UA-149949619-1"></script><script nonce="3d07ea2a-7816-4181-be02-2205580227d4">function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-149949619-1");</script><script id="js-clientConfig" type="text/json">{"host":"zhihu.com","protocol":"https:","wwwHost":"www.zhihu.com","fetchRoot":{"www":"https:\u002F\u002Fwww.zhihu.com","api":"https:\u002F\u002Fapi.zhihu.com","zhuanlan":"https:\u002F\u002Fzhuanlan.zhihu.com"}}</script><script id="js-initialData" type="text/json">{"initialState":{"common":{"ask":{}},"loading":{"global":{"count":0},"local":{"env\u002FgetIpinfo\u002F":false,"article\u002Fget\u002F":false,"brand\u002FgetUrl\u002F":false}},"club":{"tags":{}},"entities":{"users":{"zhang-chu-heng":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"清华大学 交叉信息院博士在读"}],"exposedMedal":{"medalId":"1124316222665379841","medalName":"我的知乎 2019","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2592b0b52e1fac99f69b38e00252413b_r.png","miniAvatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ad363cc3088dc8de7544fd08b1c4987a_is.png","description":"参与「我的知乎 2019」即可获得"}}},"questions":{},"answers":{},"articles":{"50322028":{"trackUrl":["https:\u002F\u002Fsugar.zhihu.com\u002Fplutus_adreaper\u002Fpage_monitor_log?si=__SESSIONID__&ti=__ATOKEN__&at=view&pf=__OS__&ed=__MEMBERID__&idfa=__IDFA__&imei=__IMEI__&androidid=__ANDROIDID__&oaid=__OAID__&ci=__CREATIVEID__"],"id":50322028,"title":"【强化学习实践 30】复现PPO","type":"article","excerptTitle":"","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F50322028","imageUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-9a8b3231d89fc41c9fdbdb28590dba32_b.jpg","titleImage":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-9a8b3231d89fc41c9fdbdb28590dba32_b.jpg","excerpt":"\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-769f0975ef21d9bd9a63f60bb1a3a7e9_200x112.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1008\" data-rawheight=\"419\" data-watermark=\"watermark\" data-original-src=\"v2-769f0975ef21d9bd9a63f60bb1a3a7e9\" data-watermark-src=\"v2-c88e188d9413dab181a387dbb2df7c00\" data-private-watermark-src=\"\" class=\"origin_image inline-img zh-lightbox-thumb\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-769f0975ef21d9bd9a63f60bb1a3a7e9_r.jpg\"\u002F\u003E\u003Cb\u003E序言\u003C\u002Fb\u003E讲了好多强化学习的paper了，下面是时候仔细考虑一下Implementation matters这句话了。这些常见的算法都有已经调好参数的程序，大家可以直接跑，就在\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002Fopenai\u002Fbaselines\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E[github]openai.baselines\u003C\u002Fa\u003E。如果只是为了跑一个对照试验的话，直接使用别人实现的代码就可以了。但是…","created":1542888692,"updated":1544235615,"author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"清华大学 交叉信息院博士在读"}],"exposedMedal":{"medalId":"1124316222665379841","medalName":"我的知乎 2019","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2592b0b52e1fac99f69b38e00252413b_r.png","miniAvatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ad363cc3088dc8de7544fd08b1c4987a_is.png","description":"参与「我的知乎 2019」即可获得"}},"commentPermission":"all","state":"published","imageWidth":1069,"imageHeight":736,"content":"\u003Ch2\u003E\u003Cb\u003E序言\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E讲了好多强化学习的paper了，下面是时候仔细考虑一下Implementation matters这句话了。这些常见的算法都有已经调好参数的程序，大家可以直接跑，就在\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002Fopenai\u002Fbaselines\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E[github]openai.baselines\u003C\u002Fa\u003E。如果只是为了跑一个对照试验的话，直接使用别人实现的代码就可以了。但是我们对于更多的东西感兴趣，比如，究竟要如何实现一个高性能的算法？有哪些（文章里面不会提到的）小技巧导致我们实现的算法性能低甚至崩溃？\u003C\u002Fp\u003E\u003Ch2\u003E\u003Cb\u003E各种实现小技巧的调研\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E首先要知己知彼才可以，我们先通读baselines代码，看看究竟这里面包含了哪些文章里面没有提到的内容。另外也参考了文献[1]里面提到的一些技巧。（注，现在baselines里面的ppo1是马上要弃用了的，但是我当时不知道，主要调研的ppo1，现在更新了多进程版本的ppo2；不过最后实践表明我实现的算法与ppo2跑出来的效果差不多）\u003C\u002Fp\u003E\u003Col\u003E\u003Cli\u003E\u003Cb\u003E超参数设置\u003C\u002Fb\u003E\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Cdiv class=\"highlight\"\u003E\u003Cpre\u003E\u003Ccode class=\"language-python3\"\u003E\u003Cspan class=\"c1\"\u003E# 最多采样多少步，可以用户设定\u003C\u002Fspan\u003E\n\u003Cspan class=\"n\"\u003Emax_timesteps\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"mf\"\u003E2e7\u003C\u002Fspan\u003E \n\u003Cspan class=\"c1\"\u003E# 每个batch采样多少步，里面可能包含很多回合的终点，然后起点开始继续采样，直到凑够\u003C\u002Fspan\u003E\n\u003Cspan class=\"n\"\u003Etimesteps_per_actorbatch\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"mi\"\u003E2048\u003C\u002Fspan\u003E   \n\u003Cspan class=\"c1\"\u003E# PPO的clip参数\u003C\u002Fspan\u003E\n\u003Cspan class=\"n\"\u003Eclip_param\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"mf\"\u003E0.2\u003C\u002Fspan\u003E\n\u003Cspan class=\"c1\"\u003E# 交叉熵项系数\u003C\u002Fspan\u003E\n\u003Cspan class=\"n\"\u003Eentcoeff\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"mf\"\u003E0.0\u003C\u002Fspan\u003E\n\u003Cspan class=\"c1\"\u003E# 每次采集一个batch的样本之后过几遍\u003C\u002Fspan\u003E\n\u003Cspan class=\"n\"\u003Eoptim_epochs\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"mi\"\u003E10\u003C\u002Fspan\u003E \n\u003Cspan class=\"c1\"\u003E# Adam学习率 \u003C\u002Fspan\u003E\n\u003Cspan class=\"n\"\u003Eoptim_stepsize\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"mf\"\u003E3e-4\u003C\u002Fspan\u003E\n\u003Cspan class=\"c1\"\u003E# 优化用的minibatch size\u003C\u002Fspan\u003E\n\u003Cspan class=\"n\"\u003Eoptim_batchsize\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"mi\"\u003E64\u003C\u002Fspan\u003E\n\u003Cspan class=\"c1\"\u003E# discount rate\u003C\u002Fspan\u003E\n\u003Cspan class=\"n\"\u003Egamma\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"mf\"\u003E0.99\u003C\u002Fspan\u003E\n\u003Cspan class=\"c1\"\u003E# GAE parameter\u003C\u002Fspan\u003E\n\u003Cspan class=\"n\"\u003Elam\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"mf\"\u003E0.95\u003C\u002Fspan\u003E \n\u003Cspan class=\"n\"\u003Eadam_epsilon\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"mf\"\u003E1e-5\u003C\u002Fspan\u003E  \n\u003Cspan class=\"n\"\u003Eschedule\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"s1\"\u003E&#39;linear&#39;\u003C\u002Fspan\u003E\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003Cp\u003E\u003Cb\u003E2. observation normalization and clipping\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cdiv class=\"highlight\"\u003E\u003Cpre\u003E\u003Ccode class=\"language-python3\"\u003E\u003Cspan class=\"n\"\u003Etf\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eclip_by_value\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E((\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eob\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E-\u003C\u002Fspan\u003E \u003Cspan class=\"bp\"\u003Eself\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eob_rms\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Emean\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E\u002F\u003C\u002Fspan\u003E \u003Cspan class=\"bp\"\u003Eself\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eob_rms\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Estd\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E-\u003C\u002Fspan\u003E\u003Cspan class=\"mf\"\u003E5.0\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"mf\"\u003E5.0\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003Cp\u003E即归一化到(0,1)高斯分布，然后再clip掉偏离比较远的。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E3. value function clipping\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E在参考资料[1]和[2]里面都提到了要类似策略的损失函数一样对价值函数的损失函数做类似的clip。但是我在openai.baselines.ppo1里面并没有找到相应的实现。况且参考资料[1]里面也说了这个技巧没啥效果。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E4. reward scaling \u002F clipping\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E同样，在文献[1]里面提到了这个技巧，不过我没有在openai.baselines.ppo1里找到。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E5. orthogonal initialization and layer scaling\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E一般的神经网络实现（TensorFlow、PyTorch等）一般默认xavier初始化[3]，但是在强化学习里面一般都在使用正交初始化[4]。\u003C\u002Fp\u003E\u003Cp\u003E在openai.baselines.ppo1里面是独立的正态分布生成权重，然后每一行做归一化\u003C\u002Fp\u003E\u003Cdiv class=\"highlight\"\u003E\u003Cpre\u003E\u003Ccode class=\"language-python3\"\u003E\u003Cspan class=\"k\"\u003Edef\u003C\u002Fspan\u003E \u003Cspan class=\"nf\"\u003Enormc_initializer\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Estd\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"mf\"\u003E1.0\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Eaxis\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"mi\"\u003E0\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E):\u003C\u002Fspan\u003E\n    \u003Cspan class=\"k\"\u003Edef\u003C\u002Fspan\u003E \u003Cspan class=\"nf\"\u003E_initializer\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eshape\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Edtype\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"kc\"\u003ENone\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Epartition_info\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"kc\"\u003ENone\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E):\u003C\u002Fspan\u003E  \u003Cspan class=\"c1\"\u003E# pylint: disable=W0613\u003C\u002Fspan\u003E\n        \u003Cspan class=\"n\"\u003Eout\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Enp\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Erandom\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Erandn\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E*\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eshape\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eastype\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Edtype\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eas_numpy_dtype\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E\n        \u003Cspan class=\"n\"\u003Eout\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E*=\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Estd\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E\u002F\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Enp\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Esqrt\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Enp\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Esquare\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eout\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"nb\"\u003Esum\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eaxis\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eaxis\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Ekeepdims\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"kc\"\u003ETrue\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E))\u003C\u002Fspan\u003E\n        \u003Cspan class=\"k\"\u003Ereturn\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Etf\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Econstant\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eout\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E\n    \u003Cspan class=\"k\"\u003Ereturn\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003E_initializer\u003C\u002Fspan\u003E\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003Cp\u003E在openai.baselines.ppo2里面是利用SVD分解来做的\u003C\u002Fp\u003E\u003Cdiv class=\"highlight\"\u003E\u003Cpre\u003E\u003Ccode class=\"language-python3\"\u003E\u003Cspan class=\"n\"\u003Ew\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Etf\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eget_variable\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"s2\"\u003E&#34;w&#34;\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"p\"\u003E[\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Enin\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Enh\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E],\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Einitializer\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eortho_init\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Einit_scale\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E))\u003C\u002Fspan\u003E\n\u003Cspan class=\"n\"\u003Eb\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Etf\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eget_variable\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"s2\"\u003E&#34;b&#34;\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"p\"\u003E[\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Enh\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E],\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Einitializer\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Etf\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Econstant_initializer\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Einit_bias\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E))\u003C\u002Fspan\u003E\n\n\n\u003Cspan class=\"k\"\u003Edef\u003C\u002Fspan\u003E \u003Cspan class=\"nf\"\u003Eortho_init\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Escale\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"mf\"\u003E1.0\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E):\u003C\u002Fspan\u003E\n    \u003Cspan class=\"k\"\u003Edef\u003C\u002Fspan\u003E \u003Cspan class=\"nf\"\u003E_ortho_init\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eshape\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Edtype\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Epartition_info\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"kc\"\u003ENone\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E):\u003C\u002Fspan\u003E\n        \u003Cspan class=\"c1\"\u003E#lasagne ortho init for tf\u003C\u002Fspan\u003E\n        \u003Cspan class=\"n\"\u003Eshape\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E \u003Cspan class=\"nb\"\u003Etuple\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eshape\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E\n        \u003Cspan class=\"k\"\u003Eif\u003C\u002Fspan\u003E \u003Cspan class=\"nb\"\u003Elen\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eshape\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E==\u003C\u002Fspan\u003E \u003Cspan class=\"mi\"\u003E2\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E:\u003C\u002Fspan\u003E\n            \u003Cspan class=\"n\"\u003Eflat_shape\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Eshape\u003C\u002Fspan\u003E\n        \u003Cspan class=\"k\"\u003Eelif\u003C\u002Fspan\u003E \u003Cspan class=\"nb\"\u003Elen\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eshape\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E==\u003C\u002Fspan\u003E \u003Cspan class=\"mi\"\u003E4\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E:\u003C\u002Fspan\u003E \u003Cspan class=\"c1\"\u003E# assumes NHWC\u003C\u002Fspan\u003E\n            \u003Cspan class=\"n\"\u003Eflat_shape\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E \u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Enp\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eprod\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eshape\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E[:\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E-\u003C\u002Fspan\u003E\u003Cspan class=\"mi\"\u003E1\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E]),\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Eshape\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E[\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E-\u003C\u002Fspan\u003E\u003Cspan class=\"mi\"\u003E1\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E])\u003C\u002Fspan\u003E\n        \u003Cspan class=\"k\"\u003Eelse\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E:\u003C\u002Fspan\u003E\n            \u003Cspan class=\"k\"\u003Eraise\u003C\u002Fspan\u003E \u003Cspan class=\"ne\"\u003ENotImplementedError\u003C\u002Fspan\u003E\n        \u003Cspan class=\"n\"\u003Ea\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Enp\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Erandom\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Enormal\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"mf\"\u003E0.0\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"mf\"\u003E1.0\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Eflat_shape\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E\n        \u003Cspan class=\"n\"\u003Eu\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003E_\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Ev\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Enp\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Elinalg\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Esvd\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Ea\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Efull_matrices\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"kc\"\u003EFalse\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E\n        \u003Cspan class=\"n\"\u003Eq\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Eu\u003C\u002Fspan\u003E \u003Cspan class=\"k\"\u003Eif\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Eu\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eshape\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E==\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Eflat_shape\u003C\u002Fspan\u003E \u003Cspan class=\"k\"\u003Eelse\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Ev\u003C\u002Fspan\u003E \u003Cspan class=\"c1\"\u003E# pick the one with the correct shape\u003C\u002Fspan\u003E\n        \u003Cspan class=\"n\"\u003Eq\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Eq\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Ereshape\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eshape\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E\n        \u003Cspan class=\"k\"\u003Ereturn\u003C\u002Fspan\u003E \u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Escale\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E*\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Eq\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E[:\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eshape\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E[\u003C\u002Fspan\u003E\u003Cspan class=\"mi\"\u003E0\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E],\u003C\u002Fspan\u003E \u003Cspan class=\"p\"\u003E:\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eshape\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E[\u003C\u002Fspan\u003E\u003Cspan class=\"mi\"\u003E1\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E]])\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eastype\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Enp\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Efloat32\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E\n    \u003Cspan class=\"k\"\u003Ereturn\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003E_ortho_init\u003C\u002Fspan\u003E\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003Cp\u003E\u003Cb\u003E6. Adam learning rate annealing\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E在不同的learning epoch使用不断减小的学习率。\u003C\u002Fp\u003E\u003Cdiv class=\"highlight\"\u003E\u003Cpre\u003E\u003Ccode class=\"language-python3\"\u003E\u003Cspan class=\"n\"\u003Ecur_lrmult\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E  \u003Cspan class=\"nb\"\u003Emax\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"mf\"\u003E1.0\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E-\u003C\u002Fspan\u003E \u003Cspan class=\"nb\"\u003Efloat\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Etimesteps_so_far\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E\u002F\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Emax_timesteps\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"mi\"\u003E0\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E\n\u003Cspan class=\"n\"\u003Eadam\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eupdate\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eg\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Eoptim_stepsize\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E*\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Ecur_lrmult\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003Cp\u003E\u003Cb\u003E7. PPO clip parameter annealing\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E和上面类似，对于PPO的参数也使用这样的clipping。\u003C\u002Fp\u003E\u003Cdiv class=\"highlight\"\u003E\u003Cpre\u003E\u003Ccode class=\"language-python3\"\u003E\u003Cspan class=\"n\"\u003Ecur_lrmult\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E  \u003Cspan class=\"nb\"\u003Emax\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"mf\"\u003E1.0\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E-\u003C\u002Fspan\u003E \u003Cspan class=\"nb\"\u003Efloat\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Etimesteps_so_far\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E\u002F\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Emax_timesteps\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"mi\"\u003E0\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E\n\u003Cspan class=\"n\"\u003Eclip_param\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Eclip_param\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E*\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Elrmult\u003C\u002Fspan\u003E\n\u003Cspan class=\"n\"\u003Esurr2\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Etf\u003C\u002Fspan\u003E\u003Cspan class=\"o\"\u003E.\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eclip_by_value\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Eratio\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"mf\"\u003E1.0\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E-\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Eclip_param\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"mf\"\u003E1.0\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E+\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Eclip_param\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E*\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Eatarg\u003C\u002Fspan\u003E\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003Cp\u003E\u003Cb\u003E8. 神经网络结构\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cdiv class=\"highlight\"\u003E\u003Cpre\u003E\u003Ccode class=\"language-text\"\u003Ehid_size=64\nnum_hid_layers=2\n\nvalue network:\n    MLP1 tanh(obs_dim, hid_size) init=normc(1.0)\n    MLP2 tanh(hid_size, hid_size) init=normc(1.0)\n    MLP3 linear(hid_size, 1) init=norm(1.0)\npolicy network:\n    MLP1 tanh(obs_dim, hid_size) init=normc(1.0)\n    MLP2 tanh(hid_size, hid_size) init=normc(1.0)\n    MLP3 tanh(hid_size, act_dim) init=normc(0.01)  --&gt; mean\n    Variable logstd init=zeros                     --&gt; logstd\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003Ch2\u003E\u003Cb\u003E实现的结果\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E最后我实现的结果如下，其中蓝线是运行baselines算法得到的曲线（单次运行），橙线是运行我复现的PPO算法得到的曲线（用不同的随机数种子运行五次取平均）。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-c88e188d9413dab181a387dbb2df7c00_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1008\" data-rawheight=\"419\" class=\"origin_image zh-lightbox-thumb\" width=\"1008\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-c88e188d9413dab181a387dbb2df7c00_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1008&#39; height=&#39;419&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1008\" data-rawheight=\"419\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1008\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-c88e188d9413dab181a387dbb2df7c00_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-c88e188d9413dab181a387dbb2df7c00_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Ch2\u003E\u003Cb\u003E不同小技巧的效果对比（Ablation Study）\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E可以看到对于advantage和observation的归一化对于算法的性能影响是比较大的，其他方面影响倒不是很大，这一点和文献[1]里面的结果有一些区别。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-9817a2b6fb4256b41be6568a3079e67c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"920\" data-rawheight=\"383\" class=\"origin_image zh-lightbox-thumb\" width=\"920\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-9817a2b6fb4256b41be6568a3079e67c_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;920&#39; height=&#39;383&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"920\" data-rawheight=\"383\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"920\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-9817a2b6fb4256b41be6568a3079e67c_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-9817a2b6fb4256b41be6568a3079e67c_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Ch2\u003E\u003Cb\u003E代码\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E欢迎大家来围观我复现的代码，这里用不到400行代码达到了和baselines一样的性能。\u003C\u002Fp\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002Fzhangchuheng123\u002FReinforcement-Implementation\u002Fblob\u002Fmaster\u002Fcode\u002Fppo.py\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E\u003Cspan class=\"invisible\"\u003Ehttps:\u002F\u002F\u003C\u002Fspan\u003E\u003Cspan class=\"visible\"\u003Egithub.com\u002Fzhangchuheng\u003C\u002Fspan\u003E\u003Cspan class=\"invisible\"\u003E123\u002FReinforcement-Implementation\u002Fblob\u002Fmaster\u002Fcode\u002Fppo.py\u003C\u002Fspan\u003E\u003Cspan class=\"ellipsis\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Chr\u002F\u003E\u003Cp\u003E参考资料\u003C\u002Fp\u003E\u003Cp\u003E[1] Ilyas, Andrew, et al. &#34;Are Deep Policy Gradient Algorithms Truly Policy Gradient Algorithms?.&#34;\u003Ci\u003EarXiv preprint arXiv:1811.02553\u003C\u002Fi\u003E(2018).\u003C\u002Fp\u003E\u003Cp\u003E[2] \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002FJiankai-Sun\u002FProximal-Policy-Optimization-in-Pytorch\u002Fblob\u002Fmaster\u002Fppo.py\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E\u003Cspan class=\"invisible\"\u003Ehttps:\u002F\u002F\u003C\u002Fspan\u003E\u003Cspan class=\"visible\"\u003Egithub.com\u002FJiankai-Sun\u002F\u003C\u002Fspan\u003E\u003Cspan class=\"invisible\"\u003EProximal-Policy-Optimization-in-Pytorch\u002Fblob\u002Fmaster\u002Fppo.py\u003C\u002Fspan\u003E\u003Cspan class=\"ellipsis\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cp\u003E[3] Glorot, Xavier, and Yoshua Bengio. &#34;Understanding the difficulty of training deep feedforward neural networks.&#34;\u003Ci\u003EProceedings of the thirteenth international conference on artificial intelligence and statistics\u003C\u002Fi\u003E. 2010.\u003C\u002Fp\u003E\u003Cp\u003E[4] Saxe, Andrew M., James L. McClelland, and Surya Ganguli. &#34;Exact solutions to the nonlinear dynamics of learning in deep linear neural networks.&#34;\u003Ci\u003EarXiv preprint arXiv:1312.6120\u003C\u002Fi\u003E(2013).\u003C\u002Fp\u003E\u003Chr\u002F\u003E\u003Ch2\u003E\u003Cb\u003E不同Mujoco环境里面的奖励函数的计算方法\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E做实验的时候也不能把环境和任务当做一个黑盒子搞呀，还是要注意看看现在训练的究竟是个什么任务。而奖励的计算则尤为重要，因此，我还专门去统计了一个各个环境的奖励函数是如何算出来的。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b80b9a45c576cc3f33ed9cd5cc5805bc_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"996\" data-rawheight=\"557\" class=\"origin_image zh-lightbox-thumb\" width=\"996\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b80b9a45c576cc3f33ed9cd5cc5805bc_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;996&#39; height=&#39;557&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"996\" data-rawheight=\"557\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"996\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b80b9a45c576cc3f33ed9cd5cc5805bc_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b80b9a45c576cc3f33ed9cd5cc5805bc_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-06ff2115da23de8acd4986241af90f8e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"698\" data-rawheight=\"383\" class=\"origin_image zh-lightbox-thumb\" width=\"698\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-06ff2115da23de8acd4986241af90f8e_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;698&#39; height=&#39;383&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"698\" data-rawheight=\"383\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"698\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-06ff2115da23de8acd4986241af90f8e_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-06ff2115da23de8acd4986241af90f8e_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003C\u002Fp\u003E","adminClosedComment":false,"topics":[{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F19553510","type":"topic","id":"19553510","name":"算法"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F20039099","type":"topic","id":"20039099","name":"强化学习 (Reinforcement Learning)"}],"voteupCount":44,"voting":0,"column":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"},"commentCount":30,"contributions":[{"id":2543011,"state":"accepted","type":"first_publish","column":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}}],"isTitleImageFullScreen":false,"upvotedFollowees":[],"commercialInfo":{"isCommercial":false,"plugin":{}},"suggestEdit":{"status":false,"reason":"","tip":"","url":"","title":""},"reason":"","annotationAction":[],"canTip":false,"tipjarorsCount":0,"isLabeled":false,"hasPublishingDraft":false,"isFavorited":false,"isNormal":true,"status":0,"shareText":"【强化学习实践 30】复现PPO - 来自知乎专栏「强化学习前沿」，作者: 张楚珩 https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F50322028 （想看更多？下载 @知乎 App：http:\u002F\u002Fweibo.com\u002Fp\u002F100404711598 ）","canComment":{"status":true,"reason":""},"mcnFpShow":-1,"isVisible":true,"isLiked":false,"likedCount":0,"visibleOnlyToAuthor":false}},"columns":{"reinforcementlearning":{"description":"读呀读paper","canManage":false,"intro":"我们的目标是通用人工智能！","isFollowing":false,"urlToken":"reinforcementlearning","id":"reinforcementlearning","articlesCount":137,"acceptSubmission":true,"title":"强化学习前沿","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Freinforcementlearning","commentPermission":"all","created":1537150763,"updated":1541142463,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5d1f04a84f6be8896c07a32a05e1d6d1_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_{size}.jpg","uid":"35077274730496","userType":"people","isFollowing":false,"urlToken":"zhang-chu-heng","id":"db39e3e0528520071b0a6e5f6240cfea","description":"","name":"张楚珩","isAdvertiser":false,"headline":"强化学习 量化投资","gender":1,"url":"\u002Fpeople\u002Fdb39e3e0528520071b0a6e5f6240cfea","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2b7c11f27a7fd03282819889435815aa_l.jpg","isOrg":false,"type":"people"},"followers":4344,"type":"column"}},"topics":{},"roundtables":{},"favlists":{},"comments":{},"notifications":{},"ebooks":{},"activities":{},"feeds":{},"pins":{},"promotions":{},"drafts":{},"chats":{},"posts":{},"clubs":{},"clubTags":{}},"currentUser":"","account":{"lockLevel":{},"unlockTicketStatus":false,"unlockTicket":null,"challenge":[],"errorStatus":false,"message":"","isFetching":false,"accountInfo":{},"urlToken":{"loading":false}},"settings":{"socialBind":null,"inboxMsg":null,"notification":{},"email":{},"privacyFlag":null,"blockedUsers":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"blockedFollowees":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"ignoredTopics":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"restrictedTopics":null,"laboratory":{}},"notification":{},"people":{"profileStatus":{},"activitiesByUser":{},"answersByUser":{},"answersSortByVotesByUser":{},"answersIncludedByUser":{},"votedAnswersByUser":{},"thankedAnswersByUser":{},"voteAnswersByUser":{},"thankAnswersByUser":{},"topicAnswersByUser":{},"zvideosByUser":{},"articlesByUser":{},"articlesSortByVotesByUser":{},"articlesIncludedByUser":{},"pinsByUser":{},"questionsByUser":{},"commercialQuestionsByUser":{},"favlistsByUser":{},"followingByUser":{},"followersByUser":{},"mutualsByUser":{},"followingColumnsByUser":{},"followingQuestionsByUser":{},"followingFavlistsByUser":{},"followingTopicsByUser":{},"publicationsByUser":{},"columnsByUser":{},"allFavlistsByUser":{},"brands":null,"creationsByUser":{},"creationsSortByVotesByUser":{},"creationsFeed":{}},"env":{"ab":{"config":{"experiments":[{"expId":"launch-gw_mweb_rec-1","expPrefix":"gw_mweb_rec","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-qa_hdpimg-2","expPrefix":"qa_hdpimg","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-us_foltopic_user-10","expPrefix":"us_foltopic_user","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_bullet_second-2","expPrefix":"vd_bullet_second","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_zvideo_link-10","expPrefix":"vd_zvideo_link","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"vd_bullet_gui-4","expPrefix":"vd_bullet_gui","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"gw_mweb_launch-2","expPrefix":"gw_mweb_launch","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false}],"params":[{"id":"li_video_section","type":"String","value":"0","chainId":"_all_"},{"id":"li_ebok_chap","type":"String","value":"0","chainId":"_all_"},{"id":"qap_thanks","type":"String","value":"1","chainId":"_all_"},{"id":"se_hotsearch_num","type":"String","value":"0","chainId":"_all_"},{"id":"se_college","type":"String","value":"default","chainId":"_all_"},{"id":"se_zu_recommend","type":"String","value":"0","chainId":"_all_"},{"id":"se_webrs","type":"String","value":"1","chainId":"_all_"},{"id":"se_cate_l3","type":"String","value":"0","chainId":"_all_"},{"id":"se_lottery","type":"String","value":"0","chainId":"_all_"},{"id":"soc_zuichangfangwen","type":"String","value":"0","chainId":"_all_"},{"id":"se_colorfultab","type":"String","value":"1","chainId":"_all_"},{"id":"tp_qa_toast","type":"String","value":"1","chainId":"_all_"},{"id":"tsp_hotlist_ui","type":"String","value":"1","chainId":"_all_"},{"id":"se_pek_test2","type":"String","value":"1","chainId":"_all_"},{"id":"soc_notification","type":"String","value":"0","chainId":"_all_"},{"id":"tsp_vote","type":"String","value":"2","chainId":"_all_"},{"id":"li_qa_new_cover","type":"String","value":"1","chainId":"_all_"},{"id":"soc_bignew","type":"String","value":"1","chainId":"_all_"},{"id":"soc_stickypush","type":"String","value":"1","chainId":"_all_"},{"id":"web_creator_route","type":"String","value":"1"},{"id":"web_heifetz_grow_ad","type":"String","value":"1"},{"id":"gue_new_special_page","type":"String","value":"1"},{"id":"web_collect","type":"String","value":"0"},{"id":"se_whitelist","type":"String","value":"0","chainId":"_all_"},{"id":"web_answer_update","type":"String","value":"0"},{"id":"web_hdpimg","type":"String","value":"1"},{"id":"se_topiclabel","type":"String","value":"1","chainId":"_all_"},{"id":"se_ad_index","type":"String","value":"10","chainId":"_all_"},{"id":"soc_leave_recommend","type":"String","value":"2","chainId":"_all_"},{"id":"web_ad_banner","type":"String","value":"0"},{"id":"tp_qa_metacard","type":"String","value":"1","chainId":"_all_"},{"id":"tp_sft_v2","type":"String","value":"d","chainId":"_all_"},{"id":"tp_header_style","type":"String","value":"1","chainId":"_all_"},{"id":"se_search_feed","type":"String","value":"N","chainId":"_all_"},{"id":"se_wannasearch","type":"String","value":"0","chainId":"_all_"},{"id":"se_famous","type":"String","value":"1","chainId":"_all_"},{"id":"pf_creator_card","type":"String","value":"1","chainId":"_all_"},{"id":"soc_ri_merge","type":"String","value":"0","chainId":"_all_"},{"id":"pf_adjust","type":"String","value":"0","chainId":"_all_"},{"id":"ug_follow_topic_1","type":"String","value":"2","chainId":"_all_"},{"id":"tp_discover","type":"String","value":"0","chainId":"_all_"},{"id":"soc_authormore2","type":"String","value":"2","chainId":"_all_"},{"id":"ug_zero_follow","type":"String","value":"0","chainId":"_all_"},{"id":"soc_bigone","type":"String","value":"0","chainId":"_all_"},{"id":"soc_yxzl_zcfw","type":"String","value":"0","chainId":"_all_"},{"id":"web_upload","type":"String","value":"1"},{"id":"se_webmajorob","type":"String","value":"0","chainId":"_all_"},{"id":"se_amovietab","type":"String","value":"1","chainId":"_all_"},{"id":"se_agency","type":"String","value":" 0","chainId":"_all_"},{"id":"soc_userrec","type":"String","value":"0","chainId":"_all_"},{"id":"soc_update","type":"String","value":"1","chainId":"_all_"},{"id":"li_android_vip","type":"String","value":"0","chainId":"_all_"},{"id":"li_purchase_test","type":"String","value":"0","chainId":"_all_"},{"id":"li_salt_hot","type":"String","value":"1","chainId":"_all_"},{"id":"se_hotmore","type":"String","value":"2","chainId":"_all_"},{"id":"se_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"se_aa","type":"String","value":"0","chainId":"_all_"},{"id":"se_waterfall","type":"String","value":"0","chainId":"_all_"},{"id":"gue_video_replay","type":"String","value":"0"},{"id":"li_ebook_read","type":"String","value":"0","chainId":"_all_"},{"id":"li_ebook_gen_search","type":"String","value":"0","chainId":"_all_"},{"id":"li_assessment_show","type":"String","value":"1","chainId":"_all_"},{"id":"se_new_p","type":"String","value":"0","chainId":"_all_"},{"id":"se_relation_1","type":"String","value":"0","chainId":"_all_"},{"id":"sem_up_growth","type":"String","value":"in_app","chainId":"_all_"},{"id":"tp_club_header","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_qa","type":"String","value":"1","chainId":"_all_"},{"id":"web_mweb_launch","type":"String","value":"0"},{"id":"zr_km_answer","type":"String","value":"open_cvr","chainId":"_all_"},{"id":"zr_slotpaidexp","type":"String","value":"1","chainId":"_all_"},{"id":"se_new_topic","type":"String","value":"0","chainId":"_all_"},{"id":"se_cbert_index","type":"String","value":"0","chainId":"_all_"},{"id":"se_college_cm","type":"String","value":"0","chainId":"_all_"},{"id":"web_answerlist_ad","type":"String","value":"0"},{"id":"se_preset_tech","type":"String","value":"0","chainId":"_all_"},{"id":"top_quality","type":"String","value":"0","chainId":"_all_"},{"id":"zr_search_paid","type":"String","value":"0","chainId":"_all_"},{"id":"se_sug_term","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_qa_pic","type":"String","value":"1","chainId":"_all_"},{"id":"soc_authormore","type":"String","value":"2","chainId":"_all_"},{"id":"li_answer_card","type":"String","value":"0","chainId":"_all_"},{"id":"li_paid_answer_exp","type":"String","value":"0","chainId":"_all_"},{"id":"gue_self_censoring","type":"String","value":"1"},{"id":"se_timebox_up","type":"String","value":"0","chainId":"_all_"},{"id":"se_presearch_ab","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_pic_swiper","type":"String","value":"1","chainId":"_all_"},{"id":"li_se_across","type":"String","value":"1","chainId":"_all_"},{"id":"zr_ans_rec","type":"String","value":"gbrank","chainId":"_all_"},{"id":"se_billboardsearch","type":"String","value":"0","chainId":"_all_"},{"id":"se_adxtest","type":"String","value":"1","chainId":"_all_"},{"id":"li_answers_link","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_section","type":"String","value":"0","chainId":"_all_"},{"id":"se_ltr_video","type":"String","value":"0","chainId":"_all_"},{"id":"se_dnn_mt_v2","type":"String","value":"0","chainId":"_all_"},{"id":"top_new_feed","type":"String","value":"5","chainId":"_all_"},{"id":"tp_topic_rec","type":"String","value":"1","chainId":"_all_"},{"id":"soc_special","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iossort","type":"String","value":"0","chainId":"_all_"},{"id":"gue_zvideo_link","type":"String","value":"1"},{"id":"zr_article_new","type":"String","value":"close","chainId":"_all_"},{"id":"se_backsearch","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_3","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_pic","type":"String","value":"0.6","chainId":"_all_"},{"id":"tp_topic_tab_new","type":"String","value":"0-0-0","chainId":"_all_"},{"id":"gue_card_test","type":"String","value":"1"},{"id":"gue_thanks","type":"String","value":"0"},{"id":"qap_ques_invite","type":"String","value":"0","chainId":"_all_"},{"id":"web_answer_list_ad","type":"String","value":"1"},{"id":"se_entity_model","type":"String","value":"0","chainId":"_all_"},{"id":"tp_discover_copy","type":"String","value":"0","chainId":"_all_"},{"id":"web_n_web_msg","type":"String","value":"0"},{"id":"li_se_edu","type":"String","value":"1","chainId":"_all_"},{"id":"qap_article_like","type":"String","value":"1","chainId":"_all_"},{"id":"zr_art_rec","type":"String","value":"base","chainId":"_all_"},{"id":"se_preset_label","type":"String","value":"1","chainId":"_all_"},{"id":"se_new_merger","type":"String","value":"1","chainId":"_all_"},{"id":"pf_newguide_vertical","type":"String","value":"0","chainId":"_all_"},{"id":"ls_recommend_test","type":"String","value":"0","chainId":"_all_"},{"id":"web_sec672","type":"String","value":"0"},{"id":"zr_answer_rec_cp","type":"String","value":"open","chainId":"_all_"},{"id":"se_entity_model_14","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_1","type":"String","value":"0","chainId":"_all_"},{"id":"soc_wonderuser_recom","type":"String","value":"2","chainId":"_all_"},{"id":"ug_follow_answerer_0","type":"String","value":"0","chainId":"_all_"},{"id":"zr_update_merge_size","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_join","type":"String","value":"0","chainId":"_all_"},{"id":"tp_m_intro_re_topic","type":"String","value":"1","chainId":"_all_"},{"id":"soc_adreadline","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_head","type":"String","value":"0","chainId":"_all_"},{"id":"web_unfriendly_comm","type":"String","value":"0"},{"id":"se_col_boost","type":"String","value":"0","chainId":"_all_"},{"id":"se_article_icon","type":"String","value":"0","chainId":"_all_"},{"id":"se_content0","type":"String","value":"0","chainId":"_all_"},{"id":"se_site_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_subtext","type":"String","value":"0","chainId":"_all_"},{"id":"web_sem_ab","type":"String","value":"1"},{"id":"zr_search_sim","type":"String","value":"0","chainId":"_all_"},{"id":"se_sug_entrance","type":"String","value":"1","chainId":"_all_"},{"id":"se_cardrank_4","type":"String","value":"1","chainId":"_all_"},{"id":"ug_fw_answ_aut_1","type":"String","value":"0","chainId":"_all_"},{"id":"gue_bullet_guide","type":"String","value":"点我，做第一个上屏的人"},{"id":"li_se_heat","type":"String","value":"1","chainId":"_all_"},{"id":"qap_question_visitor","type":"String","value":" 0","chainId":"_all_"},{"id":"top_root","type":"String","value":"0","chainId":"_all_"},{"id":"ls_videoad","type":"String","value":"2","chainId":"_all_"},{"id":"zw_payc_qaedit","type":"String","value":"0","chainId":"_all_"},{"id":"se_click_club","type":"String","value":"1","chainId":"_all_"},{"id":"se_sug","type":"String","value":"1","chainId":"_all_"},{"id":"gue_video_autoplay","type":"String","value":"0"},{"id":"top_ydyq","type":"String","value":"X","chainId":"_all_"},{"id":"se_ffzx_jushen1","type":"String","value":"0","chainId":"_all_"},{"id":"se_highlight","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_discover","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iosintimacy","type":"String","value":"2","chainId":"_all_"},{"id":"web_question_invite","type":"String","value":"B"},{"id":"zr_rel_search","type":"String","value":"base","chainId":"_all_"},{"id":"se_likebutton","type":"String","value":"0","chainId":"_all_"},{"id":"se_use_zitem","type":"String","value":"0","chainId":"_all_"},{"id":"soc_brdcst3","type":"String","value":"0","chainId":"_all_"},{"id":"se_prf","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adsort","type":"String","value":"0","chainId":"_all_"},{"id":"ug_newtag","type":"String","value":"0","chainId":"_all_"},{"id":"gue_bullet_second","type":"String","value":"1"},{"id":"zr_km_feed_nlp","type":"String","value":"old","chainId":"_all_"},{"id":"zr_training_boost","type":"String","value":"false","chainId":"_all_"},{"id":"tp_sft","type":"String","value":"a","chainId":"_all_"},{"id":"soc_newfeed","type":"String","value":"2","chainId":"_all_"},{"id":"top_test_4_liguangyi","type":"String","value":"1","chainId":"_all_"},{"id":"ug_zero_follow_0","type":"String","value":"0","chainId":"_all_"},{"id":"li_yxzl_new_style_a","type":"String","value":"1","chainId":"_all_"},{"id":"se_related_index","type":"String","value":"3","chainId":"_all_"},{"id":"soc_zcfw_broadcast","type":"String","value":"0","chainId":"_all_"},{"id":"top_v_album","type":"String","value":"1","chainId":"_all_"},{"id":"li_sku_bottom_bar_re","type":"String","value":"0","chainId":"_all_"},{"id":"se_ios_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"se_cardrank_2","type":"String","value":"1","chainId":"_all_"},{"id":"se_mobileweb","type":"String","value":"1","chainId":"_all_"},{"id":"tp_topic_tab","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_style","type":"String","value":"0","chainId":"_all_"},{"id":"top_ebook","type":"String","value":"0","chainId":"_all_"},{"id":"pf_foltopic_usernum","type":"String","value":"50","chainId":"_all_"},{"id":"li_se_media_icon","type":"String","value":"1","chainId":"_all_"},{"id":"zr_training_first","type":"String","value":"false","chainId":"_all_"},{"id":"se_expired_ob","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_entry","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_android_feed","type":"String","value":"old","chainId":"_all_"},{"id":"soc_zcfw_shipinshiti","type":"String","value":"1","chainId":"_all_"},{"id":"se_rf_w","type":"String","value":"0","chainId":"_all_"},{"id":"se_searchwiki","type":"String","value":"0","chainId":"_all_"},{"id":"se_payconsult","type":"String","value":"0","chainId":"_all_"},{"id":"soc_adreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"pf_fuceng","type":"String","value":"1","chainId":"_all_"},{"id":"se_websearch","type":"String","value":"3","chainId":"_all_"},{"id":"tp_discovery_ab_1","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_tab_feed","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iosreadline","type":"String","value":"0","chainId":"_all_"},{"id":"pf_noti_entry_num","type":"String","value":"0","chainId":"_all_"},{"id":"web_mini_review","type":"String","value":"0"},{"id":"tp_score_1","type":"String","value":"a","chainId":"_all_"},{"id":"soc_adpinweight","type":"String","value":"0","chainId":"_all_"},{"id":"zr_expslotpaid","type":"String","value":"1","chainId":"_all_"},{"id":"qap_question_author","type":"String","value":"0","chainId":"_all_"},{"id":"se_aa_base","type":"String","value":"0","chainId":"_all_"},{"id":"se_auto_syn","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_tab","type":"String","value":"0","chainId":"_all_"},{"id":"soc_iosreadfilter","type":"String","value":"0","chainId":"_all_"},{"id":"top_hotcommerce","type":"String","value":"1","chainId":"_all_"},{"id":"gue_zhuantikapian","type":"String","value":"0"},{"id":"qap_payc_invite","type":"String","value":"0","chainId":"_all_"},{"id":"zr_video_rank","type":"String","value":"new_rank","chainId":"_all_"},{"id":"se_specialbutton","type":"String","value":"0","chainId":"_all_"},{"id":"gue_goods_card","type":"String","value":"0"},{"id":"se_relationship","type":"String","value":"1","chainId":"_all_"},{"id":"tp_meta_card","type":"String","value":"0","chainId":"_all_"},{"id":"li_answer_label","type":"String","value":"0","chainId":"_all_"},{"id":"zw_sameq_sorce","type":"String","value":"999","chainId":"_all_"},{"id":"zr_slot_training","type":"String","value":"1","chainId":"_all_"},{"id":"se_pek_test3","type":"String","value":"1","chainId":"_all_"},{"id":"se_featured","type":"String","value":"1","chainId":"_all_"},{"id":"tp_club_pk","type":"String","value":"1","chainId":"_all_"},{"id":"soc_zcfw_broadcast2","type":"String","value":"1","chainId":"_all_"},{"id":"top_universalebook","type":"String","value":"1","chainId":"_all_"},{"id":"web_mweb_rec_length","type":"String","value":"1"},{"id":"zr_rec_answer_cp","type":"String","value":"close","chainId":"_all_"},{"id":"se_club_post","type":"String","value":"5","chainId":"_all_"},{"id":"se_hotsearch_2","type":"String","value":"1","chainId":"_all_"},{"id":"se_multianswer","type":"String","value":"2","chainId":"_all_"},{"id":"soc_zcfw_badcase","type":"String","value":"0","chainId":"_all_"},{"id":"zr_video_rank_nn","type":"String","value":"new_rank","chainId":"_all_"},{"id":"se_webtimebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_hotsearch","type":"String","value":"0","chainId":"_all_"},{"id":"se_zu_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_time_threshold","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_feed","type":"String","value":"1","chainId":"_all_"},{"id":"web_column_auto_invite","type":"String","value":"0"},{"id":"se_movietab","type":"String","value":"1","chainId":"_all_"},{"id":"ug_follow_answerer","type":"String","value":"0","chainId":"_all_"},{"id":"ls_fmp4","type":"String","value":"0","chainId":"_all_"},{"id":"se_ctx_rerank","type":"String","value":"1","chainId":"_all_"},{"id":"li_hot_voted","type":"String","value":"0","chainId":"_all_"},{"id":"tsp_videobillboard","type":"String","value":"1","chainId":"_all_"},{"id":"soc_iospinweight","type":"String","value":"0","chainId":"_all_"},{"id":"soc_brdcst4","type":"String","value":"3","chainId":"_all_"},{"id":"li_svip_tab_search","type":"String","value":"0","chainId":"_all_"},{"id":"li_qa_btn_text","type":"String","value":"0","chainId":"_all_"},{"id":"zr_video_recall","type":"String","value":"current_recall","chainId":"_all_"},{"id":"se_pek_test","type":"String","value":"1","chainId":"_all_"},{"id":"se_hot_timebox","type":"String","value":"0","chainId":"_all_"},{"id":"tp_qa_metacard_top","type":"String","value":"top","chainId":"_all_"},{"id":"li_catalog_card","type":"String","value":"1","chainId":"_all_"},{"id":"zr_slot_cold_start","type":"String","value":"aver","chainId":"_all_"},{"id":"li_pay_banner_type","type":"String","value":"6","chainId":"_all_"},{"id":"soc_feed_intimacy","type":"String","value":"2","chainId":"_all_"},{"id":"li_vip_verti_search","type":"String","value":"0","chainId":"_all_"},{"id":"web_audit_01","type":"String","value":"case1"},{"id":"se_page_quality","type":"String","value":"0","chainId":"_all_"},{"id":"tp_club_android_join","type":"String","value":"1","chainId":"_all_"},{"id":"soc_cardheight","type":"String","value":"2","chainId":"_all_"},{"id":"ug_goodcomment_0","type":"String","value":"1","chainId":"_all_"},{"id":"li_svip_cardshow","type":"String","value":"1","chainId":"_all_"},{"id":"li_education_box","type":"String","value":"0","chainId":"_all_"},{"id":"zr_intervene","type":"String","value":"0","chainId":"_all_"},{"id":"zr_test_aa1","type":"String","value":"0","chainId":"_all_"},{"id":"se_topicfeed","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sticky_android","type":"String","value":"2","chainId":"_all_"},{"id":"web_ask","type":"String","value":"0"},{"id":"se_p_slideshow","type":"String","value":"0","chainId":"_all_"}],"chains":[{"chainId":"_all_"}]},"triggers":{}},"userAgent":{"Edge":false,"Wechat":false,"Weibo":false,"QQ":false,"MQQBrowser":false,"Qzone":false,"Mobile":false,"Android":false,"iOS":false,"isAppleDevice":false,"Zhihu":false,"ZhihuHybrid":false,"isBot":false,"Tablet":false,"UC":false,"Sogou":false,"Qihoo":false,"Baidu":false,"BaiduApp":false,"Safari":false,"GoogleBot":false,"AndroidDaily":false,"iOSDaily":false,"isWebView":false,"origin":"Mozilla\u002F5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\u002F537.36 (KHTML, like Gecko) Chrome\u002F80.0.3987.100 Safari\u002F537.36"},"appViewConfig":{},"ctx":{"path":"\u002Fp\u002F50322028","query":{},"href":"http:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F50322028","host":"zhuanlan.zhihu.com"},"trafficSource":"production","edition":{"baidu":false,"sogou":false,"baiduBeijing":false,"sogouBeijing":false,"sogouInput":false},"theme":"light","enableShortcut":true,"referer":"","conf":{},"ipInfo":{"cityName":"德州","countryName":"中国","regionName":"山东","countryCode":"CN"},"logged":false},"me":{"columnContributions":[]},"label":{"recognizerLists":{}},"ecommerce":{},"comments":{"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"parent":{}},"commentsV2":{"stickers":[],"commentWithPicPermission":{},"notificationsComments":{},"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"conversationMore":{},"parent":{}},"pushNotifications":{"default":{"isFetching":false,"isDrained":false,"ids":[]},"follow":{"isFetching":false,"isDrained":false,"ids":[]},"vote_thank":{"isFetching":false,"isDrained":false,"ids":[]},"currentTab":"default","notificationsCount":{"default":0,"follow":0,"vote_thank":0}},"messages":{"data":{},"currentTab":"common","messageCount":0},"register":{"registerValidateSucceeded":null,"registerValidateErrors":{},"registerConfirmError":null,"sendDigitsError":null,"registerConfirmSucceeded":null},"login":{"loginUnregisteredError":false,"loginBindWechatError":false,"loginConfirmError":null,"sendDigitsError":null,"needSMSIdentify":false,"validateDigitsError":false,"loginConfirmSucceeded":null,"qrcodeLoginToken":"","qrcodeLoginScanStatus":0,"qrcodeLoginError":null,"qrcodeLoginReturnNewToken":false},"active":{"sendDigitsError":null,"activeConfirmSucceeded":null,"activeConfirmError":null},"switches":{},"captcha":{"captchaNeeded":false,"captchaValidated":false,"captchaBase64String":null,"captchaValidationMessage":null,"loginCaptchaExpires":false},"sms":{"supportedCountries":[]},"chat":{"chats":{},"inbox":{"recents":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"strangers":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"friends":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"search":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"config":{"newCount":0,"strangerMessageSwitch":false,"strangerMessageUnread":false,"friendCount":0}},"global":{"isChatMqttExisted":false}},"emoticons":{"emoticonGroupList":[],"emoticonGroupDetail":{}},"creator":{"currentCreatorUrlToken":null,"homeData":{"recommendQuestions":[]},"tools":{"question":{"invitationCount":{"questionFolloweeCount":0,"questionTotalCount":0},"goodatTopics":[]},"customPromotion":{"itemLists":{}},"recommend":{"recommendTimes":{}}},"explore":{"academy":{"tabs":[],"article":{}}},"rights":[],"rightsStatus":{},"levelUpperLimit":10,"account":{"growthLevel":{}},"mcn":{},"applyStatus":{}},"recommendation":{"homeRecommendations":[]},"shareTexts":{},"articles":{"voters":{}},"previewPost":{},"favlists":{"relations":{}},"columns":{"voters":{}},"reward":{"answer":{},"article":{},"question":{}},"video":{"data":{},"shareVideoDetail":{},"last":{}},"topstory":{"recommend":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"follow":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followWonderful":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"sidebar":null,"announcement":{},"hotListCategories":[],"hotList":[],"guestFeeds":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followExtra":{"isNewUser":null,"isFetched":false,"followCount":0,"followers":[]}},"readStatus":{},"column":{},"requestColumn":{"categories":[],"error":null},"articleContribution":{"contributeRequests":[],"deleteContributeIdList":[],"handledContributeIdList":[],"recommendedColumns":[],"pinnedColumns":[],"sentContributeRequestsIdList":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"reinforcementlearning"]},"columnContribution":{"contributeRequests":[],"autoInviteEnabled":false,"recommendedContributors":[],"contributionInvitation":null},"draftHistory":{"history":{},"drafts":{}},"upload":{},"articleDraft":{"titleImage":"","titleImageSize":{},"isTitleImageFullScreen":false,"canTitleImageFullScreen":false,"title":"","titleImageUploading":false,"error":"","content":"","draftLoading":false,"updating":false,"globalLoading":false,"pendingVideo":{"resource":null,"error":null},"deleteFail":{"fail":false},"recommendTopics":[],"selectedColumn":0,"articleDisclaimers":[]},"articleDrafts":{"isDrained":false,"isLoading":false,"items":[]},"columnAutocomplete":{"users":[],"friends":[]},"columnCollection":{},"mcn":{"bindInfo":{},"memberCategoryList":[],"producerList":[],"categoryList":[]}},"fetchHost":"www.zhihu.com","subAppName":"column"}</script><script src="https://static.zhihu.com/heifetz/vendor.7b36fae46082fd30a0db.js"></script><script src="https://static.zhihu.com/heifetz/column.app.76e02b16e87eec249f44.js"></script></body><script src="https://hm.baidu.com/hm.js?98beee57fd2ef70ccdd5ca52b9740c49" async=""></script><script src="https://zz.bdstatic.com/linksubmit/push.js" async=""></script></html>